created virtual environment CPython3.7.7.final.0-64 in 1201ms
  creator CPython3Posix(dest=/localscratch/helenr6.6279052.0/env, clear=False, global=False)
  seeder FromAppData(download=False, pip=latest, setuptools=latest, wheel=latest, via=copy, app_data_dir=/home/helenr6/.local/share/virtualenv/seed-app-data/v1.0.1)
  activators BashActivator,CShellActivator,FishActivator,PowerShellActivator,PythonActivator,XonshActivator
Ignoring pip: markers 'python_version < "3"' don't match your environment
Looking in links: /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/gentoo/avx2, /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/gentoo/generic, /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/pip-21.2.3+computecanada-py3-none-any.whl
Installing collected packages: pip
  Attempting uninstall: pip
    Found existing installation: pip 20.0.2
    Uninstalling pip-20.0.2:
      Successfully uninstalled pip-20.0.2
Successfully installed pip-21.2.3+computecanada
Looking in links: /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/gentoo/avx2, /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/gentoo/generic, /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/gentoo/generic/torchvision-0.11.1+computecanada-cp37-cp37m-linux_x86_64.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/gentoo/avx2/torch-1.10.0+computecanada-cp37-cp37m-linux_x86_64.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/gentoo/generic/numpy-1.21.4+computecanada-cp37-cp37m-linux_x86_64.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/gentoo/avx2/Pillow_SIMD-7.0.0.post3+computecanada-cp37-cp37m-linux_x86_64.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/typing_extensions-4.2.0+computecanada-py3-none-any.whl
Installing collected packages: typing-extensions, torch, pillow-simd, numpy, torchvision
Successfully installed numpy-1.21.4+computecanada pillow-simd-7.0.0.post3+computecanada torch-1.10.0+computecanada torchvision-0.11.1+computecanada typing-extensions-4.2.0+computecanada
Looking in links: /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/gentoo/avx2, /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/gentoo/generic, /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic
Requirement already satisfied: torch in /localscratch/helenr6.6279052.0/env/lib/python3.7/site-packages (1.10.0+computecanada)
Requirement already satisfied: typing-extensions in /localscratch/helenr6.6279052.0/env/lib/python3.7/site-packages (from torch) (4.2.0+computecanada)
Looking in links: /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/gentoo/avx2, /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/gentoo/generic, /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/tensorboard-2.8.0+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/gentoo/generic/grpcio-1.38.1+computecanada-cp37-cp37m-linux_x86_64.whl
Requirement already satisfied: wheel>=0.26 in /localscratch/helenr6.6279052.0/env/lib/python3.7/site-packages (from tensorboard) (0.34.2)
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/tensorboard_data_server-0.6.1+computecanada-py3-none-linux_x86_64.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/absl_py-1.0.0+computecanada-py3-none-any.whl
Requirement already satisfied: setuptools>=41.0.0 in /localscratch/helenr6.6279052.0/env/lib/python3.7/site-packages (from tensorboard) (46.1.3)
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/Werkzeug-2.1.2+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/Markdown-3.3.6+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/google_auth_oauthlib-0.4.6+computecanada-py2.py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/tensorboard_plugin_wit-1.8.0+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/protobuf-3.19.4+computecanada-py2.py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/requests-2.27.1+computecanada-py2.py3-none-any.whl
Requirement already satisfied: numpy>=1.12.0 in /localscratch/helenr6.6279052.0/env/lib/python3.7/site-packages (from tensorboard) (1.21.4+computecanada)
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/google_auth-2.3.3+computecanada-py2.py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/six-1.16.0+computecanada-py2.py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/rsa-4.8+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/cachetools-4.2.4+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/pyasn1_modules-0.2.8+computecanada-py2.py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/requests_oauthlib-1.3.0+computecanada-py2.py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/importlib_metadata-4.11.3+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/zipp-3.8.0+computecanada-py3-none-any.whl
Requirement already satisfied: typing-extensions>=3.6.4 in /localscratch/helenr6.6279052.0/env/lib/python3.7/site-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard) (4.2.0+computecanada)
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/pyasn1-0.4.8+computecanada-py2.py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/urllib3-1.26.9+computecanada-py2.py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/idna-3.3+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/charset_normalizer-2.0.12+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/certifi-2021.10.8+computecanada-py2.py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/oauthlib-3.1.1+computecanada-py2.py3-none-any.whl
Installing collected packages: urllib3, pyasn1, idna, charset-normalizer, certifi, zipp, six, rsa, requests, pyasn1-modules, oauthlib, cachetools, requests-oauthlib, importlib-metadata, google-auth, werkzeug, tensorboard-plugin-wit, tensorboard-data-server, protobuf, markdown, grpcio, google-auth-oauthlib, absl-py, tensorboard
Successfully installed absl-py-1.0.0+computecanada cachetools-4.2.4+computecanada certifi-2021.10.8+computecanada charset-normalizer-2.0.12+computecanada google-auth-2.3.3+computecanada google-auth-oauthlib-0.4.6+computecanada grpcio-1.38.1+computecanada idna-3.3+computecanada importlib-metadata-4.11.3+computecanada markdown-3.3.6+computecanada oauthlib-3.1.1+computecanada protobuf-3.19.4+computecanada pyasn1-0.4.8+computecanada pyasn1-modules-0.2.8+computecanada requests-2.27.1+computecanada requests-oauthlib-1.3.0+computecanada rsa-4.8+computecanada six-1.16.0+computecanada tensorboard-2.8.0+computecanada tensorboard-data-server-0.6.1+computecanada tensorboard-plugin-wit-1.8.0+computecanada urllib3-1.26.9+computecanada werkzeug-2.1.2+computecanada zipp-3.8.0+computecanada
Looking in links: /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/gentoo/avx2, /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/gentoo/generic, /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/gentoo/avx2/h5py-3.4.0+computecanada-cp37-cp37m-linux_x86_64.whl
Requirement already satisfied: numpy>=1.14.5 in /localscratch/helenr6.6279052.0/env/lib/python3.7/site-packages (from h5py) (1.21.4+computecanada)
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/cached_property-1.5.2+computecanada-py2.py3-none-any.whl
Installing collected packages: cached-property, h5py
Successfully installed cached-property-1.5.2+computecanada h5py-3.4.0+computecanada
Looking in links: /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/gentoo/avx2, /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/gentoo/generic, /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/gentoo/avx2/matplotlib-3.4.2+computecanada-cp37-cp37m-linux_x86_64.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/gentoo/avx2/Pillow-8.4.0+computecanada-cp37-cp37m-linux_x86_64.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/pyparsing-3.0.8+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/cycler-0.11.0+computecanada-py3-none-any.whl
Requirement already satisfied: numpy>=1.16 in /localscratch/helenr6.6279052.0/env/lib/python3.7/site-packages (from matplotlib) (1.21.4+computecanada)
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/gentoo/avx2/kiwisolver-1.3.1+computecanada-cp37-cp37m-linux_x86_64.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/python_dateutil-2.8.2+computecanada-py2.py3-none-any.whl
Requirement already satisfied: six>=1.5 in /localscratch/helenr6.6279052.0/env/lib/python3.7/site-packages (from python-dateutil>=2.7->matplotlib) (1.16.0+computecanada)
Installing collected packages: python-dateutil, pyparsing, pillow, kiwisolver, cycler, matplotlib
Successfully installed cycler-0.11.0+computecanada kiwisolver-1.3.1+computecanada matplotlib-3.4.2+computecanada pillow-8.4.0+computecanada pyparsing-3.0.8+computecanada python-dateutil-2.8.2+computecanada
Looking in links: /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/gentoo/avx2, /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/gentoo/generic, /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/sklearn-0.0+computecanada-py2.py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/gentoo/generic/scikit_learn-1.0.1+computecanada-cp37-cp37m-linux_x86_64.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/joblib-1.1.0+computecanada-py2.py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/gentoo/generic/scipy-1.7.3+computecanada-cp37-cp37m-linux_x86_64.whl
Requirement already satisfied: numpy>=1.14.6 in /localscratch/helenr6.6279052.0/env/lib/python3.7/site-packages (from scikit-learn->sklearn) (1.21.4+computecanada)
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/threadpoolctl-3.0.0+computecanada-py3-none-any.whl
Installing collected packages: threadpoolctl, scipy, joblib, scikit-learn, sklearn
Successfully installed joblib-1.1.0+computecanada scikit-learn-1.0.1+computecanada scipy-1.7.3+computecanada sklearn-0.0+computecanada threadpoolctl-3.0.0+computecanada
Looking in links: /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/gentoo/avx2, /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/gentoo/generic, /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/gentoo/avx2/pandas-1.3.5+computecanada-cp37-cp37m-linux_x86_64.whl
Requirement already satisfied: numpy>=1.17.3 in /localscratch/helenr6.6279052.0/env/lib/python3.7/site-packages (from pandas) (1.21.4+computecanada)
Requirement already satisfied: python-dateutil>=2.7.3 in /localscratch/helenr6.6279052.0/env/lib/python3.7/site-packages (from pandas) (2.8.2+computecanada)
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/pytz-2022.1+computecanada-py3-none-any.whl
Requirement already satisfied: six>=1.5 in /localscratch/helenr6.6279052.0/env/lib/python3.7/site-packages (from python-dateutil>=2.7.3->pandas) (1.16.0+computecanada)
Installing collected packages: pytz, pandas
Successfully installed pandas-1.3.5+computecanada pytz-2022.1+computecanada
Looking in links: /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/gentoo/avx2, /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/gentoo/generic, /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic
Processing /localscratch/helenr6.6279052.0/model_setup
  DEPRECATION: A future pip version will change local packages to be built in-place without first copying to a temporary directory. We recommend you use --use-feature=in-tree-build to test your packages with this new behavior before it becomes the default.
   pip 21.3 will remove support for this functionality. You can find discussion regarding this at https://github.com/pypa/pip/issues/7555.
Building wheels for collected packages: load-model
  Building wheel for load-model (setup.py): started
  Building wheel for load-model (setup.py): finished with status 'done'
  Created wheel for load-model: filename=load_model-0.1.0-py3-none-any.whl size=28532 sha256=b7697e017b07da8df41126c90cb87e6dc36109d439209ffc304796373fd9d0a4
  Stored in directory: /tmp/pip-ephem-wheel-cache-t330pgkp/wheels/f9/b7/ff/c117194d33cd42a6c5eb5c058f1c85730234303d95ada1f533
Successfully built load-model
Installing collected packages: load-model
Successfully installed load-model-0.1.0
Looking in links: /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/gentoo/avx2, /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/gentoo/generic, /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic
Processing /localscratch/helenr6.6279052.0/advertorch
  DEPRECATION: A future pip version will change local packages to be built in-place without first copying to a temporary directory. We recommend you use --use-feature=in-tree-build to test your packages with this new behavior before it becomes the default.
   pip 21.3 will remove support for this functionality. You can find discussion regarding this at https://github.com/pypa/pip/issues/7555.
Building wheels for collected packages: advertorch
  Building wheel for advertorch (setup.py): started
  Building wheel for advertorch (setup.py): finished with status 'done'
  Created wheel for advertorch: filename=advertorch-0.2.4-py3-none-any.whl size=5694836 sha256=cac98e7f511b296a3bff40911a7ee40ba977484352b2605b107b5c3e6bf9e270
  Stored in directory: /tmp/pip-ephem-wheel-cache-flifg7az/wheels/96/af/c4/6d35d1903d494981b296fb93912f8ebfbfc691231407756703
Successfully built advertorch
Installing collected packages: advertorch
Successfully installed advertorch-0.2.4
/var/spool/slurmd/job6279052/slurm_script: line 33: s_ohp_session1: command not found
=> using pre-trained model 'st_resnet'
s/ohp/session_1
torch.Size([640, 3, 224, 224])
(640, 22)
(64, 1024, 14, 14)
(128, 1024, 14, 14)
(192, 1024, 14, 14)
(256, 1024, 14, 14)
(320, 1024, 14, 14)
(384, 1024, 14, 14)
(448, 1024, 14, 14)
(512, 1024, 14, 14)
(576, 1024, 14, 14)
attach reg
0
TRAINING
/home/helenr6/Adv_mapper/train_split.py:125: UserWarning: You have chosen to seed training. This will turn on the CUDNN deterministic setting, which can slow down your training considerably! You may see unexpected behavior when restarting from checkpoints.
  warnings.warn('You have chosen to seed training. '
/localscratch/helenr6.6279052.0/env/lib/python3.7/site-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  cpuset_checked))
Epoch: [0][0/1]	Time  5.470 ( 5.470)	Data  1.686 ( 1.686)	Loss 1.8117e+00 (1.8117e+00)	Acc@1   0.01 (  0.01)	Acc@5   0.00 (  0.00)
[0.011128212232320158]
Test: [0/1]	Time  0.451 ( 0.451)	Loss 1.3376e+00 (1.3376e+00)	Acc@1  -0.13 ( -0.13)	Acc@5   0.00 (  0.00)
 * Acc@1 -0.130 Acc@5 0.000
Test: [0/1]	Time  0.583 ( 0.583)	Loss 1.2849e+00 (1.2849e+00)	Acc@1  -0.02 ( -0.02)	Acc@5   0.00 (  0.00)
 * Acc@1 -0.017 Acc@5 0.000
1
TRAINING
Epoch: [1][0/1]	Time  0.934 ( 0.934)	Data  0.238 ( 0.238)	Loss 1.7085e+00 (1.7085e+00)	Acc@1   0.02 (  0.02)	Acc@5   0.00 (  0.00)
[0.015499422618678751]
Test: [0/1]	Time  0.257 ( 0.257)	Loss 1.3419e+00 (1.3419e+00)	Acc@1  -0.13 ( -0.13)	Acc@5   0.00 (  0.00)
 * Acc@1 -0.127 Acc@5 0.000
Test: [0/1]	Time  0.322 ( 0.322)	Loss 1.1827e+00 (1.1827e+00)	Acc@1  -0.01 ( -0.01)	Acc@5   0.00 (  0.00)
 * Acc@1 -0.014 Acc@5 0.000
2
TRAINING
Epoch: [2][0/1]	Time  0.930 ( 0.930)	Data  0.251 ( 0.251)	Loss 1.5563e+00 (1.5563e+00)	Acc@1   0.02 (  0.02)	Acc@5   0.00 (  0.00)
[0.023758644055028987]
Test: [0/1]	Time  0.262 ( 0.262)	Loss 1.3499e+00 (1.3499e+00)	Acc@1  -0.11 ( -0.11)	Acc@5   0.00 (  0.00)
 * Acc@1 -0.109 Acc@5 0.000
Test: [0/1]	Time  0.329 ( 0.329)	Loss 1.0906e+00 (1.0906e+00)	Acc@1  -0.01 ( -0.01)	Acc@5   0.00 (  0.00)
 * Acc@1 -0.011 Acc@5 0.000
3
TRAINING
Epoch: [3][0/1]	Time  0.935 ( 0.935)	Data  0.256 ( 0.256)	Loss 1.4156e+00 (1.4156e+00)	Acc@1   0.04 (  0.04)	Acc@5   0.00 (  0.00)
[0.037156174829268626]
Test: [0/1]	Time  0.261 ( 0.261)	Loss 1.3603e+00 (1.3603e+00)	Acc@1  -0.07 ( -0.07)	Acc@5   0.00 (  0.00)
 * Acc@1 -0.072 Acc@5 0.000
Test: [0/1]	Time  0.329 ( 0.329)	Loss 1.0376e+00 (1.0376e+00)	Acc@1  -0.01 ( -0.01)	Acc@5   0.00 (  0.00)
 * Acc@1 -0.006 Acc@5 0.000
4
TRAINING
Epoch: [4][0/1]	Time  0.931 ( 0.931)	Data  0.253 ( 0.253)	Loss 1.3199e+00 (1.3199e+00)	Acc@1   0.05 (  0.05)	Acc@5   0.00 (  0.00)
[0.04977925211131006]
Test: [0/1]	Time  0.258 ( 0.258)	Loss 1.3684e+00 (1.3684e+00)	Acc@1  -0.04 ( -0.04)	Acc@5   0.00 (  0.00)
 * Acc@1 -0.042 Acc@5 0.000
Test: [0/1]	Time  0.323 ( 0.323)	Loss 1.0206e+00 (1.0206e+00)	Acc@1  -0.00 ( -0.00)	Acc@5   0.00 (  0.00)
 * Acc@1 -0.000 Acc@5 0.000
5
TRAINING
Epoch: [5][0/1]	Time  0.938 ( 0.938)	Data  0.267 ( 0.267)	Loss 1.2638e+00 (1.2638e+00)	Acc@1   0.07 (  0.07)	Acc@5   0.00 (  0.00)
[0.06641662572584452]
Test: [0/1]	Time  0.262 ( 0.262)	Loss 1.3677e+00 (1.3677e+00)	Acc@1  -0.04 ( -0.04)	Acc@5   0.00 (  0.00)
 * Acc@1 -0.040 Acc@5 0.000
Test: [0/1]	Time  0.320 ( 0.320)	Loss 1.0131e+00 (1.0131e+00)	Acc@1   0.01 (  0.01)	Acc@5   0.00 (  0.00)
 * Acc@1 0.007 Acc@5 0.000
6
TRAINING
Epoch: [6][0/1]	Time  0.943 ( 0.943)	Data  0.246 ( 0.246)	Loss 1.2165e+00 (1.2165e+00)	Acc@1   0.08 (  0.08)	Acc@5   0.00 (  0.00)
[0.08352054305213825]
Test: [0/1]	Time  0.261 ( 0.261)	Loss 1.3531e+00 (1.3531e+00)	Acc@1  -0.04 ( -0.04)	Acc@5   0.00 (  0.00)
 * Acc@1 -0.039 Acc@5 0.000
Test: [0/1]	Time  0.324 ( 0.324)	Loss 9.8599e-01 (9.8599e-01)	Acc@1   0.02 (  0.02)	Acc@5   0.00 (  0.00)
 * Acc@1 0.019 Acc@5 0.000
7
TRAINING
Epoch: [7][0/1]	Time  0.951 ( 0.951)	Data  0.260 ( 0.260)	Loss 1.1460e+00 (1.1460e+00)	Acc@1   0.10 (  0.10)	Acc@5   0.00 (  0.00)
[0.10143059753567799]
Test: [0/1]	Time  0.268 ( 0.268)	Loss 1.3241e+00 (1.3241e+00)	Acc@1  -0.02 ( -0.02)	Acc@5   0.00 (  0.00)
 * Acc@1 -0.024 Acc@5 0.000
Test: [0/1]	Time  0.327 ( 0.327)	Loss 9.2653e-01 (9.2653e-01)	Acc@1   0.03 (  0.03)	Acc@5   0.00 (  0.00)
 * Acc@1 0.034 Acc@5 0.000
8
TRAINING
Epoch: [8][0/1]	Time  0.948 ( 0.948)	Data  0.254 ( 0.254)	Loss 1.0401e+00 (1.0401e+00)	Acc@1   0.12 (  0.12)	Acc@5   0.00 (  0.00)
[0.1208023625065304]
Test: [0/1]	Time  0.262 ( 0.262)	Loss 1.2846e+00 (1.2846e+00)	Acc@1  -0.01 ( -0.01)	Acc@5   0.00 (  0.00)
 * Acc@1 -0.008 Acc@5 0.000
Test: [0/1]	Time  0.322 ( 0.322)	Loss 8.4370e-01 (8.4370e-01)	Acc@1   0.05 (  0.05)	Acc@5   0.00 (  0.00)
 * Acc@1 0.046 Acc@5 0.000
9
TRAINING
Epoch: [9][0/1]	Time  0.957 ( 0.957)	Data  0.247 ( 0.247)	Loss 9.1034e-01 (9.1034e-01)	Acc@1   0.14 (  0.14)	Acc@5   0.00 (  0.00)
[0.14413327045057472]
Test: [0/1]	Time  0.304 ( 0.304)	Loss 1.2412e+00 (1.2412e+00)	Acc@1   0.01 (  0.01)	Acc@5   0.00 (  0.00)
 * Acc@1 0.007 Acc@5 0.000
Test: [0/1]	Time  0.320 ( 0.320)	Loss 7.5981e-01 (7.5981e-01)	Acc@1   0.06 (  0.06)	Acc@5   0.00 (  0.00)
 * Acc@1 0.059 Acc@5 0.000
10
TRAINING
Epoch: [10][0/1]	Time  0.950 ( 0.950)	Data  0.240 ( 0.240)	Loss 7.8246e-01 (7.8246e-01)	Acc@1   0.17 (  0.17)	Acc@5   0.00 (  0.00)
[0.17242652066811137]
Test: [0/1]	Time  0.255 ( 0.255)	Loss 1.2002e+00 (1.2002e+00)	Acc@1   0.06 (  0.06)	Acc@5   0.00 (  0.00)
 * Acc@1 0.056 Acc@5 0.000
Test: [0/1]	Time  0.318 ( 0.318)	Loss 6.9522e-01 (6.9522e-01)	Acc@1   0.07 (  0.07)	Acc@5   0.00 (  0.00)
 * Acc@1 0.073 Acc@5 0.000
11
TRAINING
Epoch: [11][0/1]	Time  0.953 ( 0.953)	Data  0.250 ( 0.250)	Loss 6.7898e-01 (6.7898e-01)	Acc@1   0.19 (  0.19)	Acc@5   0.00 (  0.00)
[0.1946746067174988]
Test: [0/1]	Time  0.258 ( 0.258)	Loss 1.1657e+00 (1.1657e+00)	Acc@1   0.10 (  0.10)	Acc@5   0.00 (  0.00)
 * Acc@1 0.098 Acc@5 0.000
Test: [0/1]	Time  0.320 ( 0.320)	Loss 6.5654e-01 (6.5654e-01)	Acc@1   0.09 (  0.09)	Acc@5   0.00 (  0.00)
 * Acc@1 0.088 Acc@5 0.000
12
TRAINING
Epoch: [12][0/1]	Time  1.026 ( 1.026)	Data  0.312 ( 0.312)	Loss 6.0740e-01 (6.0740e-01)	Acc@1   0.23 (  0.23)	Acc@5   0.00 (  0.00)
[0.22868717854421705]
Test: [0/1]	Time  0.263 ( 0.263)	Loss 1.1384e+00 (1.1384e+00)	Acc@1   0.14 (  0.14)	Acc@5   0.00 (  0.00)
 * Acc@1 0.143 Acc@5 0.000
Test: [0/1]	Time  0.325 ( 0.325)	Loss 6.3491e-01 (6.3491e-01)	Acc@1   0.10 (  0.10)	Acc@5   0.00 (  0.00)
 * Acc@1 0.101 Acc@5 0.000
13
TRAINING
Epoch: [13][0/1]	Time  1.003 ( 1.003)	Data  0.299 ( 0.299)	Loss 5.5878e-01 (5.5878e-01)	Acc@1   0.26 (  0.26)	Acc@5   0.00 (  0.00)
[0.25698757542126704]
Test: [0/1]	Time  0.259 ( 0.259)	Loss 1.1167e+00 (1.1167e+00)	Acc@1   0.20 (  0.20)	Acc@5   0.00 (  0.00)
 * Acc@1 0.202 Acc@5 0.000
Test: [0/1]	Time  0.320 ( 0.320)	Loss 6.1363e-01 (6.1363e-01)	Acc@1   0.12 (  0.12)	Acc@5   0.00 (  0.00)
 * Acc@1 0.121 Acc@5 0.000
14
TRAINING
Epoch: [14][0/1]	Time  1.005 ( 1.005)	Data  0.294 ( 0.294)	Loss 5.1606e-01 (5.1606e-01)	Acc@1   0.29 (  0.29)	Acc@5   0.00 (  0.00)
[0.2856692151239282]
Test: [0/1]	Time  0.259 ( 0.259)	Loss 1.0987e+00 (1.0987e+00)	Acc@1   0.26 (  0.26)	Acc@5   0.00 (  0.00)
 * Acc@1 0.261 Acc@5 0.000
Test: [0/1]	Time  0.320 ( 0.320)	Loss 5.7911e-01 (5.7911e-01)	Acc@1   0.13 (  0.13)	Acc@5   0.00 (  0.00)
 * Acc@1 0.135 Acc@5 0.000
15
TRAINING
Epoch: [15][0/1]	Time  0.930 ( 0.930)	Data  0.246 ( 0.246)	Loss 4.6537e-01 (4.6537e-01)	Acc@1   0.33 (  0.33)	Acc@5   0.00 (  0.00)
[0.3260234792353945]
Test: [0/1]	Time  0.263 ( 0.263)	Loss 1.0831e+00 (1.0831e+00)	Acc@1   0.28 (  0.28)	Acc@5   0.00 (  0.00)
 * Acc@1 0.282 Acc@5 0.000
Test: [0/1]	Time  0.320 ( 0.320)	Loss 5.2831e-01 (5.2831e-01)	Acc@1   0.15 (  0.15)	Acc@5   0.00 (  0.00)
 * Acc@1 0.149 Acc@5 0.000
16
TRAINING
Epoch: [16][0/1]	Time  0.957 ( 0.957)	Data  0.250 ( 0.250)	Loss 4.0335e-01 (4.0335e-01)	Acc@1   0.37 (  0.37)	Acc@5   0.00 (  0.00)
[0.3668855271783554]
Test: [0/1]	Time  0.281 ( 0.281)	Loss 1.0697e+00 (1.0697e+00)	Acc@1   0.29 (  0.29)	Acc@5   0.00 (  0.00)
 * Acc@1 0.286 Acc@5 0.000
Test: [0/1]	Time  0.328 ( 0.328)	Loss 4.6882e-01 (4.6882e-01)	Acc@1   0.17 (  0.17)	Acc@5   0.00 (  0.00)
 * Acc@1 0.171 Acc@5 0.000
17
TRAINING
Epoch: [17][0/1]	Time  0.939 ( 0.939)	Data  0.246 ( 0.246)	Loss 3.3704e-01 (3.3704e-01)	Acc@1   0.41 (  0.41)	Acc@5   0.00 (  0.00)
[0.41051692796873945]
Test: [0/1]	Time  0.271 ( 0.271)	Loss 1.0585e+00 (1.0585e+00)	Acc@1   0.29 (  0.29)	Acc@5   0.00 (  0.00)
 * Acc@1 0.290 Acc@5 0.000
Test: [0/1]	Time  0.330 ( 0.330)	Loss 4.1288e-01 (4.1288e-01)	Acc@1   0.20 (  0.20)	Acc@5   0.00 (  0.00)
 * Acc@1 0.200 Acc@5 0.000
18
TRAINING
Epoch: [18][0/1]	Time  0.935 ( 0.935)	Data  0.244 ( 0.244)	Loss 2.7783e-01 (2.7783e-01)	Acc@1   0.46 (  0.46)	Acc@5   0.00 (  0.00)
[0.4564833967802773]
Test: [0/1]	Time  0.263 ( 0.263)	Loss 1.0495e+00 (1.0495e+00)	Acc@1   0.29 (  0.29)	Acc@5   0.00 (  0.00)
 * Acc@1 0.291 Acc@5 0.000
Test: [0/1]	Time  0.328 ( 0.328)	Loss 3.6984e-01 (3.6984e-01)	Acc@1   0.23 (  0.23)	Acc@5   0.00 (  0.00)
 * Acc@1 0.226 Acc@5 0.000
19
TRAINING
Epoch: [19][0/1]	Time  0.957 ( 0.957)	Data  0.244 ( 0.244)	Loss 2.3401e-01 (2.3401e-01)	Acc@1   0.50 (  0.50)	Acc@5   0.00 (  0.00)
[0.5032268487691148]
Test: [0/1]	Time  0.259 ( 0.259)	Loss 1.0419e+00 (1.0419e+00)	Acc@1   0.32 (  0.32)	Acc@5   0.00 (  0.00)
 * Acc@1 0.319 Acc@5 0.000
Test: [0/1]	Time  0.322 ( 0.322)	Loss 3.4156e-01 (3.4156e-01)	Acc@1   0.25 (  0.25)	Acc@5   0.00 (  0.00)
 * Acc@1 0.249 Acc@5 0.000
20
TRAINING
Epoch: [20][0/1]	Time  0.948 ( 0.948)	Data  0.242 ( 0.242)	Loss 2.0653e-01 (2.0653e-01)	Acc@1   0.55 (  0.55)	Acc@5   0.00 (  0.00)
[0.5464784888383476]
Test: [0/1]	Time  0.276 ( 0.276)	Loss 1.0343e+00 (1.0343e+00)	Acc@1   0.35 (  0.35)	Acc@5   0.00 (  0.00)
 * Acc@1 0.352 Acc@5 0.000
Test: [0/1]	Time  0.329 ( 0.329)	Loss 3.2307e-01 (3.2307e-01)	Acc@1   0.28 (  0.28)	Acc@5   0.00 (  0.00)
 * Acc@1 0.280 Acc@5 0.000
21
TRAINING
Epoch: [21][0/1]	Time  0.962 ( 0.962)	Data  0.249 ( 0.249)	Loss 1.8972e-01 (1.8972e-01)	Acc@1   0.59 (  0.59)	Acc@5   0.00 (  0.00)
[0.5896493471845239]
Test: [0/1]	Time  0.262 ( 0.262)	Loss 1.0256e+00 (1.0256e+00)	Acc@1   0.40 (  0.40)	Acc@5   0.00 (  0.00)
 * Acc@1 0.398 Acc@5 0.000
Test: [0/1]	Time  0.325 ( 0.325)	Loss 3.0675e-01 (3.0675e-01)	Acc@1   0.31 (  0.31)	Acc@5   0.00 (  0.00)
 * Acc@1 0.310 Acc@5 0.000
22
TRAINING
Epoch: [22][0/1]	Time  0.951 ( 0.951)	Data  0.253 ( 0.253)	Loss 1.7567e-01 (1.7567e-01)	Acc@1   0.63 (  0.63)	Acc@5   0.00 (  0.00)
[0.6331643693657735]
Test: [0/1]	Time  0.258 ( 0.258)	Loss 1.0150e+00 (1.0150e+00)	Acc@1   0.44 (  0.44)	Acc@5   0.00 (  0.00)
 * Acc@1 0.440 Acc@5 0.000
Test: [0/1]	Time  0.349 ( 0.349)	Loss 2.8729e-01 (2.8729e-01)	Acc@1   0.34 (  0.34)	Acc@5   0.00 (  0.00)
 * Acc@1 0.336 Acc@5 0.000
23
TRAINING
Epoch: [23][0/1]	Time  0.933 ( 0.933)	Data  0.235 ( 0.235)	Loss 1.5896e-01 (1.5896e-01)	Acc@1   0.68 (  0.68)	Acc@5   0.00 (  0.00)
[0.6751502949461547]
Test: [0/1]	Time  0.256 ( 0.256)	Loss 1.0032e+00 (1.0032e+00)	Acc@1   0.48 (  0.48)	Acc@5   0.00 (  0.00)
 * Acc@1 0.476 Acc@5 0.000
Test: [0/1]	Time  0.317 ( 0.317)	Loss 2.6417e-01 (2.6417e-01)	Acc@1   0.36 (  0.36)	Acc@5   0.00 (  0.00)
 * Acc@1 0.359 Acc@5 0.000
24
TRAINING
Epoch: [24][0/1]	Time  0.928 ( 0.928)	Data  0.236 ( 0.236)	Loss 1.3909e-01 (1.3909e-01)	Acc@1   0.72 (  0.72)	Acc@5   0.00 (  0.00)
[0.7165424705677934]
Test: [0/1]	Time  0.261 ( 0.261)	Loss 9.9113e-01 (9.9113e-01)	Acc@1   0.51 (  0.51)	Acc@5   0.00 (  0.00)
 * Acc@1 0.507 Acc@5 0.000
Test: [0/1]	Time  0.320 ( 0.320)	Loss 2.4083e-01 (2.4083e-01)	Acc@1   0.38 (  0.38)	Acc@5   0.00 (  0.00)
 * Acc@1 0.385 Acc@5 0.000
25
TRAINING
Epoch: [25][0/1]	Time  0.950 ( 0.950)	Data  0.240 ( 0.240)	Loss 1.1950e-01 (1.1950e-01)	Acc@1   0.75 (  0.75)	Acc@5   0.00 (  0.00)
[0.7522846336854379]
Test: [0/1]	Time  0.257 ( 0.257)	Loss 9.7995e-01 (9.7995e-01)	Acc@1   0.53 (  0.53)	Acc@5   0.00 (  0.00)
 * Acc@1 0.531 Acc@5 0.000
Test: [0/1]	Time  0.317 ( 0.317)	Loss 2.2170e-01 (2.2170e-01)	Acc@1   0.41 (  0.41)	Acc@5   0.00 (  0.00)
 * Acc@1 0.407 Acc@5 0.000
26
TRAINING
Epoch: [26][0/1]	Time  0.948 ( 0.948)	Data  0.249 ( 0.249)	Loss 1.0455e-01 (1.0455e-01)	Acc@1   0.78 (  0.78)	Acc@5   0.00 (  0.00)
[0.777786627934107]
Test: [0/1]	Time  0.261 ( 0.261)	Loss 9.7049e-01 (9.7049e-01)	Acc@1   0.55 (  0.55)	Acc@5   0.00 (  0.00)
 * Acc@1 0.551 Acc@5 0.000
Test: [0/1]	Time  0.325 ( 0.325)	Loss 2.0915e-01 (2.0915e-01)	Acc@1   0.43 (  0.43)	Acc@5   0.00 (  0.00)
 * Acc@1 0.429 Acc@5 0.000
27
TRAINING
Epoch: [27][0/1]	Time  0.952 ( 0.952)	Data  0.240 ( 0.240)	Loss 9.6553e-02 (9.6553e-02)	Acc@1   0.80 (  0.80)	Acc@5   0.00 (  0.00)
[0.7995103902328768]
Test: [0/1]	Time  0.259 ( 0.259)	Loss 9.6294e-01 (9.6294e-01)	Acc@1   0.57 (  0.57)	Acc@5   0.00 (  0.00)
 * Acc@1 0.567 Acc@5 0.000
Test: [0/1]	Time  0.321 ( 0.321)	Loss 2.0228e-01 (2.0228e-01)	Acc@1   0.45 (  0.45)	Acc@5   0.00 (  0.00)
 * Acc@1 0.453 Acc@5 0.000
28
TRAINING
Epoch: [28][0/1]	Time  0.958 ( 0.958)	Data  0.245 ( 0.245)	Loss 9.4520e-02 (9.4520e-02)	Acc@1   0.82 (  0.82)	Acc@5   0.00 (  0.00)
[0.8222935157745923]
Test: [0/1]	Time  0.274 ( 0.274)	Loss 9.5703e-01 (9.5703e-01)	Acc@1   0.58 (  0.58)	Acc@5   0.00 (  0.00)
 * Acc@1 0.583 Acc@5 0.000
Test: [0/1]	Time  0.326 ( 0.326)	Loss 1.9786e-01 (1.9786e-01)	Acc@1   0.48 (  0.48)	Acc@5   0.00 (  0.00)
 * Acc@1 0.477 Acc@5 0.000
29
TRAINING
Epoch: [29][0/1]	Time  0.931 ( 0.931)	Data  0.245 ( 0.245)	Loss 9.5129e-02 (9.5129e-02)	Acc@1   0.84 (  0.84)	Acc@5   0.00 (  0.00)
[0.8407710940479665]
Test: [0/1]	Time  0.259 ( 0.259)	Loss 9.5229e-01 (9.5229e-01)	Acc@1   0.60 (  0.60)	Acc@5   0.00 (  0.00)
 * Acc@1 0.600 Acc@5 0.000
Test: [0/1]	Time  0.323 ( 0.323)	Loss 1.9247e-01 (1.9247e-01)	Acc@1   0.50 (  0.50)	Acc@5   0.00 (  0.00)
 * Acc@1 0.502 Acc@5 0.000
30
TRAINING
Epoch: [30][0/1]	Time  0.932 ( 0.932)	Data  0.238 ( 0.238)	Loss 9.4872e-02 (9.4872e-02)	Acc@1   0.85 (  0.85)	Acc@5   0.00 (  0.00)
[0.854964373751255]
Test: [0/1]	Time  0.254 ( 0.254)	Loss 9.4835e-01 (9.4835e-01)	Acc@1   0.62 (  0.62)	Acc@5   0.00 (  0.00)
 * Acc@1 0.617 Acc@5 0.000
Test: [0/1]	Time  0.318 ( 0.318)	Loss 1.8444e-01 (1.8444e-01)	Acc@1   0.52 (  0.52)	Acc@5   0.00 (  0.00)
 * Acc@1 0.524 Acc@5 0.000
31
TRAINING
Epoch: [31][0/1]	Time  0.935 ( 0.935)	Data  0.241 ( 0.241)	Loss 9.1952e-02 (9.1952e-02)	Acc@1   0.87 (  0.87)	Acc@5   0.00 (  0.00)
[0.8653826703781016]
Test: [0/1]	Time  0.254 ( 0.254)	Loss 9.4505e-01 (9.4505e-01)	Acc@1   0.63 (  0.63)	Acc@5   0.00 (  0.00)
 * Acc@1 0.635 Acc@5 0.000
Test: [0/1]	Time  0.329 ( 0.329)	Loss 1.7440e-01 (1.7440e-01)	Acc@1   0.55 (  0.55)	Acc@5   0.00 (  0.00)
 * Acc@1 0.545 Acc@5 0.000
32
TRAINING
Epoch: [32][0/1]	Time  0.955 ( 0.955)	Data  0.251 ( 0.251)	Loss 8.6875e-02 (8.6875e-02)	Acc@1   0.88 (  0.88)	Acc@5   0.00 (  0.00)
[0.8755273675394295]
Test: [0/1]	Time  0.262 ( 0.262)	Loss 9.4242e-01 (9.4242e-01)	Acc@1   0.65 (  0.65)	Acc@5   0.00 (  0.00)
 * Acc@1 0.650 Acc@5 0.000
Test: [0/1]	Time  0.323 ( 0.323)	Loss 1.6449e-01 (1.6449e-01)	Acc@1   0.57 (  0.57)	Acc@5   0.00 (  0.00)
 * Acc@1 0.566 Acc@5 0.000
33
TRAINING
Epoch: [33][0/1]	Time  0.939 ( 0.939)	Data  0.255 ( 0.255)	Loss 8.1651e-02 (8.1651e-02)	Acc@1   0.88 (  0.88)	Acc@5   0.00 (  0.00)
[0.8812732776329734]
Test: [0/1]	Time  0.264 ( 0.264)	Loss 9.4044e-01 (9.4044e-01)	Acc@1   0.66 (  0.66)	Acc@5   0.00 (  0.00)
 * Acc@1 0.658 Acc@5 0.000
Test: [0/1]	Time  0.325 ( 0.325)	Loss 1.5680e-01 (1.5680e-01)	Acc@1   0.59 (  0.59)	Acc@5   0.00 (  0.00)
 * Acc@1 0.585 Acc@5 0.000
34
TRAINING
Epoch: [34][0/1]	Time  0.945 ( 0.945)	Data  0.247 ( 0.247)	Loss 7.8297e-02 (7.8297e-02)	Acc@1   0.88 (  0.88)	Acc@5   0.00 (  0.00)
[0.8833792574188327]
Test: [0/1]	Time  0.258 ( 0.258)	Loss 9.3903e-01 (9.3903e-01)	Acc@1   0.66 (  0.66)	Acc@5   0.00 (  0.00)
 * Acc@1 0.660 Acc@5 0.000
Test: [0/1]	Time  0.327 ( 0.327)	Loss 1.5225e-01 (1.5225e-01)	Acc@1   0.60 (  0.60)	Acc@5   0.00 (  0.00)
 * Acc@1 0.602 Acc@5 0.000
35
TRAINING
Epoch: [35][0/1]	Time  0.961 ( 0.961)	Data  0.248 ( 0.248)	Loss 7.7647e-02 (7.7647e-02)	Acc@1   0.88 (  0.88)	Acc@5   0.00 (  0.00)
[0.8849992113670226]
Test: [0/1]	Time  0.270 ( 0.270)	Loss 9.3794e-01 (9.3794e-01)	Acc@1   0.66 (  0.66)	Acc@5   0.00 (  0.00)
 * Acc@1 0.659 Acc@5 0.000
Test: [0/1]	Time  0.324 ( 0.324)	Loss 1.5024e-01 (1.5024e-01)	Acc@1   0.62 (  0.62)	Acc@5   0.00 (  0.00)
 * Acc@1 0.616 Acc@5 0.000
36
TRAINING
Epoch: [36][0/1]	Time  0.940 ( 0.940)	Data  0.249 ( 0.249)	Loss 7.9070e-02 (7.9070e-02)	Acc@1   0.89 (  0.89)	Acc@5   0.00 (  0.00)
[0.8856109280045164]
Test: [0/1]	Time  0.259 ( 0.259)	Loss 9.3692e-01 (9.3692e-01)	Acc@1   0.66 (  0.66)	Acc@5   0.00 (  0.00)
 * Acc@1 0.658 Acc@5 0.000
Test: [0/1]	Time  0.322 ( 0.322)	Loss 1.4931e-01 (1.4931e-01)	Acc@1   0.63 (  0.63)	Acc@5   0.00 (  0.00)
 * Acc@1 0.627 Acc@5 0.000
37
TRAINING
Epoch: [37][0/1]	Time  0.954 ( 0.954)	Data  0.245 ( 0.245)	Loss 8.1089e-02 (8.1089e-02)	Acc@1   0.88 (  0.88)	Acc@5   0.00 (  0.00)
[0.8847362581545086]
Test: [0/1]	Time  0.261 ( 0.261)	Loss 9.3575e-01 (9.3575e-01)	Acc@1   0.66 (  0.66)	Acc@5   0.00 (  0.00)
 * Acc@1 0.657 Acc@5 0.000
Test: [0/1]	Time  0.322 ( 0.322)	Loss 1.4813e-01 (1.4813e-01)	Acc@1   0.64 (  0.64)	Acc@5   0.00 (  0.00)
 * Acc@1 0.637 Acc@5 0.000
38
TRAINING
Epoch: [38][0/1]	Time  0.933 ( 0.933)	Data  0.236 ( 0.236)	Loss 8.2360e-02 (8.2360e-02)	Acc@1   0.88 (  0.88)	Acc@5   0.00 (  0.00)
[0.8828772545715329]
Test: [0/1]	Time  0.258 ( 0.258)	Loss 9.3438e-01 (9.3438e-01)	Acc@1   0.66 (  0.66)	Acc@5   0.00 (  0.00)
 * Acc@1 0.657 Acc@5 0.000
Test: [0/1]	Time  0.327 ( 0.327)	Loss 1.4617e-01 (1.4617e-01)	Acc@1   0.65 (  0.65)	Acc@5   0.00 (  0.00)
 * Acc@1 0.650 Acc@5 0.000
39
TRAINING
Epoch: [39][0/1]	Time  0.954 ( 0.954)	Data  0.249 ( 0.249)	Loss 8.2386e-02 (8.2386e-02)	Acc@1   0.88 (  0.88)	Acc@5   0.00 (  0.00)
[0.8805686427303692]
Test: [0/1]	Time  0.259 ( 0.259)	Loss 9.3289e-01 (9.3289e-01)	Acc@1   0.66 (  0.66)	Acc@5   0.00 (  0.00)
 * Acc@1 0.662 Acc@5 0.000
Test: [0/1]	Time  0.323 ( 0.323)	Loss 1.4384e-01 (1.4384e-01)	Acc@1   0.66 (  0.66)	Acc@5   0.00 (  0.00)
 * Acc@1 0.663 Acc@5 0.000
40
TRAINING
Epoch: [40][0/1]	Time  0.940 ( 0.940)	Data  0.244 ( 0.244)	Loss 8.1597e-02 (8.1597e-02)	Acc@1   0.88 (  0.88)	Acc@5   0.00 (  0.00)
[0.8783042234180591]
Test: [0/1]	Time  0.259 ( 0.259)	Loss 9.3145e-01 (9.3145e-01)	Acc@1   0.67 (  0.67)	Acc@5   0.00 (  0.00)
 * Acc@1 0.670 Acc@5 0.000
Test: [0/1]	Time  0.319 ( 0.319)	Loss 1.4197e-01 (1.4197e-01)	Acc@1   0.68 (  0.68)	Acc@5   0.00 (  0.00)
 * Acc@1 0.675 Acc@5 0.000
41
TRAINING
Epoch: [41][0/1]	Time  0.941 ( 0.941)	Data  0.249 ( 0.249)	Loss 8.0884e-02 (8.0884e-02)	Acc@1   0.88 (  0.88)	Acc@5   0.00 (  0.00)
[0.8762857534040793]
Test: [0/1]	Time  0.269 ( 0.269)	Loss 9.3020e-01 (9.3020e-01)	Acc@1   0.68 (  0.68)	Acc@5   0.00 (  0.00)
 * Acc@1 0.679 Acc@5 0.000
Test: [0/1]	Time  0.332 ( 0.332)	Loss 1.4119e-01 (1.4119e-01)	Acc@1   0.68 (  0.68)	Acc@5   0.00 (  0.00)
 * Acc@1 0.682 Acc@5 0.000
42
TRAINING
Epoch: [42][0/1]	Time  0.940 ( 0.940)	Data  0.241 ( 0.241)	Loss 8.0949e-02 (8.0949e-02)	Acc@1   0.88 (  0.88)	Acc@5   0.00 (  0.00)
[0.8764964186647177]
Test: [0/1]	Time  0.260 ( 0.260)	Loss 9.2923e-01 (9.2923e-01)	Acc@1   0.69 (  0.69)	Acc@5   0.00 (  0.00)
 * Acc@1 0.686 Acc@5 0.000
Test: [0/1]	Time  0.318 ( 0.318)	Loss 1.4154e-01 (1.4154e-01)	Acc@1   0.69 (  0.69)	Acc@5   0.00 (  0.00)
 * Acc@1 0.688 Acc@5 0.000
43
TRAINING
Epoch: [43][0/1]	Time  0.957 ( 0.957)	Data  0.243 ( 0.243)	Loss 8.1899e-02 (8.1899e-02)	Acc@1   0.88 (  0.88)	Acc@5   0.00 (  0.00)
[0.8771985366266015]
Test: [0/1]	Time  0.255 ( 0.255)	Loss 9.2853e-01 (9.2853e-01)	Acc@1   0.69 (  0.69)	Acc@5   0.00 (  0.00)
 * Acc@1 0.692 Acc@5 0.000
Test: [0/1]	Time  0.325 ( 0.325)	Loss 1.4250e-01 (1.4250e-01)	Acc@1   0.69 (  0.69)	Acc@5   0.00 (  0.00)
 * Acc@1 0.693 Acc@5 0.000
44
TRAINING
Epoch: [44][0/1]	Time  0.929 ( 0.929)	Data  0.229 ( 0.229)	Loss 8.3264e-02 (8.3264e-02)	Acc@1   0.88 (  0.88)	Acc@5   0.00 (  0.00)
[0.8784220161098453]
Test: [0/1]	Time  0.257 ( 0.257)	Loss 9.2806e-01 (9.2806e-01)	Acc@1   0.70 (  0.70)	Acc@5   0.00 (  0.00)
 * Acc@1 0.696 Acc@5 0.000
Test: [0/1]	Time  0.315 ( 0.315)	Loss 1.4332e-01 (1.4332e-01)	Acc@1   0.70 (  0.70)	Acc@5   0.00 (  0.00)
 * Acc@1 0.696 Acc@5 0.000
45
TRAINING
Epoch: [45][0/1]	Time  0.918 ( 0.918)	Data  0.228 ( 0.228)	Loss 8.4352e-02 (8.4352e-02)	Acc@1   0.88 (  0.88)	Acc@5   0.00 (  0.00)
[0.8803831424994393]
Test: [0/1]	Time  0.265 ( 0.265)	Loss 9.2781e-01 (9.2781e-01)	Acc@1   0.70 (  0.70)	Acc@5   0.00 (  0.00)
 * Acc@1 0.698 Acc@5 0.000
Test: [0/1]	Time  0.319 ( 0.319)	Loss 1.4349e-01 (1.4349e-01)	Acc@1   0.70 (  0.70)	Acc@5   0.00 (  0.00)
 * Acc@1 0.699 Acc@5 0.000
46
TRAINING
Epoch: [46][0/1]	Time  0.933 ( 0.933)	Data  0.238 ( 0.238)	Loss 8.4683e-02 (8.4683e-02)	Acc@1   0.88 (  0.88)	Acc@5   0.00 (  0.00)
[0.882948065500843]
Test: [0/1]	Time  0.257 ( 0.257)	Loss 9.2776e-01 (9.2776e-01)	Acc@1   0.70 (  0.70)	Acc@5   0.00 (  0.00)
 * Acc@1 0.699 Acc@5 0.000
Test: [0/1]	Time  0.319 ( 0.319)	Loss 1.4294e-01 (1.4294e-01)	Acc@1   0.70 (  0.70)	Acc@5   0.00 (  0.00)
 * Acc@1 0.701 Acc@5 0.000
47
TRAINING
Epoch: [47][0/1]	Time  0.931 ( 0.931)	Data  0.235 ( 0.235)	Loss 8.4223e-02 (8.4223e-02)	Acc@1   0.89 (  0.89)	Acc@5   0.00 (  0.00)
[0.8859703734590648]
Test: [0/1]	Time  0.251 ( 0.251)	Loss 9.2793e-01 (9.2793e-01)	Acc@1   0.70 (  0.70)	Acc@5   0.00 (  0.00)
 * Acc@1 0.698 Acc@5 0.000
Test: [0/1]	Time  0.316 ( 0.316)	Loss 1.4201e-01 (1.4201e-01)	Acc@1   0.70 (  0.70)	Acc@5   0.00 (  0.00)
 * Acc@1 0.703 Acc@5 0.000
48
TRAINING
Epoch: [48][0/1]	Time  0.962 ( 0.962)	Data  0.247 ( 0.247)	Loss 8.3329e-02 (8.3329e-02)	Acc@1   0.89 (  0.89)	Acc@5   0.00 (  0.00)
[0.8893449879403608]
Test: [0/1]	Time  0.261 ( 0.261)	Loss 9.2833e-01 (9.2833e-01)	Acc@1   0.70 (  0.70)	Acc@5   0.00 (  0.00)
 * Acc@1 0.697 Acc@5 0.000
Test: [0/1]	Time  0.319 ( 0.319)	Loss 1.4118e-01 (1.4118e-01)	Acc@1   0.70 (  0.70)	Acc@5   0.00 (  0.00)
 * Acc@1 0.701 Acc@5 0.000
49
TRAINING
Epoch: [49][0/1]	Time  0.917 ( 0.917)	Data  0.241 ( 0.241)	Loss 8.2484e-02 (8.2484e-02)	Acc@1   0.89 (  0.89)	Acc@5   0.00 (  0.00)
[0.8927743357471747]
Test: [0/1]	Time  0.271 ( 0.271)	Loss 9.2891e-01 (9.2891e-01)	Acc@1   0.69 (  0.69)	Acc@5   0.00 (  0.00)
 * Acc@1 0.694 Acc@5 0.000
Test: [0/1]	Time  0.323 ( 0.323)	Loss 1.4077e-01 (1.4077e-01)	Acc@1   0.70 (  0.70)	Acc@5   0.00 (  0.00)
 * Acc@1 0.700 Acc@5 0.000
50
TRAINING
Epoch: [50][0/1]	Time  0.944 ( 0.944)	Data  0.249 ( 0.249)	Loss 8.2019e-02 (8.2019e-02)	Acc@1   0.90 (  0.90)	Acc@5   0.00 (  0.00)
[0.8963841314822263]
Test: [0/1]	Time  0.262 ( 0.262)	Loss 9.2961e-01 (9.2961e-01)	Acc@1   0.69 (  0.69)	Acc@5   0.00 (  0.00)
 * Acc@1 0.692 Acc@5 0.000
Test: [0/1]	Time  0.324 ( 0.324)	Loss 1.4082e-01 (1.4082e-01)	Acc@1   0.70 (  0.70)	Acc@5   0.00 (  0.00)
 * Acc@1 0.701 Acc@5 0.000
51
TRAINING
Epoch: [51][0/1]	Time  0.922 ( 0.922)	Data  0.247 ( 0.247)	Loss 8.1968e-02 (8.1968e-02)	Acc@1   0.90 (  0.90)	Acc@5   0.00 (  0.00)
[0.8999927248132354]
Test: [0/1]	Time  0.270 ( 0.270)	Loss 9.3034e-01 (9.3034e-01)	Acc@1   0.69 (  0.69)	Acc@5   0.00 (  0.00)
 * Acc@1 0.690 Acc@5 0.000
Test: [0/1]	Time  0.318 ( 0.318)	Loss 1.4113e-01 (1.4113e-01)	Acc@1   0.70 (  0.70)	Acc@5   0.00 (  0.00)
 * Acc@1 0.700 Acc@5 0.000
52
TRAINING
Epoch: [52][0/1]	Time  0.942 ( 0.942)	Data  0.258 ( 0.258)	Loss 8.2123e-02 (8.2123e-02)	Acc@1   0.90 (  0.90)	Acc@5   0.00 (  0.00)
[0.9038860565791291]
Test: [0/1]	Time  0.259 ( 0.259)	Loss 9.3100e-01 (9.3100e-01)	Acc@1   0.69 (  0.69)	Acc@5   0.00 (  0.00)
 * Acc@1 0.688 Acc@5 0.000
Test: [0/1]	Time  0.321 ( 0.321)	Loss 1.4142e-01 (1.4142e-01)	Acc@1   0.70 (  0.70)	Acc@5   0.00 (  0.00)
 * Acc@1 0.700 Acc@5 0.000
53
TRAINING
Epoch: [53][0/1]	Time  0.961 ( 0.961)	Data  0.255 ( 0.255)	Loss 8.2212e-02 (8.2212e-02)	Acc@1   0.91 (  0.91)	Acc@5   0.00 (  0.00)
[0.9081647155674188]
Test: [0/1]	Time  0.261 ( 0.261)	Loss 9.3155e-01 (9.3155e-01)	Acc@1   0.69 (  0.69)	Acc@5   0.00 (  0.00)
 * Acc@1 0.688 Acc@5 0.000
Test: [0/1]	Time  0.325 ( 0.325)	Loss 1.4152e-01 (1.4152e-01)	Acc@1   0.70 (  0.70)	Acc@5   0.00 (  0.00)
 * Acc@1 0.699 Acc@5 0.000
54
TRAINING
Epoch: [54][0/1]	Time  0.932 ( 0.932)	Data  0.257 ( 0.257)	Loss 8.2075e-02 (8.2075e-02)	Acc@1   0.91 (  0.91)	Acc@5   0.00 (  0.00)
[0.9115227180024064]
Test: [0/1]	Time  0.258 ( 0.258)	Loss 9.3199e-01 (9.3199e-01)	Acc@1   0.69 (  0.69)	Acc@5   0.00 (  0.00)
 * Acc@1 0.688 Acc@5 0.000
Test: [0/1]	Time  0.322 ( 0.322)	Loss 1.4145e-01 (1.4145e-01)	Acc@1   0.70 (  0.70)	Acc@5   0.00 (  0.00)
 * Acc@1 0.699 Acc@5 0.000
55
TRAINING
Epoch: [55][0/1]	Time  0.976 ( 0.976)	Data  0.256 ( 0.256)	Loss 8.1737e-02 (8.1737e-02)	Acc@1   0.91 (  0.91)	Acc@5   0.00 (  0.00)
[0.9144674495453892]
Test: [0/1]	Time  0.267 ( 0.267)	Loss 9.3234e-01 (9.3234e-01)	Acc@1   0.69 (  0.69)	Acc@5   0.00 (  0.00)
 * Acc@1 0.689 Acc@5 0.000
Test: [0/1]	Time  0.326 ( 0.326)	Loss 1.4133e-01 (1.4133e-01)	Acc@1   0.70 (  0.70)	Acc@5   0.00 (  0.00)
 * Acc@1 0.699 Acc@5 0.000
56
TRAINING
Epoch: [56][0/1]	Time  0.928 ( 0.928)	Data  0.252 ( 0.252)	Loss 8.1353e-02 (8.1353e-02)	Acc@1   0.92 (  0.92)	Acc@5   0.00 (  0.00)
[0.9172242202453331]
Test: [0/1]	Time  0.256 ( 0.256)	Loss 9.3269e-01 (9.3269e-01)	Acc@1   0.69 (  0.69)	Acc@5   0.00 (  0.00)
 * Acc@1 0.690 Acc@5 0.000
Test: [0/1]	Time  0.325 ( 0.325)	Loss 1.4133e-01 (1.4133e-01)	Acc@1   0.70 (  0.70)	Acc@5   0.00 (  0.00)
 * Acc@1 0.699 Acc@5 0.000
57
TRAINING
Epoch: [57][0/1]	Time  0.931 ( 0.931)	Data  0.255 ( 0.255)	Loss 8.1090e-02 (8.1090e-02)	Acc@1   0.92 (  0.92)	Acc@5   0.00 (  0.00)
[0.9199475616832622]
Test: [0/1]	Time  0.259 ( 0.259)	Loss 9.3308e-01 (9.3308e-01)	Acc@1   0.69 (  0.69)	Acc@5   0.00 (  0.00)
 * Acc@1 0.692 Acc@5 0.000
Test: [0/1]	Time  0.319 ( 0.319)	Loss 1.4149e-01 (1.4149e-01)	Acc@1   0.70 (  0.70)	Acc@5   0.00 (  0.00)
 * Acc@1 0.699 Acc@5 0.000
58
TRAINING
Epoch: [58][0/1]	Time  0.929 ( 0.929)	Data  0.257 ( 0.257)	Loss 8.1018e-02 (8.1018e-02)	Acc@1   0.92 (  0.92)	Acc@5   0.00 (  0.00)
[0.9218797601938762]
Test: [0/1]	Time  0.259 ( 0.259)	Loss 9.3356e-01 (9.3356e-01)	Acc@1   0.69 (  0.69)	Acc@5   0.00 (  0.00)
 * Acc@1 0.694 Acc@5 0.000
Test: [0/1]	Time  0.319 ( 0.319)	Loss 1.4175e-01 (1.4175e-01)	Acc@1   0.70 (  0.70)	Acc@5   0.00 (  0.00)
 * Acc@1 0.699 Acc@5 0.000
59
TRAINING
Epoch: [59][0/1]	Time  0.938 ( 0.938)	Data  0.243 ( 0.243)	Loss 8.1081e-02 (8.1081e-02)	Acc@1   0.92 (  0.92)	Acc@5   0.00 (  0.00)
[0.9234916481743046]
Test: [0/1]	Time  0.259 ( 0.259)	Loss 9.3415e-01 (9.3415e-01)	Acc@1   0.70 (  0.70)	Acc@5   0.00 (  0.00)
 * Acc@1 0.697 Acc@5 0.000
Test: [0/1]	Time  0.323 ( 0.323)	Loss 1.4197e-01 (1.4197e-01)	Acc@1   0.70 (  0.70)	Acc@5   0.00 (  0.00)
 * Acc@1 0.699 Acc@5 0.000
60
TRAINING
Epoch: [60][0/1]	Time  0.933 ( 0.933)	Data  0.236 ( 0.236)	Loss 8.1148e-02 (8.1148e-02)	Acc@1   0.93 (  0.93)	Acc@5   0.00 (  0.00)
[0.9253506310476577]
Test: [0/1]	Time  0.254 ( 0.254)	Loss 9.3487e-01 (9.3487e-01)	Acc@1   0.70 (  0.70)	Acc@5   0.00 (  0.00)
 * Acc@1 0.699 Acc@5 0.000
Test: [0/1]	Time  0.319 ( 0.319)	Loss 1.4201e-01 (1.4201e-01)	Acc@1   0.70 (  0.70)	Acc@5   0.00 (  0.00)
 * Acc@1 0.699 Acc@5 0.000
61
TRAINING
Epoch: [61][0/1]	Time  0.912 ( 0.912)	Data  0.240 ( 0.240)	Loss 8.1095e-02 (8.1095e-02)	Acc@1   0.93 (  0.93)	Acc@5   0.00 (  0.00)
[0.9270298370905257]
Test: [0/1]	Time  0.255 ( 0.255)	Loss 9.3570e-01 (9.3570e-01)	Acc@1   0.70 (  0.70)	Acc@5   0.00 (  0.00)
 * Acc@1 0.701 Acc@5 0.000
Test: [0/1]	Time  0.316 ( 0.316)	Loss 1.4185e-01 (1.4185e-01)	Acc@1   0.70 (  0.70)	Acc@5   0.00 (  0.00)
 * Acc@1 0.698 Acc@5 0.000
62
TRAINING
Epoch: [62][0/1]	Time  0.912 ( 0.912)	Data  0.241 ( 0.241)	Loss 8.0878e-02 (8.0878e-02)	Acc@1   0.93 (  0.93)	Acc@5   0.00 (  0.00)
[0.9285686429890495]
Test: [0/1]	Time  0.257 ( 0.257)	Loss 9.3662e-01 (9.3662e-01)	Acc@1   0.70 (  0.70)	Acc@5   0.00 (  0.00)
 * Acc@1 0.702 Acc@5 0.000
Test: [0/1]	Time  0.318 ( 0.318)	Loss 1.4152e-01 (1.4152e-01)	Acc@1   0.70 (  0.70)	Acc@5   0.00 (  0.00)
 * Acc@1 0.698 Acc@5 0.000
63
TRAINING
Epoch: [63][0/1]	Time  0.912 ( 0.912)	Data  0.237 ( 0.237)	Loss 8.0542e-02 (8.0542e-02)	Acc@1   0.93 (  0.93)	Acc@5   0.00 (  0.00)
[0.9298047612503926]
Test: [0/1]	Time  0.254 ( 0.254)	Loss 9.3761e-01 (9.3761e-01)	Acc@1   0.70 (  0.70)	Acc@5   0.00 (  0.00)
 * Acc@1 0.704 Acc@5 0.000
Test: [0/1]	Time  0.315 ( 0.315)	Loss 1.4114e-01 (1.4114e-01)	Acc@1   0.70 (  0.70)	Acc@5   0.00 (  0.00)
 * Acc@1 0.698 Acc@5 0.000
64
TRAINING
Epoch: [64][0/1]	Time  0.937 ( 0.937)	Data  0.241 ( 0.241)	Loss 8.0184e-02 (8.0184e-02)	Acc@1   0.93 (  0.93)	Acc@5   0.00 (  0.00)
[0.9301775142645944]
Test: [0/1]	Time  0.255 ( 0.255)	Loss 9.3862e-01 (9.3862e-01)	Acc@1   0.70 (  0.70)	Acc@5   0.00 (  0.00)
 * Acc@1 0.705 Acc@5 0.000
Test: [0/1]	Time  0.318 ( 0.318)	Loss 1.4079e-01 (1.4079e-01)	Acc@1   0.70 (  0.70)	Acc@5   0.00 (  0.00)
 * Acc@1 0.697 Acc@5 0.000
65
TRAINING
Epoch: [65][0/1]	Time  0.911 ( 0.911)	Data  0.239 ( 0.239)	Loss 7.9893e-02 (7.9893e-02)	Acc@1   0.93 (  0.93)	Acc@5   0.00 (  0.00)
[0.9306562660297139]
Test: [0/1]	Time  0.257 ( 0.257)	Loss 9.3960e-01 (9.3960e-01)	Acc@1   0.71 (  0.71)	Acc@5   0.00 (  0.00)
 * Acc@1 0.705 Acc@5 0.000
Test: [0/1]	Time  0.319 ( 0.319)	Loss 1.4054e-01 (1.4054e-01)	Acc@1   0.70 (  0.70)	Acc@5   0.00 (  0.00)
 * Acc@1 0.697 Acc@5 0.000
66
TRAINING
Epoch: [66][0/1]	Time  0.948 ( 0.948)	Data  0.255 ( 0.255)	Loss 7.9707e-02 (7.9707e-02)	Acc@1   0.93 (  0.93)	Acc@5   0.00 (  0.00)
[0.9310495705185721]
Test: [0/1]	Time  0.270 ( 0.270)	Loss 9.4050e-01 (9.4050e-01)	Acc@1   0.71 (  0.71)	Acc@5   0.00 (  0.00)
 * Acc@1 0.705 Acc@5 0.000
Test: [0/1]	Time  0.323 ( 0.323)	Loss 1.4038e-01 (1.4038e-01)	Acc@1   0.70 (  0.70)	Acc@5   0.00 (  0.00)
 * Acc@1 0.697 Acc@5 0.000
67
TRAINING
Epoch: [67][0/1]	Time  0.921 ( 0.921)	Data  0.246 ( 0.246)	Loss 7.9605e-02 (7.9605e-02)	Acc@1   0.93 (  0.93)	Acc@5   0.00 (  0.00)
[0.931750572076371]
Test: [0/1]	Time  0.263 ( 0.263)	Loss 9.4128e-01 (9.4128e-01)	Acc@1   0.71 (  0.71)	Acc@5   0.00 (  0.00)
 * Acc@1 0.705 Acc@5 0.000
Test: [0/1]	Time  0.324 ( 0.324)	Loss 1.4025e-01 (1.4025e-01)	Acc@1   0.70 (  0.70)	Acc@5   0.00 (  0.00)
 * Acc@1 0.697 Acc@5 0.000
68
TRAINING
Epoch: [68][0/1]	Time  0.938 ( 0.938)	Data  0.243 ( 0.243)	Loss 7.9538e-02 (7.9538e-02)	Acc@1   0.93 (  0.93)	Acc@5   0.00 (  0.00)
[0.9324427513077456]
Test: [0/1]	Time  0.260 ( 0.260)	Loss 9.4191e-01 (9.4191e-01)	Acc@1   0.71 (  0.71)	Acc@5   0.00 (  0.00)
 * Acc@1 0.705 Acc@5 0.000
Test: [0/1]	Time  0.336 ( 0.336)	Loss 1.4013e-01 (1.4013e-01)	Acc@1   0.70 (  0.70)	Acc@5   0.00 (  0.00)
 * Acc@1 0.698 Acc@5 0.000
69
TRAINING
Epoch: [69][0/1]	Time  0.923 ( 0.923)	Data  0.249 ( 0.249)	Loss 7.9462e-02 (7.9462e-02)	Acc@1   0.93 (  0.93)	Acc@5   0.00 (  0.00)
[0.9330139404585595]
Test: [0/1]	Time  0.262 ( 0.262)	Loss 9.4239e-01 (9.4239e-01)	Acc@1   0.71 (  0.71)	Acc@5   0.00 (  0.00)
 * Acc@1 0.705 Acc@5 0.000
Test: [0/1]	Time  0.322 ( 0.322)	Loss 1.3999e-01 (1.3999e-01)	Acc@1   0.70 (  0.70)	Acc@5   0.00 (  0.00)
 * Acc@1 0.698 Acc@5 0.000
70
TRAINING
Epoch: [70][0/1]	Time  0.941 ( 0.941)	Data  0.237 ( 0.237)	Loss 7.9365e-02 (7.9365e-02)	Acc@1   0.93 (  0.93)	Acc@5   0.00 (  0.00)
[0.933471206289658]
Test: [0/1]	Time  0.256 ( 0.256)	Loss 9.4274e-01 (9.4274e-01)	Acc@1   0.71 (  0.71)	Acc@5   0.00 (  0.00)
 * Acc@1 0.705 Acc@5 0.000
Test: [0/1]	Time  0.320 ( 0.320)	Loss 1.3986e-01 (1.3986e-01)	Acc@1   0.70 (  0.70)	Acc@5   0.00 (  0.00)
 * Acc@1 0.699 Acc@5 0.000
71
TRAINING
Epoch: [71][0/1]	Time  0.913 ( 0.913)	Data  0.240 ( 0.240)	Loss 7.9265e-02 (7.9265e-02)	Acc@1   0.93 (  0.93)	Acc@5   0.00 (  0.00)
[0.9336935355771041]
Test: [0/1]	Time  0.264 ( 0.264)	Loss 9.4297e-01 (9.4297e-01)	Acc@1   0.71 (  0.71)	Acc@5   0.00 (  0.00)
 * Acc@1 0.706 Acc@5 0.000
Test: [0/1]	Time  0.324 ( 0.324)	Loss 1.3975e-01 (1.3975e-01)	Acc@1   0.70 (  0.70)	Acc@5   0.00 (  0.00)
 * Acc@1 0.700 Acc@5 0.000
72
TRAINING
Epoch: [72][0/1]	Time  0.916 ( 0.916)	Data  0.244 ( 0.244)	Loss 7.9193e-02 (7.9193e-02)	Acc@1   0.93 (  0.93)	Acc@5   0.00 (  0.00)
[0.9336786726430967]
Test: [0/1]	Time  0.259 ( 0.259)	Loss 9.4315e-01 (9.4315e-01)	Acc@1   0.71 (  0.71)	Acc@5   0.00 (  0.00)
 * Acc@1 0.706 Acc@5 0.000
Test: [0/1]	Time  0.317 ( 0.317)	Loss 1.3969e-01 (1.3969e-01)	Acc@1   0.70 (  0.70)	Acc@5   0.00 (  0.00)
 * Acc@1 0.701 Acc@5 0.000
73
TRAINING
Epoch: [73][0/1]	Time  0.911 ( 0.911)	Data  0.239 ( 0.239)	Loss 7.9166e-02 (7.9166e-02)	Acc@1   0.93 (  0.93)	Acc@5   0.00 (  0.00)
[0.933564461050467]
Test: [0/1]	Time  0.260 ( 0.260)	Loss 9.4328e-01 (9.4328e-01)	Acc@1   0.71 (  0.71)	Acc@5   0.00 (  0.00)
 * Acc@1 0.706 Acc@5 0.000
Test: [0/1]	Time  0.321 ( 0.321)	Loss 1.3967e-01 (1.3967e-01)	Acc@1   0.70 (  0.70)	Acc@5   0.00 (  0.00)
 * Acc@1 0.702 Acc@5 0.000
74
TRAINING
Epoch: [74][0/1]	Time  0.940 ( 0.940)	Data  0.248 ( 0.248)	Loss 7.9178e-02 (7.9178e-02)	Acc@1   0.93 (  0.93)	Acc@5   0.00 (  0.00)
[0.933432486538017]
Test: [0/1]	Time  0.258 ( 0.258)	Loss 9.4342e-01 (9.4342e-01)	Acc@1   0.71 (  0.71)	Acc@5   0.00 (  0.00)
 * Acc@1 0.706 Acc@5 0.000
Test: [0/1]	Time  0.321 ( 0.321)	Loss 1.3966e-01 (1.3966e-01)	Acc@1   0.70 (  0.70)	Acc@5   0.00 (  0.00)
 * Acc@1 0.703 Acc@5 0.000
75
TRAINING
Epoch: [75][0/1]	Time  0.915 ( 0.915)	Data  0.242 ( 0.242)	Loss 7.9203e-02 (7.9203e-02)	Acc@1   0.93 (  0.93)	Acc@5   0.00 (  0.00)
[0.933297987672393]
Test: [0/1]	Time  0.260 ( 0.260)	Loss 9.4356e-01 (9.4356e-01)	Acc@1   0.71 (  0.71)	Acc@5   0.00 (  0.00)
 * Acc@1 0.706 Acc@5 0.000
Test: [0/1]	Time  0.345 ( 0.345)	Loss 1.3962e-01 (1.3962e-01)	Acc@1   0.70 (  0.70)	Acc@5   0.00 (  0.00)
 * Acc@1 0.703 Acc@5 0.000
76
TRAINING
Epoch: [76][0/1]	Time  0.943 ( 0.943)	Data  0.250 ( 0.250)	Loss 7.9211e-02 (7.9211e-02)	Acc@1   0.93 (  0.93)	Acc@5   0.00 (  0.00)
[0.9331736888736102]
Test: [0/1]	Time  0.265 ( 0.265)	Loss 9.4372e-01 (9.4372e-01)	Acc@1   0.71 (  0.71)	Acc@5   0.00 (  0.00)
 * Acc@1 0.707 Acc@5 0.000
Test: [0/1]	Time  0.331 ( 0.331)	Loss 1.3954e-01 (1.3954e-01)	Acc@1   0.70 (  0.70)	Acc@5   0.00 (  0.00)
 * Acc@1 0.704 Acc@5 0.000
77
TRAINING
Epoch: [77][0/1]	Time  0.931 ( 0.931)	Data  0.239 ( 0.239)	Loss 7.9183e-02 (7.9183e-02)	Acc@1   0.93 (  0.93)	Acc@5   0.00 (  0.00)
[0.9330680864093825]
Test: [0/1]	Time  0.259 ( 0.259)	Loss 9.4389e-01 (9.4389e-01)	Acc@1   0.71 (  0.71)	Acc@5   0.00 (  0.00)
 * Acc@1 0.707 Acc@5 0.000
Test: [0/1]	Time  0.319 ( 0.319)	Loss 1.3943e-01 (1.3943e-01)	Acc@1   0.71 (  0.71)	Acc@5   0.00 (  0.00)
 * Acc@1 0.705 Acc@5 0.000
78
TRAINING
Epoch: [78][0/1]	Time  0.942 ( 0.942)	Data  0.250 ( 0.250)	Loss 7.9122e-02 (7.9122e-02)	Acc@1   0.93 (  0.93)	Acc@5   0.00 (  0.00)
[0.9329849354977533]
Test: [0/1]	Time  0.261 ( 0.261)	Loss 9.4408e-01 (9.4408e-01)	Acc@1   0.71 (  0.71)	Acc@5   0.00 (  0.00)
 * Acc@1 0.707 Acc@5 0.000
Test: [0/1]	Time  0.327 ( 0.327)	Loss 1.3930e-01 (1.3930e-01)	Acc@1   0.71 (  0.71)	Acc@5   0.00 (  0.00)
 * Acc@1 0.706 Acc@5 0.000
79
TRAINING
Epoch: [79][0/1]	Time  0.943 ( 0.943)	Data  0.252 ( 0.252)	Loss 7.9044e-02 (7.9044e-02)	Acc@1   0.93 (  0.93)	Acc@5   0.00 (  0.00)
[0.9329240752315581]
Test: [0/1]	Time  0.260 ( 0.260)	Loss 9.4426e-01 (9.4426e-01)	Acc@1   0.71 (  0.71)	Acc@5   0.00 (  0.00)
 * Acc@1 0.707 Acc@5 0.000
Test: [0/1]	Time  0.339 ( 0.339)	Loss 1.3918e-01 (1.3918e-01)	Acc@1   0.71 (  0.71)	Acc@5   0.00 (  0.00)
 * Acc@1 0.707 Acc@5 0.000
80
TRAINING
Epoch: [80][0/1]	Time  0.934 ( 0.934)	Data  0.248 ( 0.248)	Loss 7.8972e-02 (7.8972e-02)	Acc@1   0.93 (  0.93)	Acc@5   0.00 (  0.00)
[0.9328831101187975]
Test: [0/1]	Time  0.258 ( 0.258)	Loss 9.4441e-01 (9.4441e-01)	Acc@1   0.71 (  0.71)	Acc@5   0.00 (  0.00)
 * Acc@1 0.708 Acc@5 0.000
Test: [0/1]	Time  0.323 ( 0.323)	Loss 1.3908e-01 (1.3908e-01)	Acc@1   0.71 (  0.71)	Acc@5   0.00 (  0.00)
 * Acc@1 0.708 Acc@5 0.000
81
TRAINING
Epoch: [81][0/1]	Time  0.936 ( 0.936)	Data  0.246 ( 0.246)	Loss 7.8918e-02 (7.8918e-02)	Acc@1   0.93 (  0.93)	Acc@5   0.00 (  0.00)
[0.9328591800810737]
Test: [0/1]	Time  0.268 ( 0.268)	Loss 9.4452e-01 (9.4452e-01)	Acc@1   0.71 (  0.71)	Acc@5   0.00 (  0.00)
 * Acc@1 0.708 Acc@5 0.000
Test: [0/1]	Time  0.331 ( 0.331)	Loss 1.3901e-01 (1.3901e-01)	Acc@1   0.71 (  0.71)	Acc@5   0.00 (  0.00)
 * Acc@1 0.710 Acc@5 0.000
82
TRAINING
Epoch: [82][0/1]	Time  0.925 ( 0.925)	Data  0.239 ( 0.239)	Loss 7.8886e-02 (7.8886e-02)	Acc@1   0.93 (  0.93)	Acc@5   0.00 (  0.00)
[0.9328501796726483]
Test: [0/1]	Time  0.261 ( 0.261)	Loss 9.4457e-01 (9.4457e-01)	Acc@1   0.71 (  0.71)	Acc@5   0.00 (  0.00)
 * Acc@1 0.708 Acc@5 0.000
Test: [0/1]	Time  0.322 ( 0.322)	Loss 1.3897e-01 (1.3897e-01)	Acc@1   0.71 (  0.71)	Acc@5   0.00 (  0.00)
 * Acc@1 0.711 Acc@5 0.000
83
TRAINING
Epoch: [83][0/1]	Time  0.946 ( 0.946)	Data  0.252 ( 0.252)	Loss 7.8869e-02 (7.8869e-02)	Acc@1   0.93 (  0.93)	Acc@5   0.00 (  0.00)
[0.9328551856273493]
Test: [0/1]	Time  0.263 ( 0.263)	Loss 9.4456e-01 (9.4456e-01)	Acc@1   0.71 (  0.71)	Acc@5   0.00 (  0.00)
 * Acc@1 0.708 Acc@5 0.000
Test: [0/1]	Time  0.320 ( 0.320)	Loss 1.3894e-01 (1.3894e-01)	Acc@1   0.71 (  0.71)	Acc@5   0.00 (  0.00)
 * Acc@1 0.711 Acc@5 0.000
84
TRAINING
Epoch: [84][0/1]	Time  0.969 ( 0.969)	Data  0.251 ( 0.251)	Loss 7.8857e-02 (7.8857e-02)	Acc@1   0.93 (  0.93)	Acc@5   0.00 (  0.00)
[0.9328742604103102]
Test: [0/1]	Time  0.258 ( 0.258)	Loss 9.4448e-01 (9.4448e-01)	Acc@1   0.71 (  0.71)	Acc@5   0.00 (  0.00)
 * Acc@1 0.708 Acc@5 0.000
Test: [0/1]	Time  0.321 ( 0.321)	Loss 1.3892e-01 (1.3892e-01)	Acc@1   0.71 (  0.71)	Acc@5   0.00 (  0.00)
 * Acc@1 0.712 Acc@5 0.000
85
TRAINING
Epoch: [85][0/1]	Time  0.941 ( 0.941)	Data  0.247 ( 0.247)	Loss 7.8846e-02 (7.8846e-02)	Acc@1   0.93 (  0.93)	Acc@5   0.00 (  0.00)
[0.9329080057920703]
Test: [0/1]	Time  0.260 ( 0.260)	Loss 9.4435e-01 (9.4435e-01)	Acc@1   0.71 (  0.71)	Acc@5   0.00 (  0.00)
 * Acc@1 0.708 Acc@5 0.000
Test: [0/1]	Time  0.320 ( 0.320)	Loss 1.3891e-01 (1.3891e-01)	Acc@1   0.71 (  0.71)	Acc@5   0.00 (  0.00)
 * Acc@1 0.713 Acc@5 0.000
86
TRAINING
Epoch: [86][0/1]	Time  0.947 ( 0.947)	Data  0.241 ( 0.241)	Loss 7.8835e-02 (7.8835e-02)	Acc@1   0.93 (  0.93)	Acc@5   0.00 (  0.00)
[0.9329571877443371]
Test: [0/1]	Time  0.265 ( 0.265)	Loss 9.4417e-01 (9.4417e-01)	Acc@1   0.71 (  0.71)	Acc@5   0.00 (  0.00)
 * Acc@1 0.708 Acc@5 0.000
Test: [0/1]	Time  0.319 ( 0.319)	Loss 1.3891e-01 (1.3891e-01)	Acc@1   0.71 (  0.71)	Acc@5   0.00 (  0.00)
 * Acc@1 0.713 Acc@5 0.000
87
TRAINING
Epoch: [87][0/1]	Time  0.979 ( 0.979)	Data  0.265 ( 0.265)	Loss 7.8829e-02 (7.8829e-02)	Acc@1   0.93 (  0.93)	Acc@5   0.00 (  0.00)
[0.9330225435287199]
Test: [0/1]	Time  0.264 ( 0.264)	Loss 9.4398e-01 (9.4398e-01)	Acc@1   0.71 (  0.71)	Acc@5   0.00 (  0.00)
 * Acc@1 0.709 Acc@5 0.000
Test: [0/1]	Time  0.330 ( 0.330)	Loss 1.3893e-01 (1.3893e-01)	Acc@1   0.71 (  0.71)	Acc@5   0.00 (  0.00)
 * Acc@1 0.714 Acc@5 0.000
88
TRAINING
Epoch: [88][0/1]	Time  0.947 ( 0.947)	Data  0.254 ( 0.254)	Loss 7.8830e-02 (7.8830e-02)	Acc@1   0.93 (  0.93)	Acc@5   0.00 (  0.00)
[0.933104682602292]
Test: [0/1]	Time  0.263 ( 0.263)	Loss 9.4378e-01 (9.4378e-01)	Acc@1   0.71 (  0.71)	Acc@5   0.00 (  0.00)
 * Acc@1 0.709 Acc@5 0.000
Test: [0/1]	Time  0.325 ( 0.325)	Loss 1.3895e-01 (1.3895e-01)	Acc@1   0.71 (  0.71)	Acc@5   0.00 (  0.00)
 * Acc@1 0.714 Acc@5 0.000
89
TRAINING
Epoch: [89][0/1]	Time  0.944 ( 0.944)	Data  0.243 ( 0.243)	Loss 7.8838e-02 (7.8838e-02)	Acc@1   0.93 (  0.93)	Acc@5   0.00 (  0.00)
[0.9332039270364357]
Test: [0/1]	Time  0.260 ( 0.260)	Loss 9.4360e-01 (9.4360e-01)	Acc@1   0.71 (  0.71)	Acc@5   0.00 (  0.00)
 * Acc@1 0.708 Acc@5 0.000
Test: [0/1]	Time  0.321 ( 0.321)	Loss 1.3898e-01 (1.3898e-01)	Acc@1   0.71 (  0.71)	Acc@5   0.00 (  0.00)
 * Acc@1 0.715 Acc@5 0.000
90
TRAINING
Epoch: [90][0/1]	Time  0.946 ( 0.946)	Data  0.246 ( 0.246)	Loss 7.8847e-02 (7.8847e-02)	Acc@1   0.93 (  0.93)	Acc@5   0.00 (  0.00)
[0.9333200162449791]
Test: [0/1]	Time  0.265 ( 0.265)	Loss 9.4345e-01 (9.4345e-01)	Acc@1   0.71 (  0.71)	Acc@5   0.00 (  0.00)
 * Acc@1 0.708 Acc@5 0.000
Test: [0/1]	Time  0.323 ( 0.323)	Loss 1.3900e-01 (1.3900e-01)	Acc@1   0.72 (  0.72)	Acc@5   0.00 (  0.00)
 * Acc@1 0.715 Acc@5 0.000
91
TRAINING
Epoch: [91][0/1]	Time  0.939 ( 0.939)	Data  0.243 ( 0.243)	Loss 7.8850e-02 (7.8850e-02)	Acc@1   0.93 (  0.93)	Acc@5   0.00 (  0.00)
[0.9334517425239894]
Test: [0/1]	Time  0.268 ( 0.268)	Loss 9.4332e-01 (9.4332e-01)	Acc@1   0.71 (  0.71)	Acc@5   0.00 (  0.00)
 * Acc@1 0.708 Acc@5 0.000
Test: [0/1]	Time  0.331 ( 0.331)	Loss 1.3900e-01 (1.3900e-01)	Acc@1   0.72 (  0.72)	Acc@5   0.00 (  0.00)
 * Acc@1 0.715 Acc@5 0.000
92
TRAINING
Epoch: [92][0/1]	Time  0.932 ( 0.932)	Data  0.245 ( 0.245)	Loss 7.8842e-02 (7.8842e-02)	Acc@1   0.93 (  0.93)	Acc@5   0.00 (  0.00)
[0.9335966814655399]
Test: [0/1]	Time  0.260 ( 0.260)	Loss 9.4322e-01 (9.4322e-01)	Acc@1   0.71 (  0.71)	Acc@5   0.00 (  0.00)
 * Acc@1 0.708 Acc@5 0.000
Test: [0/1]	Time  0.326 ( 0.326)	Loss 1.3900e-01 (1.3900e-01)	Acc@1   0.72 (  0.72)	Acc@5   0.00 (  0.00)
 * Acc@1 0.716 Acc@5 0.000
93
TRAINING
Epoch: [93][0/1]	Time  0.948 ( 0.948)	Data  0.246 ( 0.246)	Loss 7.8821e-02 (7.8821e-02)	Acc@1   0.93 (  0.93)	Acc@5   0.00 (  0.00)
[0.9337511732333124]
Test: [0/1]	Time  0.262 ( 0.262)	Loss 9.4316e-01 (9.4316e-01)	Acc@1   0.71 (  0.71)	Acc@5   0.00 (  0.00)
 * Acc@1 0.708 Acc@5 0.000
Test: [0/1]	Time  0.325 ( 0.325)	Loss 1.3898e-01 (1.3898e-01)	Acc@1   0.72 (  0.72)	Acc@5   0.00 (  0.00)
 * Acc@1 0.716 Acc@5 0.000
94
TRAINING
Epoch: [94][0/1]	Time  0.940 ( 0.940)	Data  0.246 ( 0.246)	Loss 7.8792e-02 (7.8792e-02)	Acc@1   0.93 (  0.93)	Acc@5   0.00 (  0.00)
[0.9339106090322322]
Test: [0/1]	Time  0.278 ( 0.278)	Loss 9.4311e-01 (9.4311e-01)	Acc@1   0.71 (  0.71)	Acc@5   0.00 (  0.00)
 * Acc@1 0.708 Acc@5 0.000
Test: [0/1]	Time  0.329 ( 0.329)	Loss 1.3896e-01 (1.3896e-01)	Acc@1   0.72 (  0.72)	Acc@5   0.00 (  0.00)
 * Acc@1 0.716 Acc@5 0.000
95
TRAINING
Epoch: [95][0/1]	Time  0.938 ( 0.938)	Data  0.242 ( 0.242)	Loss 7.8759e-02 (7.8759e-02)	Acc@1   0.93 (  0.93)	Acc@5   0.00 (  0.00)
[0.9340699473585528]
Test: [0/1]	Time  0.264 ( 0.264)	Loss 9.4307e-01 (9.4307e-01)	Acc@1   0.71 (  0.71)	Acc@5   0.00 (  0.00)
 * Acc@1 0.708 Acc@5 0.000
Test: [0/1]	Time  0.329 ( 0.329)	Loss 1.3894e-01 (1.3894e-01)	Acc@1   0.72 (  0.72)	Acc@5   0.00 (  0.00)
 * Acc@1 0.716 Acc@5 0.000
96
TRAINING
Epoch: [96][0/1]	Time  0.961 ( 0.961)	Data  0.262 ( 0.262)	Loss 7.8728e-02 (7.8728e-02)	Acc@1   0.93 (  0.93)	Acc@5   0.00 (  0.00)
[0.934224299244022]
Test: [0/1]	Time  0.261 ( 0.261)	Loss 9.4303e-01 (9.4303e-01)	Acc@1   0.71 (  0.71)	Acc@5   0.00 (  0.00)
 * Acc@1 0.707 Acc@5 0.000
Test: [0/1]	Time  0.328 ( 0.328)	Loss 1.3893e-01 (1.3893e-01)	Acc@1   0.72 (  0.72)	Acc@5   0.00 (  0.00)
 * Acc@1 0.716 Acc@5 0.000
97
TRAINING
Epoch: [97][0/1]	Time  0.957 ( 0.957)	Data  0.270 ( 0.270)	Loss 7.8702e-02 (7.8702e-02)	Acc@1   0.93 (  0.93)	Acc@5   0.00 (  0.00)
[0.9343694185418457]
Test: [0/1]	Time  0.266 ( 0.266)	Loss 9.4298e-01 (9.4298e-01)	Acc@1   0.71 (  0.71)	Acc@5   0.00 (  0.00)
 * Acc@1 0.707 Acc@5 0.000
Test: [0/1]	Time  0.323 ( 0.323)	Loss 1.3892e-01 (1.3892e-01)	Acc@1   0.72 (  0.72)	Acc@5   0.00 (  0.00)
 * Acc@1 0.716 Acc@5 0.000
98
TRAINING
Epoch: [98][0/1]	Time  0.942 ( 0.942)	Data  0.254 ( 0.254)	Loss 7.8682e-02 (7.8682e-02)	Acc@1   0.93 (  0.93)	Acc@5   0.00 (  0.00)
[0.9345020005251357]
Test: [0/1]	Time  0.261 ( 0.261)	Loss 9.4292e-01 (9.4292e-01)	Acc@1   0.71 (  0.71)	Acc@5   0.00 (  0.00)
 * Acc@1 0.707 Acc@5 0.000
Test: [0/1]	Time  0.327 ( 0.327)	Loss 1.3892e-01 (1.3892e-01)	Acc@1   0.72 (  0.72)	Acc@5   0.00 (  0.00)
 * Acc@1 0.716 Acc@5 0.000
99
TRAINING
Epoch: [99][0/1]	Time  0.960 ( 0.960)	Data  0.249 ( 0.249)	Loss 7.8666e-02 (7.8666e-02)	Acc@1   0.93 (  0.93)	Acc@5   0.00 (  0.00)
[0.9346197831003007]
Test: [0/1]	Time  0.259 ( 0.259)	Loss 9.4284e-01 (9.4284e-01)	Acc@1   0.71 (  0.71)	Acc@5   0.00 (  0.00)
 * Acc@1 0.707 Acc@5 0.000
Test: [0/1]	Time  0.323 ( 0.323)	Loss 1.3893e-01 (1.3893e-01)	Acc@1   0.72 (  0.72)	Acc@5   0.00 (  0.00)
 * Acc@1 0.716 Acc@5 0.000
=> using pre-trained model 'st_resnet'
s/ohp/session_1
torch.Size([640, 3, 224, 224])
(640, 22)
attach reg
0
TRAINING
/home/helenr6/Adv_mapper/train_split.py:125: UserWarning: You have chosen to seed training. This will turn on the CUDNN deterministic setting, which can slow down your training considerably! You may see unexpected behavior when restarting from checkpoints.
  warnings.warn('You have chosen to seed training. '
/localscratch/helenr6.6279052.0/env/lib/python3.7/site-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  cpuset_checked))
Epoch: [0][0/1]	Time  4.995 ( 4.995)	Data  1.634 ( 1.634)	Loss 1.8449e+00 (1.8449e+00)	Acc@1   0.00 (  0.00)	Acc@5   0.00 (  0.00)
[0.002728525319208976]
Test: [0/1]	Time  0.412 ( 0.412)	Loss 1.2853e+00 (1.2853e+00)	Acc@1  -0.11 ( -0.11)	Acc@5   0.00 (  0.00)
 * Acc@1 -0.111 Acc@5 0.000
Test: [0/1]	Time  0.528 ( 0.528)	Loss 1.0653e+00 (1.0653e+00)	Acc@1   0.01 (  0.01)	Acc@5   0.00 (  0.00)
 * Acc@1 0.012 Acc@5 0.000
1
TRAINING
Epoch: [1][0/1]	Time  0.926 ( 0.926)	Data  0.230 ( 0.230)	Loss 1.7437e+00 (1.7437e+00)	Acc@1   0.01 (  0.01)	Acc@5   0.00 (  0.00)
[0.006200509625586383]
Test: [0/1]	Time  0.220 ( 0.220)	Loss 1.2938e+00 (1.2938e+00)	Acc@1  -0.10 ( -0.10)	Acc@5   0.00 (  0.00)
 * Acc@1 -0.103 Acc@5 0.000
Test: [0/1]	Time  0.271 ( 0.271)	Loss 9.6500e-01 (9.6500e-01)	Acc@1   0.03 (  0.03)	Acc@5   0.00 (  0.00)
 * Acc@1 0.030 Acc@5 0.000
2
TRAINING
Epoch: [2][0/1]	Time  0.942 ( 0.942)	Data  0.226 ( 0.226)	Loss 1.5931e+00 (1.5931e+00)	Acc@1   0.01 (  0.01)	Acc@5   0.00 (  0.00)
[0.012050391965720053]
Test: [0/1]	Time  0.224 ( 0.224)	Loss 1.3046e+00 (1.3046e+00)	Acc@1  -0.09 ( -0.09)	Acc@5   0.00 (  0.00)
 * Acc@1 -0.095 Acc@5 0.000
Test: [0/1]	Time  0.270 ( 0.270)	Loss 8.7398e-01 (8.7398e-01)	Acc@1   0.04 (  0.04)	Acc@5   0.00 (  0.00)
 * Acc@1 0.038 Acc@5 0.000
3
TRAINING
Epoch: [3][0/1]	Time  0.933 ( 0.933)	Data  0.225 ( 0.225)	Loss 1.4514e+00 (1.4514e+00)	Acc@1   0.03 (  0.03)	Acc@5   0.00 (  0.00)
[0.031815476770913856]
Test: [0/1]	Time  0.222 ( 0.222)	Loss 1.3166e+00 (1.3166e+00)	Acc@1  -0.07 ( -0.07)	Acc@5   0.00 (  0.00)
 * Acc@1 -0.070 Acc@5 0.000
Test: [0/1]	Time  0.272 ( 0.272)	Loss 8.1740e-01 (8.1740e-01)	Acc@1   0.05 (  0.05)	Acc@5   0.00 (  0.00)
 * Acc@1 0.047 Acc@5 0.000
4
TRAINING
Epoch: [4][0/1]	Time  0.946 ( 0.946)	Data  0.253 ( 0.253)	Loss 1.3512e+00 (1.3512e+00)	Acc@1   0.04 (  0.04)	Acc@5   0.00 (  0.00)
[0.042346832453407035]
Test: [0/1]	Time  0.231 ( 0.231)	Loss 1.3260e+00 (1.3260e+00)	Acc@1  -0.05 ( -0.05)	Acc@5   0.00 (  0.00)
 * Acc@1 -0.052 Acc@5 0.000
Test: [0/1]	Time  0.286 ( 0.286)	Loss 7.9510e-01 (7.9510e-01)	Acc@1   0.05 (  0.05)	Acc@5   0.00 (  0.00)
 * Acc@1 0.054 Acc@5 0.000
5
TRAINING
Epoch: [5][0/1]	Time  0.947 ( 0.947)	Data  0.241 ( 0.241)	Loss 1.2884e+00 (1.2884e+00)	Acc@1   0.05 (  0.05)	Acc@5   0.00 (  0.00)
[0.053482178472432654]
Test: [0/1]	Time  0.228 ( 0.228)	Loss 1.3281e+00 (1.3281e+00)	Acc@1  -0.03 ( -0.03)	Acc@5   0.00 (  0.00)
 * Acc@1 -0.032 Acc@5 0.000
Test: [0/1]	Time  0.277 ( 0.277)	Loss 7.8742e-01 (7.8742e-01)	Acc@1   0.06 (  0.06)	Acc@5   0.00 (  0.00)
 * Acc@1 0.062 Acc@5 0.000
6
TRAINING
Epoch: [6][0/1]	Time  0.941 ( 0.941)	Data  0.244 ( 0.244)	Loss 1.2344e+00 (1.2344e+00)	Acc@1   0.06 (  0.06)	Acc@5   0.00 (  0.00)
[0.06452892722440619]
Test: [0/1]	Time  0.247 ( 0.247)	Loss 1.3190e+00 (1.3190e+00)	Acc@1  -0.01 ( -0.01)	Acc@5   0.00 (  0.00)
 * Acc@1 -0.012 Acc@5 0.000
Test: [0/1]	Time  0.286 ( 0.286)	Loss 7.7098e-01 (7.7098e-01)	Acc@1   0.07 (  0.07)	Acc@5   0.00 (  0.00)
 * Acc@1 0.070 Acc@5 0.000
7
TRAINING
Epoch: [7][0/1]	Time  0.923 ( 0.923)	Data  0.237 ( 0.237)	Loss 1.1591e+00 (1.1591e+00)	Acc@1   0.08 (  0.08)	Acc@5   0.00 (  0.00)
[0.07664796712983538]
Test: [0/1]	Time  0.227 ( 0.227)	Loss 1.2978e+00 (1.2978e+00)	Acc@1  -0.01 ( -0.01)	Acc@5   0.00 (  0.00)
 * Acc@1 -0.007 Acc@5 0.000
Test: [0/1]	Time  0.284 ( 0.284)	Loss 7.3375e-01 (7.3375e-01)	Acc@1   0.08 (  0.08)	Acc@5   0.00 (  0.00)
 * Acc@1 0.084 Acc@5 0.000
8
TRAINING
Epoch: [8][0/1]	Time  0.940 ( 0.940)	Data  0.240 ( 0.240)	Loss 1.0504e+00 (1.0504e+00)	Acc@1   0.09 (  0.09)	Acc@5   0.00 (  0.00)
[0.09302516742822164]
Test: [0/1]	Time  0.233 ( 0.233)	Loss 1.2673e+00 (1.2673e+00)	Acc@1   0.01 (  0.01)	Acc@5   0.00 (  0.00)
 * Acc@1 0.013 Acc@5 0.000
Test: [0/1]	Time  0.283 ( 0.283)	Loss 6.8050e-01 (6.8050e-01)	Acc@1   0.10 (  0.10)	Acc@5   0.00 (  0.00)
 * Acc@1 0.099 Acc@5 0.000
9
TRAINING
Epoch: [9][0/1]	Time  0.955 ( 0.955)	Data  0.255 ( 0.255)	Loss 9.1908e-01 (9.1908e-01)	Acc@1   0.11 (  0.11)	Acc@5   0.00 (  0.00)
[0.11083816236685862]
Test: [0/1]	Time  0.229 ( 0.229)	Loss 1.2327e+00 (1.2327e+00)	Acc@1   0.03 (  0.03)	Acc@5   0.00 (  0.00)
 * Acc@1 0.035 Acc@5 0.000
Test: [0/1]	Time  0.281 ( 0.281)	Loss 6.2707e-01 (6.2707e-01)	Acc@1   0.11 (  0.11)	Acc@5   0.00 (  0.00)
 * Acc@1 0.115 Acc@5 0.000
10
TRAINING
Epoch: [10][0/1]	Time  0.938 ( 0.938)	Data  0.228 ( 0.228)	Loss 7.8938e-01 (7.8938e-01)	Acc@1   0.14 (  0.14)	Acc@5   0.00 (  0.00)
[0.1369001471370192]
Test: [0/1]	Time  0.219 ( 0.219)	Loss 1.1991e+00 (1.1991e+00)	Acc@1   0.05 (  0.05)	Acc@5   0.00 (  0.00)
 * Acc@1 0.055 Acc@5 0.000
Test: [0/1]	Time  0.272 ( 0.272)	Loss 5.8873e-01 (5.8873e-01)	Acc@1   0.13 (  0.13)	Acc@5   0.00 (  0.00)
 * Acc@1 0.132 Acc@5 0.000
11
TRAINING
Epoch: [11][0/1]	Time  0.950 ( 0.950)	Data  0.240 ( 0.240)	Loss 6.8311e-01 (6.8311e-01)	Acc@1   0.17 (  0.17)	Acc@5   0.00 (  0.00)
[0.1655052509615496]
Test: [0/1]	Time  0.225 ( 0.225)	Loss 1.1700e+00 (1.1700e+00)	Acc@1   0.10 (  0.10)	Acc@5   0.00 (  0.00)
 * Acc@1 0.104 Acc@5 0.000
Test: [0/1]	Time  0.278 ( 0.278)	Loss 5.7041e-01 (5.7041e-01)	Acc@1   0.15 (  0.15)	Acc@5   0.00 (  0.00)
 * Acc@1 0.151 Acc@5 0.000
12
TRAINING
Epoch: [12][0/1]	Time  0.971 ( 0.971)	Data  0.278 ( 0.278)	Loss 6.0810e-01 (6.0810e-01)	Acc@1   0.20 (  0.20)	Acc@5   0.00 (  0.00)
[0.19930754188208483]
Test: [0/1]	Time  0.222 ( 0.222)	Loss 1.1465e+00 (1.1465e+00)	Acc@1   0.13 (  0.13)	Acc@5   0.00 (  0.00)
 * Acc@1 0.135 Acc@5 0.000
Test: [0/1]	Time  0.274 ( 0.274)	Loss 5.6457e-01 (5.6457e-01)	Acc@1   0.16 (  0.16)	Acc@5   0.00 (  0.00)
 * Acc@1 0.163 Acc@5 0.000
13
TRAINING
Epoch: [13][0/1]	Time  0.988 ( 0.988)	Data  0.288 ( 0.288)	Loss 5.5647e-01 (5.5647e-01)	Acc@1   0.24 (  0.24)	Acc@5   0.00 (  0.00)
[0.23686561269216536]
Test: [0/1]	Time  0.224 ( 0.224)	Loss 1.1274e+00 (1.1274e+00)	Acc@1   0.19 (  0.19)	Acc@5   0.00 (  0.00)
 * Acc@1 0.185 Acc@5 0.000
Test: [0/1]	Time  0.275 ( 0.275)	Loss 5.5674e-01 (5.5674e-01)	Acc@1   0.18 (  0.18)	Acc@5   0.00 (  0.00)
 * Acc@1 0.179 Acc@5 0.000
14
TRAINING
Epoch: [14][0/1]	Time  1.007 ( 1.007)	Data  0.304 ( 0.304)	Loss 5.1215e-01 (5.1215e-01)	Acc@1   0.28 (  0.28)	Acc@5   0.00 (  0.00)
[0.2779058534190457]
Test: [0/1]	Time  0.230 ( 0.230)	Loss 1.1113e+00 (1.1113e+00)	Acc@1   0.24 (  0.24)	Acc@5   0.00 (  0.00)
 * Acc@1 0.238 Acc@5 0.000
Test: [0/1]	Time  0.281 ( 0.281)	Loss 5.3468e-01 (5.3468e-01)	Acc@1   0.19 (  0.19)	Acc@5   0.00 (  0.00)
 * Acc@1 0.187 Acc@5 0.000
15
TRAINING
Epoch: [15][0/1]	Time  0.945 ( 0.945)	Data  0.245 ( 0.245)	Loss 4.6151e-01 (4.6151e-01)	Acc@1   0.33 (  0.33)	Acc@5   0.00 (  0.00)
[0.3311770985976133]
Test: [0/1]	Time  0.225 ( 0.225)	Loss 1.0970e+00 (1.0970e+00)	Acc@1   0.27 (  0.27)	Acc@5   0.00 (  0.00)
 * Acc@1 0.272 Acc@5 0.000
Test: [0/1]	Time  0.277 ( 0.277)	Loss 4.9516e-01 (4.9516e-01)	Acc@1   0.20 (  0.20)	Acc@5   0.00 (  0.00)
 * Acc@1 0.196 Acc@5 0.000
16
TRAINING
Epoch: [16][0/1]	Time  0.944 ( 0.944)	Data  0.239 ( 0.239)	Loss 4.0064e-01 (4.0064e-01)	Acc@1   0.38 (  0.38)	Acc@5   0.00 (  0.00)
[0.3794635274356828]
Test: [0/1]	Time  0.224 ( 0.224)	Loss 1.0842e+00 (1.0842e+00)	Acc@1   0.29 (  0.29)	Acc@5   0.00 (  0.00)
 * Acc@1 0.285 Acc@5 0.000
Test: [0/1]	Time  0.279 ( 0.279)	Loss 4.4462e-01 (4.4462e-01)	Acc@1   0.21 (  0.21)	Acc@5   0.00 (  0.00)
 * Acc@1 0.213 Acc@5 0.000
17
TRAINING
Epoch: [17][0/1]	Time  0.946 ( 0.946)	Data  0.248 ( 0.248)	Loss 3.3561e-01 (3.3561e-01)	Acc@1   0.43 (  0.43)	Acc@5   0.00 (  0.00)
[0.4278275335884951]
Test: [0/1]	Time  0.228 ( 0.228)	Loss 1.0732e+00 (1.0732e+00)	Acc@1   0.28 (  0.28)	Acc@5   0.00 (  0.00)
 * Acc@1 0.281 Acc@5 0.000
Test: [0/1]	Time  0.278 ( 0.278)	Loss 3.9448e-01 (3.9448e-01)	Acc@1   0.23 (  0.23)	Acc@5   0.00 (  0.00)
 * Acc@1 0.232 Acc@5 0.000
18
TRAINING
Epoch: [18][0/1]	Time  0.938 ( 0.938)	Data  0.244 ( 0.244)	Loss 2.7702e-01 (2.7702e-01)	Acc@1   0.47 (  0.47)	Acc@5   0.00 (  0.00)
[0.4729947244906717]
Test: [0/1]	Time  0.229 ( 0.229)	Loss 1.0639e+00 (1.0639e+00)	Acc@1   0.28 (  0.28)	Acc@5   0.00 (  0.00)
 * Acc@1 0.276 Acc@5 0.000
Test: [0/1]	Time  0.277 ( 0.277)	Loss 3.5435e-01 (3.5435e-01)	Acc@1   0.25 (  0.25)	Acc@5   0.00 (  0.00)
 * Acc@1 0.252 Acc@5 0.000
19
TRAINING
Epoch: [19][0/1]	Time  0.939 ( 0.939)	Data  0.238 ( 0.238)	Loss 2.3300e-01 (2.3300e-01)	Acc@1   0.52 (  0.52)	Acc@5   0.00 (  0.00)
[0.517563742458139]
Test: [0/1]	Time  0.226 ( 0.226)	Loss 1.0558e+00 (1.0558e+00)	Acc@1   0.31 (  0.31)	Acc@5   0.00 (  0.00)
 * Acc@1 0.314 Acc@5 0.000
Test: [0/1]	Time  0.278 ( 0.278)	Loss 3.2744e-01 (3.2744e-01)	Acc@1   0.27 (  0.27)	Acc@5   0.00 (  0.00)
 * Acc@1 0.272 Acc@5 0.000
20
TRAINING
Epoch: [20][0/1]	Time  0.956 ( 0.956)	Data  0.241 ( 0.241)	Loss 2.0490e-01 (2.0490e-01)	Acc@1   0.56 (  0.56)	Acc@5   0.00 (  0.00)
[0.5620848322898981]
Test: [0/1]	Time  0.228 ( 0.228)	Loss 1.0478e+00 (1.0478e+00)	Acc@1   0.38 (  0.38)	Acc@5   0.00 (  0.00)
 * Acc@1 0.376 Acc@5 0.000
Test: [0/1]	Time  0.277 ( 0.277)	Loss 3.1033e-01 (3.1033e-01)	Acc@1   0.29 (  0.29)	Acc@5   0.00 (  0.00)
 * Acc@1 0.291 Acc@5 0.000
21
TRAINING
Epoch: [21][0/1]	Time  0.949 ( 0.949)	Data  0.236 ( 0.236)	Loss 1.8770e-01 (1.8770e-01)	Acc@1   0.60 (  0.60)	Acc@5   0.00 (  0.00)
[0.6045832079854072]
Test: [0/1]	Time  0.225 ( 0.225)	Loss 1.0386e+00 (1.0386e+00)	Acc@1   0.44 (  0.44)	Acc@5   0.00 (  0.00)
 * Acc@1 0.436 Acc@5 0.000
Test: [0/1]	Time  0.275 ( 0.275)	Loss 2.9652e-01 (2.9652e-01)	Acc@1   0.31 (  0.31)	Acc@5   0.00 (  0.00)
 * Acc@1 0.315 Acc@5 0.000
22
TRAINING
Epoch: [22][0/1]	Time  0.929 ( 0.929)	Data  0.230 ( 0.230)	Loss 1.7384e-01 (1.7384e-01)	Acc@1   0.64 (  0.64)	Acc@5   0.00 (  0.00)
[0.6426652758651309]
Test: [0/1]	Time  0.250 ( 0.250)	Loss 1.0278e+00 (1.0278e+00)	Acc@1   0.49 (  0.49)	Acc@5   0.00 (  0.00)
 * Acc@1 0.486 Acc@5 0.000
Test: [0/1]	Time  0.323 ( 0.323)	Loss 2.8088e-01 (2.8088e-01)	Acc@1   0.34 (  0.34)	Acc@5   0.00 (  0.00)
 * Acc@1 0.339 Acc@5 0.000
23
TRAINING
Epoch: [23][0/1]	Time  0.951 ( 0.951)	Data  0.253 ( 0.253)	Loss 1.5786e-01 (1.5786e-01)	Acc@1   0.68 (  0.68)	Acc@5   0.00 (  0.00)
[0.6780259679058739]
Test: [0/1]	Time  0.233 ( 0.233)	Loss 1.0156e+00 (1.0156e+00)	Acc@1   0.53 (  0.53)	Acc@5   0.00 (  0.00)
 * Acc@1 0.528 Acc@5 0.000
Test: [0/1]	Time  0.285 ( 0.285)	Loss 2.6232e-01 (2.6232e-01)	Acc@1   0.36 (  0.36)	Acc@5   0.00 (  0.00)
 * Acc@1 0.363 Acc@5 0.000
24
TRAINING
Epoch: [24][0/1]	Time  0.956 ( 0.956)	Data  0.254 ( 0.254)	Loss 1.3880e-01 (1.3880e-01)	Acc@1   0.71 (  0.71)	Acc@5   0.00 (  0.00)
[0.7105656615988583]
Test: [0/1]	Time  0.232 ( 0.232)	Loss 1.0030e+00 (1.0030e+00)	Acc@1   0.56 (  0.56)	Acc@5   0.00 (  0.00)
 * Acc@1 0.563 Acc@5 0.000
Test: [0/1]	Time  0.282 ( 0.282)	Loss 2.4352e-01 (2.4352e-01)	Acc@1   0.39 (  0.39)	Acc@5   0.00 (  0.00)
 * Acc@1 0.386 Acc@5 0.000
25
TRAINING
Epoch: [25][0/1]	Time  0.985 ( 0.985)	Data  0.275 ( 0.275)	Loss 1.1967e-01 (1.1967e-01)	Acc@1   0.74 (  0.74)	Acc@5   0.00 (  0.00)
[0.7411956540448938]
Test: [0/1]	Time  0.244 ( 0.244)	Loss 9.9107e-01 (9.9107e-01)	Acc@1   0.59 (  0.59)	Acc@5   0.00 (  0.00)
 * Acc@1 0.593 Acc@5 0.000
Test: [0/1]	Time  0.294 ( 0.294)	Loss 2.2836e-01 (2.2836e-01)	Acc@1   0.41 (  0.41)	Acc@5   0.00 (  0.00)
 * Acc@1 0.408 Acc@5 0.000
26
TRAINING
Epoch: [26][0/1]	Time  0.952 ( 0.952)	Data  0.239 ( 0.239)	Loss 1.0460e-01 (1.0460e-01)	Acc@1   0.77 (  0.77)	Acc@5   0.00 (  0.00)
[0.7716312640131074]
Test: [0/1]	Time  0.239 ( 0.239)	Loss 9.8072e-01 (9.8072e-01)	Acc@1   0.62 (  0.62)	Acc@5   0.00 (  0.00)
 * Acc@1 0.619 Acc@5 0.000
Test: [0/1]	Time  0.284 ( 0.284)	Loss 2.1908e-01 (2.1908e-01)	Acc@1   0.43 (  0.43)	Acc@5   0.00 (  0.00)
 * Acc@1 0.429 Acc@5 0.000
27
TRAINING
Epoch: [27][0/1]	Time  0.928 ( 0.928)	Data  0.239 ( 0.239)	Loss 9.6050e-02 (9.6050e-02)	Acc@1   0.80 (  0.80)	Acc@5   0.00 (  0.00)
[0.7958603514952357]
Test: [0/1]	Time  0.232 ( 0.232)	Loss 9.7226e-01 (9.7226e-01)	Acc@1   0.64 (  0.64)	Acc@5   0.00 (  0.00)
 * Acc@1 0.642 Acc@5 0.000
Test: [0/1]	Time  0.285 ( 0.285)	Loss 2.1491e-01 (2.1491e-01)	Acc@1   0.45 (  0.45)	Acc@5   0.00 (  0.00)
 * Acc@1 0.454 Acc@5 0.000
28
TRAINING
Epoch: [28][0/1]	Time  0.948 ( 0.948)	Data  0.256 ( 0.256)	Loss 9.3415e-02 (9.3415e-02)	Acc@1   0.82 (  0.82)	Acc@5   0.00 (  0.00)
[0.8160660467193623]
Test: [0/1]	Time  0.229 ( 0.229)	Loss 9.6551e-01 (9.6551e-01)	Acc@1   0.66 (  0.66)	Acc@5   0.00 (  0.00)
 * Acc@1 0.658 Acc@5 0.000
Test: [0/1]	Time  0.283 ( 0.283)	Loss 2.1271e-01 (2.1271e-01)	Acc@1   0.48 (  0.48)	Acc@5   0.00 (  0.00)
 * Acc@1 0.480 Acc@5 0.000
29
TRAINING
Epoch: [29][0/1]	Time  0.961 ( 0.961)	Data  0.252 ( 0.252)	Loss 9.3722e-02 (9.3722e-02)	Acc@1   0.83 (  0.83)	Acc@5   0.00 (  0.00)
[0.8319198860048332]
Test: [0/1]	Time  0.233 ( 0.233)	Loss 9.6003e-01 (9.6003e-01)	Acc@1   0.67 (  0.67)	Acc@5   0.00 (  0.00)
 * Acc@1 0.672 Acc@5 0.000
Test: [0/1]	Time  0.286 ( 0.286)	Loss 2.0901e-01 (2.0901e-01)	Acc@1   0.51 (  0.51)	Acc@5   0.00 (  0.00)
 * Acc@1 0.506 Acc@5 0.000
30
TRAINING
Epoch: [30][0/1]	Time  0.943 ( 0.943)	Data  0.245 ( 0.245)	Loss 9.3588e-02 (9.3588e-02)	Acc@1   0.85 (  0.85)	Acc@5   0.00 (  0.00)
[0.8455461702535172]
Test: [0/1]	Time  0.232 ( 0.232)	Loss 9.5546e-01 (9.5546e-01)	Acc@1   0.68 (  0.68)	Acc@5   0.00 (  0.00)
 * Acc@1 0.684 Acc@5 0.000
Test: [0/1]	Time  0.277 ( 0.277)	Loss 2.0190e-01 (2.0190e-01)	Acc@1   0.53 (  0.53)	Acc@5   0.00 (  0.00)
 * Acc@1 0.527 Acc@5 0.000
31
TRAINING
Epoch: [31][0/1]	Time  0.952 ( 0.952)	Data  0.242 ( 0.242)	Loss 9.1076e-02 (9.1076e-02)	Acc@1   0.86 (  0.86)	Acc@5   0.00 (  0.00)
[0.8555612409145967]
Test: [0/1]	Time  0.253 ( 0.253)	Loss 9.5164e-01 (9.5164e-01)	Acc@1   0.69 (  0.69)	Acc@5   0.00 (  0.00)
 * Acc@1 0.692 Acc@5 0.000
Test: [0/1]	Time  0.306 ( 0.306)	Loss 1.9182e-01 (1.9182e-01)	Acc@1   0.55 (  0.55)	Acc@5   0.00 (  0.00)
 * Acc@1 0.548 Acc@5 0.000
32
TRAINING
Epoch: [32][0/1]	Time  0.958 ( 0.958)	Data  0.252 ( 0.252)	Loss 8.6413e-02 (8.6413e-02)	Acc@1   0.86 (  0.86)	Acc@5   0.00 (  0.00)
[0.8646871408553303]
Test: [0/1]	Time  0.236 ( 0.236)	Loss 9.4853e-01 (9.4853e-01)	Acc@1   0.70 (  0.70)	Acc@5   0.00 (  0.00)
 * Acc@1 0.697 Acc@5 0.000
Test: [0/1]	Time  0.285 ( 0.285)	Loss 1.8093e-01 (1.8093e-01)	Acc@1   0.57 (  0.57)	Acc@5   0.00 (  0.00)
 * Acc@1 0.569 Acc@5 0.000
33
TRAINING
Epoch: [33][0/1]	Time  0.960 ( 0.960)	Data  0.247 ( 0.247)	Loss 8.1374e-02 (8.1374e-02)	Acc@1   0.87 (  0.87)	Acc@5   0.00 (  0.00)
[0.8700694330533029]
Test: [0/1]	Time  0.230 ( 0.230)	Loss 9.4616e-01 (9.4616e-01)	Acc@1   0.70 (  0.70)	Acc@5   0.00 (  0.00)
 * Acc@1 0.698 Acc@5 0.000
Test: [0/1]	Time  0.281 ( 0.281)	Loss 1.7164e-01 (1.7164e-01)	Acc@1   0.59 (  0.59)	Acc@5   0.00 (  0.00)
 * Acc@1 0.588 Acc@5 0.000
34
TRAINING
Epoch: [34][0/1]	Time  0.954 ( 0.954)	Data  0.256 ( 0.256)	Loss 7.7920e-02 (7.7920e-02)	Acc@1   0.87 (  0.87)	Acc@5   0.00 (  0.00)
[0.873477750799943]
Test: [0/1]	Time  0.230 ( 0.230)	Loss 9.4442e-01 (9.4442e-01)	Acc@1   0.70 (  0.70)	Acc@5   0.00 (  0.00)
 * Acc@1 0.698 Acc@5 0.000
Test: [0/1]	Time  0.286 ( 0.286)	Loss 1.6535e-01 (1.6535e-01)	Acc@1   0.61 (  0.61)	Acc@5   0.00 (  0.00)
 * Acc@1 0.606 Acc@5 0.000
35
TRAINING
Epoch: [35][0/1]	Time  0.956 ( 0.956)	Data  0.255 ( 0.255)	Loss 7.7011e-02 (7.7011e-02)	Acc@1   0.87 (  0.87)	Acc@5   0.00 (  0.00)
[0.8732311510067741]
Test: [0/1]	Time  0.231 ( 0.231)	Loss 9.4308e-01 (9.4308e-01)	Acc@1   0.70 (  0.70)	Acc@5   0.00 (  0.00)
 * Acc@1 0.697 Acc@5 0.000
Test: [0/1]	Time  0.286 ( 0.286)	Loss 1.6191e-01 (1.6191e-01)	Acc@1   0.62 (  0.62)	Acc@5   0.00 (  0.00)
 * Acc@1 0.619 Acc@5 0.000
36
TRAINING
Epoch: [36][0/1]	Time  0.948 ( 0.948)	Data  0.235 ( 0.235)	Loss 7.8215e-02 (7.8215e-02)	Acc@1   0.87 (  0.87)	Acc@5   0.00 (  0.00)
[0.8735112586379509]
Test: [0/1]	Time  0.236 ( 0.236)	Loss 9.4185e-01 (9.4185e-01)	Acc@1   0.70 (  0.70)	Acc@5   0.00 (  0.00)
 * Acc@1 0.697 Acc@5 0.000
Test: [0/1]	Time  0.291 ( 0.291)	Loss 1.6018e-01 (1.6018e-01)	Acc@1   0.63 (  0.63)	Acc@5   0.00 (  0.00)
 * Acc@1 0.632 Acc@5 0.000
37
TRAINING
Epoch: [37][0/1]	Time  0.946 ( 0.946)	Data  0.249 ( 0.249)	Loss 8.0197e-02 (8.0197e-02)	Acc@1   0.87 (  0.87)	Acc@5   0.00 (  0.00)
[0.8739952836315164]
Test: [0/1]	Time  0.248 ( 0.248)	Loss 9.4050e-01 (9.4050e-01)	Acc@1   0.70 (  0.70)	Acc@5   0.00 (  0.00)
 * Acc@1 0.698 Acc@5 0.000
Test: [0/1]	Time  0.299 ( 0.299)	Loss 1.5889e-01 (1.5889e-01)	Acc@1   0.64 (  0.64)	Acc@5   0.00 (  0.00)
 * Acc@1 0.643 Acc@5 0.000
38
TRAINING
Epoch: [38][0/1]	Time  0.977 ( 0.977)	Data  0.266 ( 0.266)	Loss 8.1618e-02 (8.1618e-02)	Acc@1   0.87 (  0.87)	Acc@5   0.00 (  0.00)
[0.8743850985161294]
Test: [0/1]	Time  0.232 ( 0.232)	Loss 9.3894e-01 (9.3894e-01)	Acc@1   0.70 (  0.70)	Acc@5   0.00 (  0.00)
 * Acc@1 0.701 Acc@5 0.000
Test: [0/1]	Time  0.284 ( 0.284)	Loss 1.5739e-01 (1.5739e-01)	Acc@1   0.65 (  0.65)	Acc@5   0.00 (  0.00)
 * Acc@1 0.652 Acc@5 0.000
39
TRAINING
Epoch: [39][0/1]	Time  0.930 ( 0.930)	Data  0.241 ( 0.241)	Loss 8.1867e-02 (8.1867e-02)	Acc@1   0.87 (  0.87)	Acc@5   0.00 (  0.00)
[0.8746782584529821]
Test: [0/1]	Time  0.235 ( 0.235)	Loss 9.3724e-01 (9.3724e-01)	Acc@1   0.70 (  0.70)	Acc@5   0.00 (  0.00)
 * Acc@1 0.705 Acc@5 0.000
Test: [0/1]	Time  0.290 ( 0.290)	Loss 1.5586e-01 (1.5586e-01)	Acc@1   0.66 (  0.66)	Acc@5   0.00 (  0.00)
 * Acc@1 0.664 Acc@5 0.000
40
TRAINING
Epoch: [40][0/1]	Time  0.946 ( 0.946)	Data  0.250 ( 0.250)	Loss 8.1230e-02 (8.1230e-02)	Acc@1   0.87 (  0.87)	Acc@5   0.00 (  0.00)
[0.8748778158239631]
Test: [0/1]	Time  0.241 ( 0.241)	Loss 9.3556e-01 (9.3556e-01)	Acc@1   0.71 (  0.71)	Acc@5   0.00 (  0.00)
 * Acc@1 0.710 Acc@5 0.000
Test: [0/1]	Time  0.298 ( 0.298)	Loss 1.5495e-01 (1.5495e-01)	Acc@1   0.67 (  0.67)	Acc@5   0.00 (  0.00)
 * Acc@1 0.674 Acc@5 0.000
41
TRAINING
Epoch: [41][0/1]	Time  0.949 ( 0.949)	Data  0.256 ( 0.256)	Loss 8.0508e-02 (8.0508e-02)	Acc@1   0.87 (  0.87)	Acc@5   0.00 (  0.00)
[0.8749347824119147]
Test: [0/1]	Time  0.243 ( 0.243)	Loss 9.3408e-01 (9.3408e-01)	Acc@1   0.72 (  0.72)	Acc@5   0.00 (  0.00)
 * Acc@1 0.716 Acc@5 0.000
Test: [0/1]	Time  0.291 ( 0.291)	Loss 1.5517e-01 (1.5517e-01)	Acc@1   0.68 (  0.68)	Acc@5   0.00 (  0.00)
 * Acc@1 0.679 Acc@5 0.000
42
TRAINING
Epoch: [42][0/1]	Time  0.931 ( 0.931)	Data  0.236 ( 0.236)	Loss 8.0423e-02 (8.0423e-02)	Acc@1   0.87 (  0.87)	Acc@5   0.00 (  0.00)
[0.8743021395269707]
Test: [0/1]	Time  0.236 ( 0.236)	Loss 9.3287e-01 (9.3287e-01)	Acc@1   0.72 (  0.72)	Acc@5   0.00 (  0.00)
 * Acc@1 0.721 Acc@5 0.000
Test: [0/1]	Time  0.286 ( 0.286)	Loss 1.5650e-01 (1.5650e-01)	Acc@1   0.68 (  0.68)	Acc@5   0.00 (  0.00)
 * Acc@1 0.682 Acc@5 0.000
43
TRAINING
Epoch: [43][0/1]	Time  0.930 ( 0.930)	Data  0.233 ( 0.233)	Loss 8.1179e-02 (8.1179e-02)	Acc@1   0.88 (  0.88)	Acc@5   0.00 (  0.00)
[0.875399177165811]
Test: [0/1]	Time  0.226 ( 0.226)	Loss 9.3195e-01 (9.3195e-01)	Acc@1   0.73 (  0.73)	Acc@5   0.00 (  0.00)
 * Acc@1 0.725 Acc@5 0.000
Test: [0/1]	Time  0.278 ( 0.278)	Loss 1.5833e-01 (1.5833e-01)	Acc@1   0.68 (  0.68)	Acc@5   0.00 (  0.00)
 * Acc@1 0.684 Acc@5 0.000
44
TRAINING
Epoch: [44][0/1]	Time  0.936 ( 0.936)	Data  0.234 ( 0.234)	Loss 8.2413e-02 (8.2413e-02)	Acc@1   0.88 (  0.88)	Acc@5   0.00 (  0.00)
[0.8774522117316752]
Test: [0/1]	Time  0.227 ( 0.227)	Loss 9.3129e-01 (9.3129e-01)	Acc@1   0.73 (  0.73)	Acc@5   0.00 (  0.00)
 * Acc@1 0.729 Acc@5 0.000
Test: [0/1]	Time  0.282 ( 0.282)	Loss 1.5984e-01 (1.5984e-01)	Acc@1   0.68 (  0.68)	Acc@5   0.00 (  0.00)
 * Acc@1 0.685 Acc@5 0.000
45
TRAINING
Epoch: [45][0/1]	Time  0.938 ( 0.938)	Data  0.242 ( 0.242)	Loss 8.3489e-02 (8.3489e-02)	Acc@1   0.88 (  0.88)	Acc@5   0.00 (  0.00)
[0.8796606386212199]
Test: [0/1]	Time  0.231 ( 0.231)	Loss 9.3085e-01 (9.3085e-01)	Acc@1   0.73 (  0.73)	Acc@5   0.00 (  0.00)
 * Acc@1 0.731 Acc@5 0.000
Test: [0/1]	Time  0.284 ( 0.284)	Loss 1.6042e-01 (1.6042e-01)	Acc@1   0.68 (  0.68)	Acc@5   0.00 (  0.00)
 * Acc@1 0.685 Acc@5 0.000
46
TRAINING
Epoch: [46][0/1]	Time  0.938 ( 0.938)	Data  0.240 ( 0.240)	Loss 8.3902e-02 (8.3902e-02)	Acc@1   0.88 (  0.88)	Acc@5   0.00 (  0.00)
[0.8824665569131018]
Test: [0/1]	Time  0.225 ( 0.225)	Loss 9.3065e-01 (9.3065e-01)	Acc@1   0.73 (  0.73)	Acc@5   0.00 (  0.00)
 * Acc@1 0.729 Acc@5 0.000
Test: [0/1]	Time  0.278 ( 0.278)	Loss 1.5995e-01 (1.5995e-01)	Acc@1   0.69 (  0.69)	Acc@5   0.00 (  0.00)
 * Acc@1 0.685 Acc@5 0.000
47
TRAINING
Epoch: [47][0/1]	Time  0.949 ( 0.949)	Data  0.237 ( 0.237)	Loss 8.3543e-02 (8.3543e-02)	Acc@1   0.89 (  0.89)	Acc@5   0.00 (  0.00)
[0.8858080062834721]
Test: [0/1]	Time  0.226 ( 0.226)	Loss 9.3069e-01 (9.3069e-01)	Acc@1   0.73 (  0.73)	Acc@5   0.00 (  0.00)
 * Acc@1 0.727 Acc@5 0.000
Test: [0/1]	Time  0.281 ( 0.281)	Loss 1.5875e-01 (1.5875e-01)	Acc@1   0.69 (  0.69)	Acc@5   0.00 (  0.00)
 * Acc@1 0.688 Acc@5 0.000
48
TRAINING
Epoch: [48][0/1]	Time  0.944 ( 0.944)	Data  0.238 ( 0.238)	Loss 8.2694e-02 (8.2694e-02)	Acc@1   0.89 (  0.89)	Acc@5   0.00 (  0.00)
[0.8895216567032674]
Test: [0/1]	Time  0.228 ( 0.228)	Loss 9.3097e-01 (9.3097e-01)	Acc@1   0.72 (  0.72)	Acc@5   0.00 (  0.00)
 * Acc@1 0.724 Acc@5 0.000
Test: [0/1]	Time  0.278 ( 0.278)	Loss 1.5741e-01 (1.5741e-01)	Acc@1   0.69 (  0.69)	Acc@5   0.00 (  0.00)
 * Acc@1 0.691 Acc@5 0.000
49
TRAINING
Epoch: [49][0/1]	Time  0.941 ( 0.941)	Data  0.243 ( 0.243)	Loss 8.1808e-02 (8.1808e-02)	Acc@1   0.89 (  0.89)	Acc@5   0.00 (  0.00)
[0.8932210302939748]
Test: [0/1]	Time  0.227 ( 0.227)	Loss 9.3147e-01 (9.3147e-01)	Acc@1   0.72 (  0.72)	Acc@5   0.00 (  0.00)
 * Acc@1 0.721 Acc@5 0.000
Test: [0/1]	Time  0.276 ( 0.276)	Loss 1.5639e-01 (1.5639e-01)	Acc@1   0.69 (  0.69)	Acc@5   0.00 (  0.00)
 * Acc@1 0.693 Acc@5 0.000
50
TRAINING
Epoch: [50][0/1]	Time  0.942 ( 0.942)	Data  0.228 ( 0.228)	Loss 8.1238e-02 (8.1238e-02)	Acc@1   0.90 (  0.90)	Acc@5   0.00 (  0.00)
[0.8969568623546103]
Test: [0/1]	Time  0.221 ( 0.221)	Loss 9.3212e-01 (9.3212e-01)	Acc@1   0.72 (  0.72)	Acc@5   0.00 (  0.00)
 * Acc@1 0.719 Acc@5 0.000
Test: [0/1]	Time  0.291 ( 0.291)	Loss 1.5589e-01 (1.5589e-01)	Acc@1   0.69 (  0.69)	Acc@5   0.00 (  0.00)
 * Acc@1 0.695 Acc@5 0.000
51
TRAINING
Epoch: [51][0/1]	Time  0.929 ( 0.929)	Data  0.234 ( 0.234)	Loss 8.1071e-02 (8.1071e-02)	Acc@1   0.90 (  0.90)	Acc@5   0.00 (  0.00)
[0.9006310516432028]
Test: [0/1]	Time  0.224 ( 0.224)	Loss 9.3281e-01 (9.3281e-01)	Acc@1   0.72 (  0.72)	Acc@5   0.00 (  0.00)
 * Acc@1 0.717 Acc@5 0.000
Test: [0/1]	Time  0.275 ( 0.275)	Loss 1.5585e-01 (1.5585e-01)	Acc@1   0.70 (  0.70)	Acc@5   0.00 (  0.00)
 * Acc@1 0.696 Acc@5 0.000
52
TRAINING
Epoch: [52][0/1]	Time  0.936 ( 0.936)	Data  0.243 ( 0.243)	Loss 8.1148e-02 (8.1148e-02)	Acc@1   0.90 (  0.90)	Acc@5   0.00 (  0.00)
[0.9042609393505999]
Test: [0/1]	Time  0.229 ( 0.229)	Loss 9.3346e-01 (9.3346e-01)	Acc@1   0.72 (  0.72)	Acc@5   0.00 (  0.00)
 * Acc@1 0.716 Acc@5 0.000
Test: [0/1]	Time  0.293 ( 0.293)	Loss 1.5604e-01 (1.5604e-01)	Acc@1   0.70 (  0.70)	Acc@5   0.00 (  0.00)
 * Acc@1 0.697 Acc@5 0.000
53
TRAINING
Epoch: [53][0/1]	Time  0.952 ( 0.952)	Data  0.245 ( 0.245)	Loss 8.1214e-02 (8.1214e-02)	Acc@1   0.91 (  0.91)	Acc@5   0.00 (  0.00)
[0.9075819197512136]
Test: [0/1]	Time  0.246 ( 0.246)	Loss 9.3400e-01 (9.3400e-01)	Acc@1   0.72 (  0.72)	Acc@5   0.00 (  0.00)
 * Acc@1 0.716 Acc@5 0.000
Test: [0/1]	Time  0.298 ( 0.298)	Loss 1.5630e-01 (1.5630e-01)	Acc@1   0.70 (  0.70)	Acc@5   0.00 (  0.00)
 * Acc@1 0.697 Acc@5 0.000
54
TRAINING
Epoch: [54][0/1]	Time  0.946 ( 0.946)	Data  0.271 ( 0.271)	Loss 8.1087e-02 (8.1087e-02)	Acc@1   0.91 (  0.91)	Acc@5   0.00 (  0.00)
[0.9108037565817917]
Test: [0/1]	Time  0.239 ( 0.239)	Loss 9.3443e-01 (9.3443e-01)	Acc@1   0.72 (  0.72)	Acc@5   0.00 (  0.00)
 * Acc@1 0.717 Acc@5 0.000
Test: [0/1]	Time  0.291 ( 0.291)	Loss 1.5657e-01 (1.5657e-01)	Acc@1   0.70 (  0.70)	Acc@5   0.00 (  0.00)
 * Acc@1 0.696 Acc@5 0.000
55
TRAINING
Epoch: [55][0/1]	Time  0.946 ( 0.946)	Data  0.254 ( 0.254)	Loss 8.0754e-02 (8.0754e-02)	Acc@1   0.91 (  0.91)	Acc@5   0.00 (  0.00)
[0.9138021104732672]
Test: [0/1]	Time  0.225 ( 0.225)	Loss 9.3477e-01 (9.3477e-01)	Acc@1   0.72 (  0.72)	Acc@5   0.00 (  0.00)
 * Acc@1 0.719 Acc@5 0.000
Test: [0/1]	Time  0.275 ( 0.275)	Loss 1.5692e-01 (1.5692e-01)	Acc@1   0.70 (  0.70)	Acc@5   0.00 (  0.00)
 * Acc@1 0.695 Acc@5 0.000
56
TRAINING
Epoch: [56][0/1]	Time  0.921 ( 0.921)	Data  0.247 ( 0.247)	Loss 8.0342e-02 (8.0342e-02)	Acc@1   0.92 (  0.92)	Acc@5   0.00 (  0.00)
[0.9162745113580861]
Test: [0/1]	Time  0.221 ( 0.221)	Loss 9.3510e-01 (9.3510e-01)	Acc@1   0.72 (  0.72)	Acc@5   0.00 (  0.00)
 * Acc@1 0.722 Acc@5 0.000
Test: [0/1]	Time  0.274 ( 0.274)	Loss 1.5744e-01 (1.5744e-01)	Acc@1   0.69 (  0.69)	Acc@5   0.00 (  0.00)
 * Acc@1 0.695 Acc@5 0.000
57
TRAINING
Epoch: [57][0/1]	Time  0.920 ( 0.920)	Data  0.246 ( 0.246)	Loss 8.0015e-02 (8.0015e-02)	Acc@1   0.92 (  0.92)	Acc@5   0.00 (  0.00)
[0.9184025779222916]
Test: [0/1]	Time  0.222 ( 0.222)	Loss 9.3546e-01 (9.3546e-01)	Acc@1   0.72 (  0.72)	Acc@5   0.00 (  0.00)
 * Acc@1 0.725 Acc@5 0.000
Test: [0/1]	Time  0.276 ( 0.276)	Loss 1.5811e-01 (1.5811e-01)	Acc@1   0.69 (  0.69)	Acc@5   0.00 (  0.00)
 * Acc@1 0.694 Acc@5 0.000
58
TRAINING
Epoch: [58][0/1]	Time  0.923 ( 0.923)	Data  0.247 ( 0.247)	Loss 7.9864e-02 (7.9864e-02)	Acc@1   0.92 (  0.92)	Acc@5   0.00 (  0.00)
[0.9202485148723474]
Test: [0/1]	Time  0.219 ( 0.219)	Loss 9.3590e-01 (9.3590e-01)	Acc@1   0.73 (  0.73)	Acc@5   0.00 (  0.00)
 * Acc@1 0.727 Acc@5 0.000
Test: [0/1]	Time  0.275 ( 0.275)	Loss 1.5884e-01 (1.5884e-01)	Acc@1   0.69 (  0.69)	Acc@5   0.00 (  0.00)
 * Acc@1 0.693 Acc@5 0.000
59
TRAINING
Epoch: [59][0/1]	Time  0.938 ( 0.938)	Data  0.245 ( 0.245)	Loss 7.9862e-02 (7.9862e-02)	Acc@1   0.92 (  0.92)	Acc@5   0.00 (  0.00)
[0.9218615413742421]
Test: [0/1]	Time  0.223 ( 0.223)	Loss 9.3644e-01 (9.3644e-01)	Acc@1   0.73 (  0.73)	Acc@5   0.00 (  0.00)
 * Acc@1 0.729 Acc@5 0.000
Test: [0/1]	Time  0.274 ( 0.274)	Loss 1.5943e-01 (1.5943e-01)	Acc@1   0.69 (  0.69)	Acc@5   0.00 (  0.00)
 * Acc@1 0.692 Acc@5 0.000
60
TRAINING
Epoch: [60][0/1]	Time  0.940 ( 0.940)	Data  0.226 ( 0.226)	Loss 7.9899e-02 (7.9899e-02)	Acc@1   0.92 (  0.92)	Acc@5   0.00 (  0.00)
[0.9233142569439667]
Test: [0/1]	Time  0.221 ( 0.221)	Loss 9.3710e-01 (9.3710e-01)	Acc@1   0.73 (  0.73)	Acc@5   0.00 (  0.00)
 * Acc@1 0.731 Acc@5 0.000
Test: [0/1]	Time  0.273 ( 0.273)	Loss 1.5972e-01 (1.5972e-01)	Acc@1   0.69 (  0.69)	Acc@5   0.00 (  0.00)
 * Acc@1 0.691 Acc@5 0.000
61
TRAINING
Epoch: [61][0/1]	Time  0.934 ( 0.934)	Data  0.239 ( 0.239)	Loss 7.9850e-02 (7.9850e-02)	Acc@1   0.92 (  0.92)	Acc@5   0.00 (  0.00)
[0.9246743308096849]
Test: [0/1]	Time  0.221 ( 0.221)	Loss 9.3785e-01 (9.3785e-01)	Acc@1   0.73 (  0.73)	Acc@5   0.00 (  0.00)
 * Acc@1 0.732 Acc@5 0.000
Test: [0/1]	Time  0.272 ( 0.272)	Loss 1.5966e-01 (1.5966e-01)	Acc@1   0.69 (  0.69)	Acc@5   0.00 (  0.00)
 * Acc@1 0.690 Acc@5 0.000
62
TRAINING
Epoch: [62][0/1]	Time  0.914 ( 0.914)	Data  0.239 ( 0.239)	Loss 7.9653e-02 (7.9653e-02)	Acc@1   0.93 (  0.93)	Acc@5   0.00 (  0.00)
[0.925980829446782]
Test: [0/1]	Time  0.221 ( 0.221)	Loss 9.3870e-01 (9.3870e-01)	Acc@1   0.73 (  0.73)	Acc@5   0.00 (  0.00)
 * Acc@1 0.732 Acc@5 0.000
Test: [0/1]	Time  0.273 ( 0.273)	Loss 1.5927e-01 (1.5927e-01)	Acc@1   0.69 (  0.69)	Acc@5   0.00 (  0.00)
 * Acc@1 0.690 Acc@5 0.000
63
TRAINING
Epoch: [63][0/1]	Time  0.908 ( 0.908)	Data  0.235 ( 0.235)	Loss 7.9333e-02 (7.9333e-02)	Acc@1   0.93 (  0.93)	Acc@5   0.00 (  0.00)
[0.9268092451410671]
Test: [0/1]	Time  0.220 ( 0.220)	Loss 9.3960e-01 (9.3960e-01)	Acc@1   0.73 (  0.73)	Acc@5   0.00 (  0.00)
 * Acc@1 0.732 Acc@5 0.000
Test: [0/1]	Time  0.274 ( 0.274)	Loss 1.5870e-01 (1.5870e-01)	Acc@1   0.69 (  0.69)	Acc@5   0.00 (  0.00)
 * Acc@1 0.689 Acc@5 0.000
64
TRAINING
Epoch: [64][0/1]	Time  0.934 ( 0.934)	Data  0.260 ( 0.260)	Loss 7.8972e-02 (7.8972e-02)	Acc@1   0.93 (  0.93)	Acc@5   0.00 (  0.00)
[0.927360918690568]
Test: [0/1]	Time  0.220 ( 0.220)	Loss 9.4051e-01 (9.4051e-01)	Acc@1   0.73 (  0.73)	Acc@5   0.00 (  0.00)
 * Acc@1 0.732 Acc@5 0.000
Test: [0/1]	Time  0.270 ( 0.270)	Loss 1.5808e-01 (1.5808e-01)	Acc@1   0.69 (  0.69)	Acc@5   0.00 (  0.00)
 * Acc@1 0.688 Acc@5 0.000
65
TRAINING
Epoch: [65][0/1]	Time  0.900 ( 0.900)	Data  0.227 ( 0.227)	Loss 7.8660e-02 (7.8660e-02)	Acc@1   0.93 (  0.93)	Acc@5   0.00 (  0.00)
[0.927749200914167]
Test: [0/1]	Time  0.223 ( 0.223)	Loss 9.4139e-01 (9.4139e-01)	Acc@1   0.73 (  0.73)	Acc@5   0.00 (  0.00)
 * Acc@1 0.732 Acc@5 0.000
Test: [0/1]	Time  0.273 ( 0.273)	Loss 1.5752e-01 (1.5752e-01)	Acc@1   0.69 (  0.69)	Acc@5   0.00 (  0.00)
 * Acc@1 0.687 Acc@5 0.000
66
TRAINING
Epoch: [66][0/1]	Time  0.901 ( 0.901)	Data  0.227 ( 0.227)	Loss 7.8444e-02 (7.8444e-02)	Acc@1   0.93 (  0.93)	Acc@5   0.00 (  0.00)
[0.9279689286791731]
Test: [0/1]	Time  0.219 ( 0.219)	Loss 9.4218e-01 (9.4218e-01)	Acc@1   0.73 (  0.73)	Acc@5   0.00 (  0.00)
 * Acc@1 0.732 Acc@5 0.000
Test: [0/1]	Time  0.270 ( 0.270)	Loss 1.5709e-01 (1.5709e-01)	Acc@1   0.69 (  0.69)	Acc@5   0.00 (  0.00)
 * Acc@1 0.687 Acc@5 0.000
67
TRAINING
Epoch: [67][0/1]	Time  0.902 ( 0.902)	Data  0.228 ( 0.228)	Loss 7.8320e-02 (7.8320e-02)	Acc@1   0.93 (  0.93)	Acc@5   0.00 (  0.00)
[0.9285491845729894]
Test: [0/1]	Time  0.218 ( 0.218)	Loss 9.4284e-01 (9.4284e-01)	Acc@1   0.73 (  0.73)	Acc@5   0.00 (  0.00)
 * Acc@1 0.733 Acc@5 0.000
Test: [0/1]	Time  0.272 ( 0.272)	Loss 1.5677e-01 (1.5677e-01)	Acc@1   0.69 (  0.69)	Acc@5   0.00 (  0.00)
 * Acc@1 0.686 Acc@5 0.000
68
TRAINING
Epoch: [68][0/1]	Time  0.900 ( 0.900)	Data  0.226 ( 0.226)	Loss 7.8244e-02 (7.8244e-02)	Acc@1   0.93 (  0.93)	Acc@5   0.00 (  0.00)
[0.9292115759035802]
Test: [0/1]	Time  0.220 ( 0.220)	Loss 9.4335e-01 (9.4335e-01)	Acc@1   0.73 (  0.73)	Acc@5   0.00 (  0.00)
 * Acc@1 0.733 Acc@5 0.000
Test: [0/1]	Time  0.268 ( 0.268)	Loss 1.5654e-01 (1.5654e-01)	Acc@1   0.69 (  0.69)	Acc@5   0.00 (  0.00)
 * Acc@1 0.686 Acc@5 0.000
69
TRAINING
Epoch: [69][0/1]	Time  0.900 ( 0.900)	Data  0.228 ( 0.228)	Loss 7.8170e-02 (7.8170e-02)	Acc@1   0.93 (  0.93)	Acc@5   0.00 (  0.00)
[0.9295101069708875]
Test: [0/1]	Time  0.219 ( 0.219)	Loss 9.4369e-01 (9.4369e-01)	Acc@1   0.73 (  0.73)	Acc@5   0.00 (  0.00)
 * Acc@1 0.734 Acc@5 0.000
Test: [0/1]	Time  0.272 ( 0.272)	Loss 1.5639e-01 (1.5639e-01)	Acc@1   0.68 (  0.68)	Acc@5   0.00 (  0.00)
 * Acc@1 0.685 Acc@5 0.000
70
TRAINING
Epoch: [70][0/1]	Time  0.920 ( 0.920)	Data  0.223 ( 0.223)	Loss 7.8079e-02 (7.8079e-02)	Acc@1   0.93 (  0.93)	Acc@5   0.00 (  0.00)
[0.9297202715856892]
Test: [0/1]	Time  0.218 ( 0.218)	Loss 9.4389e-01 (9.4389e-01)	Acc@1   0.73 (  0.73)	Acc@5   0.00 (  0.00)
 * Acc@1 0.735 Acc@5 0.000
Test: [0/1]	Time  0.273 ( 0.273)	Loss 1.5630e-01 (1.5630e-01)	Acc@1   0.68 (  0.68)	Acc@5   0.00 (  0.00)
 * Acc@1 0.684 Acc@5 0.000
71
TRAINING
Epoch: [71][0/1]	Time  0.904 ( 0.904)	Data  0.227 ( 0.227)	Loss 7.7981e-02 (7.7981e-02)	Acc@1   0.93 (  0.93)	Acc@5   0.00 (  0.00)
[0.9297026915272945]
Test: [0/1]	Time  0.217 ( 0.217)	Loss 9.4396e-01 (9.4396e-01)	Acc@1   0.74 (  0.74)	Acc@5   0.00 (  0.00)
 * Acc@1 0.736 Acc@5 0.000
Test: [0/1]	Time  0.276 ( 0.276)	Loss 1.5628e-01 (1.5628e-01)	Acc@1   0.68 (  0.68)	Acc@5   0.00 (  0.00)
 * Acc@1 0.685 Acc@5 0.000
72
TRAINING
Epoch: [72][0/1]	Time  0.899 ( 0.899)	Data  0.227 ( 0.227)	Loss 7.7902e-02 (7.7902e-02)	Acc@1   0.93 (  0.93)	Acc@5   0.00 (  0.00)
[0.9296996179526069]
Test: [0/1]	Time  0.223 ( 0.223)	Loss 9.4396e-01 (9.4396e-01)	Acc@1   0.74 (  0.74)	Acc@5   0.00 (  0.00)
 * Acc@1 0.736 Acc@5 0.000
Test: [0/1]	Time  0.271 ( 0.271)	Loss 1.5632e-01 (1.5632e-01)	Acc@1   0.69 (  0.69)	Acc@5   0.00 (  0.00)
 * Acc@1 0.686 Acc@5 0.000
73
TRAINING
Epoch: [73][0/1]	Time  0.902 ( 0.902)	Data  0.227 ( 0.227)	Loss 7.7865e-02 (7.7865e-02)	Acc@1   0.93 (  0.93)	Acc@5   0.00 (  0.00)
[0.9297211656235587]
Test: [0/1]	Time  0.222 ( 0.222)	Loss 9.4391e-01 (9.4391e-01)	Acc@1   0.74 (  0.74)	Acc@5   0.00 (  0.00)
 * Acc@1 0.737 Acc@5 0.000
Test: [0/1]	Time  0.272 ( 0.272)	Loss 1.5638e-01 (1.5638e-01)	Acc@1   0.69 (  0.69)	Acc@5   0.00 (  0.00)
 * Acc@1 0.687 Acc@5 0.000
74
TRAINING
Epoch: [74][0/1]	Time  0.904 ( 0.904)	Data  0.228 ( 0.228)	Loss 7.7870e-02 (7.7870e-02)	Acc@1   0.93 (  0.93)	Acc@5   0.00 (  0.00)
[0.9297819330018096]
Test: [0/1]	Time  0.215 ( 0.215)	Loss 9.4385e-01 (9.4385e-01)	Acc@1   0.74 (  0.74)	Acc@5   0.00 (  0.00)
 * Acc@1 0.738 Acc@5 0.000
Test: [0/1]	Time  0.270 ( 0.270)	Loss 1.5642e-01 (1.5642e-01)	Acc@1   0.69 (  0.69)	Acc@5   0.00 (  0.00)
 * Acc@1 0.689 Acc@5 0.000
75
TRAINING
Epoch: [75][0/1]	Time  0.901 ( 0.901)	Data  0.227 ( 0.227)	Loss 7.7898e-02 (7.7898e-02)	Acc@1   0.93 (  0.93)	Acc@5   0.00 (  0.00)
[0.9299003234496351]
Test: [0/1]	Time  0.218 ( 0.218)	Loss 9.4380e-01 (9.4380e-01)	Acc@1   0.74 (  0.74)	Acc@5   0.00 (  0.00)
 * Acc@1 0.739 Acc@5 0.000
Test: [0/1]	Time  0.272 ( 0.272)	Loss 1.5639e-01 (1.5639e-01)	Acc@1   0.69 (  0.69)	Acc@5   0.00 (  0.00)
 * Acc@1 0.690 Acc@5 0.000
76
TRAINING
Epoch: [76][0/1]	Time  0.898 ( 0.898)	Data  0.225 ( 0.225)	Loss 7.7918e-02 (7.7918e-02)	Acc@1   0.93 (  0.93)	Acc@5   0.00 (  0.00)
[0.930091836131461]
Test: [0/1]	Time  0.222 ( 0.222)	Loss 9.4377e-01 (9.4377e-01)	Acc@1   0.74 (  0.74)	Acc@5   0.00 (  0.00)
 * Acc@1 0.740 Acc@5 0.000
Test: [0/1]	Time  0.275 ( 0.275)	Loss 1.5625e-01 (1.5625e-01)	Acc@1   0.69 (  0.69)	Acc@5   0.00 (  0.00)
 * Acc@1 0.690 Acc@5 0.000
77
TRAINING
Epoch: [77][0/1]	Time  0.912 ( 0.912)	Data  0.227 ( 0.227)	Loss 7.7910e-02 (7.7910e-02)	Acc@1   0.93 (  0.93)	Acc@5   0.00 (  0.00)
[0.9302555104938939]
Test: [0/1]	Time  0.225 ( 0.225)	Loss 9.4378e-01 (9.4378e-01)	Acc@1   0.74 (  0.74)	Acc@5   0.00 (  0.00)
 * Acc@1 0.740 Acc@5 0.000
Test: [0/1]	Time  0.271 ( 0.271)	Loss 1.5601e-01 (1.5601e-01)	Acc@1   0.69 (  0.69)	Acc@5   0.00 (  0.00)
 * Acc@1 0.691 Acc@5 0.000
78
TRAINING
Epoch: [78][0/1]	Time  0.902 ( 0.902)	Data  0.228 ( 0.228)	Loss 7.7869e-02 (7.7869e-02)	Acc@1   0.93 (  0.93)	Acc@5   0.00 (  0.00)
[0.9304318359109549]
Test: [0/1]	Time  0.224 ( 0.224)	Loss 9.4380e-01 (9.4380e-01)	Acc@1   0.74 (  0.74)	Acc@5   0.00 (  0.00)
 * Acc@1 0.740 Acc@5 0.000
Test: [0/1]	Time  0.269 ( 0.269)	Loss 1.5570e-01 (1.5570e-01)	Acc@1   0.69 (  0.69)	Acc@5   0.00 (  0.00)
 * Acc@1 0.692 Acc@5 0.000
79
TRAINING
Epoch: [79][0/1]	Time  0.897 ( 0.897)	Data  0.225 ( 0.225)	Loss 7.7808e-02 (7.7808e-02)	Acc@1   0.93 (  0.93)	Acc@5   0.00 (  0.00)
[0.9306529244497678]
Test: [0/1]	Time  0.217 ( 0.217)	Loss 9.4384e-01 (9.4384e-01)	Acc@1   0.74 (  0.74)	Acc@5   0.00 (  0.00)
 * Acc@1 0.740 Acc@5 0.000
Test: [0/1]	Time  0.272 ( 0.272)	Loss 1.5537e-01 (1.5537e-01)	Acc@1   0.69 (  0.69)	Acc@5   0.00 (  0.00)
 * Acc@1 0.692 Acc@5 0.000
80
TRAINING
Epoch: [80][0/1]	Time  0.907 ( 0.907)	Data  0.220 ( 0.220)	Loss 7.7746e-02 (7.7746e-02)	Acc@1   0.93 (  0.93)	Acc@5   0.00 (  0.00)
[0.9308997979970752]
Test: [0/1]	Time  0.218 ( 0.218)	Loss 9.4387e-01 (9.4387e-01)	Acc@1   0.74 (  0.74)	Acc@5   0.00 (  0.00)
 * Acc@1 0.740 Acc@5 0.000
Test: [0/1]	Time  0.268 ( 0.268)	Loss 1.5504e-01 (1.5504e-01)	Acc@1   0.69 (  0.69)	Acc@5   0.00 (  0.00)
 * Acc@1 0.693 Acc@5 0.000
81
TRAINING
Epoch: [81][0/1]	Time  0.898 ( 0.898)	Data  0.224 ( 0.224)	Loss 7.7698e-02 (7.7698e-02)	Acc@1   0.93 (  0.93)	Acc@5   0.00 (  0.00)
[0.9311113458530209]
Test: [0/1]	Time  0.219 ( 0.219)	Loss 9.4389e-01 (9.4389e-01)	Acc@1   0.74 (  0.74)	Acc@5   0.00 (  0.00)
 * Acc@1 0.739 Acc@5 0.000
Test: [0/1]	Time  0.271 ( 0.271)	Loss 1.5476e-01 (1.5476e-01)	Acc@1   0.69 (  0.69)	Acc@5   0.00 (  0.00)
 * Acc@1 0.693 Acc@5 0.000
82
TRAINING
Epoch: [82][0/1]	Time  0.910 ( 0.910)	Data  0.233 ( 0.233)	Loss 7.7669e-02 (7.7669e-02)	Acc@1   0.93 (  0.93)	Acc@5   0.00 (  0.00)
[0.9312474117454064]
Test: [0/1]	Time  0.230 ( 0.230)	Loss 9.4386e-01 (9.4386e-01)	Acc@1   0.74 (  0.74)	Acc@5   0.00 (  0.00)
 * Acc@1 0.739 Acc@5 0.000
Test: [0/1]	Time  0.274 ( 0.274)	Loss 1.5454e-01 (1.5454e-01)	Acc@1   0.69 (  0.69)	Acc@5   0.00 (  0.00)
 * Acc@1 0.694 Acc@5 0.000
83
TRAINING
Epoch: [83][0/1]	Time  0.903 ( 0.903)	Data  0.229 ( 0.229)	Loss 7.7657e-02 (7.7657e-02)	Acc@1   0.93 (  0.93)	Acc@5   0.00 (  0.00)
[0.9313959244487147]
Test: [0/1]	Time  0.222 ( 0.222)	Loss 9.4379e-01 (9.4379e-01)	Acc@1   0.74 (  0.74)	Acc@5   0.00 (  0.00)
 * Acc@1 0.739 Acc@5 0.000
Test: [0/1]	Time  0.270 ( 0.270)	Loss 1.5437e-01 (1.5437e-01)	Acc@1   0.69 (  0.69)	Acc@5   0.00 (  0.00)
 * Acc@1 0.694 Acc@5 0.000
84
TRAINING
Epoch: [84][0/1]	Time  0.905 ( 0.905)	Data  0.227 ( 0.227)	Loss 7.7651e-02 (7.7651e-02)	Acc@1   0.93 (  0.93)	Acc@5   0.00 (  0.00)
[0.931553589932572]
Test: [0/1]	Time  0.223 ( 0.223)	Loss 9.4366e-01 (9.4366e-01)	Acc@1   0.74 (  0.74)	Acc@5   0.00 (  0.00)
 * Acc@1 0.739 Acc@5 0.000
Test: [0/1]	Time  0.271 ( 0.271)	Loss 1.5426e-01 (1.5426e-01)	Acc@1   0.69 (  0.69)	Acc@5   0.00 (  0.00)
 * Acc@1 0.695 Acc@5 0.000
85
TRAINING
Epoch: [85][0/1]	Time  0.903 ( 0.903)	Data  0.226 ( 0.226)	Loss 7.7646e-02 (7.7646e-02)	Acc@1   0.93 (  0.93)	Acc@5   0.00 (  0.00)
[0.9317172239179481]
Test: [0/1]	Time  0.223 ( 0.223)	Loss 9.4349e-01 (9.4349e-01)	Acc@1   0.74 (  0.74)	Acc@5   0.00 (  0.00)
 * Acc@1 0.739 Acc@5 0.000
Test: [0/1]	Time  0.271 ( 0.271)	Loss 1.5420e-01 (1.5420e-01)	Acc@1   0.69 (  0.69)	Acc@5   0.00 (  0.00)
 * Acc@1 0.695 Acc@5 0.000
86
TRAINING
Epoch: [86][0/1]	Time  0.902 ( 0.902)	Data  0.229 ( 0.229)	Loss 7.7639e-02 (7.7639e-02)	Acc@1   0.93 (  0.93)	Acc@5   0.00 (  0.00)
[0.9318832164037472]
Test: [0/1]	Time  0.220 ( 0.220)	Loss 9.4330e-01 (9.4330e-01)	Acc@1   0.74 (  0.74)	Acc@5   0.00 (  0.00)
 * Acc@1 0.740 Acc@5 0.000
Test: [0/1]	Time  0.272 ( 0.272)	Loss 1.5419e-01 (1.5419e-01)	Acc@1   0.70 (  0.70)	Acc@5   0.00 (  0.00)
 * Acc@1 0.695 Acc@5 0.000
87
TRAINING
Epoch: [87][0/1]	Time  0.912 ( 0.912)	Data  0.229 ( 0.229)	Loss 7.7634e-02 (7.7634e-02)	Acc@1   0.93 (  0.93)	Acc@5   0.00 (  0.00)
[0.9320476347580091]
Test: [0/1]	Time  0.225 ( 0.225)	Loss 9.4308e-01 (9.4308e-01)	Acc@1   0.74 (  0.74)	Acc@5   0.00 (  0.00)
 * Acc@1 0.740 Acc@5 0.000
Test: [0/1]	Time  0.273 ( 0.273)	Loss 1.5421e-01 (1.5421e-01)	Acc@1   0.70 (  0.70)	Acc@5   0.00 (  0.00)
 * Acc@1 0.695 Acc@5 0.000
88
TRAINING
Epoch: [88][0/1]	Time  0.903 ( 0.903)	Data  0.228 ( 0.228)	Loss 7.7635e-02 (7.7635e-02)	Acc@1   0.93 (  0.93)	Acc@5   0.00 (  0.00)
[0.9322067693894742]
Test: [0/1]	Time  0.223 ( 0.223)	Loss 9.4288e-01 (9.4288e-01)	Acc@1   0.74 (  0.74)	Acc@5   0.00 (  0.00)
 * Acc@1 0.741 Acc@5 0.000
Test: [0/1]	Time  0.270 ( 0.270)	Loss 1.5425e-01 (1.5425e-01)	Acc@1   0.70 (  0.70)	Acc@5   0.00 (  0.00)
 * Acc@1 0.696 Acc@5 0.000
89
TRAINING
Epoch: [89][0/1]	Time  0.903 ( 0.903)	Data  0.226 ( 0.226)	Loss 7.7641e-02 (7.7641e-02)	Acc@1   0.93 (  0.93)	Acc@5   0.00 (  0.00)
[0.9323577268514591]
Test: [0/1]	Time  0.223 ( 0.223)	Loss 9.4268e-01 (9.4268e-01)	Acc@1   0.74 (  0.74)	Acc@5   0.00 (  0.00)
 * Acc@1 0.741 Acc@5 0.000
Test: [0/1]	Time  0.276 ( 0.276)	Loss 1.5428e-01 (1.5428e-01)	Acc@1   0.70 (  0.70)	Acc@5   0.00 (  0.00)
 * Acc@1 0.696 Acc@5 0.000
90
TRAINING
Epoch: [90][0/1]	Time  0.920 ( 0.920)	Data  0.223 ( 0.223)	Loss 7.7650e-02 (7.7650e-02)	Acc@1   0.93 (  0.93)	Acc@5   0.00 (  0.00)
[0.9324033880643662]
Test: [0/1]	Time  0.217 ( 0.217)	Loss 9.4252e-01 (9.4252e-01)	Acc@1   0.74 (  0.74)	Acc@5   0.00 (  0.00)
 * Acc@1 0.741 Acc@5 0.000
Test: [0/1]	Time  0.267 ( 0.267)	Loss 1.5430e-01 (1.5430e-01)	Acc@1   0.70 (  0.70)	Acc@5   0.00 (  0.00)
 * Acc@1 0.696 Acc@5 0.000
91
TRAINING
Epoch: [91][0/1]	Time  0.907 ( 0.907)	Data  0.226 ( 0.226)	Loss 7.7656e-02 (7.7656e-02)	Acc@1   0.93 (  0.93)	Acc@5   0.00 (  0.00)
[0.9324049359900458]
Test: [0/1]	Time  0.222 ( 0.222)	Loss 9.4240e-01 (9.4240e-01)	Acc@1   0.74 (  0.74)	Acc@5   0.00 (  0.00)
 * Acc@1 0.741 Acc@5 0.000
Test: [0/1]	Time  0.268 ( 0.268)	Loss 1.5428e-01 (1.5428e-01)	Acc@1   0.70 (  0.70)	Acc@5   0.00 (  0.00)
 * Acc@1 0.696 Acc@5 0.000
92
TRAINING
Epoch: [92][0/1]	Time  0.934 ( 0.934)	Data  0.229 ( 0.229)	Loss 7.7652e-02 (7.7652e-02)	Acc@1   0.93 (  0.93)	Acc@5   0.00 (  0.00)
[0.932454486809204]
Test: [0/1]	Time  0.217 ( 0.217)	Loss 9.4231e-01 (9.4231e-01)	Acc@1   0.74 (  0.74)	Acc@5   0.00 (  0.00)
 * Acc@1 0.741 Acc@5 0.000
Test: [0/1]	Time  0.272 ( 0.272)	Loss 1.5423e-01 (1.5423e-01)	Acc@1   0.70 (  0.70)	Acc@5   0.00 (  0.00)
 * Acc@1 0.696 Acc@5 0.000
93
TRAINING
Epoch: [93][0/1]	Time  0.901 ( 0.901)	Data  0.228 ( 0.228)	Loss 7.7636e-02 (7.7636e-02)	Acc@1   0.93 (  0.93)	Acc@5   0.00 (  0.00)
[0.9325137864169453]
Test: [0/1]	Time  0.223 ( 0.223)	Loss 9.4225e-01 (9.4225e-01)	Acc@1   0.74 (  0.74)	Acc@5   0.00 (  0.00)
 * Acc@1 0.741 Acc@5 0.000
Test: [0/1]	Time  0.269 ( 0.269)	Loss 1.5415e-01 (1.5415e-01)	Acc@1   0.70 (  0.70)	Acc@5   0.00 (  0.00)
 * Acc@1 0.696 Acc@5 0.000
94
TRAINING
Epoch: [94][0/1]	Time  0.967 ( 0.967)	Data  0.296 ( 0.296)	Loss 7.7611e-02 (7.7611e-02)	Acc@1   0.93 (  0.93)	Acc@5   0.00 (  0.00)
[0.9325644105474518]
Test: [0/1]	Time  0.237 ( 0.237)	Loss 9.4222e-01 (9.4222e-01)	Acc@1   0.74 (  0.74)	Acc@5   0.00 (  0.00)
 * Acc@1 0.741 Acc@5 0.000
Test: [0/1]	Time  0.286 ( 0.286)	Loss 1.5404e-01 (1.5404e-01)	Acc@1   0.70 (  0.70)	Acc@5   0.00 (  0.00)
 * Acc@1 0.696 Acc@5 0.000
95
TRAINING
Epoch: [95][0/1]	Time  0.917 ( 0.917)	Data  0.243 ( 0.243)	Loss 7.7579e-02 (7.7579e-02)	Acc@1   0.93 (  0.93)	Acc@5   0.00 (  0.00)
[0.9326083484122512]
Test: [0/1]	Time  0.226 ( 0.226)	Loss 9.4221e-01 (9.4221e-01)	Acc@1   0.74 (  0.74)	Acc@5   0.00 (  0.00)
 * Acc@1 0.740 Acc@5 0.000
Test: [0/1]	Time  0.277 ( 0.277)	Loss 1.5393e-01 (1.5393e-01)	Acc@1   0.70 (  0.70)	Acc@5   0.00 (  0.00)
 * Acc@1 0.696 Acc@5 0.000
96
TRAINING
Epoch: [96][0/1]	Time  0.915 ( 0.915)	Data  0.241 ( 0.241)	Loss 7.7548e-02 (7.7548e-02)	Acc@1   0.93 (  0.93)	Acc@5   0.00 (  0.00)
[0.9326477134347468]
Test: [0/1]	Time  0.222 ( 0.222)	Loss 9.4220e-01 (9.4220e-01)	Acc@1   0.74 (  0.74)	Acc@5   0.00 (  0.00)
 * Acc@1 0.740 Acc@5 0.000
Test: [0/1]	Time  0.278 ( 0.278)	Loss 1.5383e-01 (1.5383e-01)	Acc@1   0.70 (  0.70)	Acc@5   0.00 (  0.00)
 * Acc@1 0.696 Acc@5 0.000
97
TRAINING
Epoch: [97][0/1]	Time  0.913 ( 0.913)	Data  0.240 ( 0.240)	Loss 7.7520e-02 (7.7520e-02)	Acc@1   0.93 (  0.93)	Acc@5   0.00 (  0.00)
[0.9326846621455904]
Test: [0/1]	Time  0.222 ( 0.222)	Loss 9.4219e-01 (9.4219e-01)	Acc@1   0.74 (  0.74)	Acc@5   0.00 (  0.00)
 * Acc@1 0.740 Acc@5 0.000
Test: [0/1]	Time  0.278 ( 0.278)	Loss 1.5375e-01 (1.5375e-01)	Acc@1   0.70 (  0.70)	Acc@5   0.00 (  0.00)
 * Acc@1 0.696 Acc@5 0.000
98
TRAINING
Epoch: [98][0/1]	Time  0.915 ( 0.915)	Data  0.239 ( 0.239)	Loss 7.7497e-02 (7.7497e-02)	Acc@1   0.93 (  0.93)	Acc@5   0.00 (  0.00)
[0.9327212929867835]
Test: [0/1]	Time  0.222 ( 0.222)	Loss 9.4216e-01 (9.4216e-01)	Acc@1   0.74 (  0.74)	Acc@5   0.00 (  0.00)
 * Acc@1 0.740 Acc@5 0.000
Test: [0/1]	Time  0.270 ( 0.270)	Loss 1.5369e-01 (1.5369e-01)	Acc@1   0.70 (  0.70)	Acc@5   0.00 (  0.00)
 * Acc@1 0.696 Acc@5 0.000
99
TRAINING
Epoch: [99][0/1]	Time  0.915 ( 0.915)	Data  0.241 ( 0.241)	Loss 7.7478e-02 (7.7478e-02)	Acc@1   0.93 (  0.93)	Acc@5   0.00 (  0.00)
[0.9327595350134716]
Test: [0/1]	Time  0.247 ( 0.247)	Loss 9.4212e-01 (9.4212e-01)	Acc@1   0.74 (  0.74)	Acc@5   0.00 (  0.00)
 * Acc@1 0.739 Acc@5 0.000
Test: [0/1]	Time  0.276 ( 0.276)	Loss 1.5365e-01 (1.5365e-01)	Acc@1   0.70 (  0.70)	Acc@5   0.00 (  0.00)
 * Acc@1 0.695 Acc@5 0.000
=> using pre-trained model 'st_resnet'
s/ohp/session_1
torch.Size([640, 3, 224, 224])
(640, 22)
attach reg
0
TRAINING
/home/helenr6/Adv_mapper/train_split.py:125: UserWarning: You have chosen to seed training. This will turn on the CUDNN deterministic setting, which can slow down your training considerably! You may see unexpected behavior when restarting from checkpoints.
  warnings.warn('You have chosen to seed training. '
/localscratch/helenr6.6279052.0/env/lib/python3.7/site-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  cpuset_checked))
Epoch: [0][0/1]	Time  5.219 ( 5.219)	Data  1.831 ( 1.831)	Loss 1.8653e+00 (1.8653e+00)	Acc@1   0.00 (  0.00)	Acc@5   0.00 (  0.00)
[0.0023414532728068017]
Test: [0/1]	Time  0.418 ( 0.418)	Loss 1.2858e+00 (1.2858e+00)	Acc@1  -0.11 ( -0.11)	Acc@5   0.00 (  0.00)
 * Acc@1 -0.111 Acc@5 0.000
Test: [0/1]	Time  0.531 ( 0.531)	Loss 1.0158e+00 (1.0158e+00)	Acc@1   0.02 (  0.02)	Acc@5   0.00 (  0.00)
 * Acc@1 0.018 Acc@5 0.000
1
TRAINING
Epoch: [1][0/1]	Time  0.933 ( 0.933)	Data  0.236 ( 0.236)	Loss 1.7575e+00 (1.7575e+00)	Acc@1   0.01 (  0.01)	Acc@5   0.00 (  0.00)
[0.006406218886320678]
Test: [0/1]	Time  0.223 ( 0.223)	Loss 1.2954e+00 (1.2954e+00)	Acc@1  -0.10 ( -0.10)	Acc@5   0.00 (  0.00)
 * Acc@1 -0.103 Acc@5 0.000
Test: [0/1]	Time  0.280 ( 0.280)	Loss 9.3584e-01 (9.3584e-01)	Acc@1   0.04 (  0.04)	Acc@5   0.00 (  0.00)
 * Acc@1 0.038 Acc@5 0.000
2
TRAINING
Epoch: [2][0/1]	Time  0.928 ( 0.928)	Data  0.230 ( 0.230)	Loss 1.5992e+00 (1.5992e+00)	Acc@1   0.01 (  0.01)	Acc@5   0.00 (  0.00)
[0.012888653674794609]
Test: [0/1]	Time  0.230 ( 0.230)	Loss 1.3079e+00 (1.3079e+00)	Acc@1  -0.09 ( -0.09)	Acc@5   0.00 (  0.00)
 * Acc@1 -0.094 Acc@5 0.000
Test: [0/1]	Time  0.281 ( 0.281)	Loss 8.6873e-01 (8.6873e-01)	Acc@1   0.05 (  0.05)	Acc@5   0.00 (  0.00)
 * Acc@1 0.050 Acc@5 0.000
3
TRAINING
Epoch: [3][0/1]	Time  0.970 ( 0.970)	Data  0.263 ( 0.263)	Loss 1.4539e+00 (1.4539e+00)	Acc@1   0.02 (  0.02)	Acc@5   0.00 (  0.00)
[0.023985700784733194]
Test: [0/1]	Time  0.239 ( 0.239)	Loss 1.3220e+00 (1.3220e+00)	Acc@1  -0.06 ( -0.06)	Acc@5   0.00 (  0.00)
 * Acc@1 -0.065 Acc@5 0.000
Test: [0/1]	Time  0.283 ( 0.283)	Loss 8.3499e-01 (8.3499e-01)	Acc@1   0.06 (  0.06)	Acc@5   0.00 (  0.00)
 * Acc@1 0.063 Acc@5 0.000
4
TRAINING
Epoch: [4][0/1]	Time  0.975 ( 0.975)	Data  0.247 ( 0.247)	Loss 1.3562e+00 (1.3562e+00)	Acc@1   0.03 (  0.03)	Acc@5   0.00 (  0.00)
[0.03445512127364514]
Test: [0/1]	Time  0.231 ( 0.231)	Loss 1.3335e+00 (1.3335e+00)	Acc@1  -0.04 ( -0.04)	Acc@5   0.00 (  0.00)
 * Acc@1 -0.038 Acc@5 0.000
Test: [0/1]	Time  0.277 ( 0.277)	Loss 8.2999e-01 (8.2999e-01)	Acc@1   0.08 (  0.08)	Acc@5   0.00 (  0.00)
 * Acc@1 0.077 Acc@5 0.000
5
TRAINING
Epoch: [5][0/1]	Time  0.940 ( 0.940)	Data  0.245 ( 0.245)	Loss 1.2998e+00 (1.2998e+00)	Acc@1   0.05 (  0.05)	Acc@5   0.00 (  0.00)
[0.04693840635813416]
Test: [0/1]	Time  0.232 ( 0.232)	Loss 1.3367e+00 (1.3367e+00)	Acc@1  -0.02 ( -0.02)	Acc@5   0.00 (  0.00)
 * Acc@1 -0.017 Acc@5 0.000
Test: [0/1]	Time  0.286 ( 0.286)	Loss 8.3113e-01 (8.3113e-01)	Acc@1   0.09 (  0.09)	Acc@5   0.00 (  0.00)
 * Acc@1 0.093 Acc@5 0.000
6
TRAINING
Epoch: [6][0/1]	Time  0.960 ( 0.960)	Data  0.260 ( 0.260)	Loss 1.2514e+00 (1.2514e+00)	Acc@1   0.06 (  0.06)	Acc@5   0.00 (  0.00)
[0.06131518193938175]
Test: [0/1]	Time  0.230 ( 0.230)	Loss 1.3275e+00 (1.3275e+00)	Acc@1  -0.02 ( -0.02)	Acc@5   0.00 (  0.00)
 * Acc@1 -0.017 Acc@5 0.000
Test: [0/1]	Time  0.280 ( 0.280)	Loss 8.1437e-01 (8.1437e-01)	Acc@1   0.10 (  0.10)	Acc@5   0.00 (  0.00)
 * Acc@1 0.100 Acc@5 0.000
7
TRAINING
Epoch: [7][0/1]	Time  0.941 ( 0.941)	Data  0.249 ( 0.249)	Loss 1.1777e+00 (1.1777e+00)	Acc@1   0.08 (  0.08)	Acc@5   0.00 (  0.00)
[0.07833331943739028]
Test: [0/1]	Time  0.226 ( 0.226)	Loss 1.3050e+00 (1.3050e+00)	Acc@1  -0.02 ( -0.02)	Acc@5   0.00 (  0.00)
 * Acc@1 -0.017 Acc@5 0.000
Test: [0/1]	Time  0.280 ( 0.280)	Loss 7.6908e-01 (7.6908e-01)	Acc@1   0.11 (  0.11)	Acc@5   0.00 (  0.00)
 * Acc@1 0.107 Acc@5 0.000
8
TRAINING
Epoch: [8][0/1]	Time  0.980 ( 0.980)	Data  0.267 ( 0.267)	Loss 1.0662e+00 (1.0662e+00)	Acc@1   0.10 (  0.10)	Acc@5   0.00 (  0.00)
[0.09850340948639852]
Test: [0/1]	Time  0.234 ( 0.234)	Loss 1.2726e+00 (1.2726e+00)	Acc@1  -0.01 ( -0.01)	Acc@5   0.00 (  0.00)
 * Acc@1 -0.012 Acc@5 0.000
Test: [0/1]	Time  0.285 ( 0.285)	Loss 7.0295e-01 (7.0295e-01)	Acc@1   0.12 (  0.12)	Acc@5   0.00 (  0.00)
 * Acc@1 0.122 Acc@5 0.000
9
TRAINING
Epoch: [9][0/1]	Time  0.959 ( 0.959)	Data  0.244 ( 0.244)	Loss 9.3008e-01 (9.3008e-01)	Acc@1   0.12 (  0.12)	Acc@5   0.00 (  0.00)
[0.11847235339632366]
Test: [0/1]	Time  0.229 ( 0.229)	Loss 1.2359e+00 (1.2359e+00)	Acc@1   0.01 (  0.01)	Acc@5   0.00 (  0.00)
 * Acc@1 0.009 Acc@5 0.000
Test: [0/1]	Time  0.281 ( 0.281)	Loss 6.3492e-01 (6.3492e-01)	Acc@1   0.13 (  0.13)	Acc@5   0.00 (  0.00)
 * Acc@1 0.133 Acc@5 0.000
10
TRAINING
Epoch: [10][0/1]	Time  0.972 ( 0.972)	Data  0.248 ( 0.248)	Loss 7.9685e-01 (7.9685e-01)	Acc@1   0.14 (  0.14)	Acc@5   0.00 (  0.00)
[0.13637766147799185]
Test: [0/1]	Time  0.228 ( 0.228)	Loss 1.2006e+00 (1.2006e+00)	Acc@1   0.04 (  0.04)	Acc@5   0.00 (  0.00)
 * Acc@1 0.037 Acc@5 0.000
Test: [0/1]	Time  0.281 ( 0.281)	Loss 5.8259e-01 (5.8259e-01)	Acc@1   0.14 (  0.14)	Acc@5   0.00 (  0.00)
 * Acc@1 0.143 Acc@5 0.000
11
TRAINING
Epoch: [11][0/1]	Time  0.952 ( 0.952)	Data  0.256 ( 0.256)	Loss 6.9008e-01 (6.9008e-01)	Acc@1   0.16 (  0.16)	Acc@5   0.00 (  0.00)
[0.16214991023017417]
Test: [0/1]	Time  0.232 ( 0.232)	Loss 1.1702e+00 (1.1702e+00)	Acc@1   0.07 (  0.07)	Acc@5   0.00 (  0.00)
 * Acc@1 0.069 Acc@5 0.000
Test: [0/1]	Time  0.282 ( 0.282)	Loss 5.5215e-01 (5.5215e-01)	Acc@1   0.15 (  0.15)	Acc@5   0.00 (  0.00)
 * Acc@1 0.154 Acc@5 0.000
12
TRAINING
Epoch: [12][0/1]	Time  0.998 ( 0.998)	Data  0.295 ( 0.295)	Loss 6.1703e-01 (6.1703e-01)	Acc@1   0.19 (  0.19)	Acc@5   0.00 (  0.00)
[0.18981021425956632]
Test: [0/1]	Time  0.230 ( 0.230)	Loss 1.1457e+00 (1.1457e+00)	Acc@1   0.12 (  0.12)	Acc@5   0.00 (  0.00)
 * Acc@1 0.125 Acc@5 0.000
Test: [0/1]	Time  0.283 ( 0.283)	Loss 5.3662e-01 (5.3662e-01)	Acc@1   0.17 (  0.17)	Acc@5   0.00 (  0.00)
 * Acc@1 0.167 Acc@5 0.000
13
TRAINING
Epoch: [13][0/1]	Time  0.979 ( 0.979)	Data  0.294 ( 0.294)	Loss 5.6764e-01 (5.6764e-01)	Acc@1   0.22 (  0.22)	Acc@5   0.00 (  0.00)
[0.22447368229067408]
Test: [0/1]	Time  0.231 ( 0.231)	Loss 1.1259e+00 (1.1259e+00)	Acc@1   0.18 (  0.18)	Acc@5   0.00 (  0.00)
 * Acc@1 0.181 Acc@5 0.000
Test: [0/1]	Time  0.282 ( 0.282)	Loss 5.2201e-01 (5.2201e-01)	Acc@1   0.18 (  0.18)	Acc@5   0.00 (  0.00)
 * Acc@1 0.184 Acc@5 0.000
14
TRAINING
Epoch: [14][0/1]	Time  1.015 ( 1.015)	Data  0.307 ( 0.307)	Loss 5.2373e-01 (5.2373e-01)	Acc@1   0.26 (  0.26)	Acc@5   0.00 (  0.00)
[0.25991081695909024]
Test: [0/1]	Time  0.234 ( 0.234)	Loss 1.1091e+00 (1.1091e+00)	Acc@1   0.22 (  0.22)	Acc@5   0.00 (  0.00)
 * Acc@1 0.224 Acc@5 0.000
Test: [0/1]	Time  0.288 ( 0.288)	Loss 4.9671e-01 (4.9671e-01)	Acc@1   0.20 (  0.20)	Acc@5   0.00 (  0.00)
 * Acc@1 0.202 Acc@5 0.000
15
TRAINING
Epoch: [15][0/1]	Time  0.969 ( 0.969)	Data  0.255 ( 0.255)	Loss 4.7100e-01 (4.7100e-01)	Acc@1   0.30 (  0.30)	Acc@5   0.00 (  0.00)
[0.2960051694195064]
Test: [0/1]	Time  0.236 ( 0.236)	Loss 1.0943e+00 (1.0943e+00)	Acc@1   0.25 (  0.25)	Acc@5   0.00 (  0.00)
 * Acc@1 0.247 Acc@5 0.000
Test: [0/1]	Time  0.285 ( 0.285)	Loss 4.5803e-01 (4.5803e-01)	Acc@1   0.23 (  0.23)	Acc@5   0.00 (  0.00)
 * Acc@1 0.226 Acc@5 0.000
16
TRAINING
Epoch: [16][0/1]	Time  0.987 ( 0.987)	Data  0.252 ( 0.252)	Loss 4.0656e-01 (4.0656e-01)	Acc@1   0.33 (  0.33)	Acc@5   0.00 (  0.00)
[0.33314751904545503]
Test: [0/1]	Time  0.236 ( 0.236)	Loss 1.0812e+00 (1.0812e+00)	Acc@1   0.27 (  0.27)	Acc@5   0.00 (  0.00)
 * Acc@1 0.274 Acc@5 0.000
Test: [0/1]	Time  0.286 ( 0.286)	Loss 4.1235e-01 (4.1235e-01)	Acc@1   0.26 (  0.26)	Acc@5   0.00 (  0.00)
 * Acc@1 0.258 Acc@5 0.000
17
TRAINING
Epoch: [17][0/1]	Time  0.939 ( 0.939)	Data  0.249 ( 0.249)	Loss 3.3833e-01 (3.3833e-01)	Acc@1   0.38 (  0.38)	Acc@5   0.00 (  0.00)
[0.37517300893293914]
Test: [0/1]	Time  0.242 ( 0.242)	Loss 1.0703e+00 (1.0703e+00)	Acc@1   0.28 (  0.28)	Acc@5   0.00 (  0.00)
 * Acc@1 0.284 Acc@5 0.000
Test: [0/1]	Time  0.288 ( 0.288)	Loss 3.7003e-01 (3.7003e-01)	Acc@1   0.29 (  0.29)	Acc@5   0.00 (  0.00)
 * Acc@1 0.292 Acc@5 0.000
18
TRAINING
Epoch: [18][0/1]	Time  0.989 ( 0.989)	Data  0.248 ( 0.248)	Loss 2.7835e-01 (2.7835e-01)	Acc@1   0.42 (  0.42)	Acc@5   0.00 (  0.00)
[0.42270019177664847]
Test: [0/1]	Time  0.238 ( 0.238)	Loss 1.0614e+00 (1.0614e+00)	Acc@1   0.29 (  0.29)	Acc@5   0.00 (  0.00)
 * Acc@1 0.293 Acc@5 0.000
Test: [0/1]	Time  0.290 ( 0.290)	Loss 3.3879e-01 (3.3879e-01)	Acc@1   0.33 (  0.33)	Acc@5   0.00 (  0.00)
 * Acc@1 0.329 Acc@5 0.000
19
TRAINING
Epoch: [19][0/1]	Time  0.961 ( 0.961)	Data  0.265 ( 0.265)	Loss 2.3490e-01 (2.3490e-01)	Acc@1   0.47 (  0.47)	Acc@5   0.00 (  0.00)
[0.4712973885596162]
Test: [0/1]	Time  0.232 ( 0.232)	Loss 1.0538e+00 (1.0538e+00)	Acc@1   0.31 (  0.31)	Acc@5   0.00 (  0.00)
 * Acc@1 0.311 Acc@5 0.000
Test: [0/1]	Time  0.283 ( 0.283)	Loss 3.1970e-01 (3.1970e-01)	Acc@1   0.36 (  0.36)	Acc@5   0.00 (  0.00)
 * Acc@1 0.364 Acc@5 0.000
20
TRAINING
Epoch: [20][0/1]	Time  0.945 ( 0.945)	Data  0.235 ( 0.235)	Loss 2.0834e-01 (2.0834e-01)	Acc@1   0.52 (  0.52)	Acc@5   0.00 (  0.00)
[0.5179644753587715]
Test: [0/1]	Time  0.236 ( 0.236)	Loss 1.0461e+00 (1.0461e+00)	Acc@1   0.35 (  0.35)	Acc@5   0.00 (  0.00)
 * Acc@1 0.347 Acc@5 0.000
Test: [0/1]	Time  0.279 ( 0.279)	Loss 3.0784e-01 (3.0784e-01)	Acc@1   0.39 (  0.39)	Acc@5   0.00 (  0.00)
 * Acc@1 0.393 Acc@5 0.000
21
TRAINING
Epoch: [21][0/1]	Time  0.941 ( 0.941)	Data  0.244 ( 0.244)	Loss 1.9221e-01 (1.9221e-01)	Acc@1   0.56 (  0.56)	Acc@5   0.00 (  0.00)
[0.5638991770313597]
Test: [0/1]	Time  0.225 ( 0.225)	Loss 1.0371e+00 (1.0371e+00)	Acc@1   0.40 (  0.40)	Acc@5   0.00 (  0.00)
 * Acc@1 0.398 Acc@5 0.000
Test: [0/1]	Time  0.278 ( 0.278)	Loss 2.9624e-01 (2.9624e-01)	Acc@1   0.42 (  0.42)	Acc@5   0.00 (  0.00)
 * Acc@1 0.416 Acc@5 0.000
22
TRAINING
Epoch: [22][0/1]	Time  0.942 ( 0.942)	Data  0.247 ( 0.247)	Loss 1.7812e-01 (1.7812e-01)	Acc@1   0.61 (  0.61)	Acc@5   0.00 (  0.00)
[0.6086666069155653]
Test: [0/1]	Time  0.233 ( 0.233)	Loss 1.0263e+00 (1.0263e+00)	Acc@1   0.46 (  0.46)	Acc@5   0.00 (  0.00)
 * Acc@1 0.458 Acc@5 0.000
Test: [0/1]	Time  0.283 ( 0.283)	Loss 2.8034e-01 (2.8034e-01)	Acc@1   0.43 (  0.43)	Acc@5   0.00 (  0.00)
 * Acc@1 0.434 Acc@5 0.000
23
TRAINING
Epoch: [23][0/1]	Time  0.966 ( 0.966)	Data  0.249 ( 0.249)	Loss 1.6071e-01 (1.6071e-01)	Acc@1   0.65 (  0.65)	Acc@5   0.00 (  0.00)
[0.6544811736834978]
Test: [0/1]	Time  0.229 ( 0.229)	Loss 1.0140e+00 (1.0140e+00)	Acc@1   0.51 (  0.51)	Acc@5   0.00 (  0.00)
 * Acc@1 0.507 Acc@5 0.000
Test: [0/1]	Time  0.283 ( 0.283)	Loss 2.6022e-01 (2.6022e-01)	Acc@1   0.45 (  0.45)	Acc@5   0.00 (  0.00)
 * Acc@1 0.451 Acc@5 0.000
24
TRAINING
Epoch: [24][0/1]	Time  0.991 ( 0.991)	Data  0.264 ( 0.264)	Loss 1.3992e-01 (1.3992e-01)	Acc@1   0.70 (  0.70)	Acc@5   0.00 (  0.00)
[0.6966673375924963]
Test: [0/1]	Time  0.236 ( 0.236)	Loss 1.0014e+00 (1.0014e+00)	Acc@1   0.55 (  0.55)	Acc@5   0.00 (  0.00)
 * Acc@1 0.548 Acc@5 0.000
Test: [0/1]	Time  0.286 ( 0.286)	Loss 2.3959e-01 (2.3959e-01)	Acc@1   0.47 (  0.47)	Acc@5   0.00 (  0.00)
 * Acc@1 0.469 Acc@5 0.000
25
TRAINING
Epoch: [25][0/1]	Time  0.952 ( 0.952)	Data  0.243 ( 0.243)	Loss 1.1972e-01 (1.1972e-01)	Acc@1   0.73 (  0.73)	Acc@5   0.00 (  0.00)
[0.7340591114452895]
Test: [0/1]	Time  0.230 ( 0.230)	Loss 9.8976e-01 (9.8976e-01)	Acc@1   0.58 (  0.58)	Acc@5   0.00 (  0.00)
 * Acc@1 0.583 Acc@5 0.000
Test: [0/1]	Time  0.279 ( 0.279)	Loss 2.2288e-01 (2.2288e-01)	Acc@1   0.49 (  0.49)	Acc@5   0.00 (  0.00)
 * Acc@1 0.487 Acc@5 0.000
26
TRAINING
Epoch: [26][0/1]	Time  0.946 ( 0.946)	Data  0.255 ( 0.255)	Loss 1.0471e-01 (1.0471e-01)	Acc@1   0.77 (  0.77)	Acc@5   0.00 (  0.00)
[0.7651758195436844]
Test: [0/1]	Time  0.231 ( 0.231)	Loss 9.7989e-01 (9.7989e-01)	Acc@1   0.61 (  0.61)	Acc@5   0.00 (  0.00)
 * Acc@1 0.612 Acc@5 0.000
Test: [0/1]	Time  0.286 ( 0.286)	Loss 2.1235e-01 (2.1235e-01)	Acc@1   0.51 (  0.51)	Acc@5   0.00 (  0.00)
 * Acc@1 0.505 Acc@5 0.000
27
TRAINING
Epoch: [27][0/1]	Time  0.957 ( 0.957)	Data  0.268 ( 0.268)	Loss 9.7051e-02 (9.7051e-02)	Acc@1   0.79 (  0.79)	Acc@5   0.00 (  0.00)
[0.7886336601509956]
Test: [0/1]	Time  0.236 ( 0.236)	Loss 9.7205e-01 (9.7205e-01)	Acc@1   0.64 (  0.64)	Acc@5   0.00 (  0.00)
 * Acc@1 0.636 Acc@5 0.000
Test: [0/1]	Time  0.289 ( 0.289)	Loss 2.0702e-01 (2.0702e-01)	Acc@1   0.52 (  0.52)	Acc@5   0.00 (  0.00)
 * Acc@1 0.520 Acc@5 0.000
28
TRAINING
Epoch: [28][0/1]	Time  0.969 ( 0.969)	Data  0.248 ( 0.248)	Loss 9.5389e-02 (9.5389e-02)	Acc@1   0.81 (  0.81)	Acc@5   0.00 (  0.00)
[0.8092336478013271]
Test: [0/1]	Time  0.233 ( 0.233)	Loss 9.6592e-01 (9.6592e-01)	Acc@1   0.66 (  0.66)	Acc@5   0.00 (  0.00)
 * Acc@1 0.659 Acc@5 0.000
Test: [0/1]	Time  0.281 ( 0.281)	Loss 2.0369e-01 (2.0369e-01)	Acc@1   0.54 (  0.54)	Acc@5   0.00 (  0.00)
 * Acc@1 0.536 Acc@5 0.000
29
TRAINING
Epoch: [29][0/1]	Time  0.932 ( 0.932)	Data  0.246 ( 0.246)	Loss 9.6059e-02 (9.6059e-02)	Acc@1   0.83 (  0.83)	Acc@5   0.00 (  0.00)
[0.8253462124476831]
Test: [0/1]	Time  0.229 ( 0.229)	Loss 9.6107e-01 (9.6107e-01)	Acc@1   0.68 (  0.68)	Acc@5   0.00 (  0.00)
 * Acc@1 0.679 Acc@5 0.000
Test: [0/1]	Time  0.280 ( 0.280)	Loss 1.9911e-01 (1.9911e-01)	Acc@1   0.55 (  0.55)	Acc@5   0.00 (  0.00)
 * Acc@1 0.555 Acc@5 0.000
30
TRAINING
Epoch: [30][0/1]	Time  0.950 ( 0.950)	Data  0.236 ( 0.236)	Loss 9.5451e-02 (9.5451e-02)	Acc@1   0.84 (  0.84)	Acc@5   0.00 (  0.00)
[0.8395255383628921]
Test: [0/1]	Time  0.229 ( 0.229)	Loss 9.5712e-01 (9.5712e-01)	Acc@1   0.70 (  0.70)	Acc@5   0.00 (  0.00)
 * Acc@1 0.698 Acc@5 0.000
Test: [0/1]	Time  0.278 ( 0.278)	Loss 1.9180e-01 (1.9180e-01)	Acc@1   0.58 (  0.58)	Acc@5   0.00 (  0.00)
 * Acc@1 0.576 Acc@5 0.000
31
TRAINING
Epoch: [31][0/1]	Time  0.995 ( 0.995)	Data  0.266 ( 0.266)	Loss 9.1937e-02 (9.1937e-02)	Acc@1   0.85 (  0.85)	Acc@5   0.00 (  0.00)
[0.8517309340143328]
Test: [0/1]	Time  0.238 ( 0.238)	Loss 9.5394e-01 (9.5394e-01)	Acc@1   0.71 (  0.71)	Acc@5   0.00 (  0.00)
 * Acc@1 0.714 Acc@5 0.000
Test: [0/1]	Time  0.291 ( 0.291)	Loss 1.8254e-01 (1.8254e-01)	Acc@1   0.60 (  0.60)	Acc@5   0.00 (  0.00)
 * Acc@1 0.599 Acc@5 0.000
32
TRAINING
Epoch: [32][0/1]	Time  0.946 ( 0.946)	Data  0.232 ( 0.232)	Loss 8.6326e-02 (8.6326e-02)	Acc@1   0.86 (  0.86)	Acc@5   0.00 (  0.00)
[0.8626887536089471]
Test: [0/1]	Time  0.232 ( 0.232)	Loss 9.5155e-01 (9.5155e-01)	Acc@1   0.72 (  0.72)	Acc@5   0.00 (  0.00)
 * Acc@1 0.723 Acc@5 0.000
Test: [0/1]	Time  0.288 ( 0.288)	Loss 1.7348e-01 (1.7348e-01)	Acc@1   0.62 (  0.62)	Acc@5   0.00 (  0.00)
 * Acc@1 0.622 Acc@5 0.000
33
TRAINING
Epoch: [33][0/1]	Time  0.934 ( 0.934)	Data  0.244 ( 0.244)	Loss 8.0857e-02 (8.0857e-02)	Acc@1   0.87 (  0.87)	Acc@5   0.00 (  0.00)
[0.868951381681613]
Test: [0/1]	Time  0.226 ( 0.226)	Loss 9.4991e-01 (9.4991e-01)	Acc@1   0.73 (  0.73)	Acc@5   0.00 (  0.00)
 * Acc@1 0.728 Acc@5 0.000
Test: [0/1]	Time  0.283 ( 0.283)	Loss 1.6662e-01 (1.6662e-01)	Acc@1   0.64 (  0.64)	Acc@5   0.00 (  0.00)
 * Acc@1 0.644 Acc@5 0.000
34
TRAINING
Epoch: [34][0/1]	Time  0.945 ( 0.945)	Data  0.233 ( 0.233)	Loss 7.7579e-02 (7.7579e-02)	Acc@1   0.87 (  0.87)	Acc@5   0.00 (  0.00)
[0.8733875059193342]
Test: [0/1]	Time  0.229 ( 0.229)	Loss 9.4887e-01 (9.4887e-01)	Acc@1   0.73 (  0.73)	Acc@5   0.00 (  0.00)
 * Acc@1 0.728 Acc@5 0.000
Test: [0/1]	Time  0.281 ( 0.281)	Loss 1.6273e-01 (1.6273e-01)	Acc@1   0.66 (  0.66)	Acc@5   0.00 (  0.00)
 * Acc@1 0.662 Acc@5 0.000
35
TRAINING
Epoch: [35][0/1]	Time  0.965 ( 0.965)	Data  0.239 ( 0.239)	Loss 7.7171e-02 (7.7171e-02)	Acc@1   0.88 (  0.88)	Acc@5   0.00 (  0.00)
[0.8770159153954791]
Test: [0/1]	Time  0.232 ( 0.232)	Loss 9.4812e-01 (9.4812e-01)	Acc@1   0.72 (  0.72)	Acc@5   0.00 (  0.00)
 * Acc@1 0.725 Acc@5 0.000
Test: [0/1]	Time  0.278 ( 0.278)	Loss 1.6113e-01 (1.6113e-01)	Acc@1   0.68 (  0.68)	Acc@5   0.00 (  0.00)
 * Acc@1 0.678 Acc@5 0.000
36
TRAINING
Epoch: [36][0/1]	Time  0.936 ( 0.936)	Data  0.237 ( 0.237)	Loss 7.8778e-02 (7.8778e-02)	Acc@1   0.88 (  0.88)	Acc@5   0.00 (  0.00)
[0.8775937553344639]
Test: [0/1]	Time  0.229 ( 0.229)	Loss 9.4734e-01 (9.4734e-01)	Acc@1   0.72 (  0.72)	Acc@5   0.00 (  0.00)
 * Acc@1 0.723 Acc@5 0.000
Test: [0/1]	Time  0.279 ( 0.279)	Loss 1.6042e-01 (1.6042e-01)	Acc@1   0.69 (  0.69)	Acc@5   0.00 (  0.00)
 * Acc@1 0.691 Acc@5 0.000
37
TRAINING
Epoch: [37][0/1]	Time  0.936 ( 0.936)	Data  0.236 ( 0.236)	Loss 8.0779e-02 (8.0779e-02)	Acc@1   0.87 (  0.87)	Acc@5   0.00 (  0.00)
[0.8747045650554517]
Test: [0/1]	Time  0.229 ( 0.229)	Loss 9.4630e-01 (9.4630e-01)	Acc@1   0.72 (  0.72)	Acc@5   0.00 (  0.00)
 * Acc@1 0.722 Acc@5 0.000
Test: [0/1]	Time  0.279 ( 0.279)	Loss 1.5939e-01 (1.5939e-01)	Acc@1   0.70 (  0.70)	Acc@5   0.00 (  0.00)
 * Acc@1 0.703 Acc@5 0.000
38
TRAINING
Epoch: [38][0/1]	Time  0.915 ( 0.915)	Data  0.228 ( 0.228)	Loss 8.1834e-02 (8.1834e-02)	Acc@1   0.87 (  0.87)	Acc@5   0.00 (  0.00)
[0.8720851420031664]
Test: [0/1]	Time  0.234 ( 0.234)	Loss 9.4497e-01 (9.4497e-01)	Acc@1   0.72 (  0.72)	Acc@5   0.00 (  0.00)
 * Acc@1 0.722 Acc@5 0.000
Test: [0/1]	Time  0.280 ( 0.280)	Loss 1.5769e-01 (1.5769e-01)	Acc@1   0.71 (  0.71)	Acc@5   0.00 (  0.00)
 * Acc@1 0.712 Acc@5 0.000
39
TRAINING
Epoch: [39][0/1]	Time  0.942 ( 0.942)	Data  0.245 ( 0.245)	Loss 8.1576e-02 (8.1576e-02)	Acc@1   0.87 (  0.87)	Acc@5   0.00 (  0.00)
[0.8711366749325818]
Test: [0/1]	Time  0.231 ( 0.231)	Loss 9.4349e-01 (9.4349e-01)	Acc@1   0.72 (  0.72)	Acc@5   0.00 (  0.00)
 * Acc@1 0.723 Acc@5 0.000
Test: [0/1]	Time  0.279 ( 0.279)	Loss 1.5583e-01 (1.5583e-01)	Acc@1   0.72 (  0.72)	Acc@5   0.00 (  0.00)
 * Acc@1 0.722 Acc@5 0.000
40
TRAINING
Epoch: [40][0/1]	Time  0.919 ( 0.919)	Data  0.233 ( 0.233)	Loss 8.0590e-02 (8.0590e-02)	Acc@1   0.87 (  0.87)	Acc@5   0.00 (  0.00)
[0.8710665906716442]
Test: [0/1]	Time  0.225 ( 0.225)	Loss 9.4204e-01 (9.4204e-01)	Acc@1   0.72 (  0.72)	Acc@5   0.00 (  0.00)
 * Acc@1 0.725 Acc@5 0.000
Test: [0/1]	Time  0.277 ( 0.277)	Loss 1.5463e-01 (1.5463e-01)	Acc@1   0.73 (  0.73)	Acc@5   0.00 (  0.00)
 * Acc@1 0.729 Acc@5 0.000
41
TRAINING
Epoch: [41][0/1]	Time  0.938 ( 0.938)	Data  0.230 ( 0.230)	Loss 7.9850e-02 (7.9850e-02)	Acc@1   0.87 (  0.87)	Acc@5   0.00 (  0.00)
[0.8697789563131525]
Test: [0/1]	Time  0.234 ( 0.234)	Loss 9.4082e-01 (9.4082e-01)	Acc@1   0.73 (  0.73)	Acc@5   0.00 (  0.00)
 * Acc@1 0.726 Acc@5 0.000
Test: [0/1]	Time  0.287 ( 0.287)	Loss 1.5459e-01 (1.5459e-01)	Acc@1   0.73 (  0.73)	Acc@5   0.00 (  0.00)
 * Acc@1 0.735 Acc@5 0.000
42
TRAINING
Epoch: [42][0/1]	Time  0.969 ( 0.969)	Data  0.249 ( 0.249)	Loss 8.0029e-02 (8.0029e-02)	Acc@1   0.87 (  0.87)	Acc@5   0.00 (  0.00)
[0.8696511185780453]
Test: [0/1]	Time  0.229 ( 0.229)	Loss 9.3991e-01 (9.3991e-01)	Acc@1   0.73 (  0.73)	Acc@5   0.00 (  0.00)
 * Acc@1 0.727 Acc@5 0.000
Test: [0/1]	Time  0.285 ( 0.285)	Loss 1.5560e-01 (1.5560e-01)	Acc@1   0.74 (  0.74)	Acc@5   0.00 (  0.00)
 * Acc@1 0.739 Acc@5 0.000
43
TRAINING
Epoch: [43][0/1]	Time  0.934 ( 0.934)	Data  0.242 ( 0.242)	Loss 8.1130e-02 (8.1130e-02)	Acc@1   0.87 (  0.87)	Acc@5   0.00 (  0.00)
[0.869887099520998]
Test: [0/1]	Time  0.240 ( 0.240)	Loss 9.3929e-01 (9.3929e-01)	Acc@1   0.73 (  0.73)	Acc@5   0.00 (  0.00)
 * Acc@1 0.727 Acc@5 0.000
Test: [0/1]	Time  0.284 ( 0.284)	Loss 1.5703e-01 (1.5703e-01)	Acc@1   0.74 (  0.74)	Acc@5   0.00 (  0.00)
 * Acc@1 0.741 Acc@5 0.000
44
TRAINING
Epoch: [44][0/1]	Time  0.951 ( 0.951)	Data  0.243 ( 0.243)	Loss 8.2572e-02 (8.2572e-02)	Acc@1   0.87 (  0.87)	Acc@5   0.00 (  0.00)
[0.8712409403224902]
Test: [0/1]	Time  0.233 ( 0.233)	Loss 9.3893e-01 (9.3893e-01)	Acc@1   0.73 (  0.73)	Acc@5   0.00 (  0.00)
 * Acc@1 0.726 Acc@5 0.000
Test: [0/1]	Time  0.281 ( 0.281)	Loss 1.5812e-01 (1.5812e-01)	Acc@1   0.74 (  0.74)	Acc@5   0.00 (  0.00)
 * Acc@1 0.743 Acc@5 0.000
45
TRAINING
Epoch: [45][0/1]	Time  0.949 ( 0.949)	Data  0.242 ( 0.242)	Loss 8.3621e-02 (8.3621e-02)	Acc@1   0.87 (  0.87)	Acc@5   0.00 (  0.00)
[0.8737501650799393]
Test: [0/1]	Time  0.224 ( 0.224)	Loss 9.3878e-01 (9.3878e-01)	Acc@1   0.73 (  0.73)	Acc@5   0.00 (  0.00)
 * Acc@1 0.725 Acc@5 0.000
Test: [0/1]	Time  0.275 ( 0.275)	Loss 1.5842e-01 (1.5842e-01)	Acc@1   0.74 (  0.74)	Acc@5   0.00 (  0.00)
 * Acc@1 0.745 Acc@5 0.000
46
TRAINING
Epoch: [46][0/1]	Time  0.945 ( 0.945)	Data  0.232 ( 0.232)	Loss 8.3829e-02 (8.3829e-02)	Acc@1   0.88 (  0.88)	Acc@5   0.00 (  0.00)
[0.876685786729363]
Test: [0/1]	Time  0.231 ( 0.231)	Loss 9.3886e-01 (9.3886e-01)	Acc@1   0.72 (  0.72)	Acc@5   0.00 (  0.00)
 * Acc@1 0.722 Acc@5 0.000
Test: [0/1]	Time  0.282 ( 0.282)	Loss 1.5798e-01 (1.5798e-01)	Acc@1   0.75 (  0.75)	Acc@5   0.00 (  0.00)
 * Acc@1 0.746 Acc@5 0.000
47
TRAINING
Epoch: [47][0/1]	Time  0.960 ( 0.960)	Data  0.261 ( 0.261)	Loss 8.3241e-02 (8.3241e-02)	Acc@1   0.88 (  0.88)	Acc@5   0.00 (  0.00)
[0.8799331873568341]
Test: [0/1]	Time  0.240 ( 0.240)	Loss 9.3918e-01 (9.3918e-01)	Acc@1   0.72 (  0.72)	Acc@5   0.00 (  0.00)
 * Acc@1 0.718 Acc@5 0.000
Test: [0/1]	Time  0.291 ( 0.291)	Loss 1.5720e-01 (1.5720e-01)	Acc@1   0.75 (  0.75)	Acc@5   0.00 (  0.00)
 * Acc@1 0.746 Acc@5 0.000
48
TRAINING
Epoch: [48][0/1]	Time  0.919 ( 0.919)	Data  0.247 ( 0.247)	Loss 8.2287e-02 (8.2287e-02)	Acc@1   0.88 (  0.88)	Acc@5   0.00 (  0.00)
[0.88336409637775]
Test: [0/1]	Time  0.241 ( 0.241)	Loss 9.3972e-01 (9.3972e-01)	Acc@1   0.71 (  0.71)	Acc@5   0.00 (  0.00)
 * Acc@1 0.715 Acc@5 0.000
Test: [0/1]	Time  0.294 ( 0.294)	Loss 1.5659e-01 (1.5659e-01)	Acc@1   0.75 (  0.75)	Acc@5   0.00 (  0.00)
 * Acc@1 0.746 Acc@5 0.000
49
TRAINING
Epoch: [49][0/1]	Time  0.914 ( 0.914)	Data  0.242 ( 0.242)	Loss 8.1474e-02 (8.1474e-02)	Acc@1   0.89 (  0.89)	Acc@5   0.00 (  0.00)
[0.886852830922539]
Test: [0/1]	Time  0.226 ( 0.226)	Loss 9.4042e-01 (9.4042e-01)	Acc@1   0.71 (  0.71)	Acc@5   0.00 (  0.00)
 * Acc@1 0.711 Acc@5 0.000
Test: [0/1]	Time  0.277 ( 0.277)	Loss 1.5644e-01 (1.5644e-01)	Acc@1   0.75 (  0.75)	Acc@5   0.00 (  0.00)
 * Acc@1 0.747 Acc@5 0.000
50
TRAINING
Epoch: [50][0/1]	Time  0.944 ( 0.944)	Data  0.237 ( 0.237)	Loss 8.1097e-02 (8.1097e-02)	Acc@1   0.89 (  0.89)	Acc@5   0.00 (  0.00)
[0.8916447586701957]
Test: [0/1]	Time  0.227 ( 0.227)	Loss 9.4120e-01 (9.4120e-01)	Acc@1   0.71 (  0.71)	Acc@5   0.00 (  0.00)
 * Acc@1 0.708 Acc@5 0.000
Test: [0/1]	Time  0.282 ( 0.282)	Loss 1.5672e-01 (1.5672e-01)	Acc@1   0.75 (  0.75)	Acc@5   0.00 (  0.00)
 * Acc@1 0.749 Acc@5 0.000
51
TRAINING
Epoch: [51][0/1]	Time  0.933 ( 0.933)	Data  0.244 ( 0.244)	Loss 8.1132e-02 (8.1132e-02)	Acc@1   0.90 (  0.90)	Acc@5   0.00 (  0.00)
[0.8963731767886479]
Test: [0/1]	Time  0.231 ( 0.231)	Loss 9.4193e-01 (9.4193e-01)	Acc@1   0.71 (  0.71)	Acc@5   0.00 (  0.00)
 * Acc@1 0.705 Acc@5 0.000
Test: [0/1]	Time  0.277 ( 0.277)	Loss 1.5721e-01 (1.5721e-01)	Acc@1   0.75 (  0.75)	Acc@5   0.00 (  0.00)
 * Acc@1 0.752 Acc@5 0.000
52
TRAINING
Epoch: [52][0/1]	Time  0.948 ( 0.948)	Data  0.244 ( 0.244)	Loss 8.1320e-02 (8.1320e-02)	Acc@1   0.90 (  0.90)	Acc@5   0.00 (  0.00)
[0.9000195270463216]
Test: [0/1]	Time  0.233 ( 0.233)	Loss 9.4255e-01 (9.4255e-01)	Acc@1   0.70 (  0.70)	Acc@5   0.00 (  0.00)
 * Acc@1 0.703 Acc@5 0.000
Test: [0/1]	Time  0.281 ( 0.281)	Loss 1.5763e-01 (1.5763e-01)	Acc@1   0.75 (  0.75)	Acc@5   0.00 (  0.00)
 * Acc@1 0.753 Acc@5 0.000
53
TRAINING
Epoch: [53][0/1]	Time  0.923 ( 0.923)	Data  0.236 ( 0.236)	Loss 8.1383e-02 (8.1383e-02)	Acc@1   0.90 (  0.90)	Acc@5   0.00 (  0.00)
[0.9036463010594699]
Test: [0/1]	Time  0.226 ( 0.226)	Loss 9.4299e-01 (9.4299e-01)	Acc@1   0.70 (  0.70)	Acc@5   0.00 (  0.00)
 * Acc@1 0.702 Acc@5 0.000
Test: [0/1]	Time  0.279 ( 0.279)	Loss 1.5785e-01 (1.5785e-01)	Acc@1   0.75 (  0.75)	Acc@5   0.00 (  0.00)
 * Acc@1 0.753 Acc@5 0.000
54
TRAINING
Epoch: [54][0/1]	Time  0.934 ( 0.934)	Data  0.232 ( 0.232)	Loss 8.1187e-02 (8.1187e-02)	Acc@1   0.91 (  0.91)	Acc@5   0.00 (  0.00)
[0.9073607415717999]
Test: [0/1]	Time  0.230 ( 0.230)	Loss 9.4330e-01 (9.4330e-01)	Acc@1   0.70 (  0.70)	Acc@5   0.00 (  0.00)
 * Acc@1 0.702 Acc@5 0.000
Test: [0/1]	Time  0.278 ( 0.278)	Loss 1.5789e-01 (1.5789e-01)	Acc@1   0.75 (  0.75)	Acc@5   0.00 (  0.00)
 * Acc@1 0.753 Acc@5 0.000
55
TRAINING
Epoch: [55][0/1]	Time  0.904 ( 0.904)	Data  0.231 ( 0.231)	Loss 8.0798e-02 (8.0798e-02)	Acc@1   0.91 (  0.91)	Acc@5   0.00 (  0.00)
[0.9110831637325387]
Test: [0/1]	Time  0.224 ( 0.224)	Loss 9.4353e-01 (9.4353e-01)	Acc@1   0.70 (  0.70)	Acc@5   0.00 (  0.00)
 * Acc@1 0.702 Acc@5 0.000
Test: [0/1]	Time  0.273 ( 0.273)	Loss 1.5790e-01 (1.5790e-01)	Acc@1   0.75 (  0.75)	Acc@5   0.00 (  0.00)
 * Acc@1 0.752 Acc@5 0.000
56
TRAINING
Epoch: [56][0/1]	Time  0.923 ( 0.923)	Data  0.228 ( 0.228)	Loss 8.0402e-02 (8.0402e-02)	Acc@1   0.91 (  0.91)	Acc@5   0.00 (  0.00)
[0.9146373920119609]
Test: [0/1]	Time  0.239 ( 0.239)	Loss 9.4375e-01 (9.4375e-01)	Acc@1   0.70 (  0.70)	Acc@5   0.00 (  0.00)
 * Acc@1 0.702 Acc@5 0.000
Test: [0/1]	Time  0.289 ( 0.289)	Loss 1.5800e-01 (1.5800e-01)	Acc@1   0.75 (  0.75)	Acc@5   0.00 (  0.00)
 * Acc@1 0.751 Acc@5 0.000
57
TRAINING
Epoch: [57][0/1]	Time  0.919 ( 0.919)	Data  0.245 ( 0.245)	Loss 8.0164e-02 (8.0164e-02)	Acc@1   0.92 (  0.92)	Acc@5   0.00 (  0.00)
[0.9178487877815525]
Test: [0/1]	Time  0.228 ( 0.228)	Loss 9.4404e-01 (9.4404e-01)	Acc@1   0.70 (  0.70)	Acc@5   0.00 (  0.00)
 * Acc@1 0.703 Acc@5 0.000
Test: [0/1]	Time  0.284 ( 0.284)	Loss 1.5824e-01 (1.5824e-01)	Acc@1   0.75 (  0.75)	Acc@5   0.00 (  0.00)
 * Acc@1 0.751 Acc@5 0.000
58
TRAINING
Epoch: [58][0/1]	Time  0.916 ( 0.916)	Data  0.243 ( 0.243)	Loss 8.0131e-02 (8.0131e-02)	Acc@1   0.92 (  0.92)	Acc@5   0.00 (  0.00)
[0.920628911119096]
Test: [0/1]	Time  0.225 ( 0.225)	Loss 9.4445e-01 (9.4445e-01)	Acc@1   0.70 (  0.70)	Acc@5   0.00 (  0.00)
 * Acc@1 0.703 Acc@5 0.000
Test: [0/1]	Time  0.276 ( 0.276)	Loss 1.5851e-01 (1.5851e-01)	Acc@1   0.75 (  0.75)	Acc@5   0.00 (  0.00)
 * Acc@1 0.750 Acc@5 0.000
59
TRAINING
Epoch: [59][0/1]	Time  0.918 ( 0.918)	Data  0.244 ( 0.244)	Loss 8.0218e-02 (8.0218e-02)	Acc@1   0.92 (  0.92)	Acc@5   0.00 (  0.00)
[0.9229986628079566]
Test: [0/1]	Time  0.228 ( 0.228)	Loss 9.4497e-01 (9.4497e-01)	Acc@1   0.70 (  0.70)	Acc@5   0.00 (  0.00)
 * Acc@1 0.703 Acc@5 0.000
Test: [0/1]	Time  0.284 ( 0.284)	Loss 1.5868e-01 (1.5868e-01)	Acc@1   0.75 (  0.75)	Acc@5   0.00 (  0.00)
 * Acc@1 0.750 Acc@5 0.000
60
TRAINING
Epoch: [60][0/1]	Time  0.944 ( 0.944)	Data  0.228 ( 0.228)	Loss 8.0276e-02 (8.0276e-02)	Acc@1   0.93 (  0.93)	Acc@5   0.00 (  0.00)
[0.9250466805133173]
Test: [0/1]	Time  0.220 ( 0.220)	Loss 9.4563e-01 (9.4563e-01)	Acc@1   0.70 (  0.70)	Acc@5   0.00 (  0.00)
 * Acc@1 0.703 Acc@5 0.000
Test: [0/1]	Time  0.275 ( 0.275)	Loss 1.5866e-01 (1.5866e-01)	Acc@1   0.75 (  0.75)	Acc@5   0.00 (  0.00)
 * Acc@1 0.749 Acc@5 0.000
61
TRAINING
Epoch: [61][0/1]	Time  0.903 ( 0.903)	Data  0.230 ( 0.230)	Loss 8.0186e-02 (8.0186e-02)	Acc@1   0.93 (  0.93)	Acc@5   0.00 (  0.00)
[0.9266713050438303]
Test: [0/1]	Time  0.222 ( 0.222)	Loss 9.4641e-01 (9.4641e-01)	Acc@1   0.70 (  0.70)	Acc@5   0.00 (  0.00)
 * Acc@1 0.702 Acc@5 0.000
Test: [0/1]	Time  0.271 ( 0.271)	Loss 1.5843e-01 (1.5843e-01)	Acc@1   0.75 (  0.75)	Acc@5   0.00 (  0.00)
 * Acc@1 0.748 Acc@5 0.000
62
TRAINING
Epoch: [62][0/1]	Time  0.903 ( 0.903)	Data  0.230 ( 0.230)	Loss 7.9923e-02 (7.9923e-02)	Acc@1   0.93 (  0.93)	Acc@5   0.00 (  0.00)
[0.9280591521083194]
Test: [0/1]	Time  0.229 ( 0.229)	Loss 9.4728e-01 (9.4728e-01)	Acc@1   0.70 (  0.70)	Acc@5   0.00 (  0.00)
 * Acc@1 0.702 Acc@5 0.000
Test: [0/1]	Time  0.277 ( 0.277)	Loss 1.5805e-01 (1.5805e-01)	Acc@1   0.75 (  0.75)	Acc@5   0.00 (  0.00)
 * Acc@1 0.748 Acc@5 0.000
63
TRAINING
Epoch: [63][0/1]	Time  0.905 ( 0.905)	Data  0.231 ( 0.231)	Loss 7.9555e-02 (7.9555e-02)	Acc@1   0.93 (  0.93)	Acc@5   0.00 (  0.00)
[0.9289764418044638]
Test: [0/1]	Time  0.222 ( 0.222)	Loss 9.4821e-01 (9.4821e-01)	Acc@1   0.70 (  0.70)	Acc@5   0.00 (  0.00)
 * Acc@1 0.701 Acc@5 0.000
Test: [0/1]	Time  0.270 ( 0.270)	Loss 1.5765e-01 (1.5765e-01)	Acc@1   0.75 (  0.75)	Acc@5   0.00 (  0.00)
 * Acc@1 0.748 Acc@5 0.000
64
TRAINING
Epoch: [64][0/1]	Time  0.909 ( 0.909)	Data  0.228 ( 0.228)	Loss 7.9190e-02 (7.9190e-02)	Acc@1   0.93 (  0.93)	Acc@5   0.00 (  0.00)
[0.9294923999601674]
Test: [0/1]	Time  0.225 ( 0.225)	Loss 9.4914e-01 (9.4914e-01)	Acc@1   0.70 (  0.70)	Acc@5   0.00 (  0.00)
 * Acc@1 0.700 Acc@5 0.000
Test: [0/1]	Time  0.274 ( 0.274)	Loss 1.5730e-01 (1.5730e-01)	Acc@1   0.75 (  0.75)	Acc@5   0.00 (  0.00)
 * Acc@1 0.747 Acc@5 0.000
65
TRAINING
Epoch: [65][0/1]	Time  0.922 ( 0.922)	Data  0.228 ( 0.228)	Loss 7.8912e-02 (7.8912e-02)	Acc@1   0.93 (  0.93)	Acc@5   0.00 (  0.00)
[0.9297107077529843]
Test: [0/1]	Time  0.220 ( 0.220)	Loss 9.5001e-01 (9.5001e-01)	Acc@1   0.70 (  0.70)	Acc@5   0.00 (  0.00)
 * Acc@1 0.698 Acc@5 0.000
Test: [0/1]	Time  0.271 ( 0.271)	Loss 1.5704e-01 (1.5704e-01)	Acc@1   0.75 (  0.75)	Acc@5   0.00 (  0.00)
 * Acc@1 0.749 Acc@5 0.000
66
TRAINING
Epoch: [66][0/1]	Time  0.905 ( 0.905)	Data  0.233 ( 0.233)	Loss 7.8746e-02 (7.8746e-02)	Acc@1   0.93 (  0.93)	Acc@5   0.00 (  0.00)
[0.9302416547142023]
Test: [0/1]	Time  0.227 ( 0.227)	Loss 9.5077e-01 (9.5077e-01)	Acc@1   0.70 (  0.70)	Acc@5   0.00 (  0.00)
 * Acc@1 0.697 Acc@5 0.000
Test: [0/1]	Time  0.277 ( 0.277)	Loss 1.5685e-01 (1.5685e-01)	Acc@1   0.75 (  0.75)	Acc@5   0.00 (  0.00)
 * Acc@1 0.751 Acc@5 0.000
67
TRAINING
Epoch: [67][0/1]	Time  0.916 ( 0.916)	Data  0.232 ( 0.232)	Loss 7.8656e-02 (7.8656e-02)	Acc@1   0.93 (  0.93)	Acc@5   0.00 (  0.00)
[0.9306583787800489]
Test: [0/1]	Time  0.224 ( 0.224)	Loss 9.5138e-01 (9.5138e-01)	Acc@1   0.70 (  0.70)	Acc@5   0.00 (  0.00)
 * Acc@1 0.696 Acc@5 0.000
Test: [0/1]	Time  0.275 ( 0.275)	Loss 1.5666e-01 (1.5666e-01)	Acc@1   0.75 (  0.75)	Acc@5   0.00 (  0.00)
 * Acc@1 0.752 Acc@5 0.000
68
TRAINING
Epoch: [68][0/1]	Time  0.907 ( 0.907)	Data  0.233 ( 0.233)	Loss 7.8587e-02 (7.8587e-02)	Acc@1   0.93 (  0.93)	Acc@5   0.00 (  0.00)
[0.9309881819386077]
Test: [0/1]	Time  0.220 ( 0.220)	Loss 9.5182e-01 (9.5182e-01)	Acc@1   0.70 (  0.70)	Acc@5   0.00 (  0.00)
 * Acc@1 0.696 Acc@5 0.000
Test: [0/1]	Time  0.296 ( 0.296)	Loss 1.5646e-01 (1.5646e-01)	Acc@1   0.75 (  0.75)	Acc@5   0.00 (  0.00)
 * Acc@1 0.753 Acc@5 0.000
69
TRAINING
Epoch: [69][0/1]	Time  0.903 ( 0.903)	Data  0.228 ( 0.228)	Loss 7.8500e-02 (7.8500e-02)	Acc@1   0.93 (  0.93)	Acc@5   0.00 (  0.00)
[0.9312540827303455]
Test: [0/1]	Time  0.220 ( 0.220)	Loss 9.5211e-01 (9.5211e-01)	Acc@1   0.70 (  0.70)	Acc@5   0.00 (  0.00)
 * Acc@1 0.696 Acc@5 0.000
Test: [0/1]	Time  0.278 ( 0.278)	Loss 1.5624e-01 (1.5624e-01)	Acc@1   0.75 (  0.75)	Acc@5   0.00 (  0.00)
 * Acc@1 0.753 Acc@5 0.000
70
TRAINING
Epoch: [70][0/1]	Time  0.930 ( 0.930)	Data  0.223 ( 0.223)	Loss 7.8391e-02 (7.8391e-02)	Acc@1   0.93 (  0.93)	Acc@5   0.00 (  0.00)
[0.9314717537091415]
Test: [0/1]	Time  0.220 ( 0.220)	Loss 9.5225e-01 (9.5225e-01)	Acc@1   0.70 (  0.70)	Acc@5   0.00 (  0.00)
 * Acc@1 0.696 Acc@5 0.000
Test: [0/1]	Time  0.272 ( 0.272)	Loss 1.5602e-01 (1.5602e-01)	Acc@1   0.75 (  0.75)	Acc@5   0.00 (  0.00)
 * Acc@1 0.754 Acc@5 0.000
71
TRAINING
Epoch: [71][0/1]	Time  0.941 ( 0.941)	Data  0.232 ( 0.232)	Loss 7.8287e-02 (7.8287e-02)	Acc@1   0.93 (  0.93)	Acc@5   0.00 (  0.00)
[0.9316496959907021]
Test: [0/1]	Time  0.221 ( 0.221)	Loss 9.5229e-01 (9.5229e-01)	Acc@1   0.70 (  0.70)	Acc@5   0.00 (  0.00)
 * Acc@1 0.697 Acc@5 0.000
Test: [0/1]	Time  0.273 ( 0.273)	Loss 1.5584e-01 (1.5584e-01)	Acc@1   0.75 (  0.75)	Acc@5   0.00 (  0.00)
 * Acc@1 0.754 Acc@5 0.000
72
TRAINING
Epoch: [72][0/1]	Time  0.946 ( 0.946)	Data  0.235 ( 0.235)	Loss 7.8220e-02 (7.8220e-02)	Acc@1   0.93 (  0.93)	Acc@5   0.00 (  0.00)
[0.9317918701180057]
Test: [0/1]	Time  0.224 ( 0.224)	Loss 9.5228e-01 (9.5228e-01)	Acc@1   0.70 (  0.70)	Acc@5   0.00 (  0.00)
 * Acc@1 0.697 Acc@5 0.000
Test: [0/1]	Time  0.271 ( 0.271)	Loss 1.5570e-01 (1.5570e-01)	Acc@1   0.75 (  0.75)	Acc@5   0.00 (  0.00)
 * Acc@1 0.755 Acc@5 0.000
73
TRAINING
Epoch: [73][0/1]	Time  0.931 ( 0.931)	Data  0.226 ( 0.226)	Loss 7.8204e-02 (7.8204e-02)	Acc@1   0.93 (  0.93)	Acc@5   0.00 (  0.00)
[0.9317916810902478]
Test: [0/1]	Time  0.222 ( 0.222)	Loss 9.5224e-01 (9.5224e-01)	Acc@1   0.70 (  0.70)	Acc@5   0.00 (  0.00)
 * Acc@1 0.698 Acc@5 0.000
Test: [0/1]	Time  0.273 ( 0.273)	Loss 1.5559e-01 (1.5559e-01)	Acc@1   0.76 (  0.76)	Acc@5   0.00 (  0.00)
 * Acc@1 0.755 Acc@5 0.000
74
TRAINING
Epoch: [74][0/1]	Time  0.937 ( 0.937)	Data  0.231 ( 0.231)	Loss 7.8225e-02 (7.8225e-02)	Acc@1   0.93 (  0.93)	Acc@5   0.00 (  0.00)
[0.9317004363216159]
Test: [0/1]	Time  0.221 ( 0.221)	Loss 9.5222e-01 (9.5222e-01)	Acc@1   0.70 (  0.70)	Acc@5   0.00 (  0.00)
 * Acc@1 0.698 Acc@5 0.000
Test: [0/1]	Time  0.272 ( 0.272)	Loss 1.5548e-01 (1.5548e-01)	Acc@1   0.76 (  0.76)	Acc@5   0.00 (  0.00)
 * Acc@1 0.756 Acc@5 0.000
75
TRAINING
Epoch: [75][0/1]	Time  0.962 ( 0.962)	Data  0.244 ( 0.244)	Loss 7.8251e-02 (7.8251e-02)	Acc@1   0.93 (  0.93)	Acc@5   0.00 (  0.00)
[0.9318065845664332]
Test: [0/1]	Time  0.228 ( 0.228)	Loss 9.5222e-01 (9.5222e-01)	Acc@1   0.70 (  0.70)	Acc@5   0.00 (  0.00)
 * Acc@1 0.699 Acc@5 0.000
Test: [0/1]	Time  0.282 ( 0.282)	Loss 1.5536e-01 (1.5536e-01)	Acc@1   0.76 (  0.76)	Acc@5   0.00 (  0.00)
 * Acc@1 0.757 Acc@5 0.000
76
TRAINING
Epoch: [76][0/1]	Time  0.931 ( 0.931)	Data  0.228 ( 0.228)	Loss 7.8252e-02 (7.8252e-02)	Acc@1   0.93 (  0.93)	Acc@5   0.00 (  0.00)
[0.9318159940072643]
Test: [0/1]	Time  0.225 ( 0.225)	Loss 9.5226e-01 (9.5226e-01)	Acc@1   0.70 (  0.70)	Acc@5   0.00 (  0.00)
 * Acc@1 0.699 Acc@5 0.000
Test: [0/1]	Time  0.271 ( 0.271)	Loss 1.5520e-01 (1.5520e-01)	Acc@1   0.76 (  0.76)	Acc@5   0.00 (  0.00)
 * Acc@1 0.758 Acc@5 0.000
77
TRAINING
Epoch: [77][0/1]	Time  0.928 ( 0.928)	Data  0.231 ( 0.231)	Loss 7.8213e-02 (7.8213e-02)	Acc@1   0.93 (  0.93)	Acc@5   0.00 (  0.00)
[0.9318712409038971]
Test: [0/1]	Time  0.230 ( 0.230)	Loss 9.5232e-01 (9.5232e-01)	Acc@1   0.70 (  0.70)	Acc@5   0.00 (  0.00)
 * Acc@1 0.700 Acc@5 0.000
Test: [0/1]	Time  0.277 ( 0.277)	Loss 1.5503e-01 (1.5503e-01)	Acc@1   0.76 (  0.76)	Acc@5   0.00 (  0.00)
 * Acc@1 0.759 Acc@5 0.000
78
TRAINING
Epoch: [78][0/1]	Time  0.949 ( 0.949)	Data  0.226 ( 0.226)	Loss 7.8143e-02 (7.8143e-02)	Acc@1   0.93 (  0.93)	Acc@5   0.00 (  0.00)
[0.9319645460759161]
Test: [0/1]	Time  0.220 ( 0.220)	Loss 9.5241e-01 (9.5241e-01)	Acc@1   0.70 (  0.70)	Acc@5   0.00 (  0.00)
 * Acc@1 0.700 Acc@5 0.000
Test: [0/1]	Time  0.271 ( 0.271)	Loss 1.5485e-01 (1.5485e-01)	Acc@1   0.76 (  0.76)	Acc@5   0.00 (  0.00)
 * Acc@1 0.760 Acc@5 0.000
79
TRAINING
Epoch: [79][0/1]	Time  0.933 ( 0.933)	Data  0.229 ( 0.229)	Loss 7.8062e-02 (7.8062e-02)	Acc@1   0.93 (  0.93)	Acc@5   0.00 (  0.00)
[0.9320868296299754]
Test: [0/1]	Time  0.222 ( 0.222)	Loss 9.5250e-01 (9.5250e-01)	Acc@1   0.70 (  0.70)	Acc@5   0.00 (  0.00)
 * Acc@1 0.700 Acc@5 0.000
Test: [0/1]	Time  0.273 ( 0.273)	Loss 1.5470e-01 (1.5470e-01)	Acc@1   0.76 (  0.76)	Acc@5   0.00 (  0.00)
 * Acc@1 0.762 Acc@5 0.000
80
TRAINING
Epoch: [80][0/1]	Time  0.933 ( 0.933)	Data  0.224 ( 0.224)	Loss 7.7993e-02 (7.7993e-02)	Acc@1   0.93 (  0.93)	Acc@5   0.00 (  0.00)
[0.9321032254644691]
Test: [0/1]	Time  0.223 ( 0.223)	Loss 9.5257e-01 (9.5257e-01)	Acc@1   0.70 (  0.70)	Acc@5   0.00 (  0.00)
 * Acc@1 0.700 Acc@5 0.000
Test: [0/1]	Time  0.274 ( 0.274)	Loss 1.5457e-01 (1.5457e-01)	Acc@1   0.76 (  0.76)	Acc@5   0.00 (  0.00)
 * Acc@1 0.763 Acc@5 0.000
81
TRAINING
Epoch: [81][0/1]	Time  0.936 ( 0.936)	Data  0.231 ( 0.231)	Loss 7.7947e-02 (7.7947e-02)	Acc@1   0.93 (  0.93)	Acc@5   0.00 (  0.00)
[0.9321163533736319]
Test: [0/1]	Time  0.221 ( 0.221)	Loss 9.5260e-01 (9.5260e-01)	Acc@1   0.70 (  0.70)	Acc@5   0.00 (  0.00)
 * Acc@1 0.701 Acc@5 0.000
Test: [0/1]	Time  0.274 ( 0.274)	Loss 1.5447e-01 (1.5447e-01)	Acc@1   0.76 (  0.76)	Acc@5   0.00 (  0.00)
 * Acc@1 0.763 Acc@5 0.000
82
TRAINING
Epoch: [82][0/1]	Time  0.980 ( 0.980)	Data  0.268 ( 0.268)	Loss 7.7923e-02 (7.7923e-02)	Acc@1   0.93 (  0.93)	Acc@5   0.00 (  0.00)
[0.9321464480664698]
Test: [0/1]	Time  0.235 ( 0.235)	Loss 9.5258e-01 (9.5258e-01)	Acc@1   0.70 (  0.70)	Acc@5   0.00 (  0.00)
 * Acc@1 0.701 Acc@5 0.000
Test: [0/1]	Time  0.284 ( 0.284)	Loss 1.5440e-01 (1.5440e-01)	Acc@1   0.76 (  0.76)	Acc@5   0.00 (  0.00)
 * Acc@1 0.764 Acc@5 0.000
83
TRAINING
Epoch: [83][0/1]	Time  0.933 ( 0.933)	Data  0.232 ( 0.232)	Loss 7.7911e-02 (7.7911e-02)	Acc@1   0.93 (  0.93)	Acc@5   0.00 (  0.00)
[0.9322001189954996]
Test: [0/1]	Time  0.224 ( 0.224)	Loss 9.5250e-01 (9.5250e-01)	Acc@1   0.70 (  0.70)	Acc@5   0.00 (  0.00)
 * Acc@1 0.702 Acc@5 0.000
Test: [0/1]	Time  0.273 ( 0.273)	Loss 1.5433e-01 (1.5433e-01)	Acc@1   0.76 (  0.76)	Acc@5   0.00 (  0.00)
 * Acc@1 0.764 Acc@5 0.000
84
TRAINING
Epoch: [84][0/1]	Time  0.925 ( 0.925)	Data  0.230 ( 0.230)	Loss 7.7902e-02 (7.7902e-02)	Acc@1   0.93 (  0.93)	Acc@5   0.00 (  0.00)
[0.932282525977465]
Test: [0/1]	Time  0.228 ( 0.228)	Loss 9.5236e-01 (9.5236e-01)	Acc@1   0.70 (  0.70)	Acc@5   0.00 (  0.00)
 * Acc@1 0.702 Acc@5 0.000
Test: [0/1]	Time  0.277 ( 0.277)	Loss 1.5426e-01 (1.5426e-01)	Acc@1   0.76 (  0.76)	Acc@5   0.00 (  0.00)
 * Acc@1 0.765 Acc@5 0.000
85
TRAINING
Epoch: [85][0/1]	Time  0.930 ( 0.930)	Data  0.229 ( 0.229)	Loss 7.7893e-02 (7.7893e-02)	Acc@1   0.93 (  0.93)	Acc@5   0.00 (  0.00)
[0.9323933898863275]
Test: [0/1]	Time  0.228 ( 0.228)	Loss 9.5218e-01 (9.5218e-01)	Acc@1   0.70 (  0.70)	Acc@5   0.00 (  0.00)
 * Acc@1 0.703 Acc@5 0.000
Test: [0/1]	Time  0.285 ( 0.285)	Loss 1.5420e-01 (1.5420e-01)	Acc@1   0.76 (  0.76)	Acc@5   0.00 (  0.00)
 * Acc@1 0.765 Acc@5 0.000
86
TRAINING
Epoch: [86][0/1]	Time  0.945 ( 0.945)	Data  0.232 ( 0.232)	Loss 7.7884e-02 (7.7884e-02)	Acc@1   0.93 (  0.93)	Acc@5   0.00 (  0.00)
[0.9325182890206545]
Test: [0/1]	Time  0.228 ( 0.228)	Loss 9.5197e-01 (9.5197e-01)	Acc@1   0.70 (  0.70)	Acc@5   0.00 (  0.00)
 * Acc@1 0.704 Acc@5 0.000
Test: [0/1]	Time  0.279 ( 0.279)	Loss 1.5415e-01 (1.5415e-01)	Acc@1   0.77 (  0.77)	Acc@5   0.00 (  0.00)
 * Acc@1 0.765 Acc@5 0.000
87
TRAINING
Epoch: [87][0/1]	Time  0.939 ( 0.939)	Data  0.231 ( 0.231)	Loss 7.7882e-02 (7.7882e-02)	Acc@1   0.93 (  0.93)	Acc@5   0.00 (  0.00)
[0.9326643784732853]
Test: [0/1]	Time  0.224 ( 0.224)	Loss 9.5176e-01 (9.5176e-01)	Acc@1   0.70 (  0.70)	Acc@5   0.00 (  0.00)
 * Acc@1 0.705 Acc@5 0.000
Test: [0/1]	Time  0.277 ( 0.277)	Loss 1.5412e-01 (1.5412e-01)	Acc@1   0.77 (  0.77)	Acc@5   0.00 (  0.00)
 * Acc@1 0.766 Acc@5 0.000
88
TRAINING
Epoch: [88][0/1]	Time  0.928 ( 0.928)	Data  0.237 ( 0.237)	Loss 7.7888e-02 (7.7888e-02)	Acc@1   0.93 (  0.93)	Acc@5   0.00 (  0.00)
[0.9328192533676487]
Test: [0/1]	Time  0.229 ( 0.229)	Loss 9.5156e-01 (9.5156e-01)	Acc@1   0.71 (  0.71)	Acc@5   0.00 (  0.00)
 * Acc@1 0.705 Acc@5 0.000
Test: [0/1]	Time  0.278 ( 0.278)	Loss 1.5409e-01 (1.5409e-01)	Acc@1   0.77 (  0.77)	Acc@5   0.00 (  0.00)
 * Acc@1 0.766 Acc@5 0.000
89
TRAINING
Epoch: [89][0/1]	Time  0.928 ( 0.928)	Data  0.231 ( 0.231)	Loss 7.7900e-02 (7.7900e-02)	Acc@1   0.93 (  0.93)	Acc@5   0.00 (  0.00)
[0.9329761880579879]
Test: [0/1]	Time  0.229 ( 0.229)	Loss 9.5139e-01 (9.5139e-01)	Acc@1   0.71 (  0.71)	Acc@5   0.00 (  0.00)
 * Acc@1 0.706 Acc@5 0.000
Test: [0/1]	Time  0.278 ( 0.278)	Loss 1.5407e-01 (1.5407e-01)	Acc@1   0.77 (  0.77)	Acc@5   0.00 (  0.00)
 * Acc@1 0.766 Acc@5 0.000
90
TRAINING
Epoch: [90][0/1]	Time  0.919 ( 0.919)	Data  0.229 ( 0.229)	Loss 7.7910e-02 (7.7910e-02)	Acc@1   0.93 (  0.93)	Acc@5   0.00 (  0.00)
[0.9331298620992244]
Test: [0/1]	Time  0.224 ( 0.224)	Loss 9.5126e-01 (9.5126e-01)	Acc@1   0.71 (  0.71)	Acc@5   0.00 (  0.00)
 * Acc@1 0.707 Acc@5 0.000
Test: [0/1]	Time  0.271 ( 0.271)	Loss 1.5404e-01 (1.5404e-01)	Acc@1   0.77 (  0.77)	Acc@5   0.00 (  0.00)
 * Acc@1 0.767 Acc@5 0.000
91
TRAINING
Epoch: [91][0/1]	Time  0.941 ( 0.941)	Data  0.233 ( 0.233)	Loss 7.7912e-02 (7.7912e-02)	Acc@1   0.93 (  0.93)	Acc@5   0.00 (  0.00)
[0.9332765908782218]
Test: [0/1]	Time  0.227 ( 0.227)	Loss 9.5118e-01 (9.5118e-01)	Acc@1   0.71 (  0.71)	Acc@5   0.00 (  0.00)
 * Acc@1 0.707 Acc@5 0.000
Test: [0/1]	Time  0.273 ( 0.273)	Loss 1.5401e-01 (1.5401e-01)	Acc@1   0.77 (  0.77)	Acc@5   0.00 (  0.00)
 * Acc@1 0.767 Acc@5 0.000
92
TRAINING
Epoch: [92][0/1]	Time  0.927 ( 0.927)	Data  0.228 ( 0.228)	Loss 7.7900e-02 (7.7900e-02)	Acc@1   0.93 (  0.93)	Acc@5   0.00 (  0.00)
[0.9333669830919646]
Test: [0/1]	Time  0.225 ( 0.225)	Loss 9.5113e-01 (9.5113e-01)	Acc@1   0.71 (  0.71)	Acc@5   0.00 (  0.00)
 * Acc@1 0.707 Acc@5 0.000
Test: [0/1]	Time  0.279 ( 0.279)	Loss 1.5397e-01 (1.5397e-01)	Acc@1   0.77 (  0.77)	Acc@5   0.00 (  0.00)
 * Acc@1 0.767 Acc@5 0.000
93
TRAINING
Epoch: [93][0/1]	Time  0.947 ( 0.947)	Data  0.237 ( 0.237)	Loss 7.7876e-02 (7.7876e-02)	Acc@1   0.93 (  0.93)	Acc@5   0.00 (  0.00)
[0.933451529035751]
Test: [0/1]	Time  0.223 ( 0.223)	Loss 9.5111e-01 (9.5111e-01)	Acc@1   0.71 (  0.71)	Acc@5   0.00 (  0.00)
 * Acc@1 0.707 Acc@5 0.000
Test: [0/1]	Time  0.277 ( 0.277)	Loss 1.5393e-01 (1.5393e-01)	Acc@1   0.77 (  0.77)	Acc@5   0.00 (  0.00)
 * Acc@1 0.767 Acc@5 0.000
94
TRAINING
Epoch: [94][0/1]	Time  0.941 ( 0.941)	Data  0.229 ( 0.229)	Loss 7.7844e-02 (7.7844e-02)	Acc@1   0.93 (  0.93)	Acc@5   0.00 (  0.00)
[0.9335318120701972]
Test: [0/1]	Time  0.224 ( 0.224)	Loss 9.5111e-01 (9.5111e-01)	Acc@1   0.71 (  0.71)	Acc@5   0.00 (  0.00)
 * Acc@1 0.708 Acc@5 0.000
Test: [0/1]	Time  0.276 ( 0.276)	Loss 1.5389e-01 (1.5389e-01)	Acc@1   0.77 (  0.77)	Acc@5   0.00 (  0.00)
 * Acc@1 0.767 Acc@5 0.000
95
TRAINING
Epoch: [95][0/1]	Time  0.921 ( 0.921)	Data  0.233 ( 0.233)	Loss 7.7811e-02 (7.7811e-02)	Acc@1   0.93 (  0.93)	Acc@5   0.00 (  0.00)
[0.9336079565021553]
Test: [0/1]	Time  0.221 ( 0.221)	Loss 9.5113e-01 (9.5113e-01)	Acc@1   0.71 (  0.71)	Acc@5   0.00 (  0.00)
 * Acc@1 0.708 Acc@5 0.000
Test: [0/1]	Time  0.275 ( 0.275)	Loss 1.5386e-01 (1.5386e-01)	Acc@1   0.77 (  0.77)	Acc@5   0.00 (  0.00)
 * Acc@1 0.768 Acc@5 0.000
96
TRAINING
Epoch: [96][0/1]	Time  0.929 ( 0.929)	Data  0.233 ( 0.233)	Loss 7.7780e-02 (7.7780e-02)	Acc@1   0.93 (  0.93)	Acc@5   0.00 (  0.00)
[0.9336802690705939]
Test: [0/1]	Time  0.220 ( 0.220)	Loss 9.5114e-01 (9.5114e-01)	Acc@1   0.71 (  0.71)	Acc@5   0.00 (  0.00)
 * Acc@1 0.708 Acc@5 0.000
Test: [0/1]	Time  0.274 ( 0.274)	Loss 1.5384e-01 (1.5384e-01)	Acc@1   0.77 (  0.77)	Acc@5   0.00 (  0.00)
 * Acc@1 0.768 Acc@5 0.000
97
TRAINING
Epoch: [97][0/1]	Time  0.935 ( 0.935)	Data  0.233 ( 0.233)	Loss 7.7755e-02 (7.7755e-02)	Acc@1   0.93 (  0.93)	Acc@5   0.00 (  0.00)
[0.9337195753511374]
Test: [0/1]	Time  0.235 ( 0.235)	Loss 9.5114e-01 (9.5114e-01)	Acc@1   0.71 (  0.71)	Acc@5   0.00 (  0.00)
 * Acc@1 0.708 Acc@5 0.000
Test: [0/1]	Time  0.286 ( 0.286)	Loss 1.5382e-01 (1.5382e-01)	Acc@1   0.77 (  0.77)	Acc@5   0.00 (  0.00)
 * Acc@1 0.768 Acc@5 0.000
98
TRAINING
Epoch: [98][0/1]	Time  0.938 ( 0.938)	Data  0.243 ( 0.243)	Loss 7.7735e-02 (7.7735e-02)	Acc@1   0.93 (  0.93)	Acc@5   0.00 (  0.00)
[0.9337234593826598]
Test: [0/1]	Time  0.229 ( 0.229)	Loss 9.5112e-01 (9.5112e-01)	Acc@1   0.71 (  0.71)	Acc@5   0.00 (  0.00)
 * Acc@1 0.708 Acc@5 0.000
Test: [0/1]	Time  0.279 ( 0.279)	Loss 1.5380e-01 (1.5380e-01)	Acc@1   0.77 (  0.77)	Acc@5   0.00 (  0.00)
 * Acc@1 0.768 Acc@5 0.000
99
TRAINING
Epoch: [99][0/1]	Time  0.943 ( 0.943)	Data  0.237 ( 0.237)	Loss 7.7719e-02 (7.7719e-02)	Acc@1   0.93 (  0.93)	Acc@5   0.00 (  0.00)
[0.9337347338558302]
Test: [0/1]	Time  0.228 ( 0.228)	Loss 9.5108e-01 (9.5108e-01)	Acc@1   0.71 (  0.71)	Acc@5   0.00 (  0.00)
 * Acc@1 0.708 Acc@5 0.000
Test: [0/1]	Time  0.277 ( 0.277)	Loss 1.5378e-01 (1.5378e-01)	Acc@1   0.77 (  0.77)	Acc@5   0.00 (  0.00)
 * Acc@1 0.768 Acc@5 0.000
=> using pre-trained model 'st_resnet'
s/ohp/session_1
torch.Size([640, 3, 224, 224])
(640, 22)
attach reg
0
TRAINING
/home/helenr6/Adv_mapper/train_split.py:125: UserWarning: You have chosen to seed training. This will turn on the CUDNN deterministic setting, which can slow down your training considerably! You may see unexpected behavior when restarting from checkpoints.
  warnings.warn('You have chosen to seed training. '
/localscratch/helenr6.6279052.0/env/lib/python3.7/site-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  cpuset_checked))
Epoch: [0][0/1]	Time  5.308 ( 5.308)	Data  1.928 ( 1.928)	Loss 1.8532e+00 (1.8532e+00)	Acc@1   0.02 (  0.02)	Acc@5   0.00 (  0.00)
[0.016697450793111072]
Test: [0/1]	Time  0.456 ( 0.456)	Loss 1.2860e+00 (1.2860e+00)	Acc@1  -0.11 ( -0.11)	Acc@5   0.00 (  0.00)
 * Acc@1 -0.110 Acc@5 0.000
Test: [0/1]	Time  0.540 ( 0.540)	Loss 1.0458e+00 (1.0458e+00)	Acc@1  -0.02 ( -0.02)	Acc@5   0.00 (  0.00)
 * Acc@1 -0.020 Acc@5 0.000
1
TRAINING
Epoch: [1][0/1]	Time  0.924 ( 0.924)	Data  0.227 ( 0.227)	Loss 1.7452e+00 (1.7452e+00)	Acc@1   0.02 (  0.02)	Acc@5   0.00 (  0.00)
[0.019014973059750074]
Test: [0/1]	Time  0.225 ( 0.225)	Loss 1.2960e+00 (1.2960e+00)	Acc@1  -0.10 ( -0.10)	Acc@5   0.00 (  0.00)
 * Acc@1 -0.101 Acc@5 0.000
Test: [0/1]	Time  0.275 ( 0.275)	Loss 9.6599e-01 (9.6599e-01)	Acc@1  -0.02 ( -0.02)	Acc@5   0.00 (  0.00)
 * Acc@1 -0.018 Acc@5 0.000
2
TRAINING
Epoch: [2][0/1]	Time  0.903 ( 0.903)	Data  0.231 ( 0.231)	Loss 1.5860e+00 (1.5860e+00)	Acc@1   0.03 (  0.03)	Acc@5   0.00 (  0.00)
[0.02880181387328431]
Test: [0/1]	Time  0.224 ( 0.224)	Loss 1.3090e+00 (1.3090e+00)	Acc@1  -0.09 ( -0.09)	Acc@5   0.00 (  0.00)
 * Acc@1 -0.088 Acc@5 0.000
Test: [0/1]	Time  0.276 ( 0.276)	Loss 9.0157e-01 (9.0157e-01)	Acc@1  -0.01 ( -0.01)	Acc@5   0.00 (  0.00)
 * Acc@1 -0.009 Acc@5 0.000
3
TRAINING
Epoch: [3][0/1]	Time  0.904 ( 0.904)	Data  0.232 ( 0.232)	Loss 1.4394e+00 (1.4394e+00)	Acc@1   0.04 (  0.04)	Acc@5   0.00 (  0.00)
[0.03768487150344802]
Test: [0/1]	Time  0.233 ( 0.233)	Loss 1.3236e+00 (1.3236e+00)	Acc@1  -0.07 ( -0.07)	Acc@5   0.00 (  0.00)
 * Acc@1 -0.067 Acc@5 0.000
Test: [0/1]	Time  0.285 ( 0.285)	Loss 8.7353e-01 (8.7353e-01)	Acc@1   0.01 (  0.01)	Acc@5   0.00 (  0.00)
 * Acc@1 0.006 Acc@5 0.000
4
TRAINING
Epoch: [4][0/1]	Time  0.966 ( 0.966)	Data  0.244 ( 0.244)	Loss 1.3405e+00 (1.3405e+00)	Acc@1   0.05 (  0.05)	Acc@5   0.00 (  0.00)
[0.04791321637390098]
Test: [0/1]	Time  0.223 ( 0.223)	Loss 1.3353e+00 (1.3353e+00)	Acc@1  -0.05 ( -0.05)	Acc@5   0.00 (  0.00)
 * Acc@1 -0.049 Acc@5 0.000
Test: [0/1]	Time  0.275 ( 0.275)	Loss 8.7612e-01 (8.7612e-01)	Acc@1   0.02 (  0.02)	Acc@5   0.00 (  0.00)
 * Acc@1 0.016 Acc@5 0.000
5
TRAINING
Epoch: [5][0/1]	Time  0.996 ( 0.996)	Data  0.284 ( 0.284)	Loss 1.2841e+00 (1.2841e+00)	Acc@1   0.06 (  0.06)	Acc@5   0.00 (  0.00)
[0.056554440550829504]
Test: [0/1]	Time  0.229 ( 0.229)	Loss 1.3386e+00 (1.3386e+00)	Acc@1  -0.03 ( -0.03)	Acc@5   0.00 (  0.00)
 * Acc@1 -0.028 Acc@5 0.000
Test: [0/1]	Time  0.278 ( 0.278)	Loss 8.8417e-01 (8.8417e-01)	Acc@1   0.03 (  0.03)	Acc@5   0.00 (  0.00)
 * Acc@1 0.030 Acc@5 0.000
6
TRAINING
Epoch: [6][0/1]	Time  0.934 ( 0.934)	Data  0.236 ( 0.236)	Loss 1.2376e+00 (1.2376e+00)	Acc@1   0.07 (  0.07)	Acc@5   0.00 (  0.00)
[0.06809064885953908]
Test: [0/1]	Time  0.228 ( 0.228)	Loss 1.3289e+00 (1.3289e+00)	Acc@1  -0.02 ( -0.02)	Acc@5   0.00 (  0.00)
 * Acc@1 -0.020 Acc@5 0.000
Test: [0/1]	Time  0.285 ( 0.285)	Loss 8.7092e-01 (8.7092e-01)	Acc@1   0.05 (  0.05)	Acc@5   0.00 (  0.00)
 * Acc@1 0.049 Acc@5 0.000
7
TRAINING
Epoch: [7][0/1]	Time  0.933 ( 0.933)	Data  0.235 ( 0.235)	Loss 1.1670e+00 (1.1670e+00)	Acc@1   0.08 (  0.08)	Acc@5   0.00 (  0.00)
[0.08148139728853887]
Test: [0/1]	Time  0.229 ( 0.229)	Loss 1.3055e+00 (1.3055e+00)	Acc@1  -0.02 ( -0.02)	Acc@5   0.00 (  0.00)
 * Acc@1 -0.020 Acc@5 0.000
Test: [0/1]	Time  0.282 ( 0.282)	Loss 8.2434e-01 (8.2434e-01)	Acc@1   0.07 (  0.07)	Acc@5   0.00 (  0.00)
 * Acc@1 0.071 Acc@5 0.000
8
TRAINING
Epoch: [8][0/1]	Time  0.934 ( 0.934)	Data  0.234 ( 0.234)	Loss 1.0589e+00 (1.0589e+00)	Acc@1   0.10 (  0.10)	Acc@5   0.00 (  0.00)
[0.10365864805726364]
Test: [0/1]	Time  0.225 ( 0.225)	Loss 1.2717e+00 (1.2717e+00)	Acc@1  -0.01 ( -0.01)	Acc@5   0.00 (  0.00)
 * Acc@1 -0.013 Acc@5 0.000
Test: [0/1]	Time  0.277 ( 0.277)	Loss 7.5229e-01 (7.5229e-01)	Acc@1   0.09 (  0.09)	Acc@5   0.00 (  0.00)
 * Acc@1 0.087 Acc@5 0.000
9
TRAINING
Epoch: [9][0/1]	Time  0.954 ( 0.954)	Data  0.236 ( 0.236)	Loss 9.2519e-01 (9.2519e-01)	Acc@1   0.12 (  0.12)	Acc@5   0.00 (  0.00)
[0.121848491446842]
Test: [0/1]	Time  0.235 ( 0.235)	Loss 1.2332e+00 (1.2332e+00)	Acc@1  -0.00 ( -0.00)	Acc@5   0.00 (  0.00)
 * Acc@1 -0.001 Acc@5 0.000
Test: [0/1]	Time  0.286 ( 0.286)	Loss 6.7563e-01 (6.7563e-01)	Acc@1   0.10 (  0.10)	Acc@5   0.00 (  0.00)
 * Acc@1 0.098 Acc@5 0.000
10
TRAINING
Epoch: [10][0/1]	Time  0.935 ( 0.935)	Data  0.236 ( 0.236)	Loss 7.9270e-01 (7.9270e-01)	Acc@1   0.15 (  0.15)	Acc@5   0.00 (  0.00)
[0.14694271667191938]
Test: [0/1]	Time  0.228 ( 0.228)	Loss 1.1960e+00 (1.1960e+00)	Acc@1   0.03 (  0.03)	Acc@5   0.00 (  0.00)
 * Acc@1 0.026 Acc@5 0.000
Test: [0/1]	Time  0.278 ( 0.278)	Loss 6.1470e-01 (6.1470e-01)	Acc@1   0.11 (  0.11)	Acc@5   0.00 (  0.00)
 * Acc@1 0.107 Acc@5 0.000
11
TRAINING
Epoch: [11][0/1]	Time  0.929 ( 0.929)	Data  0.235 ( 0.235)	Loss 6.8546e-01 (6.8546e-01)	Acc@1   0.17 (  0.17)	Acc@5   0.00 (  0.00)
[0.1724060149460902]
Test: [0/1]	Time  0.225 ( 0.225)	Loss 1.1640e+00 (1.1640e+00)	Acc@1   0.07 (  0.07)	Acc@5   0.00 (  0.00)
 * Acc@1 0.070 Acc@5 0.000
Test: [0/1]	Time  0.275 ( 0.275)	Loss 5.7788e-01 (5.7788e-01)	Acc@1   0.12 (  0.12)	Acc@5   0.00 (  0.00)
 * Acc@1 0.119 Acc@5 0.000
12
TRAINING
Epoch: [12][0/1]	Time  1.018 ( 1.018)	Data  0.287 ( 0.287)	Loss 6.1187e-01 (6.1187e-01)	Acc@1   0.19 (  0.19)	Acc@5   0.00 (  0.00)
[0.19432090200478258]
Test: [0/1]	Time  0.224 ( 0.224)	Loss 1.1381e+00 (1.1381e+00)	Acc@1   0.11 (  0.11)	Acc@5   0.00 (  0.00)
 * Acc@1 0.106 Acc@5 0.000
Test: [0/1]	Time  0.275 ( 0.275)	Loss 5.5897e-01 (5.5897e-01)	Acc@1   0.13 (  0.13)	Acc@5   0.00 (  0.00)
 * Acc@1 0.133 Acc@5 0.000
13
TRAINING
Epoch: [13][0/1]	Time  1.007 ( 1.007)	Data  0.289 ( 0.289)	Loss 5.6296e-01 (5.6296e-01)	Acc@1   0.23 (  0.23)	Acc@5   0.00 (  0.00)
[0.22576853532098085]
Test: [0/1]	Time  0.226 ( 0.226)	Loss 1.1172e+00 (1.1172e+00)	Acc@1   0.15 (  0.15)	Acc@5   0.00 (  0.00)
 * Acc@1 0.151 Acc@5 0.000
Test: [0/1]	Time  0.280 ( 0.280)	Loss 5.4328e-01 (5.4328e-01)	Acc@1   0.15 (  0.15)	Acc@5   0.00 (  0.00)
 * Acc@1 0.147 Acc@5 0.000
14
TRAINING
Epoch: [14][0/1]	Time  0.986 ( 0.986)	Data  0.288 ( 0.288)	Loss 5.2087e-01 (5.2087e-01)	Acc@1   0.27 (  0.27)	Acc@5   0.00 (  0.00)
[0.2678526336108745]
Test: [0/1]	Time  0.226 ( 0.226)	Loss 1.0994e+00 (1.0994e+00)	Acc@1   0.20 (  0.20)	Acc@5   0.00 (  0.00)
 * Acc@1 0.201 Acc@5 0.000
Test: [0/1]	Time  0.282 ( 0.282)	Loss 5.1771e-01 (5.1771e-01)	Acc@1   0.16 (  0.16)	Acc@5   0.00 (  0.00)
 * Acc@1 0.162 Acc@5 0.000
15
TRAINING
Epoch: [15][0/1]	Time  0.953 ( 0.953)	Data  0.237 ( 0.237)	Loss 4.7072e-01 (4.7072e-01)	Acc@1   0.31 (  0.31)	Acc@5   0.00 (  0.00)
[0.30868474406253676]
Test: [0/1]	Time  0.228 ( 0.228)	Loss 1.0834e+00 (1.0834e+00)	Acc@1   0.23 (  0.23)	Acc@5   0.00 (  0.00)
 * Acc@1 0.235 Acc@5 0.000
Test: [0/1]	Time  0.283 ( 0.283)	Loss 4.7821e-01 (4.7821e-01)	Acc@1   0.18 (  0.18)	Acc@5   0.00 (  0.00)
 * Acc@1 0.178 Acc@5 0.000
16
TRAINING
Epoch: [16][0/1]	Time  0.922 ( 0.922)	Data  0.238 ( 0.238)	Loss 4.0847e-01 (4.0847e-01)	Acc@1   0.34 (  0.34)	Acc@5   0.00 (  0.00)
[0.3448793701787164]
Test: [0/1]	Time  0.226 ( 0.226)	Loss 1.0691e+00 (1.0691e+00)	Acc@1   0.26 (  0.26)	Acc@5   0.00 (  0.00)
 * Acc@1 0.260 Acc@5 0.000
Test: [0/1]	Time  0.280 ( 0.280)	Loss 4.3074e-01 (4.3074e-01)	Acc@1   0.20 (  0.20)	Acc@5   0.00 (  0.00)
 * Acc@1 0.203 Acc@5 0.000
17
TRAINING
Epoch: [17][0/1]	Time  0.951 ( 0.951)	Data  0.238 ( 0.238)	Loss 3.4114e-01 (3.4114e-01)	Acc@1   0.39 (  0.39)	Acc@5   0.00 (  0.00)
[0.3898186801934887]
Test: [0/1]	Time  0.226 ( 0.226)	Loss 1.0567e+00 (1.0567e+00)	Acc@1   0.29 (  0.29)	Acc@5   0.00 (  0.00)
 * Acc@1 0.288 Acc@5 0.000
Test: [0/1]	Time  0.276 ( 0.276)	Loss 3.8620e-01 (3.8620e-01)	Acc@1   0.23 (  0.23)	Acc@5   0.00 (  0.00)
 * Acc@1 0.229 Acc@5 0.000
18
TRAINING
Epoch: [18][0/1]	Time  0.941 ( 0.941)	Data  0.232 ( 0.232)	Loss 2.8061e-01 (2.8061e-01)	Acc@1   0.44 (  0.44)	Acc@5   0.00 (  0.00)
[0.43590169658483424]
Test: [0/1]	Time  0.226 ( 0.226)	Loss 1.0463e+00 (1.0463e+00)	Acc@1   0.31 (  0.31)	Acc@5   0.00 (  0.00)
 * Acc@1 0.314 Acc@5 0.000
Test: [0/1]	Time  0.277 ( 0.277)	Loss 3.5328e-01 (3.5328e-01)	Acc@1   0.26 (  0.26)	Acc@5   0.00 (  0.00)
 * Acc@1 0.260 Acc@5 0.000
19
TRAINING
Epoch: [19][0/1]	Time  0.978 ( 0.978)	Data  0.250 ( 0.250)	Loss 2.3581e-01 (2.3581e-01)	Acc@1   0.48 (  0.48)	Acc@5   0.00 (  0.00)
[0.4795566514893197]
Test: [0/1]	Time  0.238 ( 0.238)	Loss 1.0375e+00 (1.0375e+00)	Acc@1   0.33 (  0.33)	Acc@5   0.00 (  0.00)
 * Acc@1 0.331 Acc@5 0.000
Test: [0/1]	Time  0.295 ( 0.295)	Loss 3.3374e-01 (3.3374e-01)	Acc@1   0.29 (  0.29)	Acc@5   0.00 (  0.00)
 * Acc@1 0.286 Acc@5 0.000
20
TRAINING
Epoch: [20][0/1]	Time  0.957 ( 0.957)	Data  0.243 ( 0.243)	Loss 2.0808e-01 (2.0808e-01)	Acc@1   0.52 (  0.52)	Acc@5   0.00 (  0.00)
[0.524134642292176]
Test: [0/1]	Time  0.233 ( 0.233)	Loss 1.0290e+00 (1.0290e+00)	Acc@1   0.38 (  0.38)	Acc@5   0.00 (  0.00)
 * Acc@1 0.383 Acc@5 0.000
Test: [0/1]	Time  0.291 ( 0.291)	Loss 3.2254e-01 (3.2254e-01)	Acc@1   0.31 (  0.31)	Acc@5   0.00 (  0.00)
 * Acc@1 0.312 Acc@5 0.000
21
TRAINING
Epoch: [21][0/1]	Time  0.978 ( 0.978)	Data  0.254 ( 0.254)	Loss 1.9171e-01 (1.9171e-01)	Acc@1   0.57 (  0.57)	Acc@5   0.00 (  0.00)
[0.5681806451424991]
Test: [0/1]	Time  0.246 ( 0.246)	Loss 1.0197e+00 (1.0197e+00)	Acc@1   0.44 (  0.44)	Acc@5   0.00 (  0.00)
 * Acc@1 0.437 Acc@5 0.000
Test: [0/1]	Time  0.302 ( 0.302)	Loss 3.1187e-01 (3.1187e-01)	Acc@1   0.34 (  0.34)	Acc@5   0.00 (  0.00)
 * Acc@1 0.337 Acc@5 0.000
22
TRAINING
Epoch: [22][0/1]	Time  0.948 ( 0.948)	Data  0.261 ( 0.261)	Loss 1.7837e-01 (1.7837e-01)	Acc@1   0.61 (  0.61)	Acc@5   0.00 (  0.00)
[0.6127501646138347]
Test: [0/1]	Time  0.239 ( 0.239)	Loss 1.0090e+00 (1.0090e+00)	Acc@1   0.48 (  0.48)	Acc@5   0.00 (  0.00)
 * Acc@1 0.478 Acc@5 0.000
Test: [0/1]	Time  0.290 ( 0.290)	Loss 2.9607e-01 (2.9607e-01)	Acc@1   0.37 (  0.37)	Acc@5   0.00 (  0.00)
 * Acc@1 0.365 Acc@5 0.000
23
TRAINING
Epoch: [23][0/1]	Time  0.965 ( 0.965)	Data  0.253 ( 0.253)	Loss 1.6217e-01 (1.6217e-01)	Acc@1   0.66 (  0.66)	Acc@5   0.00 (  0.00)
[0.6565818012276642]
Test: [0/1]	Time  0.232 ( 0.232)	Loss 9.9708e-01 (9.9708e-01)	Acc@1   0.52 (  0.52)	Acc@5   0.00 (  0.00)
 * Acc@1 0.521 Acc@5 0.000
Test: [0/1]	Time  0.284 ( 0.284)	Loss 2.7447e-01 (2.7447e-01)	Acc@1   0.39 (  0.39)	Acc@5   0.00 (  0.00)
 * Acc@1 0.391 Acc@5 0.000
24
TRAINING
Epoch: [24][0/1]	Time  0.950 ( 0.950)	Data  0.255 ( 0.255)	Loss 1.4228e-01 (1.4228e-01)	Acc@1   0.70 (  0.70)	Acc@5   0.00 (  0.00)
[0.6964798041481555]
Test: [0/1]	Time  0.238 ( 0.238)	Loss 9.8505e-01 (9.8505e-01)	Acc@1   0.56 (  0.56)	Acc@5   0.00 (  0.00)
 * Acc@1 0.557 Acc@5 0.000
Test: [0/1]	Time  0.288 ( 0.288)	Loss 2.5080e-01 (2.5080e-01)	Acc@1   0.41 (  0.41)	Acc@5   0.00 (  0.00)
 * Acc@1 0.410 Acc@5 0.000
25
TRAINING
Epoch: [25][0/1]	Time  0.947 ( 0.947)	Data  0.257 ( 0.257)	Loss 1.2219e-01 (1.2219e-01)	Acc@1   0.73 (  0.73)	Acc@5   0.00 (  0.00)
[0.7328055801626934]
Test: [0/1]	Time  0.242 ( 0.242)	Loss 9.7405e-01 (9.7405e-01)	Acc@1   0.59 (  0.59)	Acc@5   0.00 (  0.00)
 * Acc@1 0.586 Acc@5 0.000
Test: [0/1]	Time  0.288 ( 0.288)	Loss 2.3022e-01 (2.3022e-01)	Acc@1   0.43 (  0.43)	Acc@5   0.00 (  0.00)
 * Acc@1 0.434 Acc@5 0.000
26
TRAINING
Epoch: [26][0/1]	Time  0.977 ( 0.977)	Data  0.259 ( 0.259)	Loss 1.0654e-01 (1.0654e-01)	Acc@1   0.76 (  0.76)	Acc@5   0.00 (  0.00)
[0.7647322900856952]
Test: [0/1]	Time  0.235 ( 0.235)	Loss 9.6488e-01 (9.6488e-01)	Acc@1   0.61 (  0.61)	Acc@5   0.00 (  0.00)
 * Acc@1 0.609 Acc@5 0.000
Test: [0/1]	Time  0.292 ( 0.292)	Loss 2.1600e-01 (2.1600e-01)	Acc@1   0.46 (  0.46)	Acc@5   0.00 (  0.00)
 * Acc@1 0.457 Acc@5 0.000
27
TRAINING
Epoch: [27][0/1]	Time  0.930 ( 0.930)	Data  0.241 ( 0.241)	Loss 9.7983e-02 (9.7983e-02)	Acc@1   0.79 (  0.79)	Acc@5   0.00 (  0.00)
[0.7915388873253864]
Test: [0/1]	Time  0.236 ( 0.236)	Loss 9.5775e-01 (9.5775e-01)	Acc@1   0.63 (  0.63)	Acc@5   0.00 (  0.00)
 * Acc@1 0.628 Acc@5 0.000
Test: [0/1]	Time  0.284 ( 0.284)	Loss 2.0797e-01 (2.0797e-01)	Acc@1   0.48 (  0.48)	Acc@5   0.00 (  0.00)
 * Acc@1 0.478 Acc@5 0.000
28
TRAINING
Epoch: [28][0/1]	Time  0.958 ( 0.958)	Data  0.254 ( 0.254)	Loss 9.5754e-02 (9.5754e-02)	Acc@1   0.81 (  0.81)	Acc@5   0.00 (  0.00)
[0.81109508900545]
Test: [0/1]	Time  0.234 ( 0.234)	Loss 9.5230e-01 (9.5230e-01)	Acc@1   0.64 (  0.64)	Acc@5   0.00 (  0.00)
 * Acc@1 0.644 Acc@5 0.000
Test: [0/1]	Time  0.287 ( 0.287)	Loss 2.0321e-01 (2.0321e-01)	Acc@1   0.50 (  0.50)	Acc@5   0.00 (  0.00)
 * Acc@1 0.500 Acc@5 0.000
29
TRAINING
Epoch: [29][0/1]	Time  0.942 ( 0.942)	Data  0.248 ( 0.248)	Loss 9.6504e-02 (9.6504e-02)	Acc@1   0.83 (  0.83)	Acc@5   0.00 (  0.00)
[0.8282683344861437]
Test: [0/1]	Time  0.241 ( 0.241)	Loss 9.4800e-01 (9.4800e-01)	Acc@1   0.66 (  0.66)	Acc@5   0.00 (  0.00)
 * Acc@1 0.659 Acc@5 0.000
Test: [0/1]	Time  0.283 ( 0.283)	Loss 1.9824e-01 (1.9824e-01)	Acc@1   0.52 (  0.52)	Acc@5   0.00 (  0.00)
 * Acc@1 0.523 Acc@5 0.000
30
TRAINING
Epoch: [30][0/1]	Time  0.938 ( 0.938)	Data  0.240 ( 0.240)	Loss 9.6519e-02 (9.6519e-02)	Acc@1   0.84 (  0.84)	Acc@5   0.00 (  0.00)
[0.8418645857141002]
Test: [0/1]	Time  0.232 ( 0.232)	Loss 9.4443e-01 (9.4443e-01)	Acc@1   0.67 (  0.67)	Acc@5   0.00 (  0.00)
 * Acc@1 0.672 Acc@5 0.000
Test: [0/1]	Time  0.282 ( 0.282)	Loss 1.9108e-01 (1.9108e-01)	Acc@1   0.55 (  0.55)	Acc@5   0.00 (  0.00)
 * Acc@1 0.546 Acc@5 0.000
31
TRAINING
Epoch: [31][0/1]	Time  0.948 ( 0.948)	Data  0.249 ( 0.249)	Loss 9.3761e-02 (9.3761e-02)	Acc@1   0.85 (  0.85)	Acc@5   0.00 (  0.00)
[0.8542421285877501]
Test: [0/1]	Time  0.234 ( 0.234)	Loss 9.4143e-01 (9.4143e-01)	Acc@1   0.68 (  0.68)	Acc@5   0.00 (  0.00)
 * Acc@1 0.683 Acc@5 0.000
Test: [0/1]	Time  0.286 ( 0.286)	Loss 1.8204e-01 (1.8204e-01)	Acc@1   0.57 (  0.57)	Acc@5   0.00 (  0.00)
 * Acc@1 0.570 Acc@5 0.000
32
TRAINING
Epoch: [32][0/1]	Time  0.964 ( 0.964)	Data  0.252 ( 0.252)	Loss 8.8599e-02 (8.8599e-02)	Acc@1   0.86 (  0.86)	Acc@5   0.00 (  0.00)
[0.8633924485199556]
Test: [0/1]	Time  0.232 ( 0.232)	Loss 9.3906e-01 (9.3906e-01)	Acc@1   0.69 (  0.69)	Acc@5   0.00 (  0.00)
 * Acc@1 0.691 Acc@5 0.000
Test: [0/1]	Time  0.285 ( 0.285)	Loss 1.7311e-01 (1.7311e-01)	Acc@1   0.60 (  0.60)	Acc@5   0.00 (  0.00)
 * Acc@1 0.597 Acc@5 0.000
33
TRAINING
Epoch: [33][0/1]	Time  0.951 ( 0.951)	Data  0.247 ( 0.247)	Loss 8.3071e-02 (8.3071e-02)	Acc@1   0.87 (  0.87)	Acc@5   0.00 (  0.00)
[0.8702749011609461]
Test: [0/1]	Time  0.233 ( 0.233)	Loss 9.3738e-01 (9.3738e-01)	Acc@1   0.70 (  0.70)	Acc@5   0.00 (  0.00)
 * Acc@1 0.696 Acc@5 0.000
Test: [0/1]	Time  0.287 ( 0.287)	Loss 1.6636e-01 (1.6636e-01)	Acc@1   0.62 (  0.62)	Acc@5   0.00 (  0.00)
 * Acc@1 0.621 Acc@5 0.000
34
TRAINING
Epoch: [34][0/1]	Time  0.935 ( 0.935)	Data  0.247 ( 0.247)	Loss 7.9345e-02 (7.9345e-02)	Acc@1   0.87 (  0.87)	Acc@5   0.00 (  0.00)
[0.8745956052508491]
Test: [0/1]	Time  0.233 ( 0.233)	Loss 9.3634e-01 (9.3634e-01)	Acc@1   0.70 (  0.70)	Acc@5   0.00 (  0.00)
 * Acc@1 0.699 Acc@5 0.000
Test: [0/1]	Time  0.279 ( 0.279)	Loss 1.6273e-01 (1.6273e-01)	Acc@1   0.64 (  0.64)	Acc@5   0.00 (  0.00)
 * Acc@1 0.640 Acc@5 0.000
35
TRAINING
Epoch: [35][0/1]	Time  0.937 ( 0.937)	Data  0.232 ( 0.232)	Loss 7.8423e-02 (7.8423e-02)	Acc@1   0.88 (  0.88)	Acc@5   0.00 (  0.00)
[0.8776557426641785]
Test: [0/1]	Time  0.242 ( 0.242)	Loss 9.3571e-01 (9.3571e-01)	Acc@1   0.70 (  0.70)	Acc@5   0.00 (  0.00)
 * Acc@1 0.700 Acc@5 0.000
Test: [0/1]	Time  0.291 ( 0.291)	Loss 1.6158e-01 (1.6158e-01)	Acc@1   0.66 (  0.66)	Acc@5   0.00 (  0.00)
 * Acc@1 0.656 Acc@5 0.000
36
TRAINING
Epoch: [36][0/1]	Time  0.984 ( 0.984)	Data  0.293 ( 0.293)	Loss 7.9765e-02 (7.9765e-02)	Acc@1   0.88 (  0.88)	Acc@5   0.00 (  0.00)
[0.8782990522916978]
Test: [0/1]	Time  0.235 ( 0.235)	Loss 9.3521e-01 (9.3521e-01)	Acc@1   0.70 (  0.70)	Acc@5   0.00 (  0.00)
 * Acc@1 0.699 Acc@5 0.000
Test: [0/1]	Time  0.283 ( 0.283)	Loss 1.6134e-01 (1.6134e-01)	Acc@1   0.68 (  0.68)	Acc@5   0.00 (  0.00)
 * Acc@1 0.676 Acc@5 0.000
37
TRAINING
Epoch: [37][0/1]	Time  0.942 ( 0.942)	Data  0.241 ( 0.241)	Loss 8.1864e-02 (8.1864e-02)	Acc@1   0.88 (  0.88)	Acc@5   0.00 (  0.00)
[0.878427056723586]
Test: [0/1]	Time  0.232 ( 0.232)	Loss 9.3458e-01 (9.3458e-01)	Acc@1   0.70 (  0.70)	Acc@5   0.00 (  0.00)
 * Acc@1 0.700 Acc@5 0.000
Test: [0/1]	Time  0.291 ( 0.291)	Loss 1.6051e-01 (1.6051e-01)	Acc@1   0.69 (  0.69)	Acc@5   0.00 (  0.00)
 * Acc@1 0.694 Acc@5 0.000
38
TRAINING
Epoch: [38][0/1]	Time  0.973 ( 0.973)	Data  0.256 ( 0.256)	Loss 8.3267e-02 (8.3267e-02)	Acc@1   0.88 (  0.88)	Acc@5   0.00 (  0.00)
[0.8773161827608067]
Test: [0/1]	Time  0.231 ( 0.231)	Loss 9.3372e-01 (9.3372e-01)	Acc@1   0.70 (  0.70)	Acc@5   0.00 (  0.00)
 * Acc@1 0.701 Acc@5 0.000
Test: [0/1]	Time  0.291 ( 0.291)	Loss 1.5847e-01 (1.5847e-01)	Acc@1   0.70 (  0.70)	Acc@5   0.00 (  0.00)
 * Acc@1 0.705 Acc@5 0.000
39
TRAINING
Epoch: [39][0/1]	Time  0.959 ( 0.959)	Data  0.259 ( 0.259)	Loss 8.3357e-02 (8.3357e-02)	Acc@1   0.88 (  0.88)	Acc@5   0.00 (  0.00)
[0.8751166329016142]
Test: [0/1]	Time  0.236 ( 0.236)	Loss 9.3269e-01 (9.3269e-01)	Acc@1   0.70 (  0.70)	Acc@5   0.00 (  0.00)
 * Acc@1 0.703 Acc@5 0.000
Test: [0/1]	Time  0.284 ( 0.284)	Loss 1.5564e-01 (1.5564e-01)	Acc@1   0.71 (  0.71)	Acc@5   0.00 (  0.00)
 * Acc@1 0.713 Acc@5 0.000
40
TRAINING
Epoch: [40][0/1]	Time  0.953 ( 0.953)	Data  0.241 ( 0.241)	Loss 8.2507e-02 (8.2507e-02)	Acc@1   0.87 (  0.87)	Acc@5   0.00 (  0.00)
[0.8714023893238206]
Test: [0/1]	Time  0.230 ( 0.230)	Loss 9.3166e-01 (9.3166e-01)	Acc@1   0.71 (  0.71)	Acc@5   0.00 (  0.00)
 * Acc@1 0.705 Acc@5 0.000
Test: [0/1]	Time  0.279 ( 0.279)	Loss 1.5300e-01 (1.5300e-01)	Acc@1   0.72 (  0.72)	Acc@5   0.00 (  0.00)
 * Acc@1 0.720 Acc@5 0.000
41
TRAINING
Epoch: [41][0/1]	Time  0.944 ( 0.944)	Data  0.244 ( 0.244)	Loss 8.1631e-02 (8.1631e-02)	Acc@1   0.87 (  0.87)	Acc@5   0.00 (  0.00)
[0.8688530914853005]
Test: [0/1]	Time  0.236 ( 0.236)	Loss 9.3078e-01 (9.3078e-01)	Acc@1   0.71 (  0.71)	Acc@5   0.00 (  0.00)
 * Acc@1 0.706 Acc@5 0.000
Test: [0/1]	Time  0.289 ( 0.289)	Loss 1.5140e-01 (1.5140e-01)	Acc@1   0.73 (  0.73)	Acc@5   0.00 (  0.00)
 * Acc@1 0.729 Acc@5 0.000
42
TRAINING
Epoch: [42][0/1]	Time  0.933 ( 0.933)	Data  0.237 ( 0.237)	Loss 8.1514e-02 (8.1514e-02)	Acc@1   0.87 (  0.87)	Acc@5   0.00 (  0.00)
[0.8692094537140662]
Test: [0/1]	Time  0.237 ( 0.237)	Loss 9.3013e-01 (9.3013e-01)	Acc@1   0.71 (  0.71)	Acc@5   0.00 (  0.00)
 * Acc@1 0.707 Acc@5 0.000
Test: [0/1]	Time  0.289 ( 0.289)	Loss 1.5106e-01 (1.5106e-01)	Acc@1   0.74 (  0.74)	Acc@5   0.00 (  0.00)
 * Acc@1 0.736 Acc@5 0.000
43
TRAINING
Epoch: [43][0/1]	Time  0.955 ( 0.955)	Data  0.253 ( 0.253)	Loss 8.2341e-02 (8.2341e-02)	Acc@1   0.87 (  0.87)	Acc@5   0.00 (  0.00)
[0.8705439072327539]
Test: [0/1]	Time  0.233 ( 0.233)	Loss 9.2971e-01 (9.2971e-01)	Acc@1   0.71 (  0.71)	Acc@5   0.00 (  0.00)
 * Acc@1 0.707 Acc@5 0.000
Test: [0/1]	Time  0.286 ( 0.286)	Loss 1.5155e-01 (1.5155e-01)	Acc@1   0.74 (  0.74)	Acc@5   0.00 (  0.00)
 * Acc@1 0.741 Acc@5 0.000
44
TRAINING
Epoch: [44][0/1]	Time  0.954 ( 0.954)	Data  0.255 ( 0.255)	Loss 8.3674e-02 (8.3674e-02)	Acc@1   0.87 (  0.87)	Acc@5   0.00 (  0.00)
[0.8724458342626937]
Test: [0/1]	Time  0.241 ( 0.241)	Loss 9.2949e-01 (9.2949e-01)	Acc@1   0.71 (  0.71)	Acc@5   0.00 (  0.00)
 * Acc@1 0.707 Acc@5 0.000
Test: [0/1]	Time  0.291 ( 0.291)	Loss 1.5216e-01 (1.5216e-01)	Acc@1   0.74 (  0.74)	Acc@5   0.00 (  0.00)
 * Acc@1 0.745 Acc@5 0.000
45
TRAINING
Epoch: [45][0/1]	Time  0.936 ( 0.936)	Data  0.252 ( 0.252)	Loss 8.4799e-02 (8.4799e-02)	Acc@1   0.87 (  0.87)	Acc@5   0.00 (  0.00)
[0.8748470634250058]
Test: [0/1]	Time  0.230 ( 0.230)	Loss 9.2943e-01 (9.2943e-01)	Acc@1   0.71 (  0.71)	Acc@5   0.00 (  0.00)
 * Acc@1 0.706 Acc@5 0.000
Test: [0/1]	Time  0.285 ( 0.285)	Loss 1.5233e-01 (1.5233e-01)	Acc@1   0.75 (  0.75)	Acc@5   0.00 (  0.00)
 * Acc@1 0.747 Acc@5 0.000
46
TRAINING
Epoch: [46][0/1]	Time  0.947 ( 0.947)	Data  0.249 ( 0.249)	Loss 8.5172e-02 (8.5172e-02)	Acc@1   0.88 (  0.88)	Acc@5   0.00 (  0.00)
[0.8776439927167243]
Test: [0/1]	Time  0.241 ( 0.241)	Loss 9.2955e-01 (9.2955e-01)	Acc@1   0.70 (  0.70)	Acc@5   0.00 (  0.00)
 * Acc@1 0.704 Acc@5 0.000
Test: [0/1]	Time  0.289 ( 0.289)	Loss 1.5196e-01 (1.5196e-01)	Acc@1   0.75 (  0.75)	Acc@5   0.00 (  0.00)
 * Acc@1 0.748 Acc@5 0.000
47
TRAINING
Epoch: [47][0/1]	Time  0.943 ( 0.943)	Data  0.247 ( 0.247)	Loss 8.4704e-02 (8.4704e-02)	Acc@1   0.88 (  0.88)	Acc@5   0.00 (  0.00)
[0.8807112291602786]
Test: [0/1]	Time  0.238 ( 0.238)	Loss 9.2988e-01 (9.2988e-01)	Acc@1   0.70 (  0.70)	Acc@5   0.00 (  0.00)
 * Acc@1 0.703 Acc@5 0.000
Test: [0/1]	Time  0.287 ( 0.287)	Loss 1.5135e-01 (1.5135e-01)	Acc@1   0.75 (  0.75)	Acc@5   0.00 (  0.00)
 * Acc@1 0.750 Acc@5 0.000
48
TRAINING
Epoch: [48][0/1]	Time  0.987 ( 0.987)	Data  0.261 ( 0.261)	Loss 8.3730e-02 (8.3730e-02)	Acc@1   0.88 (  0.88)	Acc@5   0.00 (  0.00)
[0.8839178664460535]
Test: [0/1]	Time  0.241 ( 0.241)	Loss 9.3044e-01 (9.3044e-01)	Acc@1   0.70 (  0.70)	Acc@5   0.00 (  0.00)
 * Acc@1 0.701 Acc@5 0.000
Test: [0/1]	Time  0.287 ( 0.287)	Loss 1.5093e-01 (1.5093e-01)	Acc@1   0.75 (  0.75)	Acc@5   0.00 (  0.00)
 * Acc@1 0.753 Acc@5 0.000
49
TRAINING
Epoch: [49][0/1]	Time  0.956 ( 0.956)	Data  0.253 ( 0.253)	Loss 8.2756e-02 (8.2756e-02)	Acc@1   0.89 (  0.89)	Acc@5   0.00 (  0.00)
[0.8871443418618049]
Test: [0/1]	Time  0.235 ( 0.235)	Loss 9.3119e-01 (9.3119e-01)	Acc@1   0.70 (  0.70)	Acc@5   0.00 (  0.00)
 * Acc@1 0.699 Acc@5 0.000
Test: [0/1]	Time  0.284 ( 0.284)	Loss 1.5101e-01 (1.5101e-01)	Acc@1   0.75 (  0.75)	Acc@5   0.00 (  0.00)
 * Acc@1 0.754 Acc@5 0.000
50
TRAINING
Epoch: [50][0/1]	Time  0.961 ( 0.961)	Data  0.244 ( 0.244)	Loss 8.2158e-02 (8.2158e-02)	Acc@1   0.89 (  0.89)	Acc@5   0.00 (  0.00)
[0.8914198615329917]
Test: [0/1]	Time  0.232 ( 0.232)	Loss 9.3207e-01 (9.3207e-01)	Acc@1   0.70 (  0.70)	Acc@5   0.00 (  0.00)
 * Acc@1 0.697 Acc@5 0.000
Test: [0/1]	Time  0.285 ( 0.285)	Loss 1.5158e-01 (1.5158e-01)	Acc@1   0.76 (  0.76)	Acc@5   0.00 (  0.00)
 * Acc@1 0.756 Acc@5 0.000
51
TRAINING
Epoch: [51][0/1]	Time  0.958 ( 0.958)	Data  0.261 ( 0.261)	Loss 8.2009e-02 (8.2009e-02)	Acc@1   0.90 (  0.90)	Acc@5   0.00 (  0.00)
[0.8956339124458772]
Test: [0/1]	Time  0.237 ( 0.237)	Loss 9.3296e-01 (9.3296e-01)	Acc@1   0.70 (  0.70)	Acc@5   0.00 (  0.00)
 * Acc@1 0.696 Acc@5 0.000
Test: [0/1]	Time  0.287 ( 0.287)	Loss 1.5236e-01 (1.5236e-01)	Acc@1   0.76 (  0.76)	Acc@5   0.00 (  0.00)
 * Acc@1 0.756 Acc@5 0.000
52
TRAINING
Epoch: [52][0/1]	Time  0.955 ( 0.955)	Data  0.252 ( 0.252)	Loss 8.2118e-02 (8.2118e-02)	Acc@1   0.90 (  0.90)	Acc@5   0.00 (  0.00)
[0.8988794631300652]
Test: [0/1]	Time  0.233 ( 0.233)	Loss 9.3377e-01 (9.3377e-01)	Acc@1   0.69 (  0.69)	Acc@5   0.00 (  0.00)
 * Acc@1 0.695 Acc@5 0.000
Test: [0/1]	Time  0.290 ( 0.290)	Loss 1.5299e-01 (1.5299e-01)	Acc@1   0.76 (  0.76)	Acc@5   0.00 (  0.00)
 * Acc@1 0.757 Acc@5 0.000
53
TRAINING
Epoch: [53][0/1]	Time  0.951 ( 0.951)	Data  0.249 ( 0.249)	Loss 8.2197e-02 (8.2197e-02)	Acc@1   0.90 (  0.90)	Acc@5   0.00 (  0.00)
[0.9020608891697943]
Test: [0/1]	Time  0.232 ( 0.232)	Loss 9.3442e-01 (9.3442e-01)	Acc@1   0.69 (  0.69)	Acc@5   0.00 (  0.00)
 * Acc@1 0.695 Acc@5 0.000
Test: [0/1]	Time  0.285 ( 0.285)	Loss 1.5324e-01 (1.5324e-01)	Acc@1   0.76 (  0.76)	Acc@5   0.00 (  0.00)
 * Acc@1 0.757 Acc@5 0.000
54
TRAINING
Epoch: [54][0/1]	Time  1.009 ( 1.009)	Data  0.279 ( 0.279)	Loss 8.2059e-02 (8.2059e-02)	Acc@1   0.91 (  0.91)	Acc@5   0.00 (  0.00)
[0.905151938562681]
Test: [0/1]	Time  0.241 ( 0.241)	Loss 9.3491e-01 (9.3491e-01)	Acc@1   0.70 (  0.70)	Acc@5   0.00 (  0.00)
 * Acc@1 0.695 Acc@5 0.000
Test: [0/1]	Time  0.297 ( 0.297)	Loss 1.5310e-01 (1.5310e-01)	Acc@1   0.76 (  0.76)	Acc@5   0.00 (  0.00)
 * Acc@1 0.758 Acc@5 0.000
55
TRAINING
Epoch: [55][0/1]	Time  0.955 ( 0.955)	Data  0.262 ( 0.262)	Loss 8.1704e-02 (8.1704e-02)	Acc@1   0.91 (  0.91)	Acc@5   0.00 (  0.00)
[0.9081009231855801]
Test: [0/1]	Time  0.241 ( 0.241)	Loss 9.3529e-01 (9.3529e-01)	Acc@1   0.70 (  0.70)	Acc@5   0.00 (  0.00)
 * Acc@1 0.696 Acc@5 0.000
Test: [0/1]	Time  0.291 ( 0.291)	Loss 1.5274e-01 (1.5274e-01)	Acc@1   0.76 (  0.76)	Acc@5   0.00 (  0.00)
 * Acc@1 0.759 Acc@5 0.000
56
TRAINING
Epoch: [56][0/1]	Time  0.958 ( 0.958)	Data  0.258 ( 0.258)	Loss 8.1280e-02 (8.1280e-02)	Acc@1   0.91 (  0.91)	Acc@5   0.00 (  0.00)
[0.910491558144386]
Test: [0/1]	Time  0.238 ( 0.238)	Loss 9.3562e-01 (9.3562e-01)	Acc@1   0.70 (  0.70)	Acc@5   0.00 (  0.00)
 * Acc@1 0.698 Acc@5 0.000
Test: [0/1]	Time  0.284 ( 0.284)	Loss 1.5238e-01 (1.5238e-01)	Acc@1   0.76 (  0.76)	Acc@5   0.00 (  0.00)
 * Acc@1 0.759 Acc@5 0.000
57
TRAINING
Epoch: [57][0/1]	Time  0.968 ( 0.968)	Data  0.259 ( 0.259)	Loss 8.0968e-02 (8.0968e-02)	Acc@1   0.91 (  0.91)	Acc@5   0.00 (  0.00)
[0.9127089940133777]
Test: [0/1]	Time  0.235 ( 0.235)	Loss 9.3597e-01 (9.3597e-01)	Acc@1   0.70 (  0.70)	Acc@5   0.00 (  0.00)
 * Acc@1 0.699 Acc@5 0.000
Test: [0/1]	Time  0.281 ( 0.281)	Loss 1.5217e-01 (1.5217e-01)	Acc@1   0.76 (  0.76)	Acc@5   0.00 (  0.00)
 * Acc@1 0.760 Acc@5 0.000
58
TRAINING
Epoch: [58][0/1]	Time  0.932 ( 0.932)	Data  0.248 ( 0.248)	Loss 8.0859e-02 (8.0859e-02)	Acc@1   0.91 (  0.91)	Acc@5   0.00 (  0.00)
[0.9147687298471687]
Test: [0/1]	Time  0.230 ( 0.230)	Loss 9.3640e-01 (9.3640e-01)	Acc@1   0.70 (  0.70)	Acc@5   0.00 (  0.00)
 * Acc@1 0.700 Acc@5 0.000
Test: [0/1]	Time  0.282 ( 0.282)	Loss 1.5212e-01 (1.5212e-01)	Acc@1   0.76 (  0.76)	Acc@5   0.00 (  0.00)
 * Acc@1 0.761 Acc@5 0.000
59
TRAINING
Epoch: [59][0/1]	Time  0.947 ( 0.947)	Data  0.250 ( 0.250)	Loss 8.0911e-02 (8.0911e-02)	Acc@1   0.92 (  0.92)	Acc@5   0.00 (  0.00)
[0.9166865082537144]
Test: [0/1]	Time  0.234 ( 0.234)	Loss 9.3693e-01 (9.3693e-01)	Acc@1   0.70 (  0.70)	Acc@5   0.00 (  0.00)
 * Acc@1 0.700 Acc@5 0.000
Test: [0/1]	Time  0.286 ( 0.286)	Loss 1.5213e-01 (1.5213e-01)	Acc@1   0.76 (  0.76)	Acc@5   0.00 (  0.00)
 * Acc@1 0.761 Acc@5 0.000
60
TRAINING
Epoch: [60][0/1]	Time  0.932 ( 0.932)	Data  0.243 ( 0.243)	Loss 8.0993e-02 (8.0993e-02)	Acc@1   0.92 (  0.92)	Acc@5   0.00 (  0.00)
[0.9184753857690436]
Test: [0/1]	Time  0.232 ( 0.232)	Loss 9.3757e-01 (9.3757e-01)	Acc@1   0.70 (  0.70)	Acc@5   0.00 (  0.00)
 * Acc@1 0.701 Acc@5 0.000
Test: [0/1]	Time  0.280 ( 0.280)	Loss 1.5211e-01 (1.5211e-01)	Acc@1   0.76 (  0.76)	Acc@5   0.00 (  0.00)
 * Acc@1 0.762 Acc@5 0.000
61
TRAINING
Epoch: [61][0/1]	Time  0.952 ( 0.952)	Data  0.256 ( 0.256)	Loss 8.0970e-02 (8.0970e-02)	Acc@1   0.92 (  0.92)	Acc@5   0.00 (  0.00)
[0.9201436301801602]
Test: [0/1]	Time  0.233 ( 0.233)	Loss 9.3831e-01 (9.3831e-01)	Acc@1   0.70 (  0.70)	Acc@5   0.00 (  0.00)
 * Acc@1 0.701 Acc@5 0.000
Test: [0/1]	Time  0.303 ( 0.303)	Loss 1.5200e-01 (1.5200e-01)	Acc@1   0.76 (  0.76)	Acc@5   0.00 (  0.00)
 * Acc@1 0.763 Acc@5 0.000
62
TRAINING
Epoch: [62][0/1]	Time  0.966 ( 0.966)	Data  0.258 ( 0.258)	Loss 8.0780e-02 (8.0780e-02)	Acc@1   0.92 (  0.92)	Acc@5   0.00 (  0.00)
[0.9216940712130652]
Test: [0/1]	Time  0.240 ( 0.240)	Loss 9.3915e-01 (9.3915e-01)	Acc@1   0.70 (  0.70)	Acc@5   0.00 (  0.00)
 * Acc@1 0.701 Acc@5 0.000
Test: [0/1]	Time  0.283 ( 0.283)	Loss 1.5182e-01 (1.5182e-01)	Acc@1   0.76 (  0.76)	Acc@5   0.00 (  0.00)
 * Acc@1 0.764 Acc@5 0.000
63
TRAINING
Epoch: [63][0/1]	Time  0.976 ( 0.976)	Data  0.257 ( 0.257)	Loss 8.0457e-02 (8.0457e-02)	Acc@1   0.92 (  0.92)	Acc@5   0.00 (  0.00)
[0.9227211904207295]
Test: [0/1]	Time  0.237 ( 0.237)	Loss 9.4003e-01 (9.4003e-01)	Acc@1   0.70 (  0.70)	Acc@5   0.00 (  0.00)
 * Acc@1 0.701 Acc@5 0.000
Test: [0/1]	Time  0.287 ( 0.287)	Loss 1.5165e-01 (1.5165e-01)	Acc@1   0.76 (  0.76)	Acc@5   0.00 (  0.00)
 * Acc@1 0.764 Acc@5 0.000
64
TRAINING
Epoch: [64][0/1]	Time  0.937 ( 0.937)	Data  0.252 ( 0.252)	Loss 8.0096e-02 (8.0096e-02)	Acc@1   0.92 (  0.92)	Acc@5   0.00 (  0.00)
[0.9240718969933126]
Test: [0/1]	Time  0.236 ( 0.236)	Loss 9.4092e-01 (9.4092e-01)	Acc@1   0.70 (  0.70)	Acc@5   0.00 (  0.00)
 * Acc@1 0.701 Acc@5 0.000
Test: [0/1]	Time  0.282 ( 0.282)	Loss 1.5155e-01 (1.5155e-01)	Acc@1   0.76 (  0.76)	Acc@5   0.00 (  0.00)
 * Acc@1 0.765 Acc@5 0.000
65
TRAINING
Epoch: [65][0/1]	Time  0.940 ( 0.940)	Data  0.245 ( 0.245)	Loss 7.9795e-02 (7.9795e-02)	Acc@1   0.93 (  0.93)	Acc@5   0.00 (  0.00)
[0.9250036539222659]
Test: [0/1]	Time  0.237 ( 0.237)	Loss 9.4176e-01 (9.4176e-01)	Acc@1   0.70 (  0.70)	Acc@5   0.00 (  0.00)
 * Acc@1 0.700 Acc@5 0.000
Test: [0/1]	Time  0.282 ( 0.282)	Loss 1.5154e-01 (1.5154e-01)	Acc@1   0.76 (  0.76)	Acc@5   0.00 (  0.00)
 * Acc@1 0.765 Acc@5 0.000
66
TRAINING
Epoch: [66][0/1]	Time  0.959 ( 0.959)	Data  0.268 ( 0.268)	Loss 7.9603e-02 (7.9603e-02)	Acc@1   0.93 (  0.93)	Acc@5   0.00 (  0.00)
[0.9253589314790123]
Test: [0/1]	Time  0.242 ( 0.242)	Loss 9.4250e-01 (9.4250e-01)	Acc@1   0.70 (  0.70)	Acc@5   0.00 (  0.00)
 * Acc@1 0.700 Acc@5 0.000
Test: [0/1]	Time  0.291 ( 0.291)	Loss 1.5158e-01 (1.5158e-01)	Acc@1   0.76 (  0.76)	Acc@5   0.00 (  0.00)
 * Acc@1 0.765 Acc@5 0.000
67
TRAINING
Epoch: [67][0/1]	Time  0.992 ( 0.992)	Data  0.253 ( 0.253)	Loss 7.9508e-02 (7.9508e-02)	Acc@1   0.93 (  0.93)	Acc@5   0.00 (  0.00)
[0.9260260814451554]
Test: [0/1]	Time  0.236 ( 0.236)	Loss 9.4309e-01 (9.4309e-01)	Acc@1   0.70 (  0.70)	Acc@5   0.00 (  0.00)
 * Acc@1 0.701 Acc@5 0.000
Test: [0/1]	Time  0.282 ( 0.282)	Loss 1.5157e-01 (1.5157e-01)	Acc@1   0.77 (  0.77)	Acc@5   0.00 (  0.00)
 * Acc@1 0.765 Acc@5 0.000
68
TRAINING
Epoch: [68][0/1]	Time  1.007 ( 1.007)	Data  0.298 ( 0.298)	Loss 7.9458e-02 (7.9458e-02)	Acc@1   0.93 (  0.93)	Acc@5   0.00 (  0.00)
[0.9268502247019195]
Test: [0/1]	Time  0.236 ( 0.236)	Loss 9.4352e-01 (9.4352e-01)	Acc@1   0.70 (  0.70)	Acc@5   0.00 (  0.00)
 * Acc@1 0.701 Acc@5 0.000
Test: [0/1]	Time  0.285 ( 0.285)	Loss 1.5148e-01 (1.5148e-01)	Acc@1   0.77 (  0.77)	Acc@5   0.00 (  0.00)
 * Acc@1 0.765 Acc@5 0.000
69
TRAINING
Epoch: [69][0/1]	Time  0.939 ( 0.939)	Data  0.250 ( 0.250)	Loss 7.9407e-02 (7.9407e-02)	Acc@1   0.93 (  0.93)	Acc@5   0.00 (  0.00)
[0.9275842919547816]
Test: [0/1]	Time  0.232 ( 0.232)	Loss 9.4377e-01 (9.4377e-01)	Acc@1   0.70 (  0.70)	Acc@5   0.00 (  0.00)
 * Acc@1 0.702 Acc@5 0.000
Test: [0/1]	Time  0.285 ( 0.285)	Loss 1.5127e-01 (1.5127e-01)	Acc@1   0.77 (  0.77)	Acc@5   0.00 (  0.00)
 * Acc@1 0.766 Acc@5 0.000
70
TRAINING
Epoch: [70][0/1]	Time  0.937 ( 0.937)	Data  0.240 ( 0.240)	Loss 7.9333e-02 (7.9333e-02)	Acc@1   0.93 (  0.93)	Acc@5   0.00 (  0.00)
[0.92777524297112]
Test: [0/1]	Time  0.231 ( 0.231)	Loss 9.4387e-01 (9.4387e-01)	Acc@1   0.70 (  0.70)	Acc@5   0.00 (  0.00)
 * Acc@1 0.703 Acc@5 0.000
Test: [0/1]	Time  0.279 ( 0.279)	Loss 1.5098e-01 (1.5098e-01)	Acc@1   0.77 (  0.77)	Acc@5   0.00 (  0.00)
 * Acc@1 0.766 Acc@5 0.000
71
TRAINING
Epoch: [71][0/1]	Time  0.958 ( 0.958)	Data  0.242 ( 0.242)	Loss 7.9251e-02 (7.9251e-02)	Acc@1   0.93 (  0.93)	Acc@5   0.00 (  0.00)
[0.927952921055487]
Test: [0/1]	Time  0.239 ( 0.239)	Loss 9.4385e-01 (9.4385e-01)	Acc@1   0.70 (  0.70)	Acc@5   0.00 (  0.00)
 * Acc@1 0.704 Acc@5 0.000
Test: [0/1]	Time  0.300 ( 0.300)	Loss 1.5067e-01 (1.5067e-01)	Acc@1   0.77 (  0.77)	Acc@5   0.00 (  0.00)
 * Acc@1 0.767 Acc@5 0.000
72
TRAINING
Epoch: [72][0/1]	Time  0.957 ( 0.957)	Data  0.249 ( 0.249)	Loss 7.9191e-02 (7.9191e-02)	Acc@1   0.93 (  0.93)	Acc@5   0.00 (  0.00)
[0.9281153617949864]
Test: [0/1]	Time  0.236 ( 0.236)	Loss 9.4376e-01 (9.4376e-01)	Acc@1   0.70 (  0.70)	Acc@5   0.00 (  0.00)
 * Acc@1 0.705 Acc@5 0.000
Test: [0/1]	Time  0.289 ( 0.289)	Loss 1.5039e-01 (1.5039e-01)	Acc@1   0.77 (  0.77)	Acc@5   0.00 (  0.00)
 * Acc@1 0.768 Acc@5 0.000
73
TRAINING
Epoch: [73][0/1]	Time  0.955 ( 0.955)	Data  0.251 ( 0.251)	Loss 7.9176e-02 (7.9176e-02)	Acc@1   0.93 (  0.93)	Acc@5   0.00 (  0.00)
[0.9279183895205978]
Test: [0/1]	Time  0.235 ( 0.235)	Loss 9.4363e-01 (9.4363e-01)	Acc@1   0.70 (  0.70)	Acc@5   0.00 (  0.00)
 * Acc@1 0.705 Acc@5 0.000
Test: [0/1]	Time  0.287 ( 0.287)	Loss 1.5015e-01 (1.5015e-01)	Acc@1   0.77 (  0.77)	Acc@5   0.00 (  0.00)
 * Acc@1 0.769 Acc@5 0.000
74
TRAINING
Epoch: [74][0/1]	Time  0.971 ( 0.971)	Data  0.262 ( 0.262)	Loss 7.9203e-02 (7.9203e-02)	Acc@1   0.93 (  0.93)	Acc@5   0.00 (  0.00)
[0.9278192438423909]
Test: [0/1]	Time  0.235 ( 0.235)	Loss 9.4350e-01 (9.4350e-01)	Acc@1   0.71 (  0.71)	Acc@5   0.00 (  0.00)
 * Acc@1 0.705 Acc@5 0.000
Test: [0/1]	Time  0.291 ( 0.291)	Loss 1.4998e-01 (1.4998e-01)	Acc@1   0.77 (  0.77)	Acc@5   0.00 (  0.00)
 * Acc@1 0.769 Acc@5 0.000
75
TRAINING
Epoch: [75][0/1]	Time  0.948 ( 0.948)	Data  0.239 ( 0.239)	Loss 7.9247e-02 (7.9247e-02)	Acc@1   0.93 (  0.93)	Acc@5   0.00 (  0.00)
[0.9278219322320507]
Test: [0/1]	Time  0.249 ( 0.249)	Loss 9.4340e-01 (9.4340e-01)	Acc@1   0.71 (  0.71)	Acc@5   0.00 (  0.00)
 * Acc@1 0.705 Acc@5 0.000
Test: [0/1]	Time  0.297 ( 0.297)	Loss 1.4985e-01 (1.4985e-01)	Acc@1   0.77 (  0.77)	Acc@5   0.00 (  0.00)
 * Acc@1 0.770 Acc@5 0.000
76
TRAINING
Epoch: [76][0/1]	Time  0.937 ( 0.937)	Data  0.251 ( 0.251)	Loss 7.9275e-02 (7.9275e-02)	Acc@1   0.93 (  0.93)	Acc@5   0.00 (  0.00)
[0.9279225151358379]
Test: [0/1]	Time  0.237 ( 0.237)	Loss 9.4332e-01 (9.4332e-01)	Acc@1   0.71 (  0.71)	Acc@5   0.00 (  0.00)
 * Acc@1 0.706 Acc@5 0.000
Test: [0/1]	Time  0.289 ( 0.289)	Loss 1.4974e-01 (1.4974e-01)	Acc@1   0.77 (  0.77)	Acc@5   0.00 (  0.00)
 * Acc@1 0.771 Acc@5 0.000
77
TRAINING
Epoch: [77][0/1]	Time  0.946 ( 0.946)	Data  0.247 ( 0.247)	Loss 7.9267e-02 (7.9267e-02)	Acc@1   0.93 (  0.93)	Acc@5   0.00 (  0.00)
[0.928108891855308]
Test: [0/1]	Time  0.240 ( 0.240)	Loss 9.4328e-01 (9.4328e-01)	Acc@1   0.71 (  0.71)	Acc@5   0.00 (  0.00)
 * Acc@1 0.706 Acc@5 0.000
Test: [0/1]	Time  0.291 ( 0.291)	Loss 1.4966e-01 (1.4966e-01)	Acc@1   0.77 (  0.77)	Acc@5   0.00 (  0.00)
 * Acc@1 0.771 Acc@5 0.000
78
TRAINING
Epoch: [78][0/1]	Time  0.959 ( 0.959)	Data  0.252 ( 0.252)	Loss 7.9218e-02 (7.9218e-02)	Acc@1   0.93 (  0.93)	Acc@5   0.00 (  0.00)
[0.928361915316142]
Test: [0/1]	Time  0.235 ( 0.235)	Loss 9.4328e-01 (9.4328e-01)	Acc@1   0.71 (  0.71)	Acc@5   0.00 (  0.00)
 * Acc@1 0.707 Acc@5 0.000
Test: [0/1]	Time  0.296 ( 0.296)	Loss 1.4961e-01 (1.4961e-01)	Acc@1   0.77 (  0.77)	Acc@5   0.00 (  0.00)
 * Acc@1 0.772 Acc@5 0.000
79
TRAINING
Epoch: [79][0/1]	Time  0.951 ( 0.951)	Data  0.253 ( 0.253)	Loss 7.9146e-02 (7.9146e-02)	Acc@1   0.93 (  0.93)	Acc@5   0.00 (  0.00)
[0.9286158550771548]
Test: [0/1]	Time  0.240 ( 0.240)	Loss 9.4330e-01 (9.4330e-01)	Acc@1   0.71 (  0.71)	Acc@5   0.00 (  0.00)
 * Acc@1 0.707 Acc@5 0.000
Test: [0/1]	Time  0.289 ( 0.289)	Loss 1.4959e-01 (1.4959e-01)	Acc@1   0.77 (  0.77)	Acc@5   0.00 (  0.00)
 * Acc@1 0.772 Acc@5 0.000
80
TRAINING
Epoch: [80][0/1]	Time  0.948 ( 0.948)	Data  0.241 ( 0.241)	Loss 7.9073e-02 (7.9073e-02)	Acc@1   0.93 (  0.93)	Acc@5   0.00 (  0.00)
[0.9287072391811471]
Test: [0/1]	Time  0.231 ( 0.231)	Loss 9.4331e-01 (9.4331e-01)	Acc@1   0.71 (  0.71)	Acc@5   0.00 (  0.00)
 * Acc@1 0.707 Acc@5 0.000
Test: [0/1]	Time  0.281 ( 0.281)	Loss 1.4961e-01 (1.4961e-01)	Acc@1   0.77 (  0.77)	Acc@5   0.00 (  0.00)
 * Acc@1 0.772 Acc@5 0.000
81
TRAINING
Epoch: [81][0/1]	Time  0.945 ( 0.945)	Data  0.251 ( 0.251)	Loss 7.9016e-02 (7.9016e-02)	Acc@1   0.93 (  0.93)	Acc@5   0.00 (  0.00)
[0.9288122713717518]
Test: [0/1]	Time  0.237 ( 0.237)	Loss 9.4331e-01 (9.4331e-01)	Acc@1   0.71 (  0.71)	Acc@5   0.00 (  0.00)
 * Acc@1 0.708 Acc@5 0.000
Test: [0/1]	Time  0.284 ( 0.284)	Loss 1.4965e-01 (1.4965e-01)	Acc@1   0.77 (  0.77)	Acc@5   0.00 (  0.00)
 * Acc@1 0.773 Acc@5 0.000
82
TRAINING
Epoch: [82][0/1]	Time  0.932 ( 0.932)	Data  0.245 ( 0.245)	Loss 7.8980e-02 (7.8980e-02)	Acc@1   0.93 (  0.93)	Acc@5   0.00 (  0.00)
[0.9289304279166701]
Test: [0/1]	Time  0.235 ( 0.235)	Loss 9.4327e-01 (9.4327e-01)	Acc@1   0.71 (  0.71)	Acc@5   0.00 (  0.00)
 * Acc@1 0.708 Acc@5 0.000
Test: [0/1]	Time  0.283 ( 0.283)	Loss 1.4969e-01 (1.4969e-01)	Acc@1   0.77 (  0.77)	Acc@5   0.00 (  0.00)
 * Acc@1 0.773 Acc@5 0.000
83
TRAINING
Epoch: [83][0/1]	Time  0.955 ( 0.955)	Data  0.250 ( 0.250)	Loss 7.8961e-02 (7.8961e-02)	Acc@1   0.93 (  0.93)	Acc@5   0.00 (  0.00)
[0.9290619903938382]
Test: [0/1]	Time  0.239 ( 0.239)	Loss 9.4319e-01 (9.4319e-01)	Acc@1   0.71 (  0.71)	Acc@5   0.00 (  0.00)
 * Acc@1 0.708 Acc@5 0.000
Test: [0/1]	Time  0.285 ( 0.285)	Loss 1.4970e-01 (1.4970e-01)	Acc@1   0.77 (  0.77)	Acc@5   0.00 (  0.00)
 * Acc@1 0.773 Acc@5 0.000
84
TRAINING
Epoch: [84][0/1]	Time  0.948 ( 0.948)	Data  0.244 ( 0.244)	Loss 7.8949e-02 (7.8949e-02)	Acc@1   0.93 (  0.93)	Acc@5   0.00 (  0.00)
[0.9292068226034378]
Test: [0/1]	Time  0.238 ( 0.238)	Loss 9.4306e-01 (9.4306e-01)	Acc@1   0.71 (  0.71)	Acc@5   0.00 (  0.00)
 * Acc@1 0.709 Acc@5 0.000
Test: [0/1]	Time  0.286 ( 0.286)	Loss 1.4968e-01 (1.4968e-01)	Acc@1   0.77 (  0.77)	Acc@5   0.00 (  0.00)
 * Acc@1 0.773 Acc@5 0.000
85
TRAINING
Epoch: [85][0/1]	Time  0.972 ( 0.972)	Data  0.267 ( 0.267)	Loss 7.8937e-02 (7.8937e-02)	Acc@1   0.93 (  0.93)	Acc@5   0.00 (  0.00)
[0.9293633892989184]
Test: [0/1]	Time  0.242 ( 0.242)	Loss 9.4290e-01 (9.4290e-01)	Acc@1   0.71 (  0.71)	Acc@5   0.00 (  0.00)
 * Acc@1 0.709 Acc@5 0.000
Test: [0/1]	Time  0.290 ( 0.290)	Loss 1.4962e-01 (1.4962e-01)	Acc@1   0.77 (  0.77)	Acc@5   0.00 (  0.00)
 * Acc@1 0.773 Acc@5 0.000
86
TRAINING
Epoch: [86][0/1]	Time  0.956 ( 0.956)	Data  0.255 ( 0.255)	Loss 7.8925e-02 (7.8925e-02)	Acc@1   0.93 (  0.93)	Acc@5   0.00 (  0.00)
[0.9295283018831011]
Test: [0/1]	Time  0.233 ( 0.233)	Loss 9.4270e-01 (9.4270e-01)	Acc@1   0.71 (  0.71)	Acc@5   0.00 (  0.00)
 * Acc@1 0.709 Acc@5 0.000
Test: [0/1]	Time  0.287 ( 0.287)	Loss 1.4954e-01 (1.4954e-01)	Acc@1   0.77 (  0.77)	Acc@5   0.00 (  0.00)
 * Acc@1 0.773 Acc@5 0.000
87
TRAINING
Epoch: [87][0/1]	Time  0.940 ( 0.940)	Data  0.248 ( 0.248)	Loss 7.8916e-02 (7.8916e-02)	Acc@1   0.93 (  0.93)	Acc@5   0.00 (  0.00)
[0.9296964769182147]
Test: [0/1]	Time  0.241 ( 0.241)	Loss 9.4249e-01 (9.4249e-01)	Acc@1   0.71 (  0.71)	Acc@5   0.00 (  0.00)
 * Acc@1 0.710 Acc@5 0.000
Test: [0/1]	Time  0.290 ( 0.290)	Loss 1.4946e-01 (1.4946e-01)	Acc@1   0.77 (  0.77)	Acc@5   0.00 (  0.00)
 * Acc@1 0.773 Acc@5 0.000
88
TRAINING
Epoch: [88][0/1]	Time  0.967 ( 0.967)	Data  0.258 ( 0.258)	Loss 7.8914e-02 (7.8914e-02)	Acc@1   0.93 (  0.93)	Acc@5   0.00 (  0.00)
[0.9298426570922047]
Test: [0/1]	Time  0.232 ( 0.232)	Loss 9.4229e-01 (9.4229e-01)	Acc@1   0.71 (  0.71)	Acc@5   0.00 (  0.00)
 * Acc@1 0.710 Acc@5 0.000
Test: [0/1]	Time  0.286 ( 0.286)	Loss 1.4938e-01 (1.4938e-01)	Acc@1   0.77 (  0.77)	Acc@5   0.00 (  0.00)
 * Acc@1 0.773 Acc@5 0.000
89
TRAINING
Epoch: [89][0/1]	Time  0.940 ( 0.940)	Data  0.250 ( 0.250)	Loss 7.8919e-02 (7.8919e-02)	Acc@1   0.93 (  0.93)	Acc@5   0.00 (  0.00)
[0.9299630809151083]
Test: [0/1]	Time  0.234 ( 0.234)	Loss 9.4212e-01 (9.4212e-01)	Acc@1   0.71 (  0.71)	Acc@5   0.00 (  0.00)
 * Acc@1 0.710 Acc@5 0.000
Test: [0/1]	Time  0.282 ( 0.282)	Loss 1.4933e-01 (1.4933e-01)	Acc@1   0.77 (  0.77)	Acc@5   0.00 (  0.00)
 * Acc@1 0.773 Acc@5 0.000
90
TRAINING
Epoch: [90][0/1]	Time  0.964 ( 0.964)	Data  0.252 ( 0.252)	Loss 7.8926e-02 (7.8926e-02)	Acc@1   0.93 (  0.93)	Acc@5   0.00 (  0.00)
[0.9300777788428988]
Test: [0/1]	Time  0.237 ( 0.237)	Loss 9.4197e-01 (9.4197e-01)	Acc@1   0.71 (  0.71)	Acc@5   0.00 (  0.00)
 * Acc@1 0.710 Acc@5 0.000
Test: [0/1]	Time  0.290 ( 0.290)	Loss 1.4929e-01 (1.4929e-01)	Acc@1   0.77 (  0.77)	Acc@5   0.00 (  0.00)
 * Acc@1 0.773 Acc@5 0.000
91
TRAINING
Epoch: [91][0/1]	Time  0.954 ( 0.954)	Data  0.244 ( 0.244)	Loss 7.8928e-02 (7.8928e-02)	Acc@1   0.93 (  0.93)	Acc@5   0.00 (  0.00)
[0.9301848419424956]
Test: [0/1]	Time  0.234 ( 0.234)	Loss 9.4187e-01 (9.4187e-01)	Acc@1   0.71 (  0.71)	Acc@5   0.00 (  0.00)
 * Acc@1 0.710 Acc@5 0.000
Test: [0/1]	Time  0.286 ( 0.286)	Loss 1.4927e-01 (1.4927e-01)	Acc@1   0.77 (  0.77)	Acc@5   0.00 (  0.00)
 * Acc@1 0.773 Acc@5 0.000
92
TRAINING
Epoch: [92][0/1]	Time  0.928 ( 0.928)	Data  0.246 ( 0.246)	Loss 7.8919e-02 (7.8919e-02)	Acc@1   0.93 (  0.93)	Acc@5   0.00 (  0.00)
[0.930268789146321]
Test: [0/1]	Time  0.234 ( 0.234)	Loss 9.4181e-01 (9.4181e-01)	Acc@1   0.71 (  0.71)	Acc@5   0.00 (  0.00)
 * Acc@1 0.710 Acc@5 0.000
Test: [0/1]	Time  0.290 ( 0.290)	Loss 1.4927e-01 (1.4927e-01)	Acc@1   0.77 (  0.77)	Acc@5   0.00 (  0.00)
 * Acc@1 0.773 Acc@5 0.000
93
TRAINING
Epoch: [93][0/1]	Time  0.916 ( 0.916)	Data  0.242 ( 0.242)	Loss 7.8896e-02 (7.8896e-02)	Acc@1   0.93 (  0.93)	Acc@5   0.00 (  0.00)
[0.9301900553656464]
Test: [0/1]	Time  0.228 ( 0.228)	Loss 9.4178e-01 (9.4178e-01)	Acc@1   0.71 (  0.71)	Acc@5   0.00 (  0.00)
 * Acc@1 0.711 Acc@5 0.000
Test: [0/1]	Time  0.280 ( 0.280)	Loss 1.4929e-01 (1.4929e-01)	Acc@1   0.77 (  0.77)	Acc@5   0.00 (  0.00)
 * Acc@1 0.773 Acc@5 0.000
94
TRAINING
Epoch: [94][0/1]	Time  0.911 ( 0.911)	Data  0.238 ( 0.238)	Loss 7.8862e-02 (7.8862e-02)	Acc@1   0.93 (  0.93)	Acc@5   0.00 (  0.00)
[0.9301095438490368]
Test: [0/1]	Time  0.227 ( 0.227)	Loss 9.4178e-01 (9.4178e-01)	Acc@1   0.71 (  0.71)	Acc@5   0.00 (  0.00)
 * Acc@1 0.711 Acc@5 0.000
Test: [0/1]	Time  0.282 ( 0.282)	Loss 1.4932e-01 (1.4932e-01)	Acc@1   0.77 (  0.77)	Acc@5   0.00 (  0.00)
 * Acc@1 0.773 Acc@5 0.000
95
TRAINING
Epoch: [95][0/1]	Time  0.926 ( 0.926)	Data  0.239 ( 0.239)	Loss 7.8823e-02 (7.8823e-02)	Acc@1   0.93 (  0.93)	Acc@5   0.00 (  0.00)
[0.9300321765789202]
Test: [0/1]	Time  0.231 ( 0.231)	Loss 9.4180e-01 (9.4180e-01)	Acc@1   0.71 (  0.71)	Acc@5   0.00 (  0.00)
 * Acc@1 0.711 Acc@5 0.000
Test: [0/1]	Time  0.278 ( 0.278)	Loss 1.4936e-01 (1.4936e-01)	Acc@1   0.77 (  0.77)	Acc@5   0.00 (  0.00)
 * Acc@1 0.773 Acc@5 0.000
96
TRAINING
Epoch: [96][0/1]	Time  0.912 ( 0.912)	Data  0.240 ( 0.240)	Loss 7.8785e-02 (7.8785e-02)	Acc@1   0.93 (  0.93)	Acc@5   0.00 (  0.00)
[0.9299622546630368]
Test: [0/1]	Time  0.227 ( 0.227)	Loss 9.4181e-01 (9.4181e-01)	Acc@1   0.71 (  0.71)	Acc@5   0.00 (  0.00)
 * Acc@1 0.711 Acc@5 0.000
Test: [0/1]	Time  0.278 ( 0.278)	Loss 1.4940e-01 (1.4940e-01)	Acc@1   0.77 (  0.77)	Acc@5   0.00 (  0.00)
 * Acc@1 0.773 Acc@5 0.000
97
TRAINING
Epoch: [97][0/1]	Time  0.915 ( 0.915)	Data  0.243 ( 0.243)	Loss 7.8751e-02 (7.8751e-02)	Acc@1   0.93 (  0.93)	Acc@5   0.00 (  0.00)
[0.9299036879547763]
Test: [0/1]	Time  0.231 ( 0.231)	Loss 9.4182e-01 (9.4182e-01)	Acc@1   0.71 (  0.71)	Acc@5   0.00 (  0.00)
 * Acc@1 0.711 Acc@5 0.000
Test: [0/1]	Time  0.278 ( 0.278)	Loss 1.4943e-01 (1.4943e-01)	Acc@1   0.77 (  0.77)	Acc@5   0.00 (  0.00)
 * Acc@1 0.773 Acc@5 0.000
98
TRAINING
Epoch: [98][0/1]	Time  0.910 ( 0.910)	Data  0.234 ( 0.234)	Loss 7.8722e-02 (7.8722e-02)	Acc@1   0.93 (  0.93)	Acc@5   0.00 (  0.00)
[0.9298600493401947]
Test: [0/1]	Time  0.228 ( 0.228)	Loss 9.4182e-01 (9.4182e-01)	Acc@1   0.71 (  0.71)	Acc@5   0.00 (  0.00)
 * Acc@1 0.711 Acc@5 0.000
Test: [0/1]	Time  0.280 ( 0.280)	Loss 1.4946e-01 (1.4946e-01)	Acc@1   0.77 (  0.77)	Acc@5   0.00 (  0.00)
 * Acc@1 0.773 Acc@5 0.000
99
TRAINING
Epoch: [99][0/1]	Time  0.912 ( 0.912)	Data  0.240 ( 0.240)	Loss 7.8700e-02 (7.8700e-02)	Acc@1   0.93 (  0.93)	Acc@5   0.00 (  0.00)
[0.9298344486437566]
Test: [0/1]	Time  0.228 ( 0.228)	Loss 9.4179e-01 (9.4179e-01)	Acc@1   0.71 (  0.71)	Acc@5   0.00 (  0.00)
 * Acc@1 0.711 Acc@5 0.000
Test: [0/1]	Time  0.285 ( 0.285)	Loss 1.4947e-01 (1.4947e-01)	Acc@1   0.77 (  0.77)	Acc@5   0.00 (  0.00)
 * Acc@1 0.773 Acc@5 0.000
=> using pre-trained model 'st_resnet'
s/ohp/session_1
torch.Size([640, 3, 224, 224])
(640, 22)
attach reg
0
TRAINING
/home/helenr6/Adv_mapper/train_split.py:125: UserWarning: You have chosen to seed training. This will turn on the CUDNN deterministic setting, which can slow down your training considerably! You may see unexpected behavior when restarting from checkpoints.
  warnings.warn('You have chosen to seed training. '
/localscratch/helenr6.6279052.0/env/lib/python3.7/site-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  cpuset_checked))
Epoch: [0][0/1]	Time  5.223 ( 5.223)	Data  1.795 ( 1.795)	Loss 1.8575e+00 (1.8575e+00)	Acc@1   0.00 (  0.00)	Acc@5   0.00 (  0.00)
[0.001209274242450091]
Test: [0/1]	Time  0.424 ( 0.424)	Loss 1.2861e+00 (1.2861e+00)	Acc@1  -0.11 ( -0.11)	Acc@5   0.00 (  0.00)
 * Acc@1 -0.110 Acc@5 0.000
Test: [0/1]	Time  0.548 ( 0.548)	Loss 1.0287e+00 (1.0287e+00)	Acc@1   0.02 (  0.02)	Acc@5   0.00 (  0.00)
 * Acc@1 0.021 Acc@5 0.000
1
TRAINING
Epoch: [1][0/1]	Time  0.954 ( 0.954)	Data  0.243 ( 0.243)	Loss 1.7499e+00 (1.7499e+00)	Acc@1   0.00 (  0.00)	Acc@5   0.00 (  0.00)
[0.003537804291466524]
Test: [0/1]	Time  0.243 ( 0.243)	Loss 1.2962e+00 (1.2962e+00)	Acc@1  -0.10 ( -0.10)	Acc@5   0.00 (  0.00)
 * Acc@1 -0.103 Acc@5 0.000
Test: [0/1]	Time  0.292 ( 0.292)	Loss 9.4318e-01 (9.4318e-01)	Acc@1   0.03 (  0.03)	Acc@5   0.00 (  0.00)
 * Acc@1 0.028 Acc@5 0.000
2
TRAINING
Epoch: [2][0/1]	Time  0.958 ( 0.958)	Data  0.259 ( 0.259)	Loss 1.5922e+00 (1.5922e+00)	Acc@1   0.01 (  0.01)	Acc@5   0.00 (  0.00)
[0.008045186849262247]
Test: [0/1]	Time  0.241 ( 0.241)	Loss 1.3093e+00 (1.3093e+00)	Acc@1  -0.09 ( -0.09)	Acc@5   0.00 (  0.00)
 * Acc@1 -0.092 Acc@5 0.000
Test: [0/1]	Time  0.294 ( 0.294)	Loss 8.6988e-01 (8.6988e-01)	Acc@1   0.04 (  0.04)	Acc@5   0.00 (  0.00)
 * Acc@1 0.036 Acc@5 0.000
3
TRAINING
Epoch: [3][0/1]	Time  0.959 ( 0.959)	Data  0.268 ( 0.268)	Loss 1.4481e+00 (1.4481e+00)	Acc@1   0.02 (  0.02)	Acc@5   0.00 (  0.00)
[0.023496379911040893]
Test: [0/1]	Time  0.243 ( 0.243)	Loss 1.3238e+00 (1.3238e+00)	Acc@1  -0.07 ( -0.07)	Acc@5   0.00 (  0.00)
 * Acc@1 -0.070 Acc@5 0.000
Test: [0/1]	Time  0.300 ( 0.300)	Loss 8.2990e-01 (8.2990e-01)	Acc@1   0.04 (  0.04)	Acc@5   0.00 (  0.00)
 * Acc@1 0.045 Acc@5 0.000
4
TRAINING
Epoch: [4][0/1]	Time  0.963 ( 0.963)	Data  0.251 ( 0.251)	Loss 1.3519e+00 (1.3519e+00)	Acc@1   0.03 (  0.03)	Acc@5   0.00 (  0.00)
[0.034400771626488684]
Test: [0/1]	Time  0.236 ( 0.236)	Loss 1.3352e+00 (1.3352e+00)	Acc@1  -0.05 ( -0.05)	Acc@5   0.00 (  0.00)
 * Acc@1 -0.050 Acc@5 0.000
Test: [0/1]	Time  0.289 ( 0.289)	Loss 8.1951e-01 (8.1951e-01)	Acc@1   0.05 (  0.05)	Acc@5   0.00 (  0.00)
 * Acc@1 0.055 Acc@5 0.000
5
TRAINING
Epoch: [5][0/1]	Time  0.943 ( 0.943)	Data  0.252 ( 0.252)	Loss 1.2965e+00 (1.2965e+00)	Acc@1   0.05 (  0.05)	Acc@5   0.00 (  0.00)
[0.04728098452403166]
Test: [0/1]	Time  0.245 ( 0.245)	Loss 1.3380e+00 (1.3380e+00)	Acc@1  -0.03 ( -0.03)	Acc@5   0.00 (  0.00)
 * Acc@1 -0.028 Acc@5 0.000
Test: [0/1]	Time  0.297 ( 0.297)	Loss 8.1685e-01 (8.1685e-01)	Acc@1   0.07 (  0.07)	Acc@5   0.00 (  0.00)
 * Acc@1 0.067 Acc@5 0.000
6
TRAINING
Epoch: [6][0/1]	Time  0.997 ( 0.997)	Data  0.269 ( 0.269)	Loss 1.2482e+00 (1.2482e+00)	Acc@1   0.06 (  0.06)	Acc@5   0.00 (  0.00)
[0.059586858735125585]
Test: [0/1]	Time  0.249 ( 0.249)	Loss 1.3277e+00 (1.3277e+00)	Acc@1  -0.02 ( -0.02)	Acc@5   0.00 (  0.00)
 * Acc@1 -0.018 Acc@5 0.000
Test: [0/1]	Time  0.296 ( 0.296)	Loss 7.9860e-01 (7.9860e-01)	Acc@1   0.08 (  0.08)	Acc@5   0.00 (  0.00)
 * Acc@1 0.077 Acc@5 0.000
7
TRAINING
Epoch: [7][0/1]	Time  0.986 ( 0.986)	Data  0.259 ( 0.259)	Loss 1.1734e+00 (1.1734e+00)	Acc@1   0.07 (  0.07)	Acc@5   0.00 (  0.00)
[0.07343864103886605]
Test: [0/1]	Time  0.235 ( 0.235)	Loss 1.3040e+00 (1.3040e+00)	Acc@1  -0.02 ( -0.02)	Acc@5   0.00 (  0.00)
 * Acc@1 -0.015 Acc@5 0.000
Test: [0/1]	Time  0.285 ( 0.285)	Loss 7.5447e-01 (7.5447e-01)	Acc@1   0.09 (  0.09)	Acc@5   0.00 (  0.00)
 * Acc@1 0.085 Acc@5 0.000
8
TRAINING
Epoch: [8][0/1]	Time  0.954 ( 0.954)	Data  0.252 ( 0.252)	Loss 1.0605e+00 (1.0605e+00)	Acc@1   0.10 (  0.10)	Acc@5   0.00 (  0.00)
[0.09545677739681557]
Test: [0/1]	Time  0.235 ( 0.235)	Loss 1.2701e+00 (1.2701e+00)	Acc@1   0.00 (  0.00)	Acc@5   0.00 (  0.00)
 * Acc@1 0.002 Acc@5 0.000
Test: [0/1]	Time  0.287 ( 0.287)	Loss 6.9172e-01 (6.9172e-01)	Acc@1   0.10 (  0.10)	Acc@5   0.00 (  0.00)
 * Acc@1 0.098 Acc@5 0.000
9
TRAINING
Epoch: [9][0/1]	Time  0.970 ( 0.970)	Data  0.262 ( 0.262)	Loss 9.2370e-01 (9.2370e-01)	Acc@1   0.12 (  0.12)	Acc@5   0.00 (  0.00)
[0.1204016447642379]
Test: [0/1]	Time  0.239 ( 0.239)	Loss 1.2322e+00 (1.2322e+00)	Acc@1   0.04 (  0.04)	Acc@5   0.00 (  0.00)
 * Acc@1 0.043 Acc@5 0.000
Test: [0/1]	Time  0.291 ( 0.291)	Loss 6.2829e-01 (6.2829e-01)	Acc@1   0.11 (  0.11)	Acc@5   0.00 (  0.00)
 * Acc@1 0.111 Acc@5 0.000
10
TRAINING
Epoch: [10][0/1]	Time  0.951 ( 0.951)	Data  0.243 ( 0.243)	Loss 7.9078e-01 (7.9078e-01)	Acc@1   0.14 (  0.14)	Acc@5   0.00 (  0.00)
[0.14114358983598413]
Test: [0/1]	Time  0.239 ( 0.239)	Loss 1.1961e+00 (1.1961e+00)	Acc@1   0.08 (  0.08)	Acc@5   0.00 (  0.00)
 * Acc@1 0.077 Acc@5 0.000
Test: [0/1]	Time  0.297 ( 0.297)	Loss 5.8052e-01 (5.8052e-01)	Acc@1   0.12 (  0.12)	Acc@5   0.00 (  0.00)
 * Acc@1 0.125 Acc@5 0.000
11
TRAINING
Epoch: [11][0/1]	Time  0.939 ( 0.939)	Data  0.242 ( 0.242)	Loss 6.8525e-01 (6.8525e-01)	Acc@1   0.17 (  0.17)	Acc@5   0.00 (  0.00)
[0.17122761352062993]
Test: [0/1]	Time  0.237 ( 0.237)	Loss 1.1654e+00 (1.1654e+00)	Acc@1   0.14 (  0.14)	Acc@5   0.00 (  0.00)
 * Acc@1 0.139 Acc@5 0.000
Test: [0/1]	Time  0.289 ( 0.289)	Loss 5.5350e-01 (5.5350e-01)	Acc@1   0.14 (  0.14)	Acc@5   0.00 (  0.00)
 * Acc@1 0.139 Acc@5 0.000
12
TRAINING
Epoch: [12][0/1]	Time  1.049 ( 1.049)	Data  0.337 ( 0.337)	Loss 6.1366e-01 (6.1366e-01)	Acc@1   0.20 (  0.20)	Acc@5   0.00 (  0.00)
[0.19965064316363523]
Test: [0/1]	Time  0.251 ( 0.251)	Loss 1.1410e+00 (1.1410e+00)	Acc@1   0.19 (  0.19)	Acc@5   0.00 (  0.00)
 * Acc@1 0.186 Acc@5 0.000
Test: [0/1]	Time  0.302 ( 0.302)	Loss 5.3962e-01 (5.3962e-01)	Acc@1   0.15 (  0.15)	Acc@5   0.00 (  0.00)
 * Acc@1 0.154 Acc@5 0.000
13
TRAINING
Epoch: [13][0/1]	Time  1.018 ( 1.018)	Data  0.313 ( 0.313)	Loss 5.6523e-01 (5.6523e-01)	Acc@1   0.23 (  0.23)	Acc@5   0.00 (  0.00)
[0.23226509035206622]
Test: [0/1]	Time  0.251 ( 0.251)	Loss 1.1215e+00 (1.1215e+00)	Acc@1   0.22 (  0.22)	Acc@5   0.00 (  0.00)
 * Acc@1 0.223 Acc@5 0.000
Test: [0/1]	Time  0.302 ( 0.302)	Loss 5.2497e-01 (5.2497e-01)	Acc@1   0.18 (  0.18)	Acc@5   0.00 (  0.00)
 * Acc@1 0.175 Acc@5 0.000
14
TRAINING
Epoch: [14][0/1]	Time  1.037 ( 1.037)	Data  0.311 ( 0.311)	Loss 5.2144e-01 (5.2144e-01)	Acc@1   0.27 (  0.27)	Acc@5   0.00 (  0.00)
[0.26819388253959336]
Test: [0/1]	Time  0.243 ( 0.243)	Loss 1.1054e+00 (1.1054e+00)	Acc@1   0.25 (  0.25)	Acc@5   0.00 (  0.00)
 * Acc@1 0.247 Acc@5 0.000
Test: [0/1]	Time  0.292 ( 0.292)	Loss 4.9852e-01 (4.9852e-01)	Acc@1   0.19 (  0.19)	Acc@5   0.00 (  0.00)
 * Acc@1 0.193 Acc@5 0.000
15
TRAINING
Epoch: [15][0/1]	Time  0.959 ( 0.959)	Data  0.262 ( 0.262)	Loss 4.6830e-01 (4.6830e-01)	Acc@1   0.31 (  0.31)	Acc@5   0.00 (  0.00)
[0.3076014628253311]
Test: [0/1]	Time  0.239 ( 0.239)	Loss 1.0914e+00 (1.0914e+00)	Acc@1   0.27 (  0.27)	Acc@5   0.00 (  0.00)
 * Acc@1 0.274 Acc@5 0.000
Test: [0/1]	Time  0.290 ( 0.290)	Loss 4.5837e-01 (4.5837e-01)	Acc@1   0.21 (  0.21)	Acc@5   0.00 (  0.00)
 * Acc@1 0.213 Acc@5 0.000
16
TRAINING
Epoch: [16][0/1]	Time  0.966 ( 0.966)	Data  0.255 ( 0.255)	Loss 4.0352e-01 (4.0352e-01)	Acc@1   0.35 (  0.35)	Acc@5   0.00 (  0.00)
[0.3536028093092502]
Test: [0/1]	Time  0.241 ( 0.241)	Loss 1.0793e+00 (1.0793e+00)	Acc@1   0.28 (  0.28)	Acc@5   0.00 (  0.00)
 * Acc@1 0.278 Acc@5 0.000
Test: [0/1]	Time  0.286 ( 0.286)	Loss 4.1145e-01 (4.1145e-01)	Acc@1   0.23 (  0.23)	Acc@5   0.00 (  0.00)
 * Acc@1 0.235 Acc@5 0.000
17
TRAINING
Epoch: [17][0/1]	Time  0.977 ( 0.977)	Data  0.270 ( 0.270)	Loss 3.3557e-01 (3.3557e-01)	Acc@1   0.40 (  0.40)	Acc@5   0.00 (  0.00)
[0.3978956602785746]
Test: [0/1]	Time  0.246 ( 0.246)	Loss 1.0693e+00 (1.0693e+00)	Acc@1   0.28 (  0.28)	Acc@5   0.00 (  0.00)
 * Acc@1 0.278 Acc@5 0.000
Test: [0/1]	Time  0.294 ( 0.294)	Loss 3.6829e-01 (3.6829e-01)	Acc@1   0.25 (  0.25)	Acc@5   0.00 (  0.00)
 * Acc@1 0.255 Acc@5 0.000
18
TRAINING
Epoch: [18][0/1]	Time  0.965 ( 0.965)	Data  0.260 ( 0.260)	Loss 2.7656e-01 (2.7656e-01)	Acc@1   0.44 (  0.44)	Acc@5   0.00 (  0.00)
[0.4439542905504429]
Test: [0/1]	Time  0.238 ( 0.238)	Loss 1.0613e+00 (1.0613e+00)	Acc@1   0.28 (  0.28)	Acc@5   0.00 (  0.00)
 * Acc@1 0.279 Acc@5 0.000
Test: [0/1]	Time  0.298 ( 0.298)	Loss 3.3635e-01 (3.3635e-01)	Acc@1   0.28 (  0.28)	Acc@5   0.00 (  0.00)
 * Acc@1 0.283 Acc@5 0.000
19
TRAINING
Epoch: [19][0/1]	Time  0.954 ( 0.954)	Data  0.249 ( 0.249)	Loss 2.3437e-01 (2.3437e-01)	Acc@1   0.49 (  0.49)	Acc@5   0.00 (  0.00)
[0.48569602344036417]
Test: [0/1]	Time  0.235 ( 0.235)	Loss 1.0543e+00 (1.0543e+00)	Acc@1   0.33 (  0.33)	Acc@5   0.00 (  0.00)
 * Acc@1 0.330 Acc@5 0.000
Test: [0/1]	Time  0.296 ( 0.296)	Loss 3.1638e-01 (3.1638e-01)	Acc@1   0.31 (  0.31)	Acc@5   0.00 (  0.00)
 * Acc@1 0.308 Acc@5 0.000
20
TRAINING
Epoch: [20][0/1]	Time  0.957 ( 0.957)	Data  0.245 ( 0.245)	Loss 2.0873e-01 (2.0873e-01)	Acc@1   0.53 (  0.53)	Acc@5   0.00 (  0.00)
[0.5273209677148203]
Test: [0/1]	Time  0.239 ( 0.239)	Loss 1.0469e+00 (1.0469e+00)	Acc@1   0.37 (  0.37)	Acc@5   0.00 (  0.00)
 * Acc@1 0.370 Acc@5 0.000
Test: [0/1]	Time  0.285 ( 0.285)	Loss 3.0332e-01 (3.0332e-01)	Acc@1   0.33 (  0.33)	Acc@5   0.00 (  0.00)
 * Acc@1 0.333 Acc@5 0.000
21
TRAINING
Epoch: [21][0/1]	Time  0.949 ( 0.949)	Data  0.250 ( 0.250)	Loss 1.9278e-01 (1.9278e-01)	Acc@1   0.57 (  0.57)	Acc@5   0.00 (  0.00)
[0.570858050702423]
Test: [0/1]	Time  0.244 ( 0.244)	Loss 1.0381e+00 (1.0381e+00)	Acc@1   0.42 (  0.42)	Acc@5   0.00 (  0.00)
 * Acc@1 0.418 Acc@5 0.000
Test: [0/1]	Time  0.306 ( 0.306)	Loss 2.9042e-01 (2.9042e-01)	Acc@1   0.36 (  0.36)	Acc@5   0.00 (  0.00)
 * Acc@1 0.357 Acc@5 0.000
22
TRAINING
Epoch: [22][0/1]	Time  0.937 ( 0.937)	Data  0.250 ( 0.250)	Loss 1.7814e-01 (1.7814e-01)	Acc@1   0.61 (  0.61)	Acc@5   0.00 (  0.00)
[0.6122429345649935]
Test: [0/1]	Time  0.243 ( 0.243)	Loss 1.0272e+00 (1.0272e+00)	Acc@1   0.47 (  0.47)	Acc@5   0.00 (  0.00)
 * Acc@1 0.469 Acc@5 0.000
Test: [0/1]	Time  0.288 ( 0.288)	Loss 2.7356e-01 (2.7356e-01)	Acc@1   0.38 (  0.38)	Acc@5   0.00 (  0.00)
 * Acc@1 0.381 Acc@5 0.000
23
TRAINING
Epoch: [23][0/1]	Time  0.962 ( 0.962)	Data  0.262 ( 0.262)	Loss 1.5985e-01 (1.5985e-01)	Acc@1   0.66 (  0.66)	Acc@5   0.00 (  0.00)
[0.6568377068557671]
Test: [0/1]	Time  0.239 ( 0.239)	Loss 1.0148e+00 (1.0148e+00)	Acc@1   0.51 (  0.51)	Acc@5   0.00 (  0.00)
 * Acc@1 0.511 Acc@5 0.000
Test: [0/1]	Time  0.290 ( 0.290)	Loss 2.5319e-01 (2.5319e-01)	Acc@1   0.41 (  0.41)	Acc@5   0.00 (  0.00)
 * Acc@1 0.406 Acc@5 0.000
24
TRAINING
Epoch: [24][0/1]	Time  0.966 ( 0.966)	Data  0.253 ( 0.253)	Loss 1.3839e-01 (1.3839e-01)	Acc@1   0.70 (  0.70)	Acc@5   0.00 (  0.00)
[0.6989204901178376]
Test: [0/1]	Time  0.237 ( 0.237)	Loss 1.0021e+00 (1.0021e+00)	Acc@1   0.55 (  0.55)	Acc@5   0.00 (  0.00)
 * Acc@1 0.546 Acc@5 0.000
Test: [0/1]	Time  0.285 ( 0.285)	Loss 2.3313e-01 (2.3313e-01)	Acc@1   0.43 (  0.43)	Acc@5   0.00 (  0.00)
 * Acc@1 0.431 Acc@5 0.000
25
TRAINING
Epoch: [25][0/1]	Time  0.955 ( 0.955)	Data  0.242 ( 0.242)	Loss 1.1804e-01 (1.1804e-01)	Acc@1   0.74 (  0.74)	Acc@5   0.00 (  0.00)
[0.7353684812116248]
Test: [0/1]	Time  0.235 ( 0.235)	Loss 9.9032e-01 (9.9032e-01)	Acc@1   0.58 (  0.58)	Acc@5   0.00 (  0.00)
 * Acc@1 0.575 Acc@5 0.000
Test: [0/1]	Time  0.292 ( 0.292)	Loss 2.1754e-01 (2.1754e-01)	Acc@1   0.45 (  0.45)	Acc@5   0.00 (  0.00)
 * Acc@1 0.455 Acc@5 0.000
26
TRAINING
Epoch: [26][0/1]	Time  0.939 ( 0.939)	Data  0.247 ( 0.247)	Loss 1.0340e-01 (1.0340e-01)	Acc@1   0.77 (  0.77)	Acc@5   0.00 (  0.00)
[0.7678669122239097]
Test: [0/1]	Time  0.236 ( 0.236)	Loss 9.8027e-01 (9.8027e-01)	Acc@1   0.60 (  0.60)	Acc@5   0.00 (  0.00)
 * Acc@1 0.600 Acc@5 0.000
Test: [0/1]	Time  0.306 ( 0.306)	Loss 2.0821e-01 (2.0821e-01)	Acc@1   0.48 (  0.48)	Acc@5   0.00 (  0.00)
 * Acc@1 0.478 Acc@5 0.000
27
TRAINING
Epoch: [27][0/1]	Time  0.950 ( 0.950)	Data  0.238 ( 0.238)	Loss 9.6312e-02 (9.6312e-02)	Acc@1   0.80 (  0.80)	Acc@5   0.00 (  0.00)
[0.7973195852314594]
Test: [0/1]	Time  0.232 ( 0.232)	Loss 9.7213e-01 (9.7213e-01)	Acc@1   0.62 (  0.62)	Acc@5   0.00 (  0.00)
 * Acc@1 0.620 Acc@5 0.000
Test: [0/1]	Time  0.282 ( 0.282)	Loss 2.0376e-01 (2.0376e-01)	Acc@1   0.50 (  0.50)	Acc@5   0.00 (  0.00)
 * Acc@1 0.501 Acc@5 0.000
28
TRAINING
Epoch: [28][0/1]	Time  0.961 ( 0.961)	Data  0.254 ( 0.254)	Loss 9.5067e-02 (9.5067e-02)	Acc@1   0.82 (  0.82)	Acc@5   0.00 (  0.00)
[0.8197513814580754]
Test: [0/1]	Time  0.234 ( 0.234)	Loss 9.6557e-01 (9.6557e-01)	Acc@1   0.64 (  0.64)	Acc@5   0.00 (  0.00)
 * Acc@1 0.637 Acc@5 0.000
Test: [0/1]	Time  0.287 ( 0.287)	Loss 2.0081e-01 (2.0081e-01)	Acc@1   0.52 (  0.52)	Acc@5   0.00 (  0.00)
 * Acc@1 0.524 Acc@5 0.000
29
TRAINING
Epoch: [29][0/1]	Time  0.946 ( 0.946)	Data  0.247 ( 0.247)	Loss 9.5802e-02 (9.5802e-02)	Acc@1   0.84 (  0.84)	Acc@5   0.00 (  0.00)
[0.8371604092091247]
Test: [0/1]	Time  0.236 ( 0.236)	Loss 9.6014e-01 (9.6014e-01)	Acc@1   0.65 (  0.65)	Acc@5   0.00 (  0.00)
 * Acc@1 0.652 Acc@5 0.000
Test: [0/1]	Time  0.331 ( 0.331)	Loss 1.9623e-01 (1.9623e-01)	Acc@1   0.55 (  0.55)	Acc@5   0.00 (  0.00)
 * Acc@1 0.548 Acc@5 0.000
30
TRAINING
Epoch: [30][0/1]	Time  0.948 ( 0.948)	Data  0.238 ( 0.238)	Loss 9.4974e-02 (9.4974e-02)	Acc@1   0.85 (  0.85)	Acc@5   0.00 (  0.00)
[0.8528166024596727]
Test: [0/1]	Time  0.231 ( 0.231)	Loss 9.5552e-01 (9.5552e-01)	Acc@1   0.66 (  0.66)	Acc@5   0.00 (  0.00)
 * Acc@1 0.665 Acc@5 0.000
Test: [0/1]	Time  0.281 ( 0.281)	Loss 1.8882e-01 (1.8882e-01)	Acc@1   0.57 (  0.57)	Acc@5   0.00 (  0.00)
 * Acc@1 0.570 Acc@5 0.000
31
TRAINING
Epoch: [31][0/1]	Time  0.947 ( 0.947)	Data  0.240 ( 0.240)	Loss 9.1197e-02 (9.1197e-02)	Acc@1   0.86 (  0.86)	Acc@5   0.00 (  0.00)
[0.8624005547142047]
Test: [0/1]	Time  0.235 ( 0.235)	Loss 9.5165e-01 (9.5165e-01)	Acc@1   0.67 (  0.67)	Acc@5   0.00 (  0.00)
 * Acc@1 0.675 Acc@5 0.000
Test: [0/1]	Time  0.283 ( 0.283)	Loss 1.7961e-01 (1.7961e-01)	Acc@1   0.59 (  0.59)	Acc@5   0.00 (  0.00)
 * Acc@1 0.593 Acc@5 0.000
32
TRAINING
Epoch: [32][0/1]	Time  0.923 ( 0.923)	Data  0.235 ( 0.235)	Loss 8.5522e-02 (8.5522e-02)	Acc@1   0.87 (  0.87)	Acc@5   0.00 (  0.00)
[0.8696804855483711]
Test: [0/1]	Time  0.239 ( 0.239)	Loss 9.4856e-01 (9.4856e-01)	Acc@1   0.68 (  0.68)	Acc@5   0.00 (  0.00)
 * Acc@1 0.681 Acc@5 0.000
Test: [0/1]	Time  0.287 ( 0.287)	Loss 1.7083e-01 (1.7083e-01)	Acc@1   0.62 (  0.62)	Acc@5   0.00 (  0.00)
 * Acc@1 0.617 Acc@5 0.000
33
TRAINING
Epoch: [33][0/1]	Time  0.978 ( 0.978)	Data  0.265 ( 0.265)	Loss 8.0277e-02 (8.0277e-02)	Acc@1   0.88 (  0.88)	Acc@5   0.00 (  0.00)
[0.875300304965274]
Test: [0/1]	Time  0.239 ( 0.239)	Loss 9.4624e-01 (9.4624e-01)	Acc@1   0.69 (  0.69)	Acc@5   0.00 (  0.00)
 * Acc@1 0.685 Acc@5 0.000
Test: [0/1]	Time  0.292 ( 0.292)	Loss 1.6437e-01 (1.6437e-01)	Acc@1   0.64 (  0.64)	Acc@5   0.00 (  0.00)
 * Acc@1 0.640 Acc@5 0.000
34
TRAINING
Epoch: [34][0/1]	Time  0.972 ( 0.972)	Data  0.259 ( 0.259)	Loss 7.7407e-02 (7.7407e-02)	Acc@1   0.88 (  0.88)	Acc@5   0.00 (  0.00)
[0.8777772355826958]
Test: [0/1]	Time  0.239 ( 0.239)	Loss 9.4450e-01 (9.4450e-01)	Acc@1   0.69 (  0.69)	Acc@5   0.00 (  0.00)
 * Acc@1 0.687 Acc@5 0.000
Test: [0/1]	Time  0.286 ( 0.286)	Loss 1.6081e-01 (1.6081e-01)	Acc@1   0.66 (  0.66)	Acc@5   0.00 (  0.00)
 * Acc@1 0.658 Acc@5 0.000
35
TRAINING
Epoch: [35][0/1]	Time  0.975 ( 0.975)	Data  0.252 ( 0.252)	Loss 7.7378e-02 (7.7378e-02)	Acc@1   0.88 (  0.88)	Acc@5   0.00 (  0.00)
[0.8789023291842202]
Test: [0/1]	Time  0.238 ( 0.238)	Loss 9.4304e-01 (9.4304e-01)	Acc@1   0.69 (  0.69)	Acc@5   0.00 (  0.00)
 * Acc@1 0.688 Acc@5 0.000
Test: [0/1]	Time  0.289 ( 0.289)	Loss 1.5935e-01 (1.5935e-01)	Acc@1   0.67 (  0.67)	Acc@5   0.00 (  0.00)
 * Acc@1 0.672 Acc@5 0.000
36
TRAINING
Epoch: [36][0/1]	Time  0.939 ( 0.939)	Data  0.252 ( 0.252)	Loss 7.9156e-02 (7.9156e-02)	Acc@1   0.88 (  0.88)	Acc@5   0.00 (  0.00)
[0.8794642655879039]
Test: [0/1]	Time  0.284 ( 0.284)	Loss 9.4154e-01 (9.4154e-01)	Acc@1   0.69 (  0.69)	Acc@5   0.00 (  0.00)
 * Acc@1 0.688 Acc@5 0.000
Test: [0/1]	Time  0.285 ( 0.285)	Loss 1.5855e-01 (1.5855e-01)	Acc@1   0.68 (  0.68)	Acc@5   0.00 (  0.00)
 * Acc@1 0.683 Acc@5 0.000
37
TRAINING
Epoch: [37][0/1]	Time  0.946 ( 0.946)	Data  0.232 ( 0.232)	Loss 8.1075e-02 (8.1075e-02)	Acc@1   0.88 (  0.88)	Acc@5   0.00 (  0.00)
[0.8804495732869626]
Test: [0/1]	Time  0.239 ( 0.239)	Loss 9.3981e-01 (9.3981e-01)	Acc@1   0.69 (  0.69)	Acc@5   0.00 (  0.00)
 * Acc@1 0.689 Acc@5 0.000
Test: [0/1]	Time  0.298 ( 0.298)	Loss 1.5735e-01 (1.5735e-01)	Acc@1   0.69 (  0.69)	Acc@5   0.00 (  0.00)
 * Acc@1 0.691 Acc@5 0.000
38
TRAINING
Epoch: [38][0/1]	Time  0.967 ( 0.967)	Data  0.269 ( 0.269)	Loss 8.1898e-02 (8.1898e-02)	Acc@1   0.88 (  0.88)	Acc@5   0.00 (  0.00)
[0.8806139947909638]
Test: [0/1]	Time  0.241 ( 0.241)	Loss 9.3784e-01 (9.3784e-01)	Acc@1   0.69 (  0.69)	Acc@5   0.00 (  0.00)
 * Acc@1 0.690 Acc@5 0.000
Test: [0/1]	Time  0.293 ( 0.293)	Loss 1.5553e-01 (1.5553e-01)	Acc@1   0.70 (  0.70)	Acc@5   0.00 (  0.00)
 * Acc@1 0.698 Acc@5 0.000
39
TRAINING
Epoch: [39][0/1]	Time  0.951 ( 0.951)	Data  0.258 ( 0.258)	Loss 8.1427e-02 (8.1427e-02)	Acc@1   0.88 (  0.88)	Acc@5   0.00 (  0.00)
[0.880241376659789]
Test: [0/1]	Time  0.245 ( 0.245)	Loss 9.3580e-01 (9.3580e-01)	Acc@1   0.69 (  0.69)	Acc@5   0.00 (  0.00)
 * Acc@1 0.691 Acc@5 0.000
Test: [0/1]	Time  0.288 ( 0.288)	Loss 1.5370e-01 (1.5370e-01)	Acc@1   0.70 (  0.70)	Acc@5   0.00 (  0.00)
 * Acc@1 0.704 Acc@5 0.000
40
TRAINING
Epoch: [40][0/1]	Time  0.945 ( 0.945)	Data  0.236 ( 0.236)	Loss 8.0378e-02 (8.0378e-02)	Acc@1   0.88 (  0.88)	Acc@5   0.00 (  0.00)
[0.8795319162928437]
Test: [0/1]	Time  0.231 ( 0.231)	Loss 9.3389e-01 (9.3389e-01)	Acc@1   0.69 (  0.69)	Acc@5   0.00 (  0.00)
 * Acc@1 0.691 Acc@5 0.000
Test: [0/1]	Time  0.283 ( 0.283)	Loss 1.5265e-01 (1.5265e-01)	Acc@1   0.71 (  0.71)	Acc@5   0.00 (  0.00)
 * Acc@1 0.709 Acc@5 0.000
41
TRAINING
Epoch: [41][0/1]	Time  0.975 ( 0.975)	Data  0.257 ( 0.257)	Loss 7.9746e-02 (7.9746e-02)	Acc@1   0.88 (  0.88)	Acc@5   0.00 (  0.00)
[0.8777638990100847]
Test: [0/1]	Time  0.252 ( 0.252)	Loss 9.3230e-01 (9.3230e-01)	Acc@1   0.69 (  0.69)	Acc@5   0.00 (  0.00)
 * Acc@1 0.692 Acc@5 0.000
Test: [0/1]	Time  0.303 ( 0.303)	Loss 1.5280e-01 (1.5280e-01)	Acc@1   0.71 (  0.71)	Acc@5   0.00 (  0.00)
 * Acc@1 0.711 Acc@5 0.000
42
TRAINING
Epoch: [42][0/1]	Time  0.953 ( 0.953)	Data  0.240 ( 0.240)	Loss 8.0126e-02 (8.0126e-02)	Acc@1   0.88 (  0.88)	Acc@5   0.00 (  0.00)
[0.8761826152670988]
Test: [0/1]	Time  0.230 ( 0.230)	Loss 9.3109e-01 (9.3109e-01)	Acc@1   0.69 (  0.69)	Acc@5   0.00 (  0.00)
 * Acc@1 0.691 Acc@5 0.000
Test: [0/1]	Time  0.283 ( 0.283)	Loss 1.5393e-01 (1.5393e-01)	Acc@1   0.71 (  0.71)	Acc@5   0.00 (  0.00)
 * Acc@1 0.712 Acc@5 0.000
43
TRAINING
Epoch: [43][0/1]	Time  0.941 ( 0.941)	Data  0.229 ( 0.229)	Loss 8.1399e-02 (8.1399e-02)	Acc@1   0.88 (  0.88)	Acc@5   0.00 (  0.00)
[0.8751288059909095]
Test: [0/1]	Time  0.240 ( 0.240)	Loss 9.3023e-01 (9.3023e-01)	Acc@1   0.69 (  0.69)	Acc@5   0.00 (  0.00)
 * Acc@1 0.689 Acc@5 0.000
Test: [0/1]	Time  0.287 ( 0.287)	Loss 1.5534e-01 (1.5534e-01)	Acc@1   0.72 (  0.72)	Acc@5   0.00 (  0.00)
 * Acc@1 0.717 Acc@5 0.000
44
TRAINING
Epoch: [44][0/1]	Time  0.925 ( 0.925)	Data  0.227 ( 0.227)	Loss 8.2903e-02 (8.2903e-02)	Acc@1   0.88 (  0.88)	Acc@5   0.00 (  0.00)
[0.8759686625395227]
Test: [0/1]	Time  0.224 ( 0.224)	Loss 9.2970e-01 (9.2970e-01)	Acc@1   0.69 (  0.69)	Acc@5   0.00 (  0.00)
 * Acc@1 0.689 Acc@5 0.000
Test: [0/1]	Time  0.276 ( 0.276)	Loss 1.5628e-01 (1.5628e-01)	Acc@1   0.72 (  0.72)	Acc@5   0.00 (  0.00)
 * Acc@1 0.721 Acc@5 0.000
45
TRAINING
Epoch: [45][0/1]	Time  0.941 ( 0.941)	Data  0.232 ( 0.232)	Loss 8.3899e-02 (8.3899e-02)	Acc@1   0.88 (  0.88)	Acc@5   0.00 (  0.00)
[0.8774167572279608]
Test: [0/1]	Time  0.234 ( 0.234)	Loss 9.2942e-01 (9.2942e-01)	Acc@1   0.69 (  0.69)	Acc@5   0.00 (  0.00)
 * Acc@1 0.693 Acc@5 0.000
Test: [0/1]	Time  0.282 ( 0.282)	Loss 1.5636e-01 (1.5636e-01)	Acc@1   0.72 (  0.72)	Acc@5   0.00 (  0.00)
 * Acc@1 0.723 Acc@5 0.000
46
TRAINING
Epoch: [46][0/1]	Time  0.949 ( 0.949)	Data  0.242 ( 0.242)	Loss 8.4003e-02 (8.4003e-02)	Acc@1   0.88 (  0.88)	Acc@5   0.00 (  0.00)
[0.879617950164091]
Test: [0/1]	Time  0.239 ( 0.239)	Loss 9.2943e-01 (9.2943e-01)	Acc@1   0.69 (  0.69)	Acc@5   0.00 (  0.00)
 * Acc@1 0.694 Acc@5 0.000
Test: [0/1]	Time  0.286 ( 0.286)	Loss 1.5571e-01 (1.5571e-01)	Acc@1   0.72 (  0.72)	Acc@5   0.00 (  0.00)
 * Acc@1 0.724 Acc@5 0.000
47
TRAINING
Epoch: [47][0/1]	Time  0.952 ( 0.952)	Data  0.249 ( 0.249)	Loss 8.3342e-02 (8.3342e-02)	Acc@1   0.88 (  0.88)	Acc@5   0.00 (  0.00)
[0.8824119349418568]
Test: [0/1]	Time  0.231 ( 0.231)	Loss 9.2970e-01 (9.2970e-01)	Acc@1   0.69 (  0.69)	Acc@5   0.00 (  0.00)
 * Acc@1 0.693 Acc@5 0.000
Test: [0/1]	Time  0.286 ( 0.286)	Loss 1.5476e-01 (1.5476e-01)	Acc@1   0.72 (  0.72)	Acc@5   0.00 (  0.00)
 * Acc@1 0.722 Acc@5 0.000
48
TRAINING
Epoch: [48][0/1]	Time  0.922 ( 0.922)	Data  0.245 ( 0.245)	Loss 8.2390e-02 (8.2390e-02)	Acc@1   0.89 (  0.89)	Acc@5   0.00 (  0.00)
[0.8856194988226856]
Test: [0/1]	Time  0.226 ( 0.226)	Loss 9.3021e-01 (9.3021e-01)	Acc@1   0.69 (  0.69)	Acc@5   0.00 (  0.00)
 * Acc@1 0.692 Acc@5 0.000
Test: [0/1]	Time  0.282 ( 0.282)	Loss 1.5400e-01 (1.5400e-01)	Acc@1   0.72 (  0.72)	Acc@5   0.00 (  0.00)
 * Acc@1 0.723 Acc@5 0.000
49
TRAINING
Epoch: [49][0/1]	Time  0.925 ( 0.925)	Data  0.249 ( 0.249)	Loss 8.1645e-02 (8.1645e-02)	Acc@1   0.89 (  0.89)	Acc@5   0.00 (  0.00)
[0.8891359987843381]
Test: [0/1]	Time  0.225 ( 0.225)	Loss 9.3090e-01 (9.3090e-01)	Acc@1   0.69 (  0.69)	Acc@5   0.00 (  0.00)
 * Acc@1 0.689 Acc@5 0.000
Test: [0/1]	Time  0.280 ( 0.280)	Loss 1.5369e-01 (1.5369e-01)	Acc@1   0.73 (  0.73)	Acc@5   0.00 (  0.00)
 * Acc@1 0.725 Acc@5 0.000
50
TRAINING
Epoch: [50][0/1]	Time  0.965 ( 0.965)	Data  0.267 ( 0.267)	Loss 8.1348e-02 (8.1348e-02)	Acc@1   0.89 (  0.89)	Acc@5   0.00 (  0.00)
[0.8928533153173563]
Test: [0/1]	Time  0.237 ( 0.237)	Loss 9.3165e-01 (9.3165e-01)	Acc@1   0.69 (  0.69)	Acc@5   0.00 (  0.00)
 * Acc@1 0.687 Acc@5 0.000
Test: [0/1]	Time  0.289 ( 0.289)	Loss 1.5379e-01 (1.5379e-01)	Acc@1   0.73 (  0.73)	Acc@5   0.00 (  0.00)
 * Acc@1 0.726 Acc@5 0.000
51
TRAINING
Epoch: [51][0/1]	Time  0.949 ( 0.949)	Data  0.239 ( 0.239)	Loss 8.1416e-02 (8.1416e-02)	Acc@1   0.90 (  0.90)	Acc@5   0.00 (  0.00)
[0.8966665745665532]
Test: [0/1]	Time  0.234 ( 0.234)	Loss 9.3237e-01 (9.3237e-01)	Acc@1   0.68 (  0.68)	Acc@5   0.00 (  0.00)
 * Acc@1 0.684 Acc@5 0.000
Test: [0/1]	Time  0.281 ( 0.281)	Loss 1.5407e-01 (1.5407e-01)	Acc@1   0.73 (  0.73)	Acc@5   0.00 (  0.00)
 * Acc@1 0.726 Acc@5 0.000
52
TRAINING
Epoch: [52][0/1]	Time  0.912 ( 0.912)	Data  0.236 ( 0.236)	Loss 8.1569e-02 (8.1569e-02)	Acc@1   0.90 (  0.90)	Acc@5   0.00 (  0.00)
[0.9009365650898886]
Test: [0/1]	Time  0.238 ( 0.238)	Loss 9.3296e-01 (9.3296e-01)	Acc@1   0.68 (  0.68)	Acc@5   0.00 (  0.00)
 * Acc@1 0.683 Acc@5 0.000
Test: [0/1]	Time  0.285 ( 0.285)	Loss 1.5431e-01 (1.5431e-01)	Acc@1   0.72 (  0.72)	Acc@5   0.00 (  0.00)
 * Acc@1 0.725 Acc@5 0.000
53
TRAINING
Epoch: [53][0/1]	Time  0.920 ( 0.920)	Data  0.238 ( 0.238)	Loss 8.1544e-02 (8.1544e-02)	Acc@1   0.91 (  0.91)	Acc@5   0.00 (  0.00)
[0.905438276170127]
Test: [0/1]	Time  0.227 ( 0.227)	Loss 9.3340e-01 (9.3340e-01)	Acc@1   0.68 (  0.68)	Acc@5   0.00 (  0.00)
 * Acc@1 0.683 Acc@5 0.000
Test: [0/1]	Time  0.281 ( 0.281)	Loss 1.5442e-01 (1.5442e-01)	Acc@1   0.72 (  0.72)	Acc@5   0.00 (  0.00)
 * Acc@1 0.723 Acc@5 0.000
54
TRAINING
Epoch: [54][0/1]	Time  0.917 ( 0.917)	Data  0.240 ( 0.240)	Loss 8.1252e-02 (8.1252e-02)	Acc@1   0.91 (  0.91)	Acc@5   0.00 (  0.00)
[0.9096207998779867]
Test: [0/1]	Time  0.232 ( 0.232)	Loss 9.3371e-01 (9.3371e-01)	Acc@1   0.68 (  0.68)	Acc@5   0.00 (  0.00)
 * Acc@1 0.683 Acc@5 0.000
Test: [0/1]	Time  0.284 ( 0.284)	Loss 1.5447e-01 (1.5447e-01)	Acc@1   0.72 (  0.72)	Acc@5   0.00 (  0.00)
 * Acc@1 0.722 Acc@5 0.000
55
TRAINING
Epoch: [55][0/1]	Time  0.913 ( 0.913)	Data  0.241 ( 0.241)	Loss 8.0803e-02 (8.0803e-02)	Acc@1   0.91 (  0.91)	Acc@5   0.00 (  0.00)
[0.9133922564169125]
Test: [0/1]	Time  0.232 ( 0.232)	Loss 9.3398e-01 (9.3398e-01)	Acc@1   0.68 (  0.68)	Acc@5   0.00 (  0.00)
 * Acc@1 0.684 Acc@5 0.000
Test: [0/1]	Time  0.282 ( 0.282)	Loss 1.5460e-01 (1.5460e-01)	Acc@1   0.72 (  0.72)	Acc@5   0.00 (  0.00)
 * Acc@1 0.723 Acc@5 0.000
56
TRAINING
Epoch: [56][0/1]	Time  0.916 ( 0.916)	Data  0.241 ( 0.241)	Loss 8.0398e-02 (8.0398e-02)	Acc@1   0.92 (  0.92)	Acc@5   0.00 (  0.00)
[0.9167082954684511]
Test: [0/1]	Time  0.235 ( 0.235)	Loss 9.3426e-01 (9.3426e-01)	Acc@1   0.69 (  0.69)	Acc@5   0.00 (  0.00)
 * Acc@1 0.685 Acc@5 0.000
Test: [0/1]	Time  0.280 ( 0.280)	Loss 1.5490e-01 (1.5490e-01)	Acc@1   0.72 (  0.72)	Acc@5   0.00 (  0.00)
 * Acc@1 0.724 Acc@5 0.000
57
TRAINING
Epoch: [57][0/1]	Time  0.945 ( 0.945)	Data  0.274 ( 0.274)	Loss 8.0188e-02 (8.0188e-02)	Acc@1   0.92 (  0.92)	Acc@5   0.00 (  0.00)
[0.9195648605702689]
Test: [0/1]	Time  0.230 ( 0.230)	Loss 9.3463e-01 (9.3463e-01)	Acc@1   0.69 (  0.69)	Acc@5   0.00 (  0.00)
 * Acc@1 0.686 Acc@5 0.000
Test: [0/1]	Time  0.281 ( 0.281)	Loss 1.5532e-01 (1.5532e-01)	Acc@1   0.72 (  0.72)	Acc@5   0.00 (  0.00)
 * Acc@1 0.725 Acc@5 0.000
58
TRAINING
Epoch: [58][0/1]	Time  0.911 ( 0.911)	Data  0.239 ( 0.239)	Loss 8.0187e-02 (8.0187e-02)	Acc@1   0.92 (  0.92)	Acc@5   0.00 (  0.00)
[0.921816193626197]
Test: [0/1]	Time  0.223 ( 0.223)	Loss 9.3512e-01 (9.3512e-01)	Acc@1   0.69 (  0.69)	Acc@5   0.00 (  0.00)
 * Acc@1 0.686 Acc@5 0.000
Test: [0/1]	Time  0.285 ( 0.285)	Loss 1.5574e-01 (1.5574e-01)	Acc@1   0.73 (  0.73)	Acc@5   0.00 (  0.00)
 * Acc@1 0.725 Acc@5 0.000
59
TRAINING
Epoch: [59][0/1]	Time  0.915 ( 0.915)	Data  0.242 ( 0.242)	Loss 8.0284e-02 (8.0284e-02)	Acc@1   0.92 (  0.92)	Acc@5   0.00 (  0.00)
[0.9236425201747784]
Test: [0/1]	Time  0.227 ( 0.227)	Loss 9.3575e-01 (9.3575e-01)	Acc@1   0.69 (  0.69)	Acc@5   0.00 (  0.00)
 * Acc@1 0.685 Acc@5 0.000
Test: [0/1]	Time  0.282 ( 0.282)	Loss 1.5598e-01 (1.5598e-01)	Acc@1   0.72 (  0.72)	Acc@5   0.00 (  0.00)
 * Acc@1 0.725 Acc@5 0.000
60
TRAINING
Epoch: [60][0/1]	Time  0.940 ( 0.940)	Data  0.231 ( 0.231)	Loss 8.0321e-02 (8.0321e-02)	Acc@1   0.92 (  0.92)	Acc@5   0.00 (  0.00)
[0.9246693796266418]
Test: [0/1]	Time  0.230 ( 0.230)	Loss 9.3651e-01 (9.3651e-01)	Acc@1   0.68 (  0.68)	Acc@5   0.00 (  0.00)
 * Acc@1 0.683 Acc@5 0.000
Test: [0/1]	Time  0.276 ( 0.276)	Loss 1.5596e-01 (1.5596e-01)	Acc@1   0.72 (  0.72)	Acc@5   0.00 (  0.00)
 * Acc@1 0.725 Acc@5 0.000
61
TRAINING
Epoch: [61][0/1]	Time  0.908 ( 0.908)	Data  0.234 ( 0.234)	Loss 8.0192e-02 (8.0192e-02)	Acc@1   0.93 (  0.93)	Acc@5   0.00 (  0.00)
[0.9254709227928682]
Test: [0/1]	Time  0.227 ( 0.227)	Loss 9.3740e-01 (9.3740e-01)	Acc@1   0.68 (  0.68)	Acc@5   0.00 (  0.00)
 * Acc@1 0.681 Acc@5 0.000
Test: [0/1]	Time  0.276 ( 0.276)	Loss 1.5567e-01 (1.5567e-01)	Acc@1   0.73 (  0.73)	Acc@5   0.00 (  0.00)
 * Acc@1 0.725 Acc@5 0.000
62
TRAINING
Epoch: [62][0/1]	Time  0.912 ( 0.912)	Data  0.237 ( 0.237)	Loss 7.9895e-02 (7.9895e-02)	Acc@1   0.93 (  0.93)	Acc@5   0.00 (  0.00)
[0.9265891400942402]
Test: [0/1]	Time  0.225 ( 0.225)	Loss 9.3839e-01 (9.3839e-01)	Acc@1   0.68 (  0.68)	Acc@5   0.00 (  0.00)
 * Acc@1 0.678 Acc@5 0.000
Test: [0/1]	Time  0.276 ( 0.276)	Loss 1.5522e-01 (1.5522e-01)	Acc@1   0.73 (  0.73)	Acc@5   0.00 (  0.00)
 * Acc@1 0.725 Acc@5 0.000
63
TRAINING
Epoch: [63][0/1]	Time  0.905 ( 0.905)	Data  0.233 ( 0.233)	Loss 7.9513e-02 (7.9513e-02)	Acc@1   0.93 (  0.93)	Acc@5   0.00 (  0.00)
[0.9271760820054628]
Test: [0/1]	Time  0.226 ( 0.226)	Loss 9.3943e-01 (9.3943e-01)	Acc@1   0.67 (  0.67)	Acc@5   0.00 (  0.00)
 * Acc@1 0.675 Acc@5 0.000
Test: [0/1]	Time  0.278 ( 0.278)	Loss 1.5474e-01 (1.5474e-01)	Acc@1   0.73 (  0.73)	Acc@5   0.00 (  0.00)
 * Acc@1 0.726 Acc@5 0.000
64
TRAINING
Epoch: [64][0/1]	Time  0.950 ( 0.950)	Data  0.250 ( 0.250)	Loss 7.9155e-02 (7.9155e-02)	Acc@1   0.93 (  0.93)	Acc@5   0.00 (  0.00)
[0.9279563217335659]
Test: [0/1]	Time  0.238 ( 0.238)	Loss 9.4046e-01 (9.4046e-01)	Acc@1   0.67 (  0.67)	Acc@5   0.00 (  0.00)
 * Acc@1 0.671 Acc@5 0.000
Test: [0/1]	Time  0.290 ( 0.290)	Loss 1.5430e-01 (1.5430e-01)	Acc@1   0.73 (  0.73)	Acc@5   0.00 (  0.00)
 * Acc@1 0.726 Acc@5 0.000
65
TRAINING
Epoch: [65][0/1]	Time  0.926 ( 0.926)	Data  0.234 ( 0.234)	Loss 7.8897e-02 (7.8897e-02)	Acc@1   0.93 (  0.93)	Acc@5   0.00 (  0.00)
[0.9288450651223545]
Test: [0/1]	Time  0.228 ( 0.228)	Loss 9.4143e-01 (9.4143e-01)	Acc@1   0.67 (  0.67)	Acc@5   0.00 (  0.00)
 * Acc@1 0.668 Acc@5 0.000
Test: [0/1]	Time  0.279 ( 0.279)	Loss 1.5397e-01 (1.5397e-01)	Acc@1   0.73 (  0.73)	Acc@5   0.00 (  0.00)
 * Acc@1 0.726 Acc@5 0.000
66
TRAINING
Epoch: [66][0/1]	Time  0.952 ( 0.952)	Data  0.260 ( 0.260)	Loss 7.8743e-02 (7.8743e-02)	Acc@1   0.93 (  0.93)	Acc@5   0.00 (  0.00)
[0.9295711701865841]
Test: [0/1]	Time  0.239 ( 0.239)	Loss 9.4228e-01 (9.4228e-01)	Acc@1   0.67 (  0.67)	Acc@5   0.00 (  0.00)
 * Acc@1 0.666 Acc@5 0.000
Test: [0/1]	Time  0.294 ( 0.294)	Loss 1.5372e-01 (1.5372e-01)	Acc@1   0.73 (  0.73)	Acc@5   0.00 (  0.00)
 * Acc@1 0.727 Acc@5 0.000
67
TRAINING
Epoch: [67][0/1]	Time  0.928 ( 0.928)	Data  0.240 ( 0.240)	Loss 7.8650e-02 (7.8650e-02)	Acc@1   0.93 (  0.93)	Acc@5   0.00 (  0.00)
[0.9301592368651255]
Test: [0/1]	Time  0.229 ( 0.229)	Loss 9.4298e-01 (9.4298e-01)	Acc@1   0.66 (  0.66)	Acc@5   0.00 (  0.00)
 * Acc@1 0.664 Acc@5 0.000
Test: [0/1]	Time  0.286 ( 0.286)	Loss 1.5351e-01 (1.5351e-01)	Acc@1   0.73 (  0.73)	Acc@5   0.00 (  0.00)
 * Acc@1 0.727 Acc@5 0.000
68
TRAINING
Epoch: [68][0/1]	Time  0.964 ( 0.964)	Data  0.251 ( 0.251)	Loss 7.8563e-02 (7.8563e-02)	Acc@1   0.93 (  0.93)	Acc@5   0.00 (  0.00)
[0.9306423176615626]
Test: [0/1]	Time  0.241 ( 0.241)	Loss 9.4352e-01 (9.4352e-01)	Acc@1   0.66 (  0.66)	Acc@5   0.00 (  0.00)
 * Acc@1 0.663 Acc@5 0.000
Test: [0/1]	Time  0.293 ( 0.293)	Loss 1.5333e-01 (1.5333e-01)	Acc@1   0.73 (  0.73)	Acc@5   0.00 (  0.00)
 * Acc@1 0.728 Acc@5 0.000
69
TRAINING
Epoch: [69][0/1]	Time  0.942 ( 0.942)	Data  0.247 ( 0.247)	Loss 7.8450e-02 (7.8450e-02)	Acc@1   0.93 (  0.93)	Acc@5   0.00 (  0.00)
[0.9310449844321871]
Test: [0/1]	Time  0.236 ( 0.236)	Loss 9.4391e-01 (9.4391e-01)	Acc@1   0.66 (  0.66)	Acc@5   0.00 (  0.00)
 * Acc@1 0.663 Acc@5 0.000
Test: [0/1]	Time  0.288 ( 0.288)	Loss 1.5317e-01 (1.5317e-01)	Acc@1   0.73 (  0.73)	Acc@5   0.00 (  0.00)
 * Acc@1 0.729 Acc@5 0.000
70
TRAINING
Epoch: [70][0/1]	Time  0.972 ( 0.972)	Data  0.267 ( 0.267)	Loss 7.8320e-02 (7.8320e-02)	Acc@1   0.93 (  0.93)	Acc@5   0.00 (  0.00)
[0.9312697881777898]
Test: [0/1]	Time  0.244 ( 0.244)	Loss 9.4417e-01 (9.4417e-01)	Acc@1   0.66 (  0.66)	Acc@5   0.00 (  0.00)
 * Acc@1 0.663 Acc@5 0.000
Test: [0/1]	Time  0.293 ( 0.293)	Loss 1.5305e-01 (1.5305e-01)	Acc@1   0.73 (  0.73)	Acc@5   0.00 (  0.00)
 * Acc@1 0.729 Acc@5 0.000
71
TRAINING
Epoch: [71][0/1]	Time  0.934 ( 0.934)	Data  0.240 ( 0.240)	Loss 7.8207e-02 (7.8207e-02)	Acc@1   0.93 (  0.93)	Acc@5   0.00 (  0.00)
[0.9311576417164409]
Test: [0/1]	Time  0.232 ( 0.232)	Loss 9.4433e-01 (9.4433e-01)	Acc@1   0.66 (  0.66)	Acc@5   0.00 (  0.00)
 * Acc@1 0.663 Acc@5 0.000
Test: [0/1]	Time  0.283 ( 0.283)	Loss 1.5298e-01 (1.5298e-01)	Acc@1   0.73 (  0.73)	Acc@5   0.00 (  0.00)
 * Acc@1 0.730 Acc@5 0.000
72
TRAINING
Epoch: [72][0/1]	Time  0.942 ( 0.942)	Data  0.251 ( 0.251)	Loss 7.8141e-02 (7.8141e-02)	Acc@1   0.93 (  0.93)	Acc@5   0.00 (  0.00)
[0.931027457863818]
Test: [0/1]	Time  0.232 ( 0.232)	Loss 9.4445e-01 (9.4445e-01)	Acc@1   0.66 (  0.66)	Acc@5   0.00 (  0.00)
 * Acc@1 0.663 Acc@5 0.000
Test: [0/1]	Time  0.286 ( 0.286)	Loss 1.5296e-01 (1.5296e-01)	Acc@1   0.73 (  0.73)	Acc@5   0.00 (  0.00)
 * Acc@1 0.732 Acc@5 0.000
73
TRAINING
Epoch: [73][0/1]	Time  0.940 ( 0.940)	Data  0.240 ( 0.240)	Loss 7.8129e-02 (7.8129e-02)	Acc@1   0.93 (  0.93)	Acc@5   0.00 (  0.00)
[0.9309012527722199]
Test: [0/1]	Time  0.229 ( 0.229)	Loss 9.4456e-01 (9.4456e-01)	Acc@1   0.66 (  0.66)	Acc@5   0.00 (  0.00)
 * Acc@1 0.663 Acc@5 0.000
Test: [0/1]	Time  0.279 ( 0.279)	Loss 1.5295e-01 (1.5295e-01)	Acc@1   0.73 (  0.73)	Acc@5   0.00 (  0.00)
 * Acc@1 0.733 Acc@5 0.000
74
TRAINING
Epoch: [74][0/1]	Time  0.923 ( 0.923)	Data  0.236 ( 0.236)	Loss 7.8148e-02 (7.8148e-02)	Acc@1   0.93 (  0.93)	Acc@5   0.00 (  0.00)
[0.9308018620864552]
Test: [0/1]	Time  0.232 ( 0.232)	Loss 9.4468e-01 (9.4468e-01)	Acc@1   0.66 (  0.66)	Acc@5   0.00 (  0.00)
 * Acc@1 0.664 Acc@5 0.000
Test: [0/1]	Time  0.282 ( 0.282)	Loss 1.5291e-01 (1.5291e-01)	Acc@1   0.73 (  0.73)	Acc@5   0.00 (  0.00)
 * Acc@1 0.734 Acc@5 0.000
75
TRAINING
Epoch: [75][0/1]	Time  0.955 ( 0.955)	Data  0.245 ( 0.245)	Loss 7.8165e-02 (7.8165e-02)	Acc@1   0.93 (  0.93)	Acc@5   0.00 (  0.00)
[0.9307487283659719]
Test: [0/1]	Time  0.233 ( 0.233)	Loss 9.4482e-01 (9.4482e-01)	Acc@1   0.66 (  0.66)	Acc@5   0.00 (  0.00)
 * Acc@1 0.664 Acc@5 0.000
Test: [0/1]	Time  0.283 ( 0.283)	Loss 1.5283e-01 (1.5283e-01)	Acc@1   0.73 (  0.73)	Acc@5   0.00 (  0.00)
 * Acc@1 0.734 Acc@5 0.000
76
TRAINING
Epoch: [76][0/1]	Time  0.943 ( 0.943)	Data  0.233 ( 0.233)	Loss 7.8150e-02 (7.8150e-02)	Acc@1   0.93 (  0.93)	Acc@5   0.00 (  0.00)
[0.9307534411703906]
Test: [0/1]	Time  0.227 ( 0.227)	Loss 9.4498e-01 (9.4498e-01)	Acc@1   0.66 (  0.66)	Acc@5   0.00 (  0.00)
 * Acc@1 0.664 Acc@5 0.000
Test: [0/1]	Time  0.282 ( 0.282)	Loss 1.5268e-01 (1.5268e-01)	Acc@1   0.74 (  0.74)	Acc@5   0.00 (  0.00)
 * Acc@1 0.735 Acc@5 0.000
77
TRAINING
Epoch: [77][0/1]	Time  0.924 ( 0.924)	Data  0.234 ( 0.234)	Loss 7.8097e-02 (7.8097e-02)	Acc@1   0.93 (  0.93)	Acc@5   0.00 (  0.00)
[0.9308173432597323]
Test: [0/1]	Time  0.231 ( 0.231)	Loss 9.4517e-01 (9.4517e-01)	Acc@1   0.66 (  0.66)	Acc@5   0.00 (  0.00)
 * Acc@1 0.665 Acc@5 0.000
Test: [0/1]	Time  0.278 ( 0.278)	Loss 1.5249e-01 (1.5249e-01)	Acc@1   0.74 (  0.74)	Acc@5   0.00 (  0.00)
 * Acc@1 0.736 Acc@5 0.000
78
TRAINING
Epoch: [78][0/1]	Time  0.931 ( 0.931)	Data  0.237 ( 0.237)	Loss 7.8018e-02 (7.8018e-02)	Acc@1   0.93 (  0.93)	Acc@5   0.00 (  0.00)
[0.9308414365265021]
Test: [0/1]	Time  0.233 ( 0.233)	Loss 9.4536e-01 (9.4536e-01)	Acc@1   0.67 (  0.67)	Acc@5   0.00 (  0.00)
 * Acc@1 0.666 Acc@5 0.000
Test: [0/1]	Time  0.279 ( 0.279)	Loss 1.5230e-01 (1.5230e-01)	Acc@1   0.74 (  0.74)	Acc@5   0.00 (  0.00)
 * Acc@1 0.737 Acc@5 0.000
79
TRAINING
Epoch: [79][0/1]	Time  0.946 ( 0.946)	Data  0.246 ( 0.246)	Loss 7.7936e-02 (7.7936e-02)	Acc@1   0.93 (  0.93)	Acc@5   0.00 (  0.00)
[0.9308599572057727]
Test: [0/1]	Time  0.231 ( 0.231)	Loss 9.4554e-01 (9.4554e-01)	Acc@1   0.67 (  0.67)	Acc@5   0.00 (  0.00)
 * Acc@1 0.666 Acc@5 0.000
Test: [0/1]	Time  0.296 ( 0.296)	Loss 1.5212e-01 (1.5212e-01)	Acc@1   0.74 (  0.74)	Acc@5   0.00 (  0.00)
 * Acc@1 0.738 Acc@5 0.000
80
TRAINING
Epoch: [80][0/1]	Time  0.930 ( 0.930)	Data  0.232 ( 0.232)	Loss 7.7871e-02 (7.7871e-02)	Acc@1   0.93 (  0.93)	Acc@5   0.00 (  0.00)
[0.9309276726252393]
Test: [0/1]	Time  0.231 ( 0.231)	Loss 9.4568e-01 (9.4568e-01)	Acc@1   0.67 (  0.67)	Acc@5   0.00 (  0.00)
 * Acc@1 0.667 Acc@5 0.000
Test: [0/1]	Time  0.275 ( 0.275)	Loss 1.5198e-01 (1.5198e-01)	Acc@1   0.74 (  0.74)	Acc@5   0.00 (  0.00)
 * Acc@1 0.739 Acc@5 0.000
81
TRAINING
Epoch: [81][0/1]	Time  0.964 ( 0.964)	Data  0.235 ( 0.235)	Loss 7.7832e-02 (7.7832e-02)	Acc@1   0.93 (  0.93)	Acc@5   0.00 (  0.00)
[0.9310126564019985]
Test: [0/1]	Time  0.249 ( 0.249)	Loss 9.4576e-01 (9.4576e-01)	Acc@1   0.67 (  0.67)	Acc@5   0.00 (  0.00)
 * Acc@1 0.667 Acc@5 0.000
Test: [0/1]	Time  0.295 ( 0.295)	Loss 1.5187e-01 (1.5187e-01)	Acc@1   0.74 (  0.74)	Acc@5   0.00 (  0.00)
 * Acc@1 0.739 Acc@5 0.000
82
TRAINING
Epoch: [82][0/1]	Time  0.972 ( 0.972)	Data  0.259 ( 0.259)	Loss 7.7812e-02 (7.7812e-02)	Acc@1   0.93 (  0.93)	Acc@5   0.00 (  0.00)
[0.9310506415553667]
Test: [0/1]	Time  0.246 ( 0.246)	Loss 9.4578e-01 (9.4578e-01)	Acc@1   0.67 (  0.67)	Acc@5   0.00 (  0.00)
 * Acc@1 0.668 Acc@5 0.000
Test: [0/1]	Time  0.297 ( 0.297)	Loss 1.5180e-01 (1.5180e-01)	Acc@1   0.74 (  0.74)	Acc@5   0.00 (  0.00)
 * Acc@1 0.740 Acc@5 0.000
83
TRAINING
Epoch: [83][0/1]	Time  0.968 ( 0.968)	Data  0.272 ( 0.272)	Loss 7.7802e-02 (7.7802e-02)	Acc@1   0.93 (  0.93)	Acc@5   0.00 (  0.00)
[0.9311357341084041]
Test: [0/1]	Time  0.241 ( 0.241)	Loss 9.4572e-01 (9.4572e-01)	Acc@1   0.67 (  0.67)	Acc@5   0.00 (  0.00)
 * Acc@1 0.669 Acc@5 0.000
Test: [0/1]	Time  0.290 ( 0.290)	Loss 1.5175e-01 (1.5175e-01)	Acc@1   0.74 (  0.74)	Acc@5   0.00 (  0.00)
 * Acc@1 0.741 Acc@5 0.000
84
TRAINING
Epoch: [84][0/1]	Time  0.949 ( 0.949)	Data  0.252 ( 0.252)	Loss 7.7793e-02 (7.7793e-02)	Acc@1   0.93 (  0.93)	Acc@5   0.00 (  0.00)
[0.931264546730824]
Test: [0/1]	Time  0.234 ( 0.234)	Loss 9.4559e-01 (9.4559e-01)	Acc@1   0.67 (  0.67)	Acc@5   0.00 (  0.00)
 * Acc@1 0.669 Acc@5 0.000
Test: [0/1]	Time  0.289 ( 0.289)	Loss 1.5173e-01 (1.5173e-01)	Acc@1   0.74 (  0.74)	Acc@5   0.00 (  0.00)
 * Acc@1 0.742 Acc@5 0.000
85
TRAINING
Epoch: [85][0/1]	Time  0.957 ( 0.957)	Data  0.260 ( 0.260)	Loss 7.7784e-02 (7.7784e-02)	Acc@1   0.93 (  0.93)	Acc@5   0.00 (  0.00)
[0.9314309103611846]
Test: [0/1]	Time  0.240 ( 0.240)	Loss 9.4542e-01 (9.4542e-01)	Acc@1   0.67 (  0.67)	Acc@5   0.00 (  0.00)
 * Acc@1 0.670 Acc@5 0.000
Test: [0/1]	Time  0.283 ( 0.283)	Loss 1.5172e-01 (1.5172e-01)	Acc@1   0.74 (  0.74)	Acc@5   0.00 (  0.00)
 * Acc@1 0.744 Acc@5 0.000
86
TRAINING
Epoch: [86][0/1]	Time  0.938 ( 0.938)	Data  0.245 ( 0.245)	Loss 7.7778e-02 (7.7778e-02)	Acc@1   0.93 (  0.93)	Acc@5   0.00 (  0.00)
[0.9316263963198907]
Test: [0/1]	Time  0.257 ( 0.257)	Loss 9.4521e-01 (9.4521e-01)	Acc@1   0.67 (  0.67)	Acc@5   0.00 (  0.00)
 * Acc@1 0.670 Acc@5 0.000
Test: [0/1]	Time  0.291 ( 0.291)	Loss 1.5174e-01 (1.5174e-01)	Acc@1   0.74 (  0.74)	Acc@5   0.00 (  0.00)
 * Acc@1 0.745 Acc@5 0.000
87
TRAINING
Epoch: [87][0/1]	Time  0.945 ( 0.945)	Data  0.251 ( 0.251)	Loss 7.7781e-02 (7.7781e-02)	Acc@1   0.93 (  0.93)	Acc@5   0.00 (  0.00)
[0.9318412485477314]
Test: [0/1]	Time  0.233 ( 0.233)	Loss 9.4499e-01 (9.4499e-01)	Acc@1   0.67 (  0.67)	Acc@5   0.00 (  0.00)
 * Acc@1 0.671 Acc@5 0.000
Test: [0/1]	Time  0.282 ( 0.282)	Loss 1.5176e-01 (1.5176e-01)	Acc@1   0.75 (  0.75)	Acc@5   0.00 (  0.00)
 * Acc@1 0.746 Acc@5 0.000
88
TRAINING
Epoch: [88][0/1]	Time  0.954 ( 0.954)	Data  0.252 ( 0.252)	Loss 7.7792e-02 (7.7792e-02)	Acc@1   0.93 (  0.93)	Acc@5   0.00 (  0.00)
[0.9320654874724422]
Test: [0/1]	Time  0.238 ( 0.238)	Loss 9.4479e-01 (9.4479e-01)	Acc@1   0.67 (  0.67)	Acc@5   0.00 (  0.00)
 * Acc@1 0.671 Acc@5 0.000
Test: [0/1]	Time  0.288 ( 0.288)	Loss 1.5179e-01 (1.5179e-01)	Acc@1   0.75 (  0.75)	Acc@5   0.00 (  0.00)
 * Acc@1 0.747 Acc@5 0.000
89
TRAINING
Epoch: [89][0/1]	Time  0.945 ( 0.945)	Data  0.259 ( 0.259)	Loss 7.7807e-02 (7.7807e-02)	Acc@1   0.93 (  0.93)	Acc@5   0.00 (  0.00)
[0.9322187136914568]
Test: [0/1]	Time  0.234 ( 0.234)	Loss 9.4461e-01 (9.4461e-01)	Acc@1   0.67 (  0.67)	Acc@5   0.00 (  0.00)
 * Acc@1 0.672 Acc@5 0.000
Test: [0/1]	Time  0.286 ( 0.286)	Loss 1.5181e-01 (1.5181e-01)	Acc@1   0.75 (  0.75)	Acc@5   0.00 (  0.00)
 * Acc@1 0.747 Acc@5 0.000
90
TRAINING
Epoch: [90][0/1]	Time  0.960 ( 0.960)	Data  0.259 ( 0.259)	Loss 7.7819e-02 (7.7819e-02)	Acc@1   0.93 (  0.93)	Acc@5   0.00 (  0.00)
[0.9323694528225652]
Test: [0/1]	Time  0.235 ( 0.235)	Loss 9.4446e-01 (9.4446e-01)	Acc@1   0.67 (  0.67)	Acc@5   0.00 (  0.00)
 * Acc@1 0.672 Acc@5 0.000
Test: [0/1]	Time  0.324 ( 0.324)	Loss 1.5181e-01 (1.5181e-01)	Acc@1   0.75 (  0.75)	Acc@5   0.00 (  0.00)
 * Acc@1 0.747 Acc@5 0.000
91
TRAINING
Epoch: [91][0/1]	Time  0.974 ( 0.974)	Data  0.253 ( 0.253)	Loss 7.7819e-02 (7.7819e-02)	Acc@1   0.93 (  0.93)	Acc@5   0.00 (  0.00)
[0.9325315805121474]
Test: [0/1]	Time  0.257 ( 0.257)	Loss 9.4436e-01 (9.4436e-01)	Acc@1   0.67 (  0.67)	Acc@5   0.00 (  0.00)
 * Acc@1 0.673 Acc@5 0.000
Test: [0/1]	Time  0.299 ( 0.299)	Loss 1.5178e-01 (1.5178e-01)	Acc@1   0.75 (  0.75)	Acc@5   0.00 (  0.00)
 * Acc@1 0.747 Acc@5 0.000
92
TRAINING
Epoch: [92][0/1]	Time  0.964 ( 0.964)	Data  0.262 ( 0.262)	Loss 7.7805e-02 (7.7805e-02)	Acc@1   0.93 (  0.93)	Acc@5   0.00 (  0.00)
[0.9327025734555807]
Test: [0/1]	Time  0.239 ( 0.239)	Loss 9.4428e-01 (9.4428e-01)	Acc@1   0.67 (  0.67)	Acc@5   0.00 (  0.00)
 * Acc@1 0.673 Acc@5 0.000
Test: [0/1]	Time  0.295 ( 0.295)	Loss 1.5175e-01 (1.5175e-01)	Acc@1   0.75 (  0.75)	Acc@5   0.00 (  0.00)
 * Acc@1 0.747 Acc@5 0.000
93
TRAINING
Epoch: [93][0/1]	Time  0.934 ( 0.934)	Data  0.255 ( 0.255)	Loss 7.7779e-02 (7.7779e-02)	Acc@1   0.93 (  0.93)	Acc@5   0.00 (  0.00)
[0.9328113102512483]
Test: [0/1]	Time  0.235 ( 0.235)	Loss 9.4423e-01 (9.4423e-01)	Acc@1   0.67 (  0.67)	Acc@5   0.00 (  0.00)
 * Acc@1 0.673 Acc@5 0.000
Test: [0/1]	Time  0.283 ( 0.283)	Loss 1.5170e-01 (1.5170e-01)	Acc@1   0.75 (  0.75)	Acc@5   0.00 (  0.00)
 * Acc@1 0.747 Acc@5 0.000
94
TRAINING
Epoch: [94][0/1]	Time  0.970 ( 0.970)	Data  0.256 ( 0.256)	Loss 7.7747e-02 (7.7747e-02)	Acc@1   0.93 (  0.93)	Acc@5   0.00 (  0.00)
[0.9329017918240499]
Test: [0/1]	Time  0.237 ( 0.237)	Loss 9.4420e-01 (9.4420e-01)	Acc@1   0.67 (  0.67)	Acc@5   0.00 (  0.00)
 * Acc@1 0.674 Acc@5 0.000
Test: [0/1]	Time  0.288 ( 0.288)	Loss 1.5165e-01 (1.5165e-01)	Acc@1   0.75 (  0.75)	Acc@5   0.00 (  0.00)
 * Acc@1 0.747 Acc@5 0.000
95
TRAINING
Epoch: [95][0/1]	Time  0.920 ( 0.920)	Data  0.247 ( 0.247)	Loss 7.7715e-02 (7.7715e-02)	Acc@1   0.93 (  0.93)	Acc@5   0.00 (  0.00)
[0.9329701865970376]
Test: [0/1]	Time  0.233 ( 0.233)	Loss 9.4417e-01 (9.4417e-01)	Acc@1   0.67 (  0.67)	Acc@5   0.00 (  0.00)
 * Acc@1 0.674 Acc@5 0.000
Test: [0/1]	Time  0.292 ( 0.292)	Loss 1.5160e-01 (1.5160e-01)	Acc@1   0.75 (  0.75)	Acc@5   0.00 (  0.00)
 * Acc@1 0.747 Acc@5 0.000
96
TRAINING
Epoch: [96][0/1]	Time  0.941 ( 0.941)	Data  0.249 ( 0.249)	Loss 7.7686e-02 (7.7686e-02)	Acc@1   0.93 (  0.93)	Acc@5   0.00 (  0.00)
[0.9330267136703438]
Test: [0/1]	Time  0.232 ( 0.232)	Loss 9.4413e-01 (9.4413e-01)	Acc@1   0.67 (  0.67)	Acc@5   0.00 (  0.00)
 * Acc@1 0.674 Acc@5 0.000
Test: [0/1]	Time  0.281 ( 0.281)	Loss 1.5157e-01 (1.5157e-01)	Acc@1   0.75 (  0.75)	Acc@5   0.00 (  0.00)
 * Acc@1 0.747 Acc@5 0.000
97
TRAINING
Epoch: [97][0/1]	Time  0.932 ( 0.932)	Data  0.244 ( 0.244)	Loss 7.7663e-02 (7.7663e-02)	Acc@1   0.93 (  0.93)	Acc@5   0.00 (  0.00)
[0.9330867292048053]
Test: [0/1]	Time  0.228 ( 0.228)	Loss 9.4408e-01 (9.4408e-01)	Acc@1   0.67 (  0.67)	Acc@5   0.00 (  0.00)
 * Acc@1 0.674 Acc@5 0.000
Test: [0/1]	Time  0.286 ( 0.286)	Loss 1.5155e-01 (1.5155e-01)	Acc@1   0.75 (  0.75)	Acc@5   0.00 (  0.00)
 * Acc@1 0.747 Acc@5 0.000
98
TRAINING
Epoch: [98][0/1]	Time  0.919 ( 0.919)	Data  0.244 ( 0.244)	Loss 7.7644e-02 (7.7644e-02)	Acc@1   0.93 (  0.93)	Acc@5   0.00 (  0.00)
[0.9332159978877598]
Test: [0/1]	Time  0.232 ( 0.232)	Loss 9.4401e-01 (9.4401e-01)	Acc@1   0.67 (  0.67)	Acc@5   0.00 (  0.00)
 * Acc@1 0.675 Acc@5 0.000
Test: [0/1]	Time  0.282 ( 0.282)	Loss 1.5153e-01 (1.5153e-01)	Acc@1   0.75 (  0.75)	Acc@5   0.00 (  0.00)
 * Acc@1 0.746 Acc@5 0.000
99
TRAINING
Epoch: [99][0/1]	Time  0.918 ( 0.918)	Data  0.246 ( 0.246)	Loss 7.7628e-02 (7.7628e-02)	Acc@1   0.93 (  0.93)	Acc@5   0.00 (  0.00)
[0.9333390571275135]
Test: [0/1]	Time  0.247 ( 0.247)	Loss 9.4393e-01 (9.4393e-01)	Acc@1   0.67 (  0.67)	Acc@5   0.00 (  0.00)
 * Acc@1 0.675 Acc@5 0.000
Test: [0/1]	Time  0.293 ( 0.293)	Loss 1.5153e-01 (1.5153e-01)	Acc@1   0.75 (  0.75)	Acc@5   0.00 (  0.00)
 * Acc@1 0.746 Acc@5 0.000
=> using pre-trained model 'st_resnet'
s/ohp/session_1
torch.Size([640, 3, 224, 224])
(640, 22)
attach reg
0
TRAINING
/home/helenr6/Adv_mapper/train_split.py:125: UserWarning: You have chosen to seed training. This will turn on the CUDNN deterministic setting, which can slow down your training considerably! You may see unexpected behavior when restarting from checkpoints.
  warnings.warn('You have chosen to seed training. '
/localscratch/helenr6.6279052.0/env/lib/python3.7/site-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  cpuset_checked))
Epoch: [0][0/1]	Time  5.254 ( 5.254)	Data  1.861 ( 1.861)	Loss 1.7799e+00 (1.7799e+00)	Acc@1  -0.01 ( -0.01)	Acc@5   0.00 (  0.00)
[-0.0062679883173415085]
Test: [0/1]	Time  0.420 ( 0.420)	Loss 1.1615e+00 (1.1615e+00)	Acc@1   0.04 (  0.04)	Acc@5   0.00 (  0.00)
 * Acc@1 0.037 Acc@5 0.000
Test: [0/1]	Time  0.538 ( 0.538)	Loss 9.3827e-01 (9.3827e-01)	Acc@1  -0.01 ( -0.01)	Acc@5   0.00 (  0.00)
 * Acc@1 -0.009 Acc@5 0.000
1
TRAINING
Epoch: [1][0/1]	Time  0.943 ( 0.943)	Data  0.228 ( 0.228)	Loss 1.6835e+00 (1.6835e+00)	Acc@1  -0.00 ( -0.00)	Acc@5   0.00 (  0.00)
[-0.003698153146777121]
Test: [0/1]	Time  0.225 ( 0.225)	Loss 1.1692e+00 (1.1692e+00)	Acc@1   0.04 (  0.04)	Acc@5   0.00 (  0.00)
 * Acc@1 0.040 Acc@5 0.000
Test: [0/1]	Time  0.277 ( 0.277)	Loss 8.8642e-01 (8.8642e-01)	Acc@1  -0.01 ( -0.01)	Acc@5   0.00 (  0.00)
 * Acc@1 -0.009 Acc@5 0.000
2
TRAINING
Epoch: [2][0/1]	Time  0.911 ( 0.911)	Data  0.235 ( 0.235)	Loss 1.5402e+00 (1.5402e+00)	Acc@1   0.00 (  0.00)	Acc@5   0.00 (  0.00)
[0.0012906543701950088]
Test: [0/1]	Time  0.228 ( 0.228)	Loss 1.1797e+00 (1.1797e+00)	Acc@1   0.05 (  0.05)	Acc@5   0.00 (  0.00)
 * Acc@1 0.047 Acc@5 0.000
Test: [0/1]	Time  0.283 ( 0.283)	Loss 8.4696e-01 (8.4696e-01)	Acc@1  -0.01 ( -0.01)	Acc@5   0.00 (  0.00)
 * Acc@1 -0.008 Acc@5 0.000
3
TRAINING
Epoch: [3][0/1]	Time  0.909 ( 0.909)	Data  0.235 ( 0.235)	Loss 1.4052e+00 (1.4052e+00)	Acc@1   0.01 (  0.01)	Acc@5   0.00 (  0.00)
[0.012711661917159963]
Test: [0/1]	Time  0.227 ( 0.227)	Loss 1.1922e+00 (1.1922e+00)	Acc@1   0.05 (  0.05)	Acc@5   0.00 (  0.00)
 * Acc@1 0.052 Acc@5 0.000
Test: [0/1]	Time  0.285 ( 0.285)	Loss 8.3497e-01 (8.3497e-01)	Acc@1  -0.00 ( -0.00)	Acc@5   0.00 (  0.00)
 * Acc@1 -0.003 Acc@5 0.000
4
TRAINING
Epoch: [4][0/1]	Time  0.909 ( 0.909)	Data  0.236 ( 0.236)	Loss 1.3092e+00 (1.3092e+00)	Acc@1   0.04 (  0.04)	Acc@5   0.00 (  0.00)
[0.035560959473724105]
Test: [0/1]	Time  0.224 ( 0.224)	Loss 1.2026e+00 (1.2026e+00)	Acc@1   0.06 (  0.06)	Acc@5   0.00 (  0.00)
 * Acc@1 0.064 Acc@5 0.000
Test: [0/1]	Time  0.275 ( 0.275)	Loss 8.4363e-01 (8.4363e-01)	Acc@1   0.00 (  0.00)	Acc@5   0.00 (  0.00)
 * Acc@1 0.001 Acc@5 0.000
5
TRAINING
Epoch: [5][0/1]	Time  0.951 ( 0.951)	Data  0.236 ( 0.236)	Loss 1.2483e+00 (1.2483e+00)	Acc@1   0.06 (  0.06)	Acc@5   0.00 (  0.00)
[0.05580992530849253]
Test: [0/1]	Time  0.228 ( 0.228)	Loss 1.2058e+00 (1.2058e+00)	Acc@1   0.07 (  0.07)	Acc@5   0.00 (  0.00)
 * Acc@1 0.075 Acc@5 0.000
Test: [0/1]	Time  0.286 ( 0.286)	Loss 8.5100e-01 (8.5100e-01)	Acc@1   0.01 (  0.01)	Acc@5   0.00 (  0.00)
 * Acc@1 0.009 Acc@5 0.000
6
TRAINING
Epoch: [6][0/1]	Time  0.948 ( 0.948)	Data  0.246 ( 0.246)	Loss 1.1952e+00 (1.1952e+00)	Acc@1   0.07 (  0.07)	Acc@5   0.00 (  0.00)
[0.0738870154843209]
Test: [0/1]	Time  0.234 ( 0.234)	Loss 1.1976e+00 (1.1976e+00)	Acc@1   0.09 (  0.09)	Acc@5   0.00 (  0.00)
 * Acc@1 0.095 Acc@5 0.000
Test: [0/1]	Time  0.281 ( 0.281)	Loss 8.3502e-01 (8.3502e-01)	Acc@1   0.03 (  0.03)	Acc@5   0.00 (  0.00)
 * Acc@1 0.026 Acc@5 0.000
7
TRAINING
Epoch: [7][0/1]	Time  0.959 ( 0.959)	Data  0.247 ( 0.247)	Loss 1.1217e+00 (1.1217e+00)	Acc@1   0.10 (  0.10)	Acc@5   0.00 (  0.00)
[0.09534968133307331]
Test: [0/1]	Time  0.231 ( 0.231)	Loss 1.1768e+00 (1.1768e+00)	Acc@1   0.13 (  0.13)	Acc@5   0.00 (  0.00)
 * Acc@1 0.129 Acc@5 0.000
Test: [0/1]	Time  0.285 ( 0.285)	Loss 7.8668e-01 (7.8668e-01)	Acc@1   0.05 (  0.05)	Acc@5   0.00 (  0.00)
 * Acc@1 0.048 Acc@5 0.000
8
TRAINING
Epoch: [8][0/1]	Time  0.950 ( 0.950)	Data  0.237 ( 0.237)	Loss 1.0169e+00 (1.0169e+00)	Acc@1   0.11 (  0.11)	Acc@5   0.00 (  0.00)
[0.11402778984583326]
Test: [0/1]	Time  0.228 ( 0.228)	Loss 1.1461e+00 (1.1461e+00)	Acc@1   0.16 (  0.16)	Acc@5   0.00 (  0.00)
 * Acc@1 0.156 Acc@5 0.000
Test: [0/1]	Time  0.284 ( 0.284)	Loss 7.1446e-01 (7.1446e-01)	Acc@1   0.07 (  0.07)	Acc@5   0.00 (  0.00)
 * Acc@1 0.071 Acc@5 0.000
9
TRAINING
Epoch: [9][0/1]	Time  0.925 ( 0.925)	Data  0.235 ( 0.235)	Loss 8.9156e-01 (8.9156e-01)	Acc@1   0.13 (  0.13)	Acc@5   0.00 (  0.00)
[0.13487481949916674]
Test: [0/1]	Time  0.240 ( 0.240)	Loss 1.1106e+00 (1.1106e+00)	Acc@1   0.19 (  0.19)	Acc@5   0.00 (  0.00)
 * Acc@1 0.194 Acc@5 0.000
Test: [0/1]	Time  0.293 ( 0.293)	Loss 6.3776e-01 (6.3776e-01)	Acc@1   0.09 (  0.09)	Acc@5   0.00 (  0.00)
 * Acc@1 0.092 Acc@5 0.000
10
TRAINING
Epoch: [10][0/1]	Time  0.944 ( 0.944)	Data  0.233 ( 0.233)	Loss 7.6877e-01 (7.6877e-01)	Acc@1   0.16 (  0.16)	Acc@5   0.00 (  0.00)
[0.15772497378075517]
Test: [0/1]	Time  0.228 ( 0.228)	Loss 1.0758e+00 (1.0758e+00)	Acc@1   0.24 (  0.24)	Acc@5   0.00 (  0.00)
 * Acc@1 0.238 Acc@5 0.000
Test: [0/1]	Time  0.281 ( 0.281)	Loss 5.7523e-01 (5.7523e-01)	Acc@1   0.11 (  0.11)	Acc@5   0.00 (  0.00)
 * Acc@1 0.111 Acc@5 0.000
11
TRAINING
Epoch: [11][0/1]	Time  0.930 ( 0.930)	Data  0.240 ( 0.240)	Loss 6.6880e-01 (6.6880e-01)	Acc@1   0.18 (  0.18)	Acc@5   0.00 (  0.00)
[0.18222439433007814]
Test: [0/1]	Time  0.227 ( 0.227)	Loss 1.0457e+00 (1.0457e+00)	Acc@1   0.28 (  0.28)	Acc@5   0.00 (  0.00)
 * Acc@1 0.284 Acc@5 0.000
Test: [0/1]	Time  0.281 ( 0.281)	Loss 5.3485e-01 (5.3485e-01)	Acc@1   0.13 (  0.13)	Acc@5   0.00 (  0.00)
 * Acc@1 0.127 Acc@5 0.000
12
TRAINING
Epoch: [12][0/1]	Time  1.049 ( 1.049)	Data  0.337 ( 0.337)	Loss 5.9832e-01 (5.9832e-01)	Acc@1   0.22 (  0.22)	Acc@5   0.00 (  0.00)
[0.21595977221170182]
Test: [0/1]	Time  0.245 ( 0.245)	Loss 1.0222e+00 (1.0222e+00)	Acc@1   0.33 (  0.33)	Acc@5   0.00 (  0.00)
 * Acc@1 0.326 Acc@5 0.000
Test: [0/1]	Time  0.292 ( 0.292)	Loss 5.1178e-01 (5.1178e-01)	Acc@1   0.14 (  0.14)	Acc@5   0.00 (  0.00)
 * Acc@1 0.143 Acc@5 0.000
13
TRAINING
Epoch: [13][0/1]	Time  1.011 ( 1.011)	Data  0.311 ( 0.311)	Loss 5.4918e-01 (5.4918e-01)	Acc@1   0.25 (  0.25)	Acc@5   0.00 (  0.00)
[0.2456310694328285]
Test: [0/1]	Time  0.240 ( 0.240)	Loss 1.0052e+00 (1.0052e+00)	Acc@1   0.36 (  0.36)	Acc@5   0.00 (  0.00)
 * Acc@1 0.364 Acc@5 0.000
Test: [0/1]	Time  0.289 ( 0.289)	Loss 4.9364e-01 (4.9364e-01)	Acc@1   0.16 (  0.16)	Acc@5   0.00 (  0.00)
 * Acc@1 0.161 Acc@5 0.000
14
TRAINING
Epoch: [14][0/1]	Time  1.018 ( 1.018)	Data  0.320 ( 0.320)	Loss 5.0595e-01 (5.0595e-01)	Acc@1   0.28 (  0.28)	Acc@5   0.00 (  0.00)
[0.27776634782374887]
Test: [0/1]	Time  0.241 ( 0.241)	Loss 9.9372e-01 (9.9372e-01)	Acc@1   0.40 (  0.40)	Acc@5   0.00 (  0.00)
 * Acc@1 0.402 Acc@5 0.000
Test: [0/1]	Time  0.289 ( 0.289)	Loss 4.6916e-01 (4.6916e-01)	Acc@1   0.18 (  0.18)	Acc@5   0.00 (  0.00)
 * Acc@1 0.175 Acc@5 0.000
15
TRAINING
Epoch: [15][0/1]	Time  0.967 ( 0.967)	Data  0.270 ( 0.270)	Loss 4.5605e-01 (4.5605e-01)	Acc@1   0.31 (  0.31)	Acc@5   0.00 (  0.00)
[0.312071066813331]
Test: [0/1]	Time  0.240 ( 0.240)	Loss 9.8698e-01 (9.8698e-01)	Acc@1   0.44 (  0.44)	Acc@5   0.00 (  0.00)
 * Acc@1 0.439 Acc@5 0.000
Test: [0/1]	Time  0.295 ( 0.295)	Loss 4.3453e-01 (4.3453e-01)	Acc@1   0.20 (  0.20)	Acc@5   0.00 (  0.00)
 * Acc@1 0.201 Acc@5 0.000
16
TRAINING
Epoch: [16][0/1]	Time  0.959 ( 0.959)	Data  0.254 ( 0.254)	Loss 3.9640e-01 (3.9640e-01)	Acc@1   0.35 (  0.35)	Acc@5   0.00 (  0.00)
[0.35080211796030736]
Test: [0/1]	Time  0.235 ( 0.235)	Loss 9.8438e-01 (9.8438e-01)	Acc@1   0.47 (  0.47)	Acc@5   0.00 (  0.00)
 * Acc@1 0.475 Acc@5 0.000
Test: [0/1]	Time  0.288 ( 0.288)	Loss 3.9418e-01 (3.9418e-01)	Acc@1   0.22 (  0.22)	Acc@5   0.00 (  0.00)
 * Acc@1 0.220 Acc@5 0.000
17
TRAINING
Epoch: [17][0/1]	Time  0.997 ( 0.997)	Data  0.271 ( 0.271)	Loss 3.3327e-01 (3.3327e-01)	Acc@1   0.39 (  0.39)	Acc@5   0.00 (  0.00)
[0.3917409207598872]
Test: [0/1]	Time  0.239 ( 0.239)	Loss 9.8536e-01 (9.8536e-01)	Acc@1   0.50 (  0.50)	Acc@5   0.00 (  0.00)
 * Acc@1 0.501 Acc@5 0.000
Test: [0/1]	Time  0.297 ( 0.297)	Loss 3.5660e-01 (3.5660e-01)	Acc@1   0.25 (  0.25)	Acc@5   0.00 (  0.00)
 * Acc@1 0.249 Acc@5 0.000
18
TRAINING
Epoch: [18][0/1]	Time  0.954 ( 0.954)	Data  0.260 ( 0.260)	Loss 2.7687e-01 (2.7687e-01)	Acc@1   0.43 (  0.43)	Acc@5   0.00 (  0.00)
[0.43174142879755617]
Test: [0/1]	Time  0.236 ( 0.236)	Loss 9.8892e-01 (9.8892e-01)	Acc@1   0.51 (  0.51)	Acc@5   0.00 (  0.00)
 * Acc@1 0.513 Acc@5 0.000
Test: [0/1]	Time  0.290 ( 0.290)	Loss 3.2844e-01 (3.2844e-01)	Acc@1   0.28 (  0.28)	Acc@5   0.00 (  0.00)
 * Acc@1 0.280 Acc@5 0.000
19
TRAINING
Epoch: [19][0/1]	Time  0.961 ( 0.961)	Data  0.251 ( 0.251)	Loss 2.3464e-01 (2.3464e-01)	Acc@1   0.48 (  0.48)	Acc@5   0.00 (  0.00)
[0.4825470897706041]
Test: [0/1]	Time  0.238 ( 0.238)	Loss 9.9336e-01 (9.9336e-01)	Acc@1   0.54 (  0.54)	Acc@5   0.00 (  0.00)
 * Acc@1 0.536 Acc@5 0.000
Test: [0/1]	Time  0.284 ( 0.284)	Loss 3.1073e-01 (3.1073e-01)	Acc@1   0.30 (  0.30)	Acc@5   0.00 (  0.00)
 * Acc@1 0.305 Acc@5 0.000
20
TRAINING
Epoch: [20][0/1]	Time  0.961 ( 0.961)	Data  0.250 ( 0.250)	Loss 2.0738e-01 (2.0738e-01)	Acc@1   0.53 (  0.53)	Acc@5   0.00 (  0.00)
[0.5328182679662786]
Test: [0/1]	Time  0.238 ( 0.238)	Loss 9.9668e-01 (9.9668e-01)	Acc@1   0.56 (  0.56)	Acc@5   0.00 (  0.00)
 * Acc@1 0.559 Acc@5 0.000
Test: [0/1]	Time  0.290 ( 0.290)	Loss 2.9914e-01 (2.9914e-01)	Acc@1   0.33 (  0.33)	Acc@5   0.00 (  0.00)
 * Acc@1 0.326 Acc@5 0.000
21
TRAINING
Epoch: [21][0/1]	Time  0.950 ( 0.950)	Data  0.246 ( 0.246)	Loss 1.8998e-01 (1.8998e-01)	Acc@1   0.58 (  0.58)	Acc@5   0.00 (  0.00)
[0.5820963681653604]
Test: [0/1]	Time  0.234 ( 0.234)	Loss 9.9718e-01 (9.9718e-01)	Acc@1   0.58 (  0.58)	Acc@5   0.00 (  0.00)
 * Acc@1 0.583 Acc@5 0.000
Test: [0/1]	Time  0.287 ( 0.287)	Loss 2.8740e-01 (2.8740e-01)	Acc@1   0.35 (  0.35)	Acc@5   0.00 (  0.00)
 * Acc@1 0.355 Acc@5 0.000
22
TRAINING
Epoch: [22][0/1]	Time  0.953 ( 0.953)	Data  0.251 ( 0.251)	Loss 1.7529e-01 (1.7529e-01)	Acc@1   0.63 (  0.63)	Acc@5   0.00 (  0.00)
[0.6302223249815834]
Test: [0/1]	Time  0.239 ( 0.239)	Loss 9.9413e-01 (9.9413e-01)	Acc@1   0.61 (  0.61)	Acc@5   0.00 (  0.00)
 * Acc@1 0.610 Acc@5 0.000
Test: [0/1]	Time  0.291 ( 0.291)	Loss 2.7136e-01 (2.7136e-01)	Acc@1   0.38 (  0.38)	Acc@5   0.00 (  0.00)
 * Acc@1 0.383 Acc@5 0.000
23
TRAINING
Epoch: [23][0/1]	Time  0.991 ( 0.991)	Data  0.257 ( 0.257)	Loss 1.5844e-01 (1.5844e-01)	Acc@1   0.67 (  0.67)	Acc@5   0.00 (  0.00)
[0.6735615256196354]
Test: [0/1]	Time  0.239 ( 0.239)	Loss 9.8791e-01 (9.8791e-01)	Acc@1   0.64 (  0.64)	Acc@5   0.00 (  0.00)
 * Acc@1 0.638 Acc@5 0.000
Test: [0/1]	Time  0.288 ( 0.288)	Loss 2.5105e-01 (2.5105e-01)	Acc@1   0.41 (  0.41)	Acc@5   0.00 (  0.00)
 * Acc@1 0.410 Acc@5 0.000
24
TRAINING
Epoch: [24][0/1]	Time  0.963 ( 0.963)	Data  0.253 ( 0.253)	Loss 1.3894e-01 (1.3894e-01)	Acc@1   0.71 (  0.71)	Acc@5   0.00 (  0.00)
[0.7117610654326381]
Test: [0/1]	Time  0.246 ( 0.246)	Loss 9.7980e-01 (9.7980e-01)	Acc@1   0.66 (  0.66)	Acc@5   0.00 (  0.00)
 * Acc@1 0.664 Acc@5 0.000
Test: [0/1]	Time  0.293 ( 0.293)	Loss 2.2997e-01 (2.2997e-01)	Acc@1   0.43 (  0.43)	Acc@5   0.00 (  0.00)
 * Acc@1 0.429 Acc@5 0.000
25
TRAINING
Epoch: [25][0/1]	Time  0.945 ( 0.945)	Data  0.254 ( 0.254)	Loss 1.1990e-01 (1.1990e-01)	Acc@1   0.75 (  0.75)	Acc@5   0.00 (  0.00)
[0.7477275640486751]
Test: [0/1]	Time  0.233 ( 0.233)	Loss 9.7137e-01 (9.7137e-01)	Acc@1   0.69 (  0.69)	Acc@5   0.00 (  0.00)
 * Acc@1 0.686 Acc@5 0.000
Test: [0/1]	Time  0.292 ( 0.292)	Loss 2.1244e-01 (2.1244e-01)	Acc@1   0.44 (  0.44)	Acc@5   0.00 (  0.00)
 * Acc@1 0.445 Acc@5 0.000
26
TRAINING
Epoch: [26][0/1]	Time  0.940 ( 0.940)	Data  0.244 ( 0.244)	Loss 1.0524e-01 (1.0524e-01)	Acc@1   0.78 (  0.78)	Acc@5   0.00 (  0.00)
[0.7774654616070332]
Test: [0/1]	Time  0.231 ( 0.231)	Loss 9.6392e-01 (9.6392e-01)	Acc@1   0.70 (  0.70)	Acc@5   0.00 (  0.00)
 * Acc@1 0.702 Acc@5 0.000
Test: [0/1]	Time  0.286 ( 0.286)	Loss 2.0088e-01 (2.0088e-01)	Acc@1   0.46 (  0.46)	Acc@5   0.00 (  0.00)
 * Acc@1 0.465 Acc@5 0.000
27
TRAINING
Epoch: [27][0/1]	Time  0.980 ( 0.980)	Data  0.260 ( 0.260)	Loss 9.7025e-02 (9.7025e-02)	Acc@1   0.80 (  0.80)	Acc@5   0.00 (  0.00)
[0.8010391985684838]
Test: [0/1]	Time  0.240 ( 0.240)	Loss 9.5819e-01 (9.5819e-01)	Acc@1   0.71 (  0.71)	Acc@5   0.00 (  0.00)
 * Acc@1 0.711 Acc@5 0.000
Test: [0/1]	Time  0.293 ( 0.293)	Loss 1.9467e-01 (1.9467e-01)	Acc@1   0.48 (  0.48)	Acc@5   0.00 (  0.00)
 * Acc@1 0.485 Acc@5 0.000
28
TRAINING
Epoch: [28][0/1]	Time  0.971 ( 0.971)	Data  0.255 ( 0.255)	Loss 9.4381e-02 (9.4381e-02)	Acc@1   0.82 (  0.82)	Acc@5   0.00 (  0.00)
[0.8218654125673135]
Test: [0/1]	Time  0.243 ( 0.243)	Loss 9.5430e-01 (9.5430e-01)	Acc@1   0.71 (  0.71)	Acc@5   0.00 (  0.00)
 * Acc@1 0.707 Acc@5 0.000
Test: [0/1]	Time  0.292 ( 0.292)	Loss 1.9099e-01 (1.9099e-01)	Acc@1   0.51 (  0.51)	Acc@5   0.00 (  0.00)
 * Acc@1 0.506 Acc@5 0.000
29
TRAINING
Epoch: [29][0/1]	Time  1.003 ( 1.003)	Data  0.289 ( 0.289)	Loss 9.4312e-02 (9.4312e-02)	Acc@1   0.84 (  0.84)	Acc@5   0.00 (  0.00)
[0.8370554257876119]
Test: [0/1]	Time  0.249 ( 0.249)	Loss 9.5205e-01 (9.5205e-01)	Acc@1   0.70 (  0.70)	Acc@5   0.00 (  0.00)
 * Acc@1 0.701 Acc@5 0.000
Test: [0/1]	Time  0.302 ( 0.302)	Loss 1.8669e-01 (1.8669e-01)	Acc@1   0.53 (  0.53)	Acc@5   0.00 (  0.00)
 * Acc@1 0.528 Acc@5 0.000
30
TRAINING
Epoch: [30][0/1]	Time  0.964 ( 0.964)	Data  0.255 ( 0.255)	Loss 9.3652e-02 (9.3652e-02)	Acc@1   0.85 (  0.85)	Acc@5   0.00 (  0.00)
[0.8486756022723696]
Test: [0/1]	Time  0.235 ( 0.235)	Loss 9.5114e-01 (9.5114e-01)	Acc@1   0.69 (  0.69)	Acc@5   0.00 (  0.00)
 * Acc@1 0.694 Acc@5 0.000
Test: [0/1]	Time  0.289 ( 0.289)	Loss 1.8011e-01 (1.8011e-01)	Acc@1   0.55 (  0.55)	Acc@5   0.00 (  0.00)
 * Acc@1 0.550 Acc@5 0.000
31
TRAINING
Epoch: [31][0/1]	Time  0.976 ( 0.976)	Data  0.255 ( 0.255)	Loss 9.0768e-02 (9.0768e-02)	Acc@1   0.86 (  0.86)	Acc@5   0.00 (  0.00)
[0.8606657661827399]
Test: [0/1]	Time  0.244 ( 0.244)	Loss 9.5129e-01 (9.5129e-01)	Acc@1   0.69 (  0.69)	Acc@5   0.00 (  0.00)
 * Acc@1 0.687 Acc@5 0.000
Test: [0/1]	Time  0.287 ( 0.287)	Loss 1.7170e-01 (1.7170e-01)	Acc@1   0.57 (  0.57)	Acc@5   0.00 (  0.00)
 * Acc@1 0.573 Acc@5 0.000
32
TRAINING
Epoch: [32][0/1]	Time  1.003 ( 1.003)	Data  0.273 ( 0.273)	Loss 8.6094e-02 (8.6094e-02)	Acc@1   0.87 (  0.87)	Acc@5   0.00 (  0.00)
[0.8697506766431358]
Test: [0/1]	Time  0.248 ( 0.248)	Loss 9.5228e-01 (9.5228e-01)	Acc@1   0.68 (  0.68)	Acc@5   0.00 (  0.00)
 * Acc@1 0.680 Acc@5 0.000
Test: [0/1]	Time  0.301 ( 0.301)	Loss 1.6327e-01 (1.6327e-01)	Acc@1   0.59 (  0.59)	Acc@5   0.00 (  0.00)
 * Acc@1 0.594 Acc@5 0.000
33
TRAINING
Epoch: [33][0/1]	Time  0.973 ( 0.973)	Data  0.252 ( 0.252)	Loss 8.1406e-02 (8.1406e-02)	Acc@1   0.88 (  0.88)	Acc@5   0.00 (  0.00)
[0.8758063910273031]
Test: [0/1]	Time  0.237 ( 0.237)	Loss 9.5383e-01 (9.5383e-01)	Acc@1   0.67 (  0.67)	Acc@5   0.00 (  0.00)
 * Acc@1 0.673 Acc@5 0.000
Test: [0/1]	Time  0.298 ( 0.298)	Loss 1.5668e-01 (1.5668e-01)	Acc@1   0.61 (  0.61)	Acc@5   0.00 (  0.00)
 * Acc@1 0.612 Acc@5 0.000
34
TRAINING
Epoch: [34][0/1]	Time  0.957 ( 0.957)	Data  0.251 ( 0.251)	Loss 7.8487e-02 (7.8487e-02)	Acc@1   0.88 (  0.88)	Acc@5   0.00 (  0.00)
[0.8805025449793537]
Test: [0/1]	Time  0.243 ( 0.243)	Loss 9.5552e-01 (9.5552e-01)	Acc@1   0.67 (  0.67)	Acc@5   0.00 (  0.00)
 * Acc@1 0.665 Acc@5 0.000
Test: [0/1]	Time  0.286 ( 0.286)	Loss 1.5278e-01 (1.5278e-01)	Acc@1   0.63 (  0.63)	Acc@5   0.00 (  0.00)
 * Acc@1 0.629 Acc@5 0.000
35
TRAINING
Epoch: [35][0/1]	Time  0.941 ( 0.941)	Data  0.251 ( 0.251)	Loss 7.8049e-02 (7.8049e-02)	Acc@1   0.88 (  0.88)	Acc@5   0.00 (  0.00)
[0.884290157113219]
Test: [0/1]	Time  0.239 ( 0.239)	Loss 9.5689e-01 (9.5689e-01)	Acc@1   0.66 (  0.66)	Acc@5   0.00 (  0.00)
 * Acc@1 0.658 Acc@5 0.000
Test: [0/1]	Time  0.286 ( 0.286)	Loss 1.5106e-01 (1.5106e-01)	Acc@1   0.64 (  0.64)	Acc@5   0.00 (  0.00)
 * Acc@1 0.643 Acc@5 0.000
36
TRAINING
Epoch: [36][0/1]	Time  0.956 ( 0.956)	Data  0.250 ( 0.250)	Loss 7.9492e-02 (7.9492e-02)	Acc@1   0.88 (  0.88)	Acc@5   0.00 (  0.00)
[0.8832390068630009]
Test: [0/1]	Time  0.235 ( 0.235)	Loss 9.5751e-01 (9.5751e-01)	Acc@1   0.65 (  0.65)	Acc@5   0.00 (  0.00)
 * Acc@1 0.651 Acc@5 0.000
Test: [0/1]	Time  0.280 ( 0.280)	Loss 1.5026e-01 (1.5026e-01)	Acc@1   0.65 (  0.65)	Acc@5   0.00 (  0.00)
 * Acc@1 0.653 Acc@5 0.000
37
TRAINING
Epoch: [37][0/1]	Time  0.951 ( 0.951)	Data  0.263 ( 0.263)	Loss 8.1457e-02 (8.1457e-02)	Acc@1   0.88 (  0.88)	Acc@5   0.00 (  0.00)
[0.8812749832511575]
Test: [0/1]	Time  0.248 ( 0.248)	Loss 9.5713e-01 (9.5713e-01)	Acc@1   0.64 (  0.64)	Acc@5   0.00 (  0.00)
 * Acc@1 0.644 Acc@5 0.000
Test: [0/1]	Time  0.293 ( 0.293)	Loss 1.4921e-01 (1.4921e-01)	Acc@1   0.66 (  0.66)	Acc@5   0.00 (  0.00)
 * Acc@1 0.664 Acc@5 0.000
38
TRAINING
Epoch: [38][0/1]	Time  0.969 ( 0.969)	Data  0.257 ( 0.257)	Loss 8.2715e-02 (8.2715e-02)	Acc@1   0.88 (  0.88)	Acc@5   0.00 (  0.00)
[0.8798789134046392]
Test: [0/1]	Time  0.235 ( 0.235)	Loss 9.5577e-01 (9.5577e-01)	Acc@1   0.64 (  0.64)	Acc@5   0.00 (  0.00)
 * Acc@1 0.638 Acc@5 0.000
Test: [0/1]	Time  0.297 ( 0.297)	Loss 1.4746e-01 (1.4746e-01)	Acc@1   0.67 (  0.67)	Acc@5   0.00 (  0.00)
 * Acc@1 0.670 Acc@5 0.000
39
TRAINING
Epoch: [39][0/1]	Time  0.944 ( 0.944)	Data  0.250 ( 0.250)	Loss 8.2805e-02 (8.2805e-02)	Acc@1   0.88 (  0.88)	Acc@5   0.00 (  0.00)
[0.8782775907656203]
Test: [0/1]	Time  0.245 ( 0.245)	Loss 9.5367e-01 (9.5367e-01)	Acc@1   0.63 (  0.63)	Acc@5   0.00 (  0.00)
 * Acc@1 0.632 Acc@5 0.000
Test: [0/1]	Time  0.299 ( 0.299)	Loss 1.4540e-01 (1.4540e-01)	Acc@1   0.67 (  0.67)	Acc@5   0.00 (  0.00)
 * Acc@1 0.672 Acc@5 0.000
40
TRAINING
Epoch: [40][0/1]	Time  0.953 ( 0.953)	Data  0.244 ( 0.244)	Loss 8.2113e-02 (8.2113e-02)	Acc@1   0.88 (  0.88)	Acc@5   0.00 (  0.00)
[0.876878211668336]
Test: [0/1]	Time  0.262 ( 0.262)	Loss 9.5120e-01 (9.5120e-01)	Acc@1   0.62 (  0.62)	Acc@5   0.00 (  0.00)
 * Acc@1 0.625 Acc@5 0.000
Test: [0/1]	Time  0.303 ( 0.303)	Loss 1.4378e-01 (1.4378e-01)	Acc@1   0.68 (  0.68)	Acc@5   0.00 (  0.00)
 * Acc@1 0.675 Acc@5 0.000
41
TRAINING
Epoch: [41][0/1]	Time  0.935 ( 0.935)	Data  0.240 ( 0.240)	Loss 8.1444e-02 (8.1444e-02)	Acc@1   0.88 (  0.88)	Acc@5   0.00 (  0.00)
[0.8757207743511122]
Test: [0/1]	Time  0.257 ( 0.257)	Loss 9.4875e-01 (9.4875e-01)	Acc@1   0.62 (  0.62)	Acc@5   0.00 (  0.00)
 * Acc@1 0.619 Acc@5 0.000
Test: [0/1]	Time  0.313 ( 0.313)	Loss 1.4317e-01 (1.4317e-01)	Acc@1   0.68 (  0.68)	Acc@5   0.00 (  0.00)
 * Acc@1 0.680 Acc@5 0.000
42
TRAINING
Epoch: [42][0/1]	Time  0.978 ( 0.978)	Data  0.281 ( 0.281)	Loss 8.1442e-02 (8.1442e-02)	Acc@1   0.87 (  0.87)	Acc@5   0.00 (  0.00)
[0.8739632435031293]
Test: [0/1]	Time  0.248 ( 0.248)	Loss 9.4662e-01 (9.4662e-01)	Acc@1   0.62 (  0.62)	Acc@5   0.00 (  0.00)
 * Acc@1 0.617 Acc@5 0.000
Test: [0/1]	Time  0.302 ( 0.302)	Loss 1.4359e-01 (1.4359e-01)	Acc@1   0.68 (  0.68)	Acc@5   0.00 (  0.00)
 * Acc@1 0.684 Acc@5 0.000
43
TRAINING
Epoch: [43][0/1]	Time  0.974 ( 0.974)	Data  0.267 ( 0.267)	Loss 8.2217e-02 (8.2217e-02)	Acc@1   0.87 (  0.87)	Acc@5   0.00 (  0.00)
[0.8741193796166122]
Test: [0/1]	Time  0.244 ( 0.244)	Loss 9.4497e-01 (9.4497e-01)	Acc@1   0.62 (  0.62)	Acc@5   0.00 (  0.00)
 * Acc@1 0.618 Acc@5 0.000
Test: [0/1]	Time  0.293 ( 0.293)	Loss 1.4452e-01 (1.4452e-01)	Acc@1   0.69 (  0.69)	Acc@5   0.00 (  0.00)
 * Acc@1 0.686 Acc@5 0.000
44
TRAINING
Epoch: [44][0/1]	Time  0.970 ( 0.970)	Data  0.274 ( 0.274)	Loss 8.3361e-02 (8.3361e-02)	Acc@1   0.88 (  0.88)	Acc@5   0.00 (  0.00)
[0.8754244272178762]
Test: [0/1]	Time  0.246 ( 0.246)	Loss 9.4387e-01 (9.4387e-01)	Acc@1   0.62 (  0.62)	Acc@5   0.00 (  0.00)
 * Acc@1 0.618 Acc@5 0.000
Test: [0/1]	Time  0.298 ( 0.298)	Loss 1.4527e-01 (1.4527e-01)	Acc@1   0.69 (  0.69)	Acc@5   0.00 (  0.00)
 * Acc@1 0.687 Acc@5 0.000
45
TRAINING
Epoch: [45][0/1]	Time  0.975 ( 0.975)	Data  0.262 ( 0.262)	Loss 8.4266e-02 (8.4266e-02)	Acc@1   0.88 (  0.88)	Acc@5   0.00 (  0.00)
[0.8775100589493297]
Test: [0/1]	Time  0.235 ( 0.235)	Loss 9.4331e-01 (9.4331e-01)	Acc@1   0.62 (  0.62)	Acc@5   0.00 (  0.00)
 * Acc@1 0.619 Acc@5 0.000
Test: [0/1]	Time  0.294 ( 0.294)	Loss 1.4538e-01 (1.4538e-01)	Acc@1   0.69 (  0.69)	Acc@5   0.00 (  0.00)
 * Acc@1 0.690 Acc@5 0.000
46
TRAINING
Epoch: [46][0/1]	Time  0.968 ( 0.968)	Data  0.252 ( 0.252)	Loss 8.4507e-02 (8.4507e-02)	Acc@1   0.88 (  0.88)	Acc@5   0.00 (  0.00)
[0.8804659356208213]
Test: [0/1]	Time  0.238 ( 0.238)	Loss 9.4327e-01 (9.4327e-01)	Acc@1   0.62 (  0.62)	Acc@5   0.00 (  0.00)
 * Acc@1 0.619 Acc@5 0.000
Test: [0/1]	Time  0.288 ( 0.288)	Loss 1.4477e-01 (1.4477e-01)	Acc@1   0.70 (  0.70)	Acc@5   0.00 (  0.00)
 * Acc@1 0.695 Acc@5 0.000
47
TRAINING
Epoch: [47][0/1]	Time  0.959 ( 0.959)	Data  0.258 ( 0.258)	Loss 8.4059e-02 (8.4059e-02)	Acc@1   0.88 (  0.88)	Acc@5   0.00 (  0.00)
[0.8841890527020889]
Test: [0/1]	Time  0.239 ( 0.239)	Loss 9.4367e-01 (9.4367e-01)	Acc@1   0.62 (  0.62)	Acc@5   0.00 (  0.00)
 * Acc@1 0.620 Acc@5 0.000
Test: [0/1]	Time  0.291 ( 0.291)	Loss 1.4379e-01 (1.4379e-01)	Acc@1   0.70 (  0.70)	Acc@5   0.00 (  0.00)
 * Acc@1 0.696 Acc@5 0.000
48
TRAINING
Epoch: [48][0/1]	Time  0.967 ( 0.967)	Data  0.257 ( 0.257)	Loss 8.3242e-02 (8.3242e-02)	Acc@1   0.89 (  0.89)	Acc@5   0.00 (  0.00)
[0.8883833531567101]
Test: [0/1]	Time  0.238 ( 0.238)	Loss 9.4439e-01 (9.4439e-01)	Acc@1   0.62 (  0.62)	Acc@5   0.00 (  0.00)
 * Acc@1 0.620 Acc@5 0.000
Test: [0/1]	Time  0.289 ( 0.289)	Loss 1.4287e-01 (1.4287e-01)	Acc@1   0.70 (  0.70)	Acc@5   0.00 (  0.00)
 * Acc@1 0.696 Acc@5 0.000
49
TRAINING
Epoch: [49][0/1]	Time  1.000 ( 1.000)	Data  0.285 ( 0.285)	Loss 8.2488e-02 (8.2488e-02)	Acc@1   0.89 (  0.89)	Acc@5   0.00 (  0.00)
[0.8926727130711913]
Test: [0/1]	Time  0.248 ( 0.248)	Loss 9.4525e-01 (9.4525e-01)	Acc@1   0.62 (  0.62)	Acc@5   0.00 (  0.00)
 * Acc@1 0.621 Acc@5 0.000
Test: [0/1]	Time  0.307 ( 0.307)	Loss 1.4234e-01 (1.4234e-01)	Acc@1   0.70 (  0.70)	Acc@5   0.00 (  0.00)
 * Acc@1 0.695 Acc@5 0.000
50
TRAINING
Epoch: [50][0/1]	Time  0.930 ( 0.930)	Data  0.242 ( 0.242)	Loss 8.2086e-02 (8.2086e-02)	Acc@1   0.90 (  0.90)	Acc@5   0.00 (  0.00)
[0.8971787741890926]
Test: [0/1]	Time  0.230 ( 0.230)	Loss 9.4609e-01 (9.4609e-01)	Acc@1   0.62 (  0.62)	Acc@5   0.00 (  0.00)
 * Acc@1 0.622 Acc@5 0.000
Test: [0/1]	Time  0.279 ( 0.279)	Loss 1.4224e-01 (1.4224e-01)	Acc@1   0.69 (  0.69)	Acc@5   0.00 (  0.00)
 * Acc@1 0.693 Acc@5 0.000
51
TRAINING
Epoch: [51][0/1]	Time  0.917 ( 0.917)	Data  0.243 ( 0.243)	Loss 8.2059e-02 (8.2059e-02)	Acc@1   0.90 (  0.90)	Acc@5   0.00 (  0.00)
[0.9014908936454201]
Test: [0/1]	Time  0.225 ( 0.225)	Loss 9.4671e-01 (9.4671e-01)	Acc@1   0.62 (  0.62)	Acc@5   0.00 (  0.00)
 * Acc@1 0.623 Acc@5 0.000
Test: [0/1]	Time  0.279 ( 0.279)	Loss 1.4240e-01 (1.4240e-01)	Acc@1   0.69 (  0.69)	Acc@5   0.00 (  0.00)
 * Acc@1 0.690 Acc@5 0.000
52
TRAINING
Epoch: [52][0/1]	Time  0.920 ( 0.920)	Data  0.248 ( 0.248)	Loss 8.2211e-02 (8.2211e-02)	Acc@1   0.91 (  0.91)	Acc@5   0.00 (  0.00)
[0.9052977692098856]
Test: [0/1]	Time  0.231 ( 0.231)	Loss 9.4701e-01 (9.4701e-01)	Acc@1   0.63 (  0.63)	Acc@5   0.00 (  0.00)
 * Acc@1 0.625 Acc@5 0.000
Test: [0/1]	Time  0.278 ( 0.278)	Loss 1.4261e-01 (1.4261e-01)	Acc@1   0.69 (  0.69)	Acc@5   0.00 (  0.00)
 * Acc@1 0.689 Acc@5 0.000
53
TRAINING
Epoch: [53][0/1]	Time  0.934 ( 0.934)	Data  0.239 ( 0.239)	Loss 8.2292e-02 (8.2292e-02)	Acc@1   0.91 (  0.91)	Acc@5   0.00 (  0.00)
[0.908339705194702]
Test: [0/1]	Time  0.228 ( 0.228)	Loss 9.4692e-01 (9.4692e-01)	Acc@1   0.63 (  0.63)	Acc@5   0.00 (  0.00)
 * Acc@1 0.627 Acc@5 0.000
Test: [0/1]	Time  0.276 ( 0.276)	Loss 1.4269e-01 (1.4269e-01)	Acc@1   0.69 (  0.69)	Acc@5   0.00 (  0.00)
 * Acc@1 0.689 Acc@5 0.000
54
TRAINING
Epoch: [54][0/1]	Time  0.936 ( 0.936)	Data  0.238 ( 0.238)	Loss 8.2155e-02 (8.2155e-02)	Acc@1   0.91 (  0.91)	Acc@5   0.00 (  0.00)
[0.9115084816268324]
Test: [0/1]	Time  0.234 ( 0.234)	Loss 9.4648e-01 (9.4648e-01)	Acc@1   0.63 (  0.63)	Acc@5   0.00 (  0.00)
 * Acc@1 0.630 Acc@5 0.000
Test: [0/1]	Time  0.283 ( 0.283)	Loss 1.4266e-01 (1.4266e-01)	Acc@1   0.69 (  0.69)	Acc@5   0.00 (  0.00)
 * Acc@1 0.689 Acc@5 0.000
55
TRAINING
Epoch: [55][0/1]	Time  0.928 ( 0.928)	Data  0.241 ( 0.241)	Loss 8.1822e-02 (8.1822e-02)	Acc@1   0.91 (  0.91)	Acc@5   0.00 (  0.00)
[0.91474362277987]
Test: [0/1]	Time  0.289 ( 0.289)	Loss 9.4580e-01 (9.4580e-01)	Acc@1   0.63 (  0.63)	Acc@5   0.00 (  0.00)
 * Acc@1 0.633 Acc@5 0.000
Test: [0/1]	Time  0.308 ( 0.308)	Loss 1.4263e-01 (1.4263e-01)	Acc@1   0.69 (  0.69)	Acc@5   0.00 (  0.00)
 * Acc@1 0.688 Acc@5 0.000
56
TRAINING
Epoch: [56][0/1]	Time  0.935 ( 0.935)	Data  0.263 ( 0.263)	Loss 8.1436e-02 (8.1436e-02)	Acc@1   0.92 (  0.92)	Acc@5   0.00 (  0.00)
[0.9175077589457414]
Test: [0/1]	Time  0.235 ( 0.235)	Loss 9.4501e-01 (9.4501e-01)	Acc@1   0.64 (  0.64)	Acc@5   0.00 (  0.00)
 * Acc@1 0.637 Acc@5 0.000
Test: [0/1]	Time  0.291 ( 0.291)	Loss 1.4269e-01 (1.4269e-01)	Acc@1   0.69 (  0.69)	Acc@5   0.00 (  0.00)
 * Acc@1 0.687 Acc@5 0.000
57
TRAINING
Epoch: [57][0/1]	Time  0.934 ( 0.934)	Data  0.256 ( 0.256)	Loss 8.1151e-02 (8.1151e-02)	Acc@1   0.92 (  0.92)	Acc@5   0.00 (  0.00)
[0.919857200765918]
Test: [0/1]	Time  0.242 ( 0.242)	Loss 9.4426e-01 (9.4426e-01)	Acc@1   0.64 (  0.64)	Acc@5   0.00 (  0.00)
 * Acc@1 0.640 Acc@5 0.000
Test: [0/1]	Time  0.301 ( 0.301)	Loss 1.4290e-01 (1.4290e-01)	Acc@1   0.69 (  0.69)	Acc@5   0.00 (  0.00)
 * Acc@1 0.687 Acc@5 0.000
58
TRAINING
Epoch: [58][0/1]	Time  0.926 ( 0.926)	Data  0.253 ( 0.253)	Loss 8.1036e-02 (8.1036e-02)	Acc@1   0.92 (  0.92)	Acc@5   0.00 (  0.00)
[0.9219744071869294]
Test: [0/1]	Time  0.235 ( 0.235)	Loss 9.4364e-01 (9.4364e-01)	Acc@1   0.64 (  0.64)	Acc@5   0.00 (  0.00)
 * Acc@1 0.644 Acc@5 0.000
Test: [0/1]	Time  0.288 ( 0.288)	Loss 1.4317e-01 (1.4317e-01)	Acc@1   0.69 (  0.69)	Acc@5   0.00 (  0.00)
 * Acc@1 0.687 Acc@5 0.000
59
TRAINING
Epoch: [59][0/1]	Time  0.939 ( 0.939)	Data  0.247 ( 0.247)	Loss 8.1047e-02 (8.1047e-02)	Acc@1   0.92 (  0.92)	Acc@5   0.00 (  0.00)
[0.9237777121530897]
Test: [0/1]	Time  0.234 ( 0.234)	Loss 9.4323e-01 (9.4323e-01)	Acc@1   0.65 (  0.65)	Acc@5   0.00 (  0.00)
 * Acc@1 0.647 Acc@5 0.000
Test: [0/1]	Time  0.285 ( 0.285)	Loss 1.4337e-01 (1.4337e-01)	Acc@1   0.69 (  0.69)	Acc@5   0.00 (  0.00)
 * Acc@1 0.688 Acc@5 0.000
60
TRAINING
Epoch: [60][0/1]	Time  0.926 ( 0.926)	Data  0.232 ( 0.232)	Loss 8.1071e-02 (8.1071e-02)	Acc@1   0.93 (  0.93)	Acc@5   0.00 (  0.00)
[0.925363980533193]
Test: [0/1]	Time  0.230 ( 0.230)	Loss 9.4307e-01 (9.4307e-01)	Acc@1   0.65 (  0.65)	Acc@5   0.00 (  0.00)
 * Acc@1 0.650 Acc@5 0.000
Test: [0/1]	Time  0.278 ( 0.278)	Loss 1.4338e-01 (1.4338e-01)	Acc@1   0.69 (  0.69)	Acc@5   0.00 (  0.00)
 * Acc@1 0.690 Acc@5 0.000
61
TRAINING
Epoch: [61][0/1]	Time  0.925 ( 0.925)	Data  0.238 ( 0.238)	Loss 8.0999e-02 (8.0999e-02)	Acc@1   0.93 (  0.93)	Acc@5   0.00 (  0.00)
[0.9267526376710127]
Test: [0/1]	Time  0.235 ( 0.235)	Loss 9.4315e-01 (9.4315e-01)	Acc@1   0.65 (  0.65)	Acc@5   0.00 (  0.00)
 * Acc@1 0.653 Acc@5 0.000
Test: [0/1]	Time  0.297 ( 0.297)	Loss 1.4318e-01 (1.4318e-01)	Acc@1   0.69 (  0.69)	Acc@5   0.00 (  0.00)
 * Acc@1 0.692 Acc@5 0.000
62
TRAINING
Epoch: [62][0/1]	Time  0.924 ( 0.924)	Data  0.241 ( 0.241)	Loss 8.0792e-02 (8.0792e-02)	Acc@1   0.93 (  0.93)	Acc@5   0.00 (  0.00)
[0.928017453724545]
Test: [0/1]	Time  0.226 ( 0.226)	Loss 9.4345e-01 (9.4345e-01)	Acc@1   0.66 (  0.66)	Acc@5   0.00 (  0.00)
 * Acc@1 0.656 Acc@5 0.000
Test: [0/1]	Time  0.283 ( 0.283)	Loss 1.4280e-01 (1.4280e-01)	Acc@1   0.69 (  0.69)	Acc@5   0.00 (  0.00)
 * Acc@1 0.694 Acc@5 0.000
63
TRAINING
Epoch: [63][0/1]	Time  0.915 ( 0.915)	Data  0.242 ( 0.242)	Loss 8.0489e-02 (8.0489e-02)	Acc@1   0.93 (  0.93)	Acc@5   0.00 (  0.00)
[0.9294635580762515]
Test: [0/1]	Time  0.243 ( 0.243)	Loss 9.4390e-01 (9.4390e-01)	Acc@1   0.66 (  0.66)	Acc@5   0.00 (  0.00)
 * Acc@1 0.659 Acc@5 0.000
Test: [0/1]	Time  0.311 ( 0.311)	Loss 1.4235e-01 (1.4235e-01)	Acc@1   0.70 (  0.70)	Acc@5   0.00 (  0.00)
 * Acc@1 0.695 Acc@5 0.000
64
TRAINING
Epoch: [64][0/1]	Time  0.938 ( 0.938)	Data  0.251 ( 0.251)	Loss 8.0175e-02 (8.0175e-02)	Acc@1   0.93 (  0.93)	Acc@5   0.00 (  0.00)
[0.9306711608237777]
Test: [0/1]	Time  0.234 ( 0.234)	Loss 9.4442e-01 (9.4442e-01)	Acc@1   0.66 (  0.66)	Acc@5   0.00 (  0.00)
 * Acc@1 0.661 Acc@5 0.000
Test: [0/1]	Time  0.283 ( 0.283)	Loss 1.4193e-01 (1.4193e-01)	Acc@1   0.70 (  0.70)	Acc@5   0.00 (  0.00)
 * Acc@1 0.696 Acc@5 0.000
65
TRAINING
Epoch: [65][0/1]	Time  0.923 ( 0.923)	Data  0.249 ( 0.249)	Loss 7.9927e-02 (7.9927e-02)	Acc@1   0.93 (  0.93)	Acc@5   0.00 (  0.00)
[0.9316529657715014]
Test: [0/1]	Time  0.228 ( 0.228)	Loss 9.4492e-01 (9.4492e-01)	Acc@1   0.66 (  0.66)	Acc@5   0.00 (  0.00)
 * Acc@1 0.663 Acc@5 0.000
Test: [0/1]	Time  0.282 ( 0.282)	Loss 1.4159e-01 (1.4159e-01)	Acc@1   0.70 (  0.70)	Acc@5   0.00 (  0.00)
 * Acc@1 0.697 Acc@5 0.000
66
TRAINING
Epoch: [66][0/1]	Time  0.965 ( 0.965)	Data  0.258 ( 0.258)	Loss 7.9774e-02 (7.9774e-02)	Acc@1   0.93 (  0.93)	Acc@5   0.00 (  0.00)
[0.9324310933137456]
Test: [0/1]	Time  0.244 ( 0.244)	Loss 9.4532e-01 (9.4532e-01)	Acc@1   0.67 (  0.67)	Acc@5   0.00 (  0.00)
 * Acc@1 0.666 Acc@5 0.000
Test: [0/1]	Time  0.293 ( 0.293)	Loss 1.4133e-01 (1.4133e-01)	Acc@1   0.70 (  0.70)	Acc@5   0.00 (  0.00)
 * Acc@1 0.697 Acc@5 0.000
67
TRAINING
Epoch: [67][0/1]	Time  0.956 ( 0.956)	Data  0.254 ( 0.254)	Loss 7.9694e-02 (7.9694e-02)	Acc@1   0.93 (  0.93)	Acc@5   0.00 (  0.00)
[0.9326945935793689]
Test: [0/1]	Time  0.239 ( 0.239)	Loss 9.4555e-01 (9.4555e-01)	Acc@1   0.67 (  0.67)	Acc@5   0.00 (  0.00)
 * Acc@1 0.670 Acc@5 0.000
Test: [0/1]	Time  0.283 ( 0.283)	Loss 1.4112e-01 (1.4112e-01)	Acc@1   0.70 (  0.70)	Acc@5   0.00 (  0.00)
 * Acc@1 0.698 Acc@5 0.000
68
TRAINING
Epoch: [68][0/1]	Time  0.949 ( 0.949)	Data  0.250 ( 0.250)	Loss 7.9638e-02 (7.9638e-02)	Acc@1   0.93 (  0.93)	Acc@5   0.00 (  0.00)
[0.9327502729565829]
Test: [0/1]	Time  0.235 ( 0.235)	Loss 9.4560e-01 (9.4560e-01)	Acc@1   0.67 (  0.67)	Acc@5   0.00 (  0.00)
 * Acc@1 0.673 Acc@5 0.000
Test: [0/1]	Time  0.284 ( 0.284)	Loss 1.4092e-01 (1.4092e-01)	Acc@1   0.70 (  0.70)	Acc@5   0.00 (  0.00)
 * Acc@1 0.699 Acc@5 0.000
69
TRAINING
Epoch: [69][0/1]	Time  0.978 ( 0.978)	Data  0.269 ( 0.269)	Loss 7.9567e-02 (7.9567e-02)	Acc@1   0.93 (  0.93)	Acc@5   0.00 (  0.00)
[0.9327229335739677]
Test: [0/1]	Time  0.240 ( 0.240)	Loss 9.4546e-01 (9.4546e-01)	Acc@1   0.68 (  0.68)	Acc@5   0.00 (  0.00)
 * Acc@1 0.677 Acc@5 0.000
Test: [0/1]	Time  0.291 ( 0.291)	Loss 1.4074e-01 (1.4074e-01)	Acc@1   0.70 (  0.70)	Acc@5   0.00 (  0.00)
 * Acc@1 0.700 Acc@5 0.000
70
TRAINING
Epoch: [70][0/1]	Time  0.961 ( 0.961)	Data  0.261 ( 0.261)	Loss 7.9469e-02 (7.9469e-02)	Acc@1   0.93 (  0.93)	Acc@5   0.00 (  0.00)
[0.9326423338010004]
Test: [0/1]	Time  0.251 ( 0.251)	Loss 9.4516e-01 (9.4516e-01)	Acc@1   0.68 (  0.68)	Acc@5   0.00 (  0.00)
 * Acc@1 0.680 Acc@5 0.000
Test: [0/1]	Time  0.303 ( 0.303)	Loss 1.4057e-01 (1.4057e-01)	Acc@1   0.70 (  0.70)	Acc@5   0.00 (  0.00)
 * Acc@1 0.701 Acc@5 0.000
71
TRAINING
Epoch: [71][0/1]	Time  0.948 ( 0.948)	Data  0.253 ( 0.253)	Loss 7.9362e-02 (7.9362e-02)	Acc@1   0.93 (  0.93)	Acc@5   0.00 (  0.00)
[0.9325320084404112]
Test: [0/1]	Time  0.240 ( 0.240)	Loss 9.4477e-01 (9.4477e-01)	Acc@1   0.68 (  0.68)	Acc@5   0.00 (  0.00)
 * Acc@1 0.683 Acc@5 0.000
Test: [0/1]	Time  0.301 ( 0.301)	Loss 1.4044e-01 (1.4044e-01)	Acc@1   0.70 (  0.70)	Acc@5   0.00 (  0.00)
 * Acc@1 0.701 Acc@5 0.000
72
TRAINING
Epoch: [72][0/1]	Time  1.051 ( 1.051)	Data  0.276 ( 0.276)	Loss 7.9276e-02 (7.9276e-02)	Acc@1   0.93 (  0.93)	Acc@5   0.00 (  0.00)
[0.9324096882219794]
Test: [0/1]	Time  0.245 ( 0.245)	Loss 9.4434e-01 (9.4434e-01)	Acc@1   0.69 (  0.69)	Acc@5   0.00 (  0.00)
 * Acc@1 0.686 Acc@5 0.000
Test: [0/1]	Time  0.292 ( 0.292)	Loss 1.4036e-01 (1.4036e-01)	Acc@1   0.70 (  0.70)	Acc@5   0.00 (  0.00)
 * Acc@1 0.702 Acc@5 0.000
73
TRAINING
Epoch: [73][0/1]	Time  0.968 ( 0.968)	Data  0.262 ( 0.262)	Loss 7.9229e-02 (7.9229e-02)	Acc@1   0.93 (  0.93)	Acc@5   0.00 (  0.00)
[0.9322886678851907]
Test: [0/1]	Time  0.238 ( 0.238)	Loss 9.4395e-01 (9.4395e-01)	Acc@1   0.69 (  0.69)	Acc@5   0.00 (  0.00)
 * Acc@1 0.688 Acc@5 0.000
Test: [0/1]	Time  0.289 ( 0.289)	Loss 1.4031e-01 (1.4031e-01)	Acc@1   0.70 (  0.70)	Acc@5   0.00 (  0.00)
 * Acc@1 0.702 Acc@5 0.000
74
TRAINING
Epoch: [74][0/1]	Time  0.969 ( 0.969)	Data  0.255 ( 0.255)	Loss 7.9219e-02 (7.9219e-02)	Acc@1   0.93 (  0.93)	Acc@5   0.00 (  0.00)
[0.9321789749474014]
Test: [0/1]	Time  0.240 ( 0.240)	Loss 9.4363e-01 (9.4363e-01)	Acc@1   0.69 (  0.69)	Acc@5   0.00 (  0.00)
 * Acc@1 0.691 Acc@5 0.000
Test: [0/1]	Time  0.288 ( 0.288)	Loss 1.4026e-01 (1.4026e-01)	Acc@1   0.70 (  0.70)	Acc@5   0.00 (  0.00)
 * Acc@1 0.703 Acc@5 0.000
75
TRAINING
Epoch: [75][0/1]	Time  0.965 ( 0.965)	Data  0.268 ( 0.268)	Loss 7.9225e-02 (7.9225e-02)	Acc@1   0.93 (  0.93)	Acc@5   0.00 (  0.00)
[0.9320878049043476]
Test: [0/1]	Time  0.242 ( 0.242)	Loss 9.4343e-01 (9.4343e-01)	Acc@1   0.69 (  0.69)	Acc@5   0.00 (  0.00)
 * Acc@1 0.693 Acc@5 0.000
Test: [0/1]	Time  0.295 ( 0.295)	Loss 1.4018e-01 (1.4018e-01)	Acc@1   0.70 (  0.70)	Acc@5   0.00 (  0.00)
 * Acc@1 0.704 Acc@5 0.000
76
TRAINING
Epoch: [76][0/1]	Time  0.997 ( 0.997)	Data  0.298 ( 0.298)	Loss 7.9221e-02 (7.9221e-02)	Acc@1   0.93 (  0.93)	Acc@5   0.00 (  0.00)
[0.9322978187495801]
Test: [0/1]	Time  0.235 ( 0.235)	Loss 9.4334e-01 (9.4334e-01)	Acc@1   0.69 (  0.69)	Acc@5   0.00 (  0.00)
 * Acc@1 0.695 Acc@5 0.000
Test: [0/1]	Time  0.287 ( 0.287)	Loss 1.4007e-01 (1.4007e-01)	Acc@1   0.70 (  0.70)	Acc@5   0.00 (  0.00)
 * Acc@1 0.705 Acc@5 0.000
77
TRAINING
Epoch: [77][0/1]	Time  0.954 ( 0.954)	Data  0.249 ( 0.249)	Loss 7.9190e-02 (7.9190e-02)	Acc@1   0.93 (  0.93)	Acc@5   0.00 (  0.00)
[0.9326046204381406]
Test: [0/1]	Time  0.232 ( 0.232)	Loss 9.4335e-01 (9.4335e-01)	Acc@1   0.70 (  0.70)	Acc@5   0.00 (  0.00)
 * Acc@1 0.697 Acc@5 0.000
Test: [0/1]	Time  0.288 ( 0.288)	Loss 1.3991e-01 (1.3991e-01)	Acc@1   0.71 (  0.71)	Acc@5   0.00 (  0.00)
 * Acc@1 0.706 Acc@5 0.000
78
TRAINING
Epoch: [78][0/1]	Time  0.974 ( 0.974)	Data  0.257 ( 0.257)	Loss 7.9135e-02 (7.9135e-02)	Acc@1   0.93 (  0.93)	Acc@5   0.00 (  0.00)
[0.9328707573223733]
Test: [0/1]	Time  0.234 ( 0.234)	Loss 9.4346e-01 (9.4346e-01)	Acc@1   0.70 (  0.70)	Acc@5   0.00 (  0.00)
 * Acc@1 0.698 Acc@5 0.000
Test: [0/1]	Time  0.285 ( 0.285)	Loss 1.3973e-01 (1.3973e-01)	Acc@1   0.71 (  0.71)	Acc@5   0.00 (  0.00)
 * Acc@1 0.706 Acc@5 0.000
79
TRAINING
Epoch: [79][0/1]	Time  0.965 ( 0.965)	Data  0.260 ( 0.260)	Loss 7.9069e-02 (7.9069e-02)	Acc@1   0.93 (  0.93)	Acc@5   0.00 (  0.00)
[0.9330972408746536]
Test: [0/1]	Time  0.243 ( 0.243)	Loss 9.4361e-01 (9.4361e-01)	Acc@1   0.70 (  0.70)	Acc@5   0.00 (  0.00)
 * Acc@1 0.700 Acc@5 0.000
Test: [0/1]	Time  0.293 ( 0.293)	Loss 1.3956e-01 (1.3956e-01)	Acc@1   0.71 (  0.71)	Acc@5   0.00 (  0.00)
 * Acc@1 0.707 Acc@5 0.000
80
TRAINING
Epoch: [80][0/1]	Time  0.961 ( 0.961)	Data  0.245 ( 0.245)	Loss 7.9009e-02 (7.9009e-02)	Acc@1   0.93 (  0.93)	Acc@5   0.00 (  0.00)
[0.9332897654836856]
Test: [0/1]	Time  0.231 ( 0.231)	Loss 9.4378e-01 (9.4378e-01)	Acc@1   0.70 (  0.70)	Acc@5   0.00 (  0.00)
 * Acc@1 0.701 Acc@5 0.000
Test: [0/1]	Time  0.319 ( 0.319)	Loss 1.3941e-01 (1.3941e-01)	Acc@1   0.71 (  0.71)	Acc@5   0.00 (  0.00)
 * Acc@1 0.708 Acc@5 0.000
81
TRAINING
Epoch: [81][0/1]	Time  0.965 ( 0.965)	Data  0.264 ( 0.264)	Loss 7.8966e-02 (7.8966e-02)	Acc@1   0.93 (  0.93)	Acc@5   0.00 (  0.00)
[0.9334581969824238]
Test: [0/1]	Time  0.235 ( 0.235)	Loss 9.4390e-01 (9.4390e-01)	Acc@1   0.70 (  0.70)	Acc@5   0.00 (  0.00)
 * Acc@1 0.703 Acc@5 0.000
Test: [0/1]	Time  0.289 ( 0.289)	Loss 1.3929e-01 (1.3929e-01)	Acc@1   0.71 (  0.71)	Acc@5   0.00 (  0.00)
 * Acc@1 0.709 Acc@5 0.000
82
TRAINING
Epoch: [82][0/1]	Time  0.968 ( 0.968)	Data  0.262 ( 0.262)	Loss 7.8941e-02 (7.8941e-02)	Acc@1   0.93 (  0.93)	Acc@5   0.00 (  0.00)
[0.9336147183294756]
Test: [0/1]	Time  0.236 ( 0.236)	Loss 9.4396e-01 (9.4396e-01)	Acc@1   0.70 (  0.70)	Acc@5   0.00 (  0.00)
 * Acc@1 0.704 Acc@5 0.000
Test: [0/1]	Time  0.289 ( 0.289)	Loss 1.3921e-01 (1.3921e-01)	Acc@1   0.71 (  0.71)	Acc@5   0.00 (  0.00)
 * Acc@1 0.709 Acc@5 0.000
83
TRAINING
Epoch: [83][0/1]	Time  0.979 ( 0.979)	Data  0.259 ( 0.259)	Loss 7.8926e-02 (7.8926e-02)	Acc@1   0.93 (  0.93)	Acc@5   0.00 (  0.00)
[0.9337708940697266]
Test: [0/1]	Time  0.244 ( 0.244)	Loss 9.4394e-01 (9.4394e-01)	Acc@1   0.70 (  0.70)	Acc@5   0.00 (  0.00)
 * Acc@1 0.705 Acc@5 0.000
Test: [0/1]	Time  0.296 ( 0.296)	Loss 1.3914e-01 (1.3914e-01)	Acc@1   0.71 (  0.71)	Acc@5   0.00 (  0.00)
 * Acc@1 0.710 Acc@5 0.000
84
TRAINING
Epoch: [84][0/1]	Time  0.968 ( 0.968)	Data  0.250 ( 0.250)	Loss 7.8911e-02 (7.8911e-02)	Acc@1   0.93 (  0.93)	Acc@5   0.00 (  0.00)
[0.933839187633708]
Test: [0/1]	Time  0.257 ( 0.257)	Loss 9.4383e-01 (9.4383e-01)	Acc@1   0.71 (  0.71)	Acc@5   0.00 (  0.00)
 * Acc@1 0.706 Acc@5 0.000
Test: [0/1]	Time  0.304 ( 0.304)	Loss 1.3910e-01 (1.3910e-01)	Acc@1   0.71 (  0.71)	Acc@5   0.00 (  0.00)
 * Acc@1 0.711 Acc@5 0.000
85
TRAINING
Epoch: [85][0/1]	Time  0.948 ( 0.948)	Data  0.253 ( 0.253)	Loss 7.8893e-02 (7.8893e-02)	Acc@1   0.93 (  0.93)	Acc@5   0.00 (  0.00)
[0.9338206646713243]
Test: [0/1]	Time  0.235 ( 0.235)	Loss 9.4365e-01 (9.4365e-01)	Acc@1   0.71 (  0.71)	Acc@5   0.00 (  0.00)
 * Acc@1 0.706 Acc@5 0.000
Test: [0/1]	Time  0.288 ( 0.288)	Loss 1.3907e-01 (1.3907e-01)	Acc@1   0.71 (  0.71)	Acc@5   0.00 (  0.00)
 * Acc@1 0.711 Acc@5 0.000
86
TRAINING
Epoch: [86][0/1]	Time  0.954 ( 0.954)	Data  0.256 ( 0.256)	Loss 7.8871e-02 (7.8871e-02)	Acc@1   0.93 (  0.93)	Acc@5   0.00 (  0.00)
[0.933859570052957]
Test: [0/1]	Time  0.234 ( 0.234)	Loss 9.4341e-01 (9.4341e-01)	Acc@1   0.71 (  0.71)	Acc@5   0.00 (  0.00)
 * Acc@1 0.707 Acc@5 0.000
Test: [0/1]	Time  0.284 ( 0.284)	Loss 1.3906e-01 (1.3906e-01)	Acc@1   0.71 (  0.71)	Acc@5   0.00 (  0.00)
 * Acc@1 0.712 Acc@5 0.000
87
TRAINING
Epoch: [87][0/1]	Time  0.962 ( 0.962)	Data  0.259 ( 0.259)	Loss 7.8851e-02 (7.8851e-02)	Acc@1   0.93 (  0.93)	Acc@5   0.00 (  0.00)
[0.9339439013817461]
Test: [0/1]	Time  0.252 ( 0.252)	Loss 9.4314e-01 (9.4314e-01)	Acc@1   0.71 (  0.71)	Acc@5   0.00 (  0.00)
 * Acc@1 0.708 Acc@5 0.000
Test: [0/1]	Time  0.300 ( 0.300)	Loss 1.3907e-01 (1.3907e-01)	Acc@1   0.71 (  0.71)	Acc@5   0.00 (  0.00)
 * Acc@1 0.712 Acc@5 0.000
88
TRAINING
Epoch: [88][0/1]	Time  0.962 ( 0.962)	Data  0.255 ( 0.255)	Loss 7.8837e-02 (7.8837e-02)	Acc@1   0.93 (  0.93)	Acc@5   0.00 (  0.00)
[0.934057522747658]
Test: [0/1]	Time  0.237 ( 0.237)	Loss 9.4288e-01 (9.4288e-01)	Acc@1   0.71 (  0.71)	Acc@5   0.00 (  0.00)
 * Acc@1 0.708 Acc@5 0.000
Test: [0/1]	Time  0.286 ( 0.286)	Loss 1.3908e-01 (1.3908e-01)	Acc@1   0.71 (  0.71)	Acc@5   0.00 (  0.00)
 * Acc@1 0.713 Acc@5 0.000
89
TRAINING
Epoch: [89][0/1]	Time  0.947 ( 0.947)	Data  0.262 ( 0.262)	Loss 7.8829e-02 (7.8829e-02)	Acc@1   0.93 (  0.93)	Acc@5   0.00 (  0.00)
[0.9341839949252203]
Test: [0/1]	Time  0.240 ( 0.240)	Loss 9.4265e-01 (9.4265e-01)	Acc@1   0.71 (  0.71)	Acc@5   0.00 (  0.00)
 * Acc@1 0.708 Acc@5 0.000
Test: [0/1]	Time  0.299 ( 0.299)	Loss 1.3910e-01 (1.3910e-01)	Acc@1   0.71 (  0.71)	Acc@5   0.00 (  0.00)
 * Acc@1 0.713 Acc@5 0.000
90
TRAINING
Epoch: [90][0/1]	Time  0.943 ( 0.943)	Data  0.247 ( 0.247)	Loss 7.8824e-02 (7.8824e-02)	Acc@1   0.93 (  0.93)	Acc@5   0.00 (  0.00)
[0.9343093800973918]
Test: [0/1]	Time  0.251 ( 0.251)	Loss 9.4247e-01 (9.4247e-01)	Acc@1   0.71 (  0.71)	Acc@5   0.00 (  0.00)
 * Acc@1 0.709 Acc@5 0.000
Test: [0/1]	Time  0.303 ( 0.303)	Loss 1.3911e-01 (1.3911e-01)	Acc@1   0.71 (  0.71)	Acc@5   0.00 (  0.00)
 * Acc@1 0.714 Acc@5 0.000
91
TRAINING
Epoch: [91][0/1]	Time  0.980 ( 0.980)	Data  0.285 ( 0.285)	Loss 7.8817e-02 (7.8817e-02)	Acc@1   0.93 (  0.93)	Acc@5   0.00 (  0.00)
[0.934423645767635]
Test: [0/1]	Time  0.238 ( 0.238)	Loss 9.4234e-01 (9.4234e-01)	Acc@1   0.71 (  0.71)	Acc@5   0.00 (  0.00)
 * Acc@1 0.709 Acc@5 0.000
Test: [0/1]	Time  0.289 ( 0.289)	Loss 1.3910e-01 (1.3910e-01)	Acc@1   0.71 (  0.71)	Acc@5   0.00 (  0.00)
 * Acc@1 0.714 Acc@5 0.000
92
TRAINING
Epoch: [92][0/1]	Time  0.961 ( 0.961)	Data  0.262 ( 0.262)	Loss 7.8802e-02 (7.8802e-02)	Acc@1   0.93 (  0.93)	Acc@5   0.00 (  0.00)
[0.934520963891949]
Test: [0/1]	Time  0.241 ( 0.241)	Loss 9.4228e-01 (9.4228e-01)	Acc@1   0.71 (  0.71)	Acc@5   0.00 (  0.00)
 * Acc@1 0.709 Acc@5 0.000
Test: [0/1]	Time  0.295 ( 0.295)	Loss 1.3908e-01 (1.3908e-01)	Acc@1   0.71 (  0.71)	Acc@5   0.00 (  0.00)
 * Acc@1 0.714 Acc@5 0.000
93
TRAINING
Epoch: [93][0/1]	Time  0.956 ( 0.956)	Data  0.260 ( 0.260)	Loss 7.8780e-02 (7.8780e-02)	Acc@1   0.93 (  0.93)	Acc@5   0.00 (  0.00)
[0.9345994650245693]
Test: [0/1]	Time  0.248 ( 0.248)	Loss 9.4226e-01 (9.4226e-01)	Acc@1   0.71 (  0.71)	Acc@5   0.00 (  0.00)
 * Acc@1 0.709 Acc@5 0.000
Test: [0/1]	Time  0.289 ( 0.289)	Loss 1.3904e-01 (1.3904e-01)	Acc@1   0.71 (  0.71)	Acc@5   0.00 (  0.00)
 * Acc@1 0.714 Acc@5 0.000
94
TRAINING
Epoch: [94][0/1]	Time  0.961 ( 0.961)	Data  0.253 ( 0.253)	Loss 7.8752e-02 (7.8752e-02)	Acc@1   0.93 (  0.93)	Acc@5   0.00 (  0.00)
[0.9346608447594154]
Test: [0/1]	Time  0.239 ( 0.239)	Loss 9.4227e-01 (9.4227e-01)	Acc@1   0.71 (  0.71)	Acc@5   0.00 (  0.00)
 * Acc@1 0.709 Acc@5 0.000
Test: [0/1]	Time  0.310 ( 0.310)	Loss 1.3900e-01 (1.3900e-01)	Acc@1   0.71 (  0.71)	Acc@5   0.00 (  0.00)
 * Acc@1 0.714 Acc@5 0.000
95
TRAINING
Epoch: [95][0/1]	Time  0.995 ( 0.995)	Data  0.284 ( 0.284)	Loss 7.8724e-02 (7.8724e-02)	Acc@1   0.93 (  0.93)	Acc@5   0.00 (  0.00)
[0.9347098690135967]
Test: [0/1]	Time  0.258 ( 0.258)	Loss 9.4230e-01 (9.4230e-01)	Acc@1   0.71 (  0.71)	Acc@5   0.00 (  0.00)
 * Acc@1 0.709 Acc@5 0.000
Test: [0/1]	Time  0.303 ( 0.303)	Loss 1.3896e-01 (1.3896e-01)	Acc@1   0.71 (  0.71)	Acc@5   0.00 (  0.00)
 * Acc@1 0.715 Acc@5 0.000
96
TRAINING
Epoch: [96][0/1]	Time  0.974 ( 0.974)	Data  0.260 ( 0.260)	Loss 7.8698e-02 (7.8698e-02)	Acc@1   0.93 (  0.93)	Acc@5   0.00 (  0.00)
[0.9346352101821818]
Test: [0/1]	Time  0.235 ( 0.235)	Loss 9.4233e-01 (9.4233e-01)	Acc@1   0.71 (  0.71)	Acc@5   0.00 (  0.00)
 * Acc@1 0.709 Acc@5 0.000
Test: [0/1]	Time  0.291 ( 0.291)	Loss 1.3893e-01 (1.3893e-01)	Acc@1   0.71 (  0.71)	Acc@5   0.00 (  0.00)
 * Acc@1 0.715 Acc@5 0.000
97
TRAINING
Epoch: [97][0/1]	Time  0.975 ( 0.975)	Data  0.265 ( 0.265)	Loss 7.8676e-02 (7.8676e-02)	Acc@1   0.93 (  0.93)	Acc@5   0.00 (  0.00)
[0.9345418829046951]
Test: [0/1]	Time  0.241 ( 0.241)	Loss 9.4234e-01 (9.4234e-01)	Acc@1   0.71 (  0.71)	Acc@5   0.00 (  0.00)
 * Acc@1 0.709 Acc@5 0.000
Test: [0/1]	Time  0.313 ( 0.313)	Loss 1.3891e-01 (1.3891e-01)	Acc@1   0.71 (  0.71)	Acc@5   0.00 (  0.00)
 * Acc@1 0.715 Acc@5 0.000
98
TRAINING
Epoch: [98][0/1]	Time  0.955 ( 0.955)	Data  0.268 ( 0.268)	Loss 7.8659e-02 (7.8659e-02)	Acc@1   0.93 (  0.93)	Acc@5   0.00 (  0.00)
[0.934462435051902]
Test: [0/1]	Time  0.237 ( 0.237)	Loss 9.4232e-01 (9.4232e-01)	Acc@1   0.71 (  0.71)	Acc@5   0.00 (  0.00)
 * Acc@1 0.709 Acc@5 0.000
Test: [0/1]	Time  0.287 ( 0.287)	Loss 1.3889e-01 (1.3889e-01)	Acc@1   0.71 (  0.71)	Acc@5   0.00 (  0.00)
 * Acc@1 0.715 Acc@5 0.000
99
TRAINING
Epoch: [99][0/1]	Time  0.940 ( 0.940)	Data  0.256 ( 0.256)	Loss 7.8644e-02 (7.8644e-02)	Acc@1   0.93 (  0.93)	Acc@5   0.00 (  0.00)
[0.934405416278544]
Test: [0/1]	Time  0.238 ( 0.238)	Loss 9.4228e-01 (9.4228e-01)	Acc@1   0.71 (  0.71)	Acc@5   0.00 (  0.00)
 * Acc@1 0.709 Acc@5 0.000
Test: [0/1]	Time  0.301 ( 0.301)	Loss 1.3889e-01 (1.3889e-01)	Acc@1   0.72 (  0.72)	Acc@5   0.00 (  0.00)
 * Acc@1 0.715 Acc@5 0.000
=> using pre-trained model 'st_resnet'
s/ohp/session_1
torch.Size([640, 3, 224, 224])
(640, 22)
attach reg
0
TRAINING
/home/helenr6/Adv_mapper/train_split.py:125: UserWarning: You have chosen to seed training. This will turn on the CUDNN deterministic setting, which can slow down your training considerably! You may see unexpected behavior when restarting from checkpoints.
  warnings.warn('You have chosen to seed training. '
/localscratch/helenr6.6279052.0/env/lib/python3.7/site-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  cpuset_checked))
Epoch: [0][0/1]	Time  5.182 ( 5.182)	Data  1.763 ( 1.763)	Loss 1.7722e+00 (1.7722e+00)	Acc@1  -0.00 ( -0.00)	Acc@5   0.00 (  0.00)
[-0.0024964744763283156]
Test: [0/1]	Time  0.433 ( 0.433)	Loss 1.1613e+00 (1.1613e+00)	Acc@1   0.04 (  0.04)	Acc@5   0.00 (  0.00)
 * Acc@1 0.037 Acc@5 0.000
Test: [0/1]	Time  0.547 ( 0.547)	Loss 9.4538e-01 (9.4538e-01)	Acc@1   0.03 (  0.03)	Acc@5   0.00 (  0.00)
 * Acc@1 0.029 Acc@5 0.000
1
TRAINING
Epoch: [1][0/1]	Time  0.960 ( 0.960)	Data  0.244 ( 0.244)	Loss 1.6785e+00 (1.6785e+00)	Acc@1   0.00 (  0.00)	Acc@5   0.00 (  0.00)
[0.0006906521451422211]
Test: [0/1]	Time  0.235 ( 0.235)	Loss 1.1685e+00 (1.1685e+00)	Acc@1   0.04 (  0.04)	Acc@5   0.00 (  0.00)
 * Acc@1 0.040 Acc@5 0.000
Test: [0/1]	Time  0.287 ( 0.287)	Loss 8.9070e-01 (8.9070e-01)	Acc@1   0.03 (  0.03)	Acc@5   0.00 (  0.00)
 * Acc@1 0.035 Acc@5 0.000
2
TRAINING
Epoch: [2][0/1]	Time  0.949 ( 0.949)	Data  0.251 ( 0.251)	Loss 1.5383e+00 (1.5383e+00)	Acc@1   0.01 (  0.01)	Acc@5   0.00 (  0.00)
[0.006695719874549665]
Test: [0/1]	Time  0.240 ( 0.240)	Loss 1.1783e+00 (1.1783e+00)	Acc@1   0.05 (  0.05)	Acc@5   0.00 (  0.00)
 * Acc@1 0.048 Acc@5 0.000
Test: [0/1]	Time  0.288 ( 0.288)	Loss 8.4735e-01 (8.4735e-01)	Acc@1   0.05 (  0.05)	Acc@5   0.00 (  0.00)
 * Acc@1 0.045 Acc@5 0.000
3
TRAINING
Epoch: [3][0/1]	Time  0.942 ( 0.942)	Data  0.244 ( 0.244)	Loss 1.4047e+00 (1.4047e+00)	Acc@1   0.02 (  0.02)	Acc@5   0.00 (  0.00)
[0.015661378789127156]
Test: [0/1]	Time  0.240 ( 0.240)	Loss 1.1900e+00 (1.1900e+00)	Acc@1   0.06 (  0.06)	Acc@5   0.00 (  0.00)
 * Acc@1 0.057 Acc@5 0.000
Test: [0/1]	Time  0.289 ( 0.289)	Loss 8.3135e-01 (8.3135e-01)	Acc@1   0.06 (  0.06)	Acc@5   0.00 (  0.00)
 * Acc@1 0.061 Acc@5 0.000
4
TRAINING
Epoch: [4][0/1]	Time  0.970 ( 0.970)	Data  0.241 ( 0.241)	Loss 1.3077e+00 (1.3077e+00)	Acc@1   0.03 (  0.03)	Acc@5   0.00 (  0.00)
[0.03265872087713854]
Test: [0/1]	Time  0.233 ( 0.233)	Loss 1.1999e+00 (1.1999e+00)	Acc@1   0.07 (  0.07)	Acc@5   0.00 (  0.00)
 * Acc@1 0.066 Acc@5 0.000
Test: [0/1]	Time  0.280 ( 0.280)	Loss 8.3727e-01 (8.3727e-01)	Acc@1   0.07 (  0.07)	Acc@5   0.00 (  0.00)
 * Acc@1 0.066 Acc@5 0.000
5
TRAINING
Epoch: [5][0/1]	Time  0.972 ( 0.972)	Data  0.248 ( 0.248)	Loss 1.2443e+00 (1.2443e+00)	Acc@1   0.06 (  0.06)	Acc@5   0.00 (  0.00)
[0.05765678573797933]
Test: [0/1]	Time  0.234 ( 0.234)	Loss 1.2034e+00 (1.2034e+00)	Acc@1   0.09 (  0.09)	Acc@5   0.00 (  0.00)
 * Acc@1 0.085 Acc@5 0.000
Test: [0/1]	Time  0.284 ( 0.284)	Loss 8.4447e-01 (8.4447e-01)	Acc@1   0.07 (  0.07)	Acc@5   0.00 (  0.00)
 * Acc@1 0.074 Acc@5 0.000
6
TRAINING
Epoch: [6][0/1]	Time  0.993 ( 0.993)	Data  0.258 ( 0.258)	Loss 1.1889e+00 (1.1889e+00)	Acc@1   0.07 (  0.07)	Acc@5   0.00 (  0.00)
[0.07251111130628754]
Test: [0/1]	Time  0.247 ( 0.247)	Loss 1.1963e+00 (1.1963e+00)	Acc@1   0.11 (  0.11)	Acc@5   0.00 (  0.00)
 * Acc@1 0.109 Acc@5 0.000
Test: [0/1]	Time  0.300 ( 0.300)	Loss 8.3152e-01 (8.3152e-01)	Acc@1   0.08 (  0.08)	Acc@5   0.00 (  0.00)
 * Acc@1 0.081 Acc@5 0.000
7
TRAINING
Epoch: [7][0/1]	Time  0.967 ( 0.967)	Data  0.271 ( 0.271)	Loss 1.1150e+00 (1.1150e+00)	Acc@1   0.09 (  0.09)	Acc@5   0.00 (  0.00)
[0.08934970681506549]
Test: [0/1]	Time  0.241 ( 0.241)	Loss 1.1775e+00 (1.1775e+00)	Acc@1   0.14 (  0.14)	Acc@5   0.00 (  0.00)
 * Acc@1 0.141 Acc@5 0.000
Test: [0/1]	Time  0.294 ( 0.294)	Loss 7.8908e-01 (7.8908e-01)	Acc@1   0.09 (  0.09)	Acc@5   0.00 (  0.00)
 * Acc@1 0.090 Acc@5 0.000
8
TRAINING
Epoch: [8][0/1]	Time  0.983 ( 0.983)	Data  0.263 ( 0.263)	Loss 1.0116e+00 (1.0116e+00)	Acc@1   0.11 (  0.11)	Acc@5   0.00 (  0.00)
[0.1050048377843131]
Test: [0/1]	Time  0.244 ( 0.244)	Loss 1.1493e+00 (1.1493e+00)	Acc@1   0.17 (  0.17)	Acc@5   0.00 (  0.00)
 * Acc@1 0.169 Acc@5 0.000
Test: [0/1]	Time  0.295 ( 0.295)	Loss 7.2437e-01 (7.2437e-01)	Acc@1   0.11 (  0.11)	Acc@5   0.00 (  0.00)
 * Acc@1 0.105 Acc@5 0.000
9
TRAINING
Epoch: [9][0/1]	Time  0.962 ( 0.962)	Data  0.272 ( 0.272)	Loss 8.8847e-01 (8.8847e-01)	Acc@1   0.13 (  0.13)	Acc@5   0.00 (  0.00)
[0.12911479292347278]
Test: [0/1]	Time  0.246 ( 0.246)	Loss 1.1162e+00 (1.1162e+00)	Acc@1   0.21 (  0.21)	Acc@5   0.00 (  0.00)
 * Acc@1 0.214 Acc@5 0.000
Test: [0/1]	Time  0.301 ( 0.301)	Loss 6.5535e-01 (6.5535e-01)	Acc@1   0.12 (  0.12)	Acc@5   0.00 (  0.00)
 * Acc@1 0.121 Acc@5 0.000
10
TRAINING
Epoch: [10][0/1]	Time  0.967 ( 0.967)	Data  0.256 ( 0.256)	Loss 7.6729e-01 (7.6729e-01)	Acc@1   0.16 (  0.16)	Acc@5   0.00 (  0.00)
[0.15513675072755517]
Test: [0/1]	Time  0.235 ( 0.235)	Loss 1.0834e+00 (1.0834e+00)	Acc@1   0.26 (  0.26)	Acc@5   0.00 (  0.00)
 * Acc@1 0.262 Acc@5 0.000
Test: [0/1]	Time  0.293 ( 0.293)	Loss 5.9940e-01 (5.9940e-01)	Acc@1   0.13 (  0.13)	Acc@5   0.00 (  0.00)
 * Acc@1 0.134 Acc@5 0.000
11
TRAINING
Epoch: [11][0/1]	Time  0.982 ( 0.982)	Data  0.274 ( 0.274)	Loss 6.6760e-01 (6.6760e-01)	Acc@1   0.18 (  0.18)	Acc@5   0.00 (  0.00)
[0.18301159155275737]
Test: [0/1]	Time  0.246 ( 0.246)	Loss 1.0548e+00 (1.0548e+00)	Acc@1   0.30 (  0.30)	Acc@5   0.00 (  0.00)
 * Acc@1 0.298 Acc@5 0.000
Test: [0/1]	Time  0.300 ( 0.300)	Loss 5.6401e-01 (5.6401e-01)	Acc@1   0.15 (  0.15)	Acc@5   0.00 (  0.00)
 * Acc@1 0.149 Acc@5 0.000
12
TRAINING
Epoch: [12][0/1]	Time  1.023 ( 1.023)	Data  0.311 ( 0.311)	Loss 5.9629e-01 (5.9629e-01)	Acc@1   0.22 (  0.22)	Acc@5   0.00 (  0.00)
[0.22354547203273967]
Test: [0/1]	Time  0.245 ( 0.245)	Loss 1.0323e+00 (1.0323e+00)	Acc@1   0.34 (  0.34)	Acc@5   0.00 (  0.00)
 * Acc@1 0.337 Acc@5 0.000
Test: [0/1]	Time  0.296 ( 0.296)	Loss 5.4439e-01 (5.4439e-01)	Acc@1   0.16 (  0.16)	Acc@5   0.00 (  0.00)
 * Acc@1 0.164 Acc@5 0.000
13
TRAINING
Epoch: [13][0/1]	Time  0.999 ( 0.999)	Data  0.313 ( 0.313)	Loss 5.4615e-01 (5.4615e-01)	Acc@1   0.26 (  0.26)	Acc@5   0.00 (  0.00)
[0.2601735784796513]
Test: [0/1]	Time  0.250 ( 0.250)	Loss 1.0157e+00 (1.0157e+00)	Acc@1   0.37 (  0.37)	Acc@5   0.00 (  0.00)
 * Acc@1 0.374 Acc@5 0.000
Test: [0/1]	Time  0.302 ( 0.302)	Loss 5.2841e-01 (5.2841e-01)	Acc@1   0.18 (  0.18)	Acc@5   0.00 (  0.00)
 * Acc@1 0.179 Acc@5 0.000
14
TRAINING
Epoch: [14][0/1]	Time  1.015 ( 1.015)	Data  0.321 ( 0.321)	Loss 5.0265e-01 (5.0265e-01)	Acc@1   0.29 (  0.29)	Acc@5   0.00 (  0.00)
[0.2901110973632198]
Test: [0/1]	Time  0.244 ( 0.244)	Loss 1.0044e+00 (1.0044e+00)	Acc@1   0.41 (  0.41)	Acc@5   0.00 (  0.00)
 * Acc@1 0.407 Acc@5 0.000
Test: [0/1]	Time  0.299 ( 0.299)	Loss 5.0491e-01 (5.0491e-01)	Acc@1   0.19 (  0.19)	Acc@5   0.00 (  0.00)
 * Acc@1 0.194 Acc@5 0.000
15
TRAINING
Epoch: [15][0/1]	Time  1.008 ( 1.008)	Data  0.313 ( 0.313)	Loss 4.5349e-01 (4.5349e-01)	Acc@1   0.33 (  0.33)	Acc@5   0.00 (  0.00)
[0.33003148260376036]
Test: [0/1]	Time  0.258 ( 0.258)	Loss 9.9754e-01 (9.9754e-01)	Acc@1   0.44 (  0.44)	Acc@5   0.00 (  0.00)
 * Acc@1 0.439 Acc@5 0.000
Test: [0/1]	Time  0.313 ( 0.313)	Loss 4.6996e-01 (4.6996e-01)	Acc@1   0.21 (  0.21)	Acc@5   0.00 (  0.00)
 * Acc@1 0.211 Acc@5 0.000
16
TRAINING
Epoch: [16][0/1]	Time  0.972 ( 0.972)	Data  0.273 ( 0.273)	Loss 3.9516e-01 (3.9516e-01)	Acc@1   0.37 (  0.37)	Acc@5   0.00 (  0.00)
[0.3728134307701969]
Test: [0/1]	Time  0.247 ( 0.247)	Loss 9.9450e-01 (9.9450e-01)	Acc@1   0.47 (  0.47)	Acc@5   0.00 (  0.00)
 * Acc@1 0.468 Acc@5 0.000
Test: [0/1]	Time  0.300 ( 0.300)	Loss 4.2794e-01 (4.2794e-01)	Acc@1   0.23 (  0.23)	Acc@5   0.00 (  0.00)
 * Acc@1 0.230 Acc@5 0.000
17
TRAINING
Epoch: [17][0/1]	Time  0.987 ( 0.987)	Data  0.298 ( 0.298)	Loss 3.3318e-01 (3.3318e-01)	Acc@1   0.41 (  0.41)	Acc@5   0.00 (  0.00)
[0.4117527024782435]
Test: [0/1]	Time  0.260 ( 0.260)	Loss 9.9477e-01 (9.9477e-01)	Acc@1   0.49 (  0.49)	Acc@5   0.00 (  0.00)
 * Acc@1 0.490 Acc@5 0.000
Test: [0/1]	Time  0.306 ( 0.306)	Loss 3.8757e-01 (3.8757e-01)	Acc@1   0.25 (  0.25)	Acc@5   0.00 (  0.00)
 * Acc@1 0.249 Acc@5 0.000
18
TRAINING
Epoch: [18][0/1]	Time  0.961 ( 0.961)	Data  0.268 ( 0.268)	Loss 2.7715e-01 (2.7715e-01)	Acc@1   0.45 (  0.45)	Acc@5   0.00 (  0.00)
[0.45127325802766616]
Test: [0/1]	Time  0.242 ( 0.242)	Loss 9.9745e-01 (9.9745e-01)	Acc@1   0.50 (  0.50)	Acc@5   0.00 (  0.00)
 * Acc@1 0.502 Acc@5 0.000
Test: [0/1]	Time  0.295 ( 0.295)	Loss 3.5611e-01 (3.5611e-01)	Acc@1   0.27 (  0.27)	Acc@5   0.00 (  0.00)
 * Acc@1 0.270 Acc@5 0.000
19
TRAINING
Epoch: [19][0/1]	Time  0.986 ( 0.986)	Data  0.281 ( 0.281)	Loss 2.3446e-01 (2.3446e-01)	Acc@1   0.49 (  0.49)	Acc@5   0.00 (  0.00)
[0.49369796451296]
Test: [0/1]	Time  0.244 ( 0.244)	Loss 1.0010e+00 (1.0010e+00)	Acc@1   0.52 (  0.52)	Acc@5   0.00 (  0.00)
 * Acc@1 0.523 Acc@5 0.000
Test: [0/1]	Time  0.299 ( 0.299)	Loss 3.3537e-01 (3.3537e-01)	Acc@1   0.29 (  0.29)	Acc@5   0.00 (  0.00)
 * Acc@1 0.294 Acc@5 0.000
20
TRAINING
Epoch: [20][0/1]	Time  0.951 ( 0.951)	Data  0.265 ( 0.265)	Loss 2.0636e-01 (2.0636e-01)	Acc@1   0.54 (  0.54)	Acc@5   0.00 (  0.00)
[0.5380283558933787]
Test: [0/1]	Time  0.272 ( 0.272)	Loss 1.0035e+00 (1.0035e+00)	Acc@1   0.55 (  0.55)	Acc@5   0.00 (  0.00)
 * Acc@1 0.548 Acc@5 0.000
Test: [0/1]	Time  0.290 ( 0.290)	Loss 3.2168e-01 (3.2168e-01)	Acc@1   0.32 (  0.32)	Acc@5   0.00 (  0.00)
 * Acc@1 0.319 Acc@5 0.000
21
TRAINING
Epoch: [21][0/1]	Time  0.972 ( 0.972)	Data  0.283 ( 0.283)	Loss 1.8835e-01 (1.8835e-01)	Acc@1   0.58 (  0.58)	Acc@5   0.00 (  0.00)
[0.5829470603845374]
Test: [0/1]	Time  0.249 ( 0.249)	Loss 1.0034e+00 (1.0034e+00)	Acc@1   0.57 (  0.57)	Acc@5   0.00 (  0.00)
 * Acc@1 0.574 Acc@5 0.000
Test: [0/1]	Time  0.299 ( 0.299)	Loss 3.0898e-01 (3.0898e-01)	Acc@1   0.34 (  0.34)	Acc@5   0.00 (  0.00)
 * Acc@1 0.343 Acc@5 0.000
22
TRAINING
Epoch: [22][0/1]	Time  0.997 ( 0.997)	Data  0.291 ( 0.291)	Loss 1.7366e-01 (1.7366e-01)	Acc@1   0.63 (  0.63)	Acc@5   0.00 (  0.00)
[0.6269705028739654]
Test: [0/1]	Time  0.248 ( 0.248)	Loss 9.9977e-01 (9.9977e-01)	Acc@1   0.60 (  0.60)	Acc@5   0.00 (  0.00)
 * Acc@1 0.599 Acc@5 0.000
Test: [0/1]	Time  0.303 ( 0.303)	Loss 2.9280e-01 (2.9280e-01)	Acc@1   0.36 (  0.36)	Acc@5   0.00 (  0.00)
 * Acc@1 0.364 Acc@5 0.000
23
TRAINING
Epoch: [23][0/1]	Time  0.980 ( 0.980)	Data  0.283 ( 0.283)	Loss 1.5735e-01 (1.5735e-01)	Acc@1   0.67 (  0.67)	Acc@5   0.00 (  0.00)
[0.6677947712911536]
Test: [0/1]	Time  0.249 ( 0.249)	Loss 9.9305e-01 (9.9305e-01)	Acc@1   0.62 (  0.62)	Acc@5   0.00 (  0.00)
 * Acc@1 0.624 Acc@5 0.000
Test: [0/1]	Time  0.298 ( 0.298)	Loss 2.7257e-01 (2.7257e-01)	Acc@1   0.39 (  0.39)	Acc@5   0.00 (  0.00)
 * Acc@1 0.385 Acc@5 0.000
24
TRAINING
Epoch: [24][0/1]	Time  0.985 ( 0.985)	Data  0.274 ( 0.274)	Loss 1.3855e-01 (1.3855e-01)	Acc@1   0.71 (  0.71)	Acc@5   0.00 (  0.00)
[0.708204539029183]
Test: [0/1]	Time  0.263 ( 0.263)	Loss 9.8437e-01 (9.8437e-01)	Acc@1   0.65 (  0.65)	Acc@5   0.00 (  0.00)
 * Acc@1 0.645 Acc@5 0.000
Test: [0/1]	Time  0.318 ( 0.318)	Loss 2.5125e-01 (2.5125e-01)	Acc@1   0.41 (  0.41)	Acc@5   0.00 (  0.00)
 * Acc@1 0.407 Acc@5 0.000
25
TRAINING
Epoch: [25][0/1]	Time  0.987 ( 0.987)	Data  0.279 ( 0.279)	Loss 1.1993e-01 (1.1993e-01)	Acc@1   0.74 (  0.74)	Acc@5   0.00 (  0.00)
[0.7425964056019914]
Test: [0/1]	Time  0.248 ( 0.248)	Loss 9.7524e-01 (9.7524e-01)	Acc@1   0.66 (  0.66)	Acc@5   0.00 (  0.00)
 * Acc@1 0.663 Acc@5 0.000
Test: [0/1]	Time  0.301 ( 0.301)	Loss 2.3291e-01 (2.3291e-01)	Acc@1   0.43 (  0.43)	Acc@5   0.00 (  0.00)
 * Acc@1 0.428 Acc@5 0.000
26
TRAINING
Epoch: [26][0/1]	Time  0.978 ( 0.978)	Data  0.287 ( 0.287)	Loss 1.0521e-01 (1.0521e-01)	Acc@1   0.77 (  0.77)	Acc@5   0.00 (  0.00)
[0.7731847948039194]
Test: [0/1]	Time  0.248 ( 0.248)	Loss 9.6693e-01 (9.6693e-01)	Acc@1   0.68 (  0.68)	Acc@5   0.00 (  0.00)
 * Acc@1 0.677 Acc@5 0.000
Test: [0/1]	Time  0.300 ( 0.300)	Loss 2.2012e-01 (2.2012e-01)	Acc@1   0.45 (  0.45)	Acc@5   0.00 (  0.00)
 * Acc@1 0.446 Acc@5 0.000
27
TRAINING
Epoch: [27][0/1]	Time  0.989 ( 0.989)	Data  0.285 ( 0.285)	Loss 9.6572e-02 (9.6572e-02)	Acc@1   0.80 (  0.80)	Acc@5   0.00 (  0.00)
[0.8010451519677317]
Test: [0/1]	Time  0.247 ( 0.247)	Loss 9.6024e-01 (9.6024e-01)	Acc@1   0.69 (  0.69)	Acc@5   0.00 (  0.00)
 * Acc@1 0.687 Acc@5 0.000
Test: [0/1]	Time  0.300 ( 0.300)	Loss 2.1263e-01 (2.1263e-01)	Acc@1   0.46 (  0.46)	Acc@5   0.00 (  0.00)
 * Acc@1 0.464 Acc@5 0.000
28
TRAINING
Epoch: [28][0/1]	Time  0.967 ( 0.967)	Data  0.276 ( 0.276)	Loss 9.3447e-02 (9.3447e-02)	Acc@1   0.82 (  0.82)	Acc@5   0.00 (  0.00)
[0.8241308010577271]
Test: [0/1]	Time  0.267 ( 0.267)	Loss 9.5536e-01 (9.5536e-01)	Acc@1   0.69 (  0.69)	Acc@5   0.00 (  0.00)
 * Acc@1 0.694 Acc@5 0.000
Test: [0/1]	Time  0.315 ( 0.315)	Loss 2.0793e-01 (2.0793e-01)	Acc@1   0.48 (  0.48)	Acc@5   0.00 (  0.00)
 * Acc@1 0.483 Acc@5 0.000
29
TRAINING
Epoch: [29][0/1]	Time  0.975 ( 0.975)	Data  0.273 ( 0.273)	Loss 9.3148e-02 (9.3148e-02)	Acc@1   0.84 (  0.84)	Acc@5   0.00 (  0.00)
[0.8381339532956451]
Test: [0/1]	Time  0.246 ( 0.246)	Loss 9.5214e-01 (9.5214e-01)	Acc@1   0.70 (  0.70)	Acc@5   0.00 (  0.00)
 * Acc@1 0.701 Acc@5 0.000
Test: [0/1]	Time  0.298 ( 0.298)	Loss 2.0302e-01 (2.0302e-01)	Acc@1   0.50 (  0.50)	Acc@5   0.00 (  0.00)
 * Acc@1 0.504 Acc@5 0.000
30
TRAINING
Epoch: [30][0/1]	Time  0.949 ( 0.949)	Data  0.255 ( 0.255)	Loss 9.2616e-02 (9.2616e-02)	Acc@1   0.85 (  0.85)	Acc@5   0.00 (  0.00)
[0.8493348888975292]
Test: [0/1]	Time  0.240 ( 0.240)	Loss 9.5030e-01 (9.5030e-01)	Acc@1   0.71 (  0.71)	Acc@5   0.00 (  0.00)
 * Acc@1 0.705 Acc@5 0.000
Test: [0/1]	Time  0.291 ( 0.291)	Loss 1.9620e-01 (1.9620e-01)	Acc@1   0.52 (  0.52)	Acc@5   0.00 (  0.00)
 * Acc@1 0.525 Acc@5 0.000
31
TRAINING
Epoch: [31][0/1]	Time  0.982 ( 0.982)	Data  0.272 ( 0.272)	Loss 9.0091e-02 (9.0091e-02)	Acc@1   0.86 (  0.86)	Acc@5   0.00 (  0.00)
[0.8595980289816115]
Test: [0/1]	Time  0.246 ( 0.246)	Loss 9.4960e-01 (9.4960e-01)	Acc@1   0.71 (  0.71)	Acc@5   0.00 (  0.00)
 * Acc@1 0.707 Acc@5 0.000
Test: [0/1]	Time  0.300 ( 0.300)	Loss 1.8769e-01 (1.8769e-01)	Acc@1   0.54 (  0.54)	Acc@5   0.00 (  0.00)
 * Acc@1 0.543 Acc@5 0.000
32
TRAINING
Epoch: [32][0/1]	Time  0.965 ( 0.965)	Data  0.260 ( 0.260)	Loss 8.5759e-02 (8.5759e-02)	Acc@1   0.87 (  0.87)	Acc@5   0.00 (  0.00)
[0.8668051824860439]
Test: [0/1]	Time  0.248 ( 0.248)	Loss 9.4981e-01 (9.4981e-01)	Acc@1   0.71 (  0.71)	Acc@5   0.00 (  0.00)
 * Acc@1 0.706 Acc@5 0.000
Test: [0/1]	Time  0.288 ( 0.288)	Loss 1.7916e-01 (1.7916e-01)	Acc@1   0.56 (  0.56)	Acc@5   0.00 (  0.00)
 * Acc@1 0.562 Acc@5 0.000
33
TRAINING
Epoch: [33][0/1]	Time  0.969 ( 0.969)	Data  0.280 ( 0.280)	Loss 8.1197e-02 (8.1197e-02)	Acc@1   0.88 (  0.88)	Acc@5   0.00 (  0.00)
[0.875301538309684]
Test: [0/1]	Time  0.249 ( 0.249)	Loss 9.5066e-01 (9.5066e-01)	Acc@1   0.70 (  0.70)	Acc@5   0.00 (  0.00)
 * Acc@1 0.703 Acc@5 0.000
Test: [0/1]	Time  0.299 ( 0.299)	Loss 1.7244e-01 (1.7244e-01)	Acc@1   0.58 (  0.58)	Acc@5   0.00 (  0.00)
 * Acc@1 0.579 Acc@5 0.000
34
TRAINING
Epoch: [34][0/1]	Time  0.959 ( 0.959)	Data  0.252 ( 0.252)	Loss 7.8145e-02 (7.8145e-02)	Acc@1   0.88 (  0.88)	Acc@5   0.00 (  0.00)
[0.88132440036816]
Test: [0/1]	Time  0.247 ( 0.247)	Loss 9.5178e-01 (9.5178e-01)	Acc@1   0.70 (  0.70)	Acc@5   0.00 (  0.00)
 * Acc@1 0.700 Acc@5 0.000
Test: [0/1]	Time  0.306 ( 0.306)	Loss 1.6841e-01 (1.6841e-01)	Acc@1   0.60 (  0.60)	Acc@5   0.00 (  0.00)
 * Acc@1 0.595 Acc@5 0.000
35
TRAINING
Epoch: [35][0/1]	Time  1.010 ( 1.010)	Data  0.312 ( 0.312)	Loss 7.7438e-02 (7.7438e-02)	Acc@1   0.88 (  0.88)	Acc@5   0.00 (  0.00)
[0.8828223140883944]
Test: [0/1]	Time  0.270 ( 0.270)	Loss 9.5273e-01 (9.5273e-01)	Acc@1   0.70 (  0.70)	Acc@5   0.00 (  0.00)
 * Acc@1 0.698 Acc@5 0.000
Test: [0/1]	Time  0.311 ( 0.311)	Loss 1.6666e-01 (1.6666e-01)	Acc@1   0.61 (  0.61)	Acc@5   0.00 (  0.00)
 * Acc@1 0.609 Acc@5 0.000
36
TRAINING
Epoch: [36][0/1]	Time  0.964 ( 0.964)	Data  0.280 ( 0.280)	Loss 7.8659e-02 (7.8659e-02)	Acc@1   0.88 (  0.88)	Acc@5   0.00 (  0.00)
[0.8835271400561231]
Test: [0/1]	Time  0.262 ( 0.262)	Loss 9.5308e-01 (9.5308e-01)	Acc@1   0.69 (  0.69)	Acc@5   0.00 (  0.00)
 * Acc@1 0.695 Acc@5 0.000
Test: [0/1]	Time  0.305 ( 0.305)	Loss 1.6591e-01 (1.6591e-01)	Acc@1   0.63 (  0.63)	Acc@5   0.00 (  0.00)
 * Acc@1 0.626 Acc@5 0.000
37
TRAINING
Epoch: [37][0/1]	Time  0.962 ( 0.962)	Data  0.264 ( 0.264)	Loss 8.0580e-02 (8.0580e-02)	Acc@1   0.88 (  0.88)	Acc@5   0.00 (  0.00)
[0.8814148406812107]
Test: [0/1]	Time  0.244 ( 0.244)	Loss 9.5257e-01 (9.5257e-01)	Acc@1   0.69 (  0.69)	Acc@5   0.00 (  0.00)
 * Acc@1 0.692 Acc@5 0.000
Test: [0/1]	Time  0.297 ( 0.297)	Loss 1.6490e-01 (1.6490e-01)	Acc@1   0.64 (  0.64)	Acc@5   0.00 (  0.00)
 * Acc@1 0.642 Acc@5 0.000
38
TRAINING
Epoch: [38][0/1]	Time  0.973 ( 0.973)	Data  0.270 ( 0.270)	Loss 8.1975e-02 (8.1975e-02)	Acc@1   0.88 (  0.88)	Acc@5   0.00 (  0.00)
[0.8782885877203153]
Test: [0/1]	Time  0.239 ( 0.239)	Loss 9.5118e-01 (9.5118e-01)	Acc@1   0.69 (  0.69)	Acc@5   0.00 (  0.00)
 * Acc@1 0.689 Acc@5 0.000
Test: [0/1]	Time  0.290 ( 0.290)	Loss 1.6307e-01 (1.6307e-01)	Acc@1   0.66 (  0.66)	Acc@5   0.00 (  0.00)
 * Acc@1 0.656 Acc@5 0.000
39
TRAINING
Epoch: [39][0/1]	Time  0.966 ( 0.966)	Data  0.262 ( 0.262)	Loss 8.2277e-02 (8.2277e-02)	Acc@1   0.88 (  0.88)	Acc@5   0.00 (  0.00)
[0.8768564002890131]
Test: [0/1]	Time  0.254 ( 0.254)	Loss 9.4910e-01 (9.4910e-01)	Acc@1   0.69 (  0.69)	Acc@5   0.00 (  0.00)
 * Acc@1 0.686 Acc@5 0.000
Test: [0/1]	Time  0.320 ( 0.320)	Loss 1.6070e-01 (1.6070e-01)	Acc@1   0.67 (  0.67)	Acc@5   0.00 (  0.00)
 * Acc@1 0.667 Acc@5 0.000
40
TRAINING
Epoch: [40][0/1]	Time  0.959 ( 0.959)	Data  0.256 ( 0.256)	Loss 8.1737e-02 (8.1737e-02)	Acc@1   0.88 (  0.88)	Acc@5   0.00 (  0.00)
[0.8758131170523804]
Test: [0/1]	Time  0.240 ( 0.240)	Loss 9.4667e-01 (9.4667e-01)	Acc@1   0.68 (  0.68)	Acc@5   0.00 (  0.00)
 * Acc@1 0.683 Acc@5 0.000
Test: [0/1]	Time  0.290 ( 0.290)	Loss 1.5854e-01 (1.5854e-01)	Acc@1   0.68 (  0.68)	Acc@5   0.00 (  0.00)
 * Acc@1 0.675 Acc@5 0.000
41
TRAINING
Epoch: [41][0/1]	Time  0.980 ( 0.980)	Data  0.283 ( 0.283)	Loss 8.1077e-02 (8.1077e-02)	Acc@1   0.88 (  0.88)	Acc@5   0.00 (  0.00)
[0.8752513131924261]
Test: [0/1]	Time  0.235 ( 0.235)	Loss 9.4428e-01 (9.4428e-01)	Acc@1   0.68 (  0.68)	Acc@5   0.00 (  0.00)
 * Acc@1 0.678 Acc@5 0.000
Test: [0/1]	Time  0.286 ( 0.286)	Loss 1.5728e-01 (1.5728e-01)	Acc@1   0.68 (  0.68)	Acc@5   0.00 (  0.00)
 * Acc@1 0.682 Acc@5 0.000
42
TRAINING
Epoch: [42][0/1]	Time  0.959 ( 0.959)	Data  0.270 ( 0.270)	Loss 8.0953e-02 (8.0953e-02)	Acc@1   0.88 (  0.88)	Acc@5   0.00 (  0.00)
[0.8751604705429201]
Test: [0/1]	Time  0.245 ( 0.245)	Loss 9.4218e-01 (9.4218e-01)	Acc@1   0.67 (  0.67)	Acc@5   0.00 (  0.00)
 * Acc@1 0.672 Acc@5 0.000
Test: [0/1]	Time  0.333 ( 0.333)	Loss 1.5710e-01 (1.5710e-01)	Acc@1   0.69 (  0.69)	Acc@5   0.00 (  0.00)
 * Acc@1 0.688 Acc@5 0.000
43
TRAINING
Epoch: [43][0/1]	Time  1.001 ( 1.001)	Data  0.292 ( 0.292)	Loss 8.1561e-02 (8.1561e-02)	Acc@1   0.88 (  0.88)	Acc@5   0.00 (  0.00)
[0.8752230913151706]
Test: [0/1]	Time  0.254 ( 0.254)	Loss 9.4057e-01 (9.4057e-01)	Acc@1   0.67 (  0.67)	Acc@5   0.00 (  0.00)
 * Acc@1 0.668 Acc@5 0.000
Test: [0/1]	Time  0.309 ( 0.309)	Loss 1.5763e-01 (1.5763e-01)	Acc@1   0.69 (  0.69)	Acc@5   0.00 (  0.00)
 * Acc@1 0.693 Acc@5 0.000
44
TRAINING
Epoch: [44][0/1]	Time  0.955 ( 0.955)	Data  0.251 ( 0.251)	Loss 8.2586e-02 (8.2586e-02)	Acc@1   0.88 (  0.88)	Acc@5   0.00 (  0.00)
[0.8759571612479293]
Test: [0/1]	Time  0.247 ( 0.247)	Loss 9.3951e-01 (9.3951e-01)	Acc@1   0.66 (  0.66)	Acc@5   0.00 (  0.00)
 * Acc@1 0.664 Acc@5 0.000
Test: [0/1]	Time  0.299 ( 0.299)	Loss 1.5824e-01 (1.5824e-01)	Acc@1   0.70 (  0.70)	Acc@5   0.00 (  0.00)
 * Acc@1 0.695 Acc@5 0.000
45
TRAINING
Epoch: [45][0/1]	Time  0.973 ( 0.973)	Data  0.279 ( 0.279)	Loss 8.3467e-02 (8.3467e-02)	Acc@1   0.88 (  0.88)	Acc@5   0.00 (  0.00)
[0.8774847363136806]
Test: [0/1]	Time  0.246 ( 0.246)	Loss 9.3900e-01 (9.3900e-01)	Acc@1   0.66 (  0.66)	Acc@5   0.00 (  0.00)
 * Acc@1 0.662 Acc@5 0.000
Test: [0/1]	Time  0.299 ( 0.299)	Loss 1.5840e-01 (1.5840e-01)	Acc@1   0.70 (  0.70)	Acc@5   0.00 (  0.00)
 * Acc@1 0.698 Acc@5 0.000
46
TRAINING
Epoch: [46][0/1]	Time  0.994 ( 0.994)	Data  0.286 ( 0.286)	Loss 8.3761e-02 (8.3761e-02)	Acc@1   0.88 (  0.88)	Acc@5   0.00 (  0.00)
[0.880517678129212]
Test: [0/1]	Time  0.246 ( 0.246)	Loss 9.3902e-01 (9.3902e-01)	Acc@1   0.66 (  0.66)	Acc@5   0.00 (  0.00)
 * Acc@1 0.660 Acc@5 0.000
Test: [0/1]	Time  0.293 ( 0.293)	Loss 1.5797e-01 (1.5797e-01)	Acc@1   0.70 (  0.70)	Acc@5   0.00 (  0.00)
 * Acc@1 0.699 Acc@5 0.000
47
TRAINING
Epoch: [47][0/1]	Time  0.961 ( 0.961)	Data  0.264 ( 0.264)	Loss 8.3377e-02 (8.3377e-02)	Acc@1   0.88 (  0.88)	Acc@5   0.00 (  0.00)
[0.8842827687901839]
Test: [0/1]	Time  0.240 ( 0.240)	Loss 9.3948e-01 (9.3948e-01)	Acc@1   0.66 (  0.66)	Acc@5   0.00 (  0.00)
 * Acc@1 0.659 Acc@5 0.000
Test: [0/1]	Time  0.296 ( 0.296)	Loss 1.5720e-01 (1.5720e-01)	Acc@1   0.70 (  0.70)	Acc@5   0.00 (  0.00)
 * Acc@1 0.698 Acc@5 0.000
48
TRAINING
Epoch: [48][0/1]	Time  0.942 ( 0.942)	Data  0.270 ( 0.270)	Loss 8.2570e-02 (8.2570e-02)	Acc@1   0.89 (  0.89)	Acc@5   0.00 (  0.00)
[0.8884781904703845]
Test: [0/1]	Time  0.244 ( 0.244)	Loss 9.4028e-01 (9.4028e-01)	Acc@1   0.66 (  0.66)	Acc@5   0.00 (  0.00)
 * Acc@1 0.659 Acc@5 0.000
Test: [0/1]	Time  0.292 ( 0.292)	Loss 1.5646e-01 (1.5646e-01)	Acc@1   0.70 (  0.70)	Acc@5   0.00 (  0.00)
 * Acc@1 0.696 Acc@5 0.000
49
TRAINING
Epoch: [49][0/1]	Time  0.946 ( 0.946)	Data  0.262 ( 0.262)	Loss 8.1747e-02 (8.1747e-02)	Acc@1   0.89 (  0.89)	Acc@5   0.00 (  0.00)
[0.8926858406961239]
Test: [0/1]	Time  0.238 ( 0.238)	Loss 9.4126e-01 (9.4126e-01)	Acc@1   0.66 (  0.66)	Acc@5   0.00 (  0.00)
 * Acc@1 0.659 Acc@5 0.000
Test: [0/1]	Time  0.290 ( 0.290)	Loss 1.5607e-01 (1.5607e-01)	Acc@1   0.69 (  0.69)	Acc@5   0.00 (  0.00)
 * Acc@1 0.693 Acc@5 0.000
50
TRAINING
Epoch: [50][0/1]	Time  0.968 ( 0.968)	Data  0.261 ( 0.261)	Loss 8.1219e-02 (8.1219e-02)	Acc@1   0.90 (  0.90)	Acc@5   0.00 (  0.00)
[0.8964452120519826]
Test: [0/1]	Time  0.257 ( 0.257)	Loss 9.4225e-01 (9.4225e-01)	Acc@1   0.66 (  0.66)	Acc@5   0.00 (  0.00)
 * Acc@1 0.660 Acc@5 0.000
Test: [0/1]	Time  0.309 ( 0.309)	Loss 1.5611e-01 (1.5611e-01)	Acc@1   0.69 (  0.69)	Acc@5   0.00 (  0.00)
 * Acc@1 0.691 Acc@5 0.000
51
TRAINING
Epoch: [51][0/1]	Time  0.954 ( 0.954)	Data  0.262 ( 0.262)	Loss 8.1060e-02 (8.1060e-02)	Acc@1   0.90 (  0.90)	Acc@5   0.00 (  0.00)
[0.9000880248767077]
Test: [0/1]	Time  0.234 ( 0.234)	Loss 9.4310e-01 (9.4310e-01)	Acc@1   0.66 (  0.66)	Acc@5   0.00 (  0.00)
 * Acc@1 0.661 Acc@5 0.000
Test: [0/1]	Time  0.327 ( 0.327)	Loss 1.5642e-01 (1.5642e-01)	Acc@1   0.69 (  0.69)	Acc@5   0.00 (  0.00)
 * Acc@1 0.691 Acc@5 0.000
52
TRAINING
Epoch: [52][0/1]	Time  0.950 ( 0.950)	Data  0.275 ( 0.275)	Loss 8.1120e-02 (8.1120e-02)	Acc@1   0.90 (  0.90)	Acc@5   0.00 (  0.00)
[0.9035587196706653]
Test: [0/1]	Time  0.238 ( 0.238)	Loss 9.4367e-01 (9.4367e-01)	Acc@1   0.66 (  0.66)	Acc@5   0.00 (  0.00)
 * Acc@1 0.663 Acc@5 0.000
Test: [0/1]	Time  0.289 ( 0.289)	Loss 1.5674e-01 (1.5674e-01)	Acc@1   0.69 (  0.69)	Acc@5   0.00 (  0.00)
 * Acc@1 0.692 Acc@5 0.000
53
TRAINING
Epoch: [53][0/1]	Time  0.938 ( 0.938)	Data  0.265 ( 0.265)	Loss 8.1161e-02 (8.1161e-02)	Acc@1   0.91 (  0.91)	Acc@5   0.00 (  0.00)
[0.9070870687643131]
Test: [0/1]	Time  0.236 ( 0.236)	Loss 9.4389e-01 (9.4389e-01)	Acc@1   0.66 (  0.66)	Acc@5   0.00 (  0.00)
 * Acc@1 0.665 Acc@5 0.000
Test: [0/1]	Time  0.284 ( 0.284)	Loss 1.5691e-01 (1.5691e-01)	Acc@1   0.69 (  0.69)	Acc@5   0.00 (  0.00)
 * Acc@1 0.691 Acc@5 0.000
54
TRAINING
Epoch: [54][0/1]	Time  0.945 ( 0.945)	Data  0.268 ( 0.268)	Loss 8.1018e-02 (8.1018e-02)	Acc@1   0.91 (  0.91)	Acc@5   0.00 (  0.00)
[0.9108170159903386]
Test: [0/1]	Time  0.239 ( 0.239)	Loss 9.4378e-01 (9.4378e-01)	Acc@1   0.67 (  0.67)	Acc@5   0.00 (  0.00)
 * Acc@1 0.667 Acc@5 0.000
Test: [0/1]	Time  0.288 ( 0.288)	Loss 1.5691e-01 (1.5691e-01)	Acc@1   0.69 (  0.69)	Acc@5   0.00 (  0.00)
 * Acc@1 0.691 Acc@5 0.000
55
TRAINING
Epoch: [55][0/1]	Time  0.942 ( 0.942)	Data  0.266 ( 0.266)	Loss 8.0679e-02 (8.0679e-02)	Acc@1   0.91 (  0.91)	Acc@5   0.00 (  0.00)
[0.9140725521811708]
Test: [0/1]	Time  0.237 ( 0.237)	Loss 9.4343e-01 (9.4343e-01)	Acc@1   0.67 (  0.67)	Acc@5   0.00 (  0.00)
 * Acc@1 0.670 Acc@5 0.000
Test: [0/1]	Time  0.289 ( 0.289)	Loss 1.5684e-01 (1.5684e-01)	Acc@1   0.69 (  0.69)	Acc@5   0.00 (  0.00)
 * Acc@1 0.689 Acc@5 0.000
56
TRAINING
Epoch: [56][0/1]	Time  0.960 ( 0.960)	Data  0.267 ( 0.267)	Loss 8.0258e-02 (8.0258e-02)	Acc@1   0.92 (  0.92)	Acc@5   0.00 (  0.00)
[0.9168642941507529]
Test: [0/1]	Time  0.232 ( 0.232)	Loss 9.4295e-01 (9.4295e-01)	Acc@1   0.67 (  0.67)	Acc@5   0.00 (  0.00)
 * Acc@1 0.673 Acc@5 0.000
Test: [0/1]	Time  0.288 ( 0.288)	Loss 1.5684e-01 (1.5684e-01)	Acc@1   0.69 (  0.69)	Acc@5   0.00 (  0.00)
 * Acc@1 0.688 Acc@5 0.000
57
TRAINING
Epoch: [57][0/1]	Time  0.941 ( 0.941)	Data  0.265 ( 0.265)	Loss 7.9907e-02 (7.9907e-02)	Acc@1   0.92 (  0.92)	Acc@5   0.00 (  0.00)
[0.9191152563320693]
Test: [0/1]	Time  0.233 ( 0.233)	Loss 9.4246e-01 (9.4246e-01)	Acc@1   0.68 (  0.68)	Acc@5   0.00 (  0.00)
 * Acc@1 0.676 Acc@5 0.000
Test: [0/1]	Time  0.285 ( 0.285)	Loss 1.5698e-01 (1.5698e-01)	Acc@1   0.69 (  0.69)	Acc@5   0.00 (  0.00)
 * Acc@1 0.685 Acc@5 0.000
58
TRAINING
Epoch: [58][0/1]	Time  0.953 ( 0.953)	Data  0.265 ( 0.265)	Loss 7.9714e-02 (7.9714e-02)	Acc@1   0.92 (  0.92)	Acc@5   0.00 (  0.00)
[0.9205274098441183]
Test: [0/1]	Time  0.240 ( 0.240)	Loss 9.4206e-01 (9.4206e-01)	Acc@1   0.68 (  0.68)	Acc@5   0.00 (  0.00)
 * Acc@1 0.679 Acc@5 0.000
Test: [0/1]	Time  0.286 ( 0.286)	Loss 1.5723e-01 (1.5723e-01)	Acc@1   0.68 (  0.68)	Acc@5   0.00 (  0.00)
 * Acc@1 0.683 Acc@5 0.000
59
TRAINING
Epoch: [59][0/1]	Time  0.933 ( 0.933)	Data  0.259 ( 0.259)	Loss 7.9660e-02 (7.9660e-02)	Acc@1   0.92 (  0.92)	Acc@5   0.00 (  0.00)
[0.921738761105251]
Test: [0/1]	Time  0.235 ( 0.235)	Loss 9.4182e-01 (9.4182e-01)	Acc@1   0.68 (  0.68)	Acc@5   0.00 (  0.00)
 * Acc@1 0.682 Acc@5 0.000
Test: [0/1]	Time  0.282 ( 0.282)	Loss 1.5747e-01 (1.5747e-01)	Acc@1   0.68 (  0.68)	Acc@5   0.00 (  0.00)
 * Acc@1 0.681 Acc@5 0.000
60
TRAINING
Epoch: [60][0/1]	Time  0.945 ( 0.945)	Data  0.243 ( 0.243)	Loss 7.9649e-02 (7.9649e-02)	Acc@1   0.92 (  0.92)	Acc@5   0.00 (  0.00)
[0.922853298290721]
Test: [0/1]	Time  0.231 ( 0.231)	Loss 9.4179e-01 (9.4179e-01)	Acc@1   0.69 (  0.69)	Acc@5   0.00 (  0.00)
 * Acc@1 0.686 Acc@5 0.000
Test: [0/1]	Time  0.282 ( 0.282)	Loss 1.5759e-01 (1.5759e-01)	Acc@1   0.68 (  0.68)	Acc@5   0.00 (  0.00)
 * Acc@1 0.680 Acc@5 0.000
61
TRAINING
Epoch: [61][0/1]	Time  0.921 ( 0.921)	Data  0.249 ( 0.249)	Loss 7.9574e-02 (7.9574e-02)	Acc@1   0.92 (  0.92)	Acc@5   0.00 (  0.00)
[0.9239354153608296]
Test: [0/1]	Time  0.230 ( 0.230)	Loss 9.4196e-01 (9.4196e-01)	Acc@1   0.69 (  0.69)	Acc@5   0.00 (  0.00)
 * Acc@1 0.689 Acc@5 0.000
Test: [0/1]	Time  0.277 ( 0.277)	Loss 1.5754e-01 (1.5754e-01)	Acc@1   0.68 (  0.68)	Acc@5   0.00 (  0.00)
 * Acc@1 0.679 Acc@5 0.000
62
TRAINING
Epoch: [62][0/1]	Time  0.917 ( 0.917)	Data  0.245 ( 0.245)	Loss 7.9380e-02 (7.9380e-02)	Acc@1   0.92 (  0.92)	Acc@5   0.00 (  0.00)
[0.9249983067470079]
Test: [0/1]	Time  0.231 ( 0.231)	Loss 9.4231e-01 (9.4231e-01)	Acc@1   0.69 (  0.69)	Acc@5   0.00 (  0.00)
 * Acc@1 0.693 Acc@5 0.000
Test: [0/1]	Time  0.283 ( 0.283)	Loss 1.5734e-01 (1.5734e-01)	Acc@1   0.68 (  0.68)	Acc@5   0.00 (  0.00)
 * Acc@1 0.680 Acc@5 0.000
63
TRAINING
Epoch: [63][0/1]	Time  0.931 ( 0.931)	Data  0.259 ( 0.259)	Loss 7.9088e-02 (7.9088e-02)	Acc@1   0.93 (  0.93)	Acc@5   0.00 (  0.00)
[0.9260087571875016]
Test: [0/1]	Time  0.240 ( 0.240)	Loss 9.4280e-01 (9.4280e-01)	Acc@1   0.70 (  0.70)	Acc@5   0.00 (  0.00)
 * Acc@1 0.696 Acc@5 0.000
Test: [0/1]	Time  0.289 ( 0.289)	Loss 1.5706e-01 (1.5706e-01)	Acc@1   0.68 (  0.68)	Acc@5   0.00 (  0.00)
 * Acc@1 0.681 Acc@5 0.000
64
TRAINING
Epoch: [64][0/1]	Time  0.926 ( 0.926)	Data  0.252 ( 0.252)	Loss 7.8771e-02 (7.8771e-02)	Acc@1   0.93 (  0.93)	Acc@5   0.00 (  0.00)
[0.9270680171533455]
Test: [0/1]	Time  0.232 ( 0.232)	Loss 9.4335e-01 (9.4335e-01)	Acc@1   0.70 (  0.70)	Acc@5   0.00 (  0.00)
 * Acc@1 0.699 Acc@5 0.000
Test: [0/1]	Time  0.285 ( 0.285)	Loss 1.5680e-01 (1.5680e-01)	Acc@1   0.68 (  0.68)	Acc@5   0.00 (  0.00)
 * Acc@1 0.683 Acc@5 0.000
65
TRAINING
Epoch: [65][0/1]	Time  0.952 ( 0.952)	Data  0.281 ( 0.281)	Loss 7.8506e-02 (7.8506e-02)	Acc@1   0.93 (  0.93)	Acc@5   0.00 (  0.00)
[0.9279230276933761]
Test: [0/1]	Time  0.242 ( 0.242)	Loss 9.4389e-01 (9.4389e-01)	Acc@1   0.70 (  0.70)	Acc@5   0.00 (  0.00)
 * Acc@1 0.703 Acc@5 0.000
Test: [0/1]	Time  0.298 ( 0.298)	Loss 1.5660e-01 (1.5660e-01)	Acc@1   0.68 (  0.68)	Acc@5   0.00 (  0.00)
 * Acc@1 0.684 Acc@5 0.000
66
TRAINING
Epoch: [66][0/1]	Time  0.929 ( 0.929)	Data  0.256 ( 0.256)	Loss 7.8331e-02 (7.8331e-02)	Acc@1   0.93 (  0.93)	Acc@5   0.00 (  0.00)
[0.9285904687433383]
Test: [0/1]	Time  0.231 ( 0.231)	Loss 9.4434e-01 (9.4434e-01)	Acc@1   0.71 (  0.71)	Acc@5   0.00 (  0.00)
 * Acc@1 0.706 Acc@5 0.000
Test: [0/1]	Time  0.289 ( 0.289)	Loss 1.5646e-01 (1.5646e-01)	Acc@1   0.69 (  0.69)	Acc@5   0.00 (  0.00)
 * Acc@1 0.685 Acc@5 0.000
67
TRAINING
Epoch: [67][0/1]	Time  0.931 ( 0.931)	Data  0.257 ( 0.257)	Loss 7.8238e-02 (7.8238e-02)	Acc@1   0.93 (  0.93)	Acc@5   0.00 (  0.00)
[0.929133939135745]
Test: [0/1]	Time  0.236 ( 0.236)	Loss 9.4464e-01 (9.4464e-01)	Acc@1   0.71 (  0.71)	Acc@5   0.00 (  0.00)
 * Acc@1 0.709 Acc@5 0.000
Test: [0/1]	Time  0.290 ( 0.290)	Loss 1.5635e-01 (1.5635e-01)	Acc@1   0.69 (  0.69)	Acc@5   0.00 (  0.00)
 * Acc@1 0.686 Acc@5 0.000
68
TRAINING
Epoch: [68][0/1]	Time  0.930 ( 0.930)	Data  0.256 ( 0.256)	Loss 7.8184e-02 (7.8184e-02)	Acc@1   0.93 (  0.93)	Acc@5   0.00 (  0.00)
[0.9300678975699898]
Test: [0/1]	Time  0.235 ( 0.235)	Loss 9.4476e-01 (9.4476e-01)	Acc@1   0.71 (  0.71)	Acc@5   0.00 (  0.00)
 * Acc@1 0.712 Acc@5 0.000
Test: [0/1]	Time  0.290 ( 0.290)	Loss 1.5624e-01 (1.5624e-01)	Acc@1   0.69 (  0.69)	Acc@5   0.00 (  0.00)
 * Acc@1 0.685 Acc@5 0.000
69
TRAINING
Epoch: [69][0/1]	Time  0.930 ( 0.930)	Data  0.258 ( 0.258)	Loss 7.8126e-02 (7.8126e-02)	Acc@1   0.93 (  0.93)	Acc@5   0.00 (  0.00)
[0.9308172696929732]
Test: [0/1]	Time  0.233 ( 0.233)	Loss 9.4469e-01 (9.4469e-01)	Acc@1   0.71 (  0.71)	Acc@5   0.00 (  0.00)
 * Acc@1 0.715 Acc@5 0.000
Test: [0/1]	Time  0.288 ( 0.288)	Loss 1.5610e-01 (1.5610e-01)	Acc@1   0.69 (  0.69)	Acc@5   0.00 (  0.00)
 * Acc@1 0.686 Acc@5 0.000
70
TRAINING
Epoch: [70][0/1]	Time  0.938 ( 0.938)	Data  0.240 ( 0.240)	Loss 7.8046e-02 (7.8046e-02)	Acc@1   0.93 (  0.93)	Acc@5   0.00 (  0.00)
[0.9310966213078009]
Test: [0/1]	Time  0.227 ( 0.227)	Loss 9.4445e-01 (9.4445e-01)	Acc@1   0.72 (  0.72)	Acc@5   0.00 (  0.00)
 * Acc@1 0.717 Acc@5 0.000
Test: [0/1]	Time  0.278 ( 0.278)	Loss 1.5594e-01 (1.5594e-01)	Acc@1   0.69 (  0.69)	Acc@5   0.00 (  0.00)
 * Acc@1 0.686 Acc@5 0.000
71
TRAINING
Epoch: [71][0/1]	Time  0.920 ( 0.920)	Data  0.246 ( 0.246)	Loss 7.7953e-02 (7.7953e-02)	Acc@1   0.93 (  0.93)	Acc@5   0.00 (  0.00)
[0.9312054117114072]
Test: [0/1]	Time  0.227 ( 0.227)	Loss 9.4410e-01 (9.4410e-01)	Acc@1   0.72 (  0.72)	Acc@5   0.00 (  0.00)
 * Acc@1 0.719 Acc@5 0.000
Test: [0/1]	Time  0.279 ( 0.279)	Loss 1.5579e-01 (1.5579e-01)	Acc@1   0.69 (  0.69)	Acc@5   0.00 (  0.00)
 * Acc@1 0.687 Acc@5 0.000
72
TRAINING
Epoch: [72][0/1]	Time  0.916 ( 0.916)	Data  0.244 ( 0.244)	Loss 7.7874e-02 (7.7874e-02)	Acc@1   0.93 (  0.93)	Acc@5   0.00 (  0.00)
[0.9312267241855419]
Test: [0/1]	Time  0.250 ( 0.250)	Loss 9.4370e-01 (9.4370e-01)	Acc@1   0.72 (  0.72)	Acc@5   0.00 (  0.00)
 * Acc@1 0.721 Acc@5 0.000
Test: [0/1]	Time  0.303 ( 0.303)	Loss 1.5567e-01 (1.5567e-01)	Acc@1   0.69 (  0.69)	Acc@5   0.00 (  0.00)
 * Acc@1 0.687 Acc@5 0.000
73
TRAINING
Epoch: [73][0/1]	Time  0.917 ( 0.917)	Data  0.245 ( 0.245)	Loss 7.7829e-02 (7.7829e-02)	Acc@1   0.93 (  0.93)	Acc@5   0.00 (  0.00)
[0.9311881417328755]
Test: [0/1]	Time  0.227 ( 0.227)	Loss 9.4330e-01 (9.4330e-01)	Acc@1   0.72 (  0.72)	Acc@5   0.00 (  0.00)
 * Acc@1 0.723 Acc@5 0.000
Test: [0/1]	Time  0.283 ( 0.283)	Loss 1.5558e-01 (1.5558e-01)	Acc@1   0.69 (  0.69)	Acc@5   0.00 (  0.00)
 * Acc@1 0.688 Acc@5 0.000
74
TRAINING
Epoch: [74][0/1]	Time  0.921 ( 0.921)	Data  0.245 ( 0.245)	Loss 7.7823e-02 (7.7823e-02)	Acc@1   0.93 (  0.93)	Acc@5   0.00 (  0.00)
[0.9311235702606033]
Test: [0/1]	Time  0.229 ( 0.229)	Loss 9.4296e-01 (9.4296e-01)	Acc@1   0.72 (  0.72)	Acc@5   0.00 (  0.00)
 * Acc@1 0.725 Acc@5 0.000
Test: [0/1]	Time  0.282 ( 0.282)	Loss 1.5550e-01 (1.5550e-01)	Acc@1   0.69 (  0.69)	Acc@5   0.00 (  0.00)
 * Acc@1 0.688 Acc@5 0.000
75
TRAINING
Epoch: [75][0/1]	Time  0.954 ( 0.954)	Data  0.282 ( 0.282)	Loss 7.7840e-02 (7.7840e-02)	Acc@1   0.93 (  0.93)	Acc@5   0.00 (  0.00)
[0.9311066068160205]
Test: [0/1]	Time  0.242 ( 0.242)	Loss 9.4271e-01 (9.4271e-01)	Acc@1   0.73 (  0.73)	Acc@5   0.00 (  0.00)
 * Acc@1 0.726 Acc@5 0.000
Test: [0/1]	Time  0.295 ( 0.295)	Loss 1.5540e-01 (1.5540e-01)	Acc@1   0.69 (  0.69)	Acc@5   0.00 (  0.00)
 * Acc@1 0.689 Acc@5 0.000
76
TRAINING
Epoch: [76][0/1]	Time  0.941 ( 0.941)	Data  0.265 ( 0.265)	Loss 7.7854e-02 (7.7854e-02)	Acc@1   0.93 (  0.93)	Acc@5   0.00 (  0.00)
[0.9312712133206578]
Test: [0/1]	Time  0.238 ( 0.238)	Loss 9.4257e-01 (9.4257e-01)	Acc@1   0.73 (  0.73)	Acc@5   0.00 (  0.00)
 * Acc@1 0.728 Acc@5 0.000
Test: [0/1]	Time  0.289 ( 0.289)	Loss 1.5528e-01 (1.5528e-01)	Acc@1   0.69 (  0.69)	Acc@5   0.00 (  0.00)
 * Acc@1 0.689 Acc@5 0.000
77
TRAINING
Epoch: [77][0/1]	Time  0.935 ( 0.935)	Data  0.259 ( 0.259)	Loss 7.7848e-02 (7.7848e-02)	Acc@1   0.93 (  0.93)	Acc@5   0.00 (  0.00)
[0.9314636842301178]
Test: [0/1]	Time  0.236 ( 0.236)	Loss 9.4254e-01 (9.4254e-01)	Acc@1   0.73 (  0.73)	Acc@5   0.00 (  0.00)
 * Acc@1 0.729 Acc@5 0.000
Test: [0/1]	Time  0.284 ( 0.284)	Loss 1.5512e-01 (1.5512e-01)	Acc@1   0.69 (  0.69)	Acc@5   0.00 (  0.00)
 * Acc@1 0.689 Acc@5 0.000
78
TRAINING
Epoch: [78][0/1]	Time  0.934 ( 0.934)	Data  0.258 ( 0.258)	Loss 7.7818e-02 (7.7818e-02)	Acc@1   0.93 (  0.93)	Acc@5   0.00 (  0.00)
[0.9315941785636697]
Test: [0/1]	Time  0.233 ( 0.233)	Loss 9.4259e-01 (9.4259e-01)	Acc@1   0.73 (  0.73)	Acc@5   0.00 (  0.00)
 * Acc@1 0.731 Acc@5 0.000
Test: [0/1]	Time  0.285 ( 0.285)	Loss 1.5494e-01 (1.5494e-01)	Acc@1   0.69 (  0.69)	Acc@5   0.00 (  0.00)
 * Acc@1 0.689 Acc@5 0.000
79
TRAINING
Epoch: [79][0/1]	Time  0.929 ( 0.929)	Data  0.256 ( 0.256)	Loss 7.7773e-02 (7.7773e-02)	Acc@1   0.93 (  0.93)	Acc@5   0.00 (  0.00)
[0.9316527284903791]
Test: [0/1]	Time  0.235 ( 0.235)	Loss 9.4270e-01 (9.4270e-01)	Acc@1   0.73 (  0.73)	Acc@5   0.00 (  0.00)
 * Acc@1 0.732 Acc@5 0.000
Test: [0/1]	Time  0.285 ( 0.285)	Loss 1.5477e-01 (1.5477e-01)	Acc@1   0.69 (  0.69)	Acc@5   0.00 (  0.00)
 * Acc@1 0.690 Acc@5 0.000
80
TRAINING
Epoch: [80][0/1]	Time  0.946 ( 0.946)	Data  0.241 ( 0.241)	Loss 7.7729e-02 (7.7729e-02)	Acc@1   0.93 (  0.93)	Acc@5   0.00 (  0.00)
[0.9317561517697235]
Test: [0/1]	Time  0.230 ( 0.230)	Loss 9.4283e-01 (9.4283e-01)	Acc@1   0.73 (  0.73)	Acc@5   0.00 (  0.00)
 * Acc@1 0.734 Acc@5 0.000
Test: [0/1]	Time  0.316 ( 0.316)	Loss 1.5461e-01 (1.5461e-01)	Acc@1   0.69 (  0.69)	Acc@5   0.00 (  0.00)
 * Acc@1 0.690 Acc@5 0.000
81
TRAINING
Epoch: [81][0/1]	Time  0.939 ( 0.939)	Data  0.255 ( 0.255)	Loss 7.7698e-02 (7.7698e-02)	Acc@1   0.93 (  0.93)	Acc@5   0.00 (  0.00)
[0.9318807050981006]
Test: [0/1]	Time  0.238 ( 0.238)	Loss 9.4295e-01 (9.4295e-01)	Acc@1   0.73 (  0.73)	Acc@5   0.00 (  0.00)
 * Acc@1 0.734 Acc@5 0.000
Test: [0/1]	Time  0.285 ( 0.285)	Loss 1.5449e-01 (1.5449e-01)	Acc@1   0.69 (  0.69)	Acc@5   0.00 (  0.00)
 * Acc@1 0.691 Acc@5 0.000
82
TRAINING
Epoch: [82][0/1]	Time  0.923 ( 0.923)	Data  0.250 ( 0.250)	Loss 7.7684e-02 (7.7684e-02)	Acc@1   0.93 (  0.93)	Acc@5   0.00 (  0.00)
[0.932007164054167]
Test: [0/1]	Time  0.235 ( 0.235)	Loss 9.4302e-01 (9.4302e-01)	Acc@1   0.73 (  0.73)	Acc@5   0.00 (  0.00)
 * Acc@1 0.735 Acc@5 0.000
Test: [0/1]	Time  0.285 ( 0.285)	Loss 1.5438e-01 (1.5438e-01)	Acc@1   0.69 (  0.69)	Acc@5   0.00 (  0.00)
 * Acc@1 0.691 Acc@5 0.000
83
TRAINING
Epoch: [83][0/1]	Time  0.917 ( 0.917)	Data  0.244 ( 0.244)	Loss 7.7680e-02 (7.7680e-02)	Acc@1   0.93 (  0.93)	Acc@5   0.00 (  0.00)
[0.9321229536109645]
Test: [0/1]	Time  0.229 ( 0.229)	Loss 9.4302e-01 (9.4302e-01)	Acc@1   0.74 (  0.74)	Acc@5   0.00 (  0.00)
 * Acc@1 0.736 Acc@5 0.000
Test: [0/1]	Time  0.323 ( 0.323)	Loss 1.5429e-01 (1.5429e-01)	Acc@1   0.69 (  0.69)	Acc@5   0.00 (  0.00)
 * Acc@1 0.692 Acc@5 0.000
84
TRAINING
Epoch: [84][0/1]	Time  0.955 ( 0.955)	Data  0.283 ( 0.283)	Loss 7.7679e-02 (7.7679e-02)	Acc@1   0.93 (  0.93)	Acc@5   0.00 (  0.00)
[0.9322212169934244]
Test: [0/1]	Time  0.248 ( 0.248)	Loss 9.4294e-01 (9.4294e-01)	Acc@1   0.74 (  0.74)	Acc@5   0.00 (  0.00)
 * Acc@1 0.736 Acc@5 0.000
Test: [0/1]	Time  0.299 ( 0.299)	Loss 1.5422e-01 (1.5422e-01)	Acc@1   0.69 (  0.69)	Acc@5   0.00 (  0.00)
 * Acc@1 0.693 Acc@5 0.000
85
TRAINING
Epoch: [85][0/1]	Time  0.958 ( 0.958)	Data  0.260 ( 0.260)	Loss 7.7673e-02 (7.7673e-02)	Acc@1   0.93 (  0.93)	Acc@5   0.00 (  0.00)
[0.932298786011769]
Test: [0/1]	Time  0.236 ( 0.236)	Loss 9.4279e-01 (9.4279e-01)	Acc@1   0.74 (  0.74)	Acc@5   0.00 (  0.00)
 * Acc@1 0.737 Acc@5 0.000
Test: [0/1]	Time  0.284 ( 0.284)	Loss 1.5415e-01 (1.5415e-01)	Acc@1   0.69 (  0.69)	Acc@5   0.00 (  0.00)
 * Acc@1 0.693 Acc@5 0.000
86
TRAINING
Epoch: [86][0/1]	Time  0.931 ( 0.931)	Data  0.258 ( 0.258)	Loss 7.7662e-02 (7.7662e-02)	Acc@1   0.93 (  0.93)	Acc@5   0.00 (  0.00)
[0.9323548591974055]
Test: [0/1]	Time  0.236 ( 0.236)	Loss 9.4260e-01 (9.4260e-01)	Acc@1   0.74 (  0.74)	Acc@5   0.00 (  0.00)
 * Acc@1 0.737 Acc@5 0.000
Test: [0/1]	Time  0.286 ( 0.286)	Loss 1.5410e-01 (1.5410e-01)	Acc@1   0.69 (  0.69)	Acc@5   0.00 (  0.00)
 * Acc@1 0.693 Acc@5 0.000
87
TRAINING
Epoch: [87][0/1]	Time  0.930 ( 0.930)	Data  0.257 ( 0.257)	Loss 7.7649e-02 (7.7649e-02)	Acc@1   0.93 (  0.93)	Acc@5   0.00 (  0.00)
[0.9323910281952899]
Test: [0/1]	Time  0.234 ( 0.234)	Loss 9.4237e-01 (9.4237e-01)	Acc@1   0.74 (  0.74)	Acc@5   0.00 (  0.00)
 * Acc@1 0.738 Acc@5 0.000
Test: [0/1]	Time  0.285 ( 0.285)	Loss 1.5406e-01 (1.5406e-01)	Acc@1   0.69 (  0.69)	Acc@5   0.00 (  0.00)
 * Acc@1 0.694 Acc@5 0.000
88
TRAINING
Epoch: [88][0/1]	Time  0.929 ( 0.929)	Data  0.258 ( 0.258)	Loss 7.7639e-02 (7.7639e-02)	Acc@1   0.93 (  0.93)	Acc@5   0.00 (  0.00)
[0.9324120266287914]
Test: [0/1]	Time  0.233 ( 0.233)	Loss 9.4214e-01 (9.4214e-01)	Acc@1   0.74 (  0.74)	Acc@5   0.00 (  0.00)
 * Acc@1 0.738 Acc@5 0.000
Test: [0/1]	Time  0.286 ( 0.286)	Loss 1.5404e-01 (1.5404e-01)	Acc@1   0.69 (  0.69)	Acc@5   0.00 (  0.00)
 * Acc@1 0.694 Acc@5 0.000
89
TRAINING
Epoch: [89][0/1]	Time  0.941 ( 0.941)	Data  0.268 ( 0.268)	Loss 7.7634e-02 (7.7634e-02)	Acc@1   0.93 (  0.93)	Acc@5   0.00 (  0.00)
[0.9324259929688805]
Test: [0/1]	Time  0.237 ( 0.237)	Loss 9.4194e-01 (9.4194e-01)	Acc@1   0.74 (  0.74)	Acc@5   0.00 (  0.00)
 * Acc@1 0.738 Acc@5 0.000
Test: [0/1]	Time  0.287 ( 0.287)	Loss 1.5402e-01 (1.5402e-01)	Acc@1   0.69 (  0.69)	Acc@5   0.00 (  0.00)
 * Acc@1 0.694 Acc@5 0.000
90
TRAINING
Epoch: [90][0/1]	Time  0.950 ( 0.950)	Data  0.240 ( 0.240)	Loss 7.7632e-02 (7.7632e-02)	Acc@1   0.93 (  0.93)	Acc@5   0.00 (  0.00)
[0.932443376818783]
Test: [0/1]	Time  0.229 ( 0.229)	Loss 9.4177e-01 (9.4177e-01)	Acc@1   0.74 (  0.74)	Acc@5   0.00 (  0.00)
 * Acc@1 0.739 Acc@5 0.000
Test: [0/1]	Time  0.304 ( 0.304)	Loss 1.5401e-01 (1.5401e-01)	Acc@1   0.69 (  0.69)	Acc@5   0.00 (  0.00)
 * Acc@1 0.694 Acc@5 0.000
91
TRAINING
Epoch: [91][0/1]	Time  0.919 ( 0.919)	Data  0.246 ( 0.246)	Loss 7.7629e-02 (7.7629e-02)	Acc@1   0.93 (  0.93)	Acc@5   0.00 (  0.00)
[0.9324745297529369]
Test: [0/1]	Time  0.228 ( 0.228)	Loss 9.4166e-01 (9.4166e-01)	Acc@1   0.74 (  0.74)	Acc@5   0.00 (  0.00)
 * Acc@1 0.739 Acc@5 0.000
Test: [0/1]	Time  0.282 ( 0.282)	Loss 1.5399e-01 (1.5399e-01)	Acc@1   0.69 (  0.69)	Acc@5   0.00 (  0.00)
 * Acc@1 0.694 Acc@5 0.000
92
TRAINING
Epoch: [92][0/1]	Time  0.923 ( 0.923)	Data  0.246 ( 0.246)	Loss 7.7620e-02 (7.7620e-02)	Acc@1   0.93 (  0.93)	Acc@5   0.00 (  0.00)
[0.9325268757263793]
Test: [0/1]	Time  0.245 ( 0.245)	Loss 9.4160e-01 (9.4160e-01)	Acc@1   0.74 (  0.74)	Acc@5   0.00 (  0.00)
 * Acc@1 0.739 Acc@5 0.000
Test: [0/1]	Time  0.302 ( 0.302)	Loss 1.5396e-01 (1.5396e-01)	Acc@1   0.69 (  0.69)	Acc@5   0.00 (  0.00)
 * Acc@1 0.695 Acc@5 0.000
93
TRAINING
Epoch: [93][0/1]	Time  0.919 ( 0.919)	Data  0.247 ( 0.247)	Loss 7.7603e-02 (7.7603e-02)	Acc@1   0.93 (  0.93)	Acc@5   0.00 (  0.00)
[0.932602848275383]
Test: [0/1]	Time  0.228 ( 0.228)	Loss 9.4160e-01 (9.4160e-01)	Acc@1   0.74 (  0.74)	Acc@5   0.00 (  0.00)
 * Acc@1 0.739 Acc@5 0.000
Test: [0/1]	Time  0.280 ( 0.280)	Loss 1.5392e-01 (1.5392e-01)	Acc@1   0.69 (  0.69)	Acc@5   0.00 (  0.00)
 * Acc@1 0.695 Acc@5 0.000
94
TRAINING
Epoch: [94][0/1]	Time  0.917 ( 0.917)	Data  0.244 ( 0.244)	Loss 7.7579e-02 (7.7579e-02)	Acc@1   0.93 (  0.93)	Acc@5   0.00 (  0.00)
[0.932699407509443]
Test: [0/1]	Time  0.229 ( 0.229)	Loss 9.4162e-01 (9.4162e-01)	Acc@1   0.74 (  0.74)	Acc@5   0.00 (  0.00)
 * Acc@1 0.739 Acc@5 0.000
Test: [0/1]	Time  0.279 ( 0.279)	Loss 1.5389e-01 (1.5389e-01)	Acc@1   0.69 (  0.69)	Acc@5   0.00 (  0.00)
 * Acc@1 0.695 Acc@5 0.000
95
TRAINING
Epoch: [95][0/1]	Time  0.928 ( 0.928)	Data  0.247 ( 0.247)	Loss 7.7553e-02 (7.7553e-02)	Acc@1   0.93 (  0.93)	Acc@5   0.00 (  0.00)
[0.9328091971881716]
Test: [0/1]	Time  0.261 ( 0.261)	Loss 9.4167e-01 (9.4167e-01)	Acc@1   0.74 (  0.74)	Acc@5   0.00 (  0.00)
 * Acc@1 0.739 Acc@5 0.000
Test: [0/1]	Time  0.315 ( 0.315)	Loss 1.5385e-01 (1.5385e-01)	Acc@1   0.69 (  0.69)	Acc@5   0.00 (  0.00)
 * Acc@1 0.695 Acc@5 0.000
96
TRAINING
Epoch: [96][0/1]	Time  0.968 ( 0.968)	Data  0.277 ( 0.277)	Loss 7.7527e-02 (7.7527e-02)	Acc@1   0.93 (  0.93)	Acc@5   0.00 (  0.00)
[0.9329227208193838]
Test: [0/1]	Time  0.239 ( 0.239)	Loss 9.4172e-01 (9.4172e-01)	Acc@1   0.74 (  0.74)	Acc@5   0.00 (  0.00)
 * Acc@1 0.739 Acc@5 0.000
Test: [0/1]	Time  0.335 ( 0.335)	Loss 1.5382e-01 (1.5382e-01)	Acc@1   0.69 (  0.69)	Acc@5   0.00 (  0.00)
 * Acc@1 0.695 Acc@5 0.000
97
TRAINING
Epoch: [97][0/1]	Time  0.945 ( 0.945)	Data  0.270 ( 0.270)	Loss 7.7505e-02 (7.7505e-02)	Acc@1   0.93 (  0.93)	Acc@5   0.00 (  0.00)
[0.9330306383339535]
Test: [0/1]	Time  0.236 ( 0.236)	Loss 9.4176e-01 (9.4176e-01)	Acc@1   0.74 (  0.74)	Acc@5   0.00 (  0.00)
 * Acc@1 0.739 Acc@5 0.000
Test: [0/1]	Time  0.291 ( 0.291)	Loss 1.5379e-01 (1.5379e-01)	Acc@1   0.69 (  0.69)	Acc@5   0.00 (  0.00)
 * Acc@1 0.695 Acc@5 0.000
98
TRAINING
Epoch: [98][0/1]	Time  0.944 ( 0.944)	Data  0.273 ( 0.273)	Loss 7.7487e-02 (7.7487e-02)	Acc@1   0.93 (  0.93)	Acc@5   0.00 (  0.00)
[0.933125466974811]
Test: [0/1]	Time  0.238 ( 0.238)	Loss 9.4177e-01 (9.4177e-01)	Acc@1   0.74 (  0.74)	Acc@5   0.00 (  0.00)
 * Acc@1 0.739 Acc@5 0.000
Test: [0/1]	Time  0.285 ( 0.285)	Loss 1.5377e-01 (1.5377e-01)	Acc@1   0.69 (  0.69)	Acc@5   0.00 (  0.00)
 * Acc@1 0.695 Acc@5 0.000
99
TRAINING
Epoch: [99][0/1]	Time  0.944 ( 0.944)	Data  0.273 ( 0.273)	Loss 7.7471e-02 (7.7471e-02)	Acc@1   0.93 (  0.93)	Acc@5   0.00 (  0.00)
[0.9332024147064157]
Test: [0/1]	Time  0.237 ( 0.237)	Loss 9.4176e-01 (9.4176e-01)	Acc@1   0.74 (  0.74)	Acc@5   0.00 (  0.00)
 * Acc@1 0.739 Acc@5 0.000
Test: [0/1]	Time  0.289 ( 0.289)	Loss 1.5376e-01 (1.5376e-01)	Acc@1   0.69 (  0.69)	Acc@5   0.00 (  0.00)
 * Acc@1 0.695 Acc@5 0.000
=> using pre-trained model 'st_resnet'
s/ohp/session_1
torch.Size([640, 3, 224, 224])
(640, 22)
attach reg
0
TRAINING
/home/helenr6/Adv_mapper/train_split.py:125: UserWarning: You have chosen to seed training. This will turn on the CUDNN deterministic setting, which can slow down your training considerably! You may see unexpected behavior when restarting from checkpoints.
  warnings.warn('You have chosen to seed training. '
/localscratch/helenr6.6279052.0/env/lib/python3.7/site-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  cpuset_checked))
Epoch: [0][0/1]	Time  5.267 ( 5.267)	Data  1.869 ( 1.869)	Loss 1.7689e+00 (1.7689e+00)	Acc@1   0.01 (  0.01)	Acc@5   0.00 (  0.00)
[0.008952899412557721]
Test: [0/1]	Time  0.426 ( 0.426)	Loss 1.1620e+00 (1.1620e+00)	Acc@1   0.04 (  0.04)	Acc@5   0.00 (  0.00)
 * Acc@1 0.038 Acc@5 0.000
Test: [0/1]	Time  0.544 ( 0.544)	Loss 9.7120e-01 (9.7120e-01)	Acc@1  -0.01 ( -0.01)	Acc@5   0.00 (  0.00)
 * Acc@1 -0.009 Acc@5 0.000
1
TRAINING
Epoch: [1][0/1]	Time  0.945 ( 0.945)	Data  0.236 ( 0.236)	Loss 1.6723e+00 (1.6723e+00)	Acc@1   0.01 (  0.01)	Acc@5   0.00 (  0.00)
[0.012279470930006624]
Test: [0/1]	Time  0.231 ( 0.231)	Loss 1.1704e+00 (1.1704e+00)	Acc@1   0.04 (  0.04)	Acc@5   0.00 (  0.00)
 * Acc@1 0.042 Acc@5 0.000
Test: [0/1]	Time  0.283 ( 0.283)	Loss 9.2348e-01 (9.2348e-01)	Acc@1  -0.01 ( -0.01)	Acc@5   0.00 (  0.00)
 * Acc@1 -0.006 Acc@5 0.000
2
TRAINING
Epoch: [2][0/1]	Time  0.919 ( 0.919)	Data  0.240 ( 0.240)	Loss 1.5290e+00 (1.5290e+00)	Acc@1   0.02 (  0.02)	Acc@5   0.00 (  0.00)
[0.01868841419414898]
Test: [0/1]	Time  0.232 ( 0.232)	Loss 1.1819e+00 (1.1819e+00)	Acc@1   0.04 (  0.04)	Acc@5   0.00 (  0.00)
 * Acc@1 0.044 Acc@5 0.000
Test: [0/1]	Time  0.284 ( 0.284)	Loss 8.8679e-01 (8.8679e-01)	Acc@1  -0.00 ( -0.00)	Acc@5   0.00 (  0.00)
 * Acc@1 -0.002 Acc@5 0.000
3
TRAINING
Epoch: [3][0/1]	Time  0.915 ( 0.915)	Data  0.242 ( 0.242)	Loss 1.3945e+00 (1.3945e+00)	Acc@1   0.03 (  0.03)	Acc@5   0.00 (  0.00)
[0.02800413381840229]
Test: [0/1]	Time  0.232 ( 0.232)	Loss 1.1953e+00 (1.1953e+00)	Acc@1   0.05 (  0.05)	Acc@5   0.00 (  0.00)
 * Acc@1 0.048 Acc@5 0.000
Test: [0/1]	Time  0.288 ( 0.288)	Loss 8.7476e-01 (8.7476e-01)	Acc@1   0.00 (  0.00)	Acc@5   0.00 (  0.00)
 * Acc@1 0.003 Acc@5 0.000
4
TRAINING
Epoch: [4][0/1]	Time  0.954 ( 0.954)	Data  0.241 ( 0.241)	Loss 1.2996e+00 (1.2996e+00)	Acc@1   0.04 (  0.04)	Acc@5   0.00 (  0.00)
[0.03917672727392855]
Test: [0/1]	Time  0.244 ( 0.244)	Loss 1.2067e+00 (1.2067e+00)	Acc@1   0.06 (  0.06)	Acc@5   0.00 (  0.00)
 * Acc@1 0.064 Acc@5 0.000
Test: [0/1]	Time  0.283 ( 0.283)	Loss 8.8074e-01 (8.8074e-01)	Acc@1   0.01 (  0.01)	Acc@5   0.00 (  0.00)
 * Acc@1 0.010 Acc@5 0.000
5
TRAINING
Epoch: [5][0/1]	Time  0.948 ( 0.948)	Data  0.238 ( 0.238)	Loss 1.2397e+00 (1.2397e+00)	Acc@1   0.06 (  0.06)	Acc@5   0.00 (  0.00)
[0.058510396998963994]
Test: [0/1]	Time  0.231 ( 0.231)	Loss 1.2110e+00 (1.2110e+00)	Acc@1   0.07 (  0.07)	Acc@5   0.00 (  0.00)
 * Acc@1 0.073 Acc@5 0.000
Test: [0/1]	Time  0.288 ( 0.288)	Loss 8.8429e-01 (8.8429e-01)	Acc@1   0.02 (  0.02)	Acc@5   0.00 (  0.00)
 * Acc@1 0.018 Acc@5 0.000
6
TRAINING
Epoch: [6][0/1]	Time  0.978 ( 0.978)	Data  0.293 ( 0.293)	Loss 1.1870e+00 (1.1870e+00)	Acc@1   0.08 (  0.08)	Acc@5   0.00 (  0.00)
[0.07595076914090328]
Test: [0/1]	Time  0.257 ( 0.257)	Loss 1.2040e+00 (1.2040e+00)	Acc@1   0.09 (  0.09)	Acc@5   0.00 (  0.00)
 * Acc@1 0.094 Acc@5 0.000
Test: [0/1]	Time  0.326 ( 0.326)	Loss 8.6521e-01 (8.6521e-01)	Acc@1   0.03 (  0.03)	Acc@5   0.00 (  0.00)
 * Acc@1 0.026 Acc@5 0.000
7
TRAINING
Epoch: [7][0/1]	Time  1.011 ( 1.011)	Data  0.304 ( 0.304)	Loss 1.1133e+00 (1.1133e+00)	Acc@1   0.09 (  0.09)	Acc@5   0.00 (  0.00)
[0.09145516049365972]
Test: [0/1]	Time  0.260 ( 0.260)	Loss 1.1847e+00 (1.1847e+00)	Acc@1   0.13 (  0.13)	Acc@5   0.00 (  0.00)
 * Acc@1 0.129 Acc@5 0.000
Test: [0/1]	Time  0.314 ( 0.314)	Loss 8.1587e-01 (8.1587e-01)	Acc@1   0.04 (  0.04)	Acc@5   0.00 (  0.00)
 * Acc@1 0.043 Acc@5 0.000
8
TRAINING
Epoch: [8][0/1]	Time  1.049 ( 1.049)	Data  0.305 ( 0.305)	Loss 1.0081e+00 (1.0081e+00)	Acc@1   0.11 (  0.11)	Acc@5   0.00 (  0.00)
[0.1143583269335578]
Test: [0/1]	Time  0.260 ( 0.260)	Loss 1.1555e+00 (1.1555e+00)	Acc@1   0.15 (  0.15)	Acc@5   0.00 (  0.00)
 * Acc@1 0.151 Acc@5 0.000
Test: [0/1]	Time  0.310 ( 0.310)	Loss 7.4497e-01 (7.4497e-01)	Acc@1   0.06 (  0.06)	Acc@5   0.00 (  0.00)
 * Acc@1 0.063 Acc@5 0.000
9
TRAINING
Epoch: [9][0/1]	Time  0.985 ( 0.985)	Data  0.278 ( 0.278)	Loss 8.8288e-01 (8.8288e-01)	Acc@1   0.14 (  0.14)	Acc@5   0.00 (  0.00)
[0.1350402719050756]
Test: [0/1]	Time  0.250 ( 0.250)	Loss 1.1216e+00 (1.1216e+00)	Acc@1   0.18 (  0.18)	Acc@5   0.00 (  0.00)
 * Acc@1 0.178 Acc@5 0.000
Test: [0/1]	Time  0.306 ( 0.306)	Loss 6.7099e-01 (6.7099e-01)	Acc@1   0.08 (  0.08)	Acc@5   0.00 (  0.00)
 * Acc@1 0.082 Acc@5 0.000
10
TRAINING
Epoch: [10][0/1]	Time  0.964 ( 0.964)	Data  0.259 ( 0.259)	Loss 7.6109e-01 (7.6109e-01)	Acc@1   0.16 (  0.16)	Acc@5   0.00 (  0.00)
[0.15579804448619805]
Test: [0/1]	Time  0.244 ( 0.244)	Loss 1.0884e+00 (1.0884e+00)	Acc@1   0.21 (  0.21)	Acc@5   0.00 (  0.00)
 * Acc@1 0.210 Acc@5 0.000
Test: [0/1]	Time  0.295 ( 0.295)	Loss 6.1093e-01 (6.1093e-01)	Acc@1   0.10 (  0.10)	Acc@5   0.00 (  0.00)
 * Acc@1 0.095 Acc@5 0.000
11
TRAINING
Epoch: [11][0/1]	Time  0.948 ( 0.948)	Data  0.250 ( 0.250)	Loss 6.6282e-01 (6.6282e-01)	Acc@1   0.19 (  0.19)	Acc@5   0.00 (  0.00)
[0.1883815705557334]
Test: [0/1]	Time  0.246 ( 0.246)	Loss 1.0597e+00 (1.0597e+00)	Acc@1   0.25 (  0.25)	Acc@5   0.00 (  0.00)
 * Acc@1 0.251 Acc@5 0.000
Test: [0/1]	Time  0.299 ( 0.299)	Loss 5.7159e-01 (5.7159e-01)	Acc@1   0.12 (  0.12)	Acc@5   0.00 (  0.00)
 * Acc@1 0.116 Acc@5 0.000
12
TRAINING
Epoch: [12][0/1]	Time  0.986 ( 0.986)	Data  0.294 ( 0.294)	Loss 5.9410e-01 (5.9410e-01)	Acc@1   0.22 (  0.22)	Acc@5   0.00 (  0.00)
[0.21589605047785249]
Test: [0/1]	Time  0.269 ( 0.269)	Loss 1.0374e+00 (1.0374e+00)	Acc@1   0.29 (  0.29)	Acc@5   0.00 (  0.00)
 * Acc@1 0.293 Acc@5 0.000
Test: [0/1]	Time  0.312 ( 0.312)	Loss 5.4775e-01 (5.4775e-01)	Acc@1   0.14 (  0.14)	Acc@5   0.00 (  0.00)
 * Acc@1 0.135 Acc@5 0.000
13
TRAINING
Epoch: [13][0/1]	Time  1.003 ( 1.003)	Data  0.316 ( 0.316)	Loss 5.4612e-01 (5.4612e-01)	Acc@1   0.24 (  0.24)	Acc@5   0.00 (  0.00)
[0.24336159572971147]
Test: [0/1]	Time  0.245 ( 0.245)	Loss 1.0213e+00 (1.0213e+00)	Acc@1   0.33 (  0.33)	Acc@5   0.00 (  0.00)
 * Acc@1 0.335 Acc@5 0.000
Test: [0/1]	Time  0.294 ( 0.294)	Loss 5.2752e-01 (5.2752e-01)	Acc@1   0.15 (  0.15)	Acc@5   0.00 (  0.00)
 * Acc@1 0.150 Acc@5 0.000
14
TRAINING
Epoch: [14][0/1]	Time  0.997 ( 0.997)	Data  0.309 ( 0.309)	Loss 5.0316e-01 (5.0316e-01)	Acc@1   0.27 (  0.27)	Acc@5   0.00 (  0.00)
[0.27364016401152164]
Test: [0/1]	Time  0.247 ( 0.247)	Loss 1.0106e+00 (1.0106e+00)	Acc@1   0.38 (  0.38)	Acc@5   0.00 (  0.00)
 * Acc@1 0.375 Acc@5 0.000
Test: [0/1]	Time  0.313 ( 0.313)	Loss 5.0051e-01 (5.0051e-01)	Acc@1   0.16 (  0.16)	Acc@5   0.00 (  0.00)
 * Acc@1 0.163 Acc@5 0.000
15
TRAINING
Epoch: [15][0/1]	Time  0.970 ( 0.970)	Data  0.261 ( 0.261)	Loss 4.5288e-01 (4.5288e-01)	Acc@1   0.31 (  0.31)	Acc@5   0.00 (  0.00)
[0.3072968741844529]
Test: [0/1]	Time  0.256 ( 0.256)	Loss 1.0044e+00 (1.0044e+00)	Acc@1   0.41 (  0.41)	Acc@5   0.00 (  0.00)
 * Acc@1 0.410 Acc@5 0.000
Test: [0/1]	Time  0.307 ( 0.307)	Loss 4.6367e-01 (4.6367e-01)	Acc@1   0.19 (  0.19)	Acc@5   0.00 (  0.00)
 * Acc@1 0.187 Acc@5 0.000
16
TRAINING
Epoch: [16][0/1]	Time  0.947 ( 0.947)	Data  0.254 ( 0.254)	Loss 3.9278e-01 (3.9278e-01)	Acc@1   0.34 (  0.34)	Acc@5   0.00 (  0.00)
[0.34471459098897517]
Test: [0/1]	Time  0.248 ( 0.248)	Loss 1.0021e+00 (1.0021e+00)	Acc@1   0.43 (  0.43)	Acc@5   0.00 (  0.00)
 * Acc@1 0.435 Acc@5 0.000
Test: [0/1]	Time  0.296 ( 0.296)	Loss 4.2166e-01 (4.2166e-01)	Acc@1   0.22 (  0.22)	Acc@5   0.00 (  0.00)
 * Acc@1 0.223 Acc@5 0.000
17
TRAINING
Epoch: [17][0/1]	Time  1.041 ( 1.041)	Data  0.346 ( 0.346)	Loss 3.2969e-01 (3.2969e-01)	Acc@1   0.38 (  0.38)	Acc@5   0.00 (  0.00)
[0.38447437094459996]
Test: [0/1]	Time  0.272 ( 0.272)	Loss 1.0033e+00 (1.0033e+00)	Acc@1   0.46 (  0.46)	Acc@5   0.00 (  0.00)
 * Acc@1 0.455 Acc@5 0.000
Test: [0/1]	Time  0.323 ( 0.323)	Loss 3.8272e-01 (3.8272e-01)	Acc@1   0.25 (  0.25)	Acc@5   0.00 (  0.00)
 * Acc@1 0.245 Acc@5 0.000
18
TRAINING
Epoch: [18][0/1]	Time  0.996 ( 0.996)	Data  0.286 ( 0.286)	Loss 2.7400e-01 (2.7400e-01)	Acc@1   0.43 (  0.43)	Acc@5   0.00 (  0.00)
[0.4262534840316503]
Test: [0/1]	Time  0.253 ( 0.253)	Loss 1.0067e+00 (1.0067e+00)	Acc@1   0.47 (  0.47)	Acc@5   0.00 (  0.00)
 * Acc@1 0.472 Acc@5 0.000
Test: [0/1]	Time  0.309 ( 0.309)	Loss 3.5302e-01 (3.5302e-01)	Acc@1   0.27 (  0.27)	Acc@5   0.00 (  0.00)
 * Acc@1 0.267 Acc@5 0.000
19
TRAINING
Epoch: [19][0/1]	Time  0.968 ( 0.968)	Data  0.263 ( 0.263)	Loss 2.3286e-01 (2.3286e-01)	Acc@1   0.47 (  0.47)	Acc@5   0.00 (  0.00)
[0.47440774052614104]
Test: [0/1]	Time  0.239 ( 0.239)	Loss 1.0108e+00 (1.0108e+00)	Acc@1   0.48 (  0.48)	Acc@5   0.00 (  0.00)
 * Acc@1 0.481 Acc@5 0.000
Test: [0/1]	Time  0.294 ( 0.294)	Loss 3.3331e-01 (3.3331e-01)	Acc@1   0.29 (  0.29)	Acc@5   0.00 (  0.00)
 * Acc@1 0.288 Acc@5 0.000
20
TRAINING
Epoch: [20][0/1]	Time  0.980 ( 0.980)	Data  0.265 ( 0.265)	Loss 2.0662e-01 (2.0662e-01)	Acc@1   0.52 (  0.52)	Acc@5   0.00 (  0.00)
[0.5205358155566114]
Test: [0/1]	Time  0.247 ( 0.247)	Loss 1.0134e+00 (1.0134e+00)	Acc@1   0.49 (  0.49)	Acc@5   0.00 (  0.00)
 * Acc@1 0.491 Acc@5 0.000
Test: [0/1]	Time  0.299 ( 0.299)	Loss 3.1943e-01 (3.1943e-01)	Acc@1   0.31 (  0.31)	Acc@5   0.00 (  0.00)
 * Acc@1 0.310 Acc@5 0.000
21
TRAINING
Epoch: [21][0/1]	Time  1.009 ( 1.009)	Data  0.297 ( 0.297)	Loss 1.8975e-01 (1.8975e-01)	Acc@1   0.57 (  0.57)	Acc@5   0.00 (  0.00)
[0.5666064572333034]
Test: [0/1]	Time  0.258 ( 0.258)	Loss 1.0129e+00 (1.0129e+00)	Acc@1   0.52 (  0.52)	Acc@5   0.00 (  0.00)
 * Acc@1 0.522 Acc@5 0.000
Test: [0/1]	Time  0.313 ( 0.313)	Loss 3.0558e-01 (3.0558e-01)	Acc@1   0.33 (  0.33)	Acc@5   0.00 (  0.00)
 * Acc@1 0.332 Acc@5 0.000
22
TRAINING
Epoch: [22][0/1]	Time  0.957 ( 0.957)	Data  0.261 ( 0.261)	Loss 1.7505e-01 (1.7505e-01)	Acc@1   0.61 (  0.61)	Acc@5   0.00 (  0.00)
[0.6148225225727915]
Test: [0/1]	Time  0.249 ( 0.249)	Loss 1.0088e+00 (1.0088e+00)	Acc@1   0.56 (  0.56)	Acc@5   0.00 (  0.00)
 * Acc@1 0.556 Acc@5 0.000
Test: [0/1]	Time  0.305 ( 0.305)	Loss 2.8810e-01 (2.8810e-01)	Acc@1   0.36 (  0.36)	Acc@5   0.00 (  0.00)
 * Acc@1 0.356 Acc@5 0.000
23
TRAINING
Epoch: [23][0/1]	Time  0.974 ( 0.974)	Data  0.289 ( 0.289)	Loss 1.5789e-01 (1.5789e-01)	Acc@1   0.66 (  0.66)	Acc@5   0.00 (  0.00)
[0.6620957795374887]
Test: [0/1]	Time  0.253 ( 0.253)	Loss 1.0014e+00 (1.0014e+00)	Acc@1   0.59 (  0.59)	Acc@5   0.00 (  0.00)
 * Acc@1 0.592 Acc@5 0.000
Test: [0/1]	Time  0.307 ( 0.307)	Loss 2.6720e-01 (2.6720e-01)	Acc@1   0.38 (  0.38)	Acc@5   0.00 (  0.00)
 * Acc@1 0.376 Acc@5 0.000
24
TRAINING
Epoch: [24][0/1]	Time  0.987 ( 0.987)	Data  0.300 ( 0.300)	Loss 1.3819e-01 (1.3819e-01)	Acc@1   0.70 (  0.70)	Acc@5   0.00 (  0.00)
[0.7036308186272162]
Test: [0/1]	Time  0.255 ( 0.255)	Loss 9.9217e-01 (9.9217e-01)	Acc@1   0.63 (  0.63)	Acc@5   0.00 (  0.00)
 * Acc@1 0.626 Acc@5 0.000
Test: [0/1]	Time  0.289 ( 0.289)	Loss 2.4623e-01 (2.4623e-01)	Acc@1   0.39 (  0.39)	Acc@5   0.00 (  0.00)
 * Acc@1 0.394 Acc@5 0.000
25
TRAINING
Epoch: [25][0/1]	Time  0.968 ( 0.968)	Data  0.278 ( 0.278)	Loss 1.1931e-01 (1.1931e-01)	Acc@1   0.74 (  0.74)	Acc@5   0.00 (  0.00)
[0.7367909493275908]
Test: [0/1]	Time  0.252 ( 0.252)	Loss 9.8270e-01 (9.8270e-01)	Acc@1   0.65 (  0.65)	Acc@5   0.00 (  0.00)
 * Acc@1 0.653 Acc@5 0.000
Test: [0/1]	Time  0.306 ( 0.306)	Loss 2.2900e-01 (2.2900e-01)	Acc@1   0.41 (  0.41)	Acc@5   0.00 (  0.00)
 * Acc@1 0.412 Acc@5 0.000
26
TRAINING
Epoch: [26][0/1]	Time  0.961 ( 0.961)	Data  0.273 ( 0.273)	Loss 1.0516e-01 (1.0516e-01)	Acc@1   0.77 (  0.77)	Acc@5   0.00 (  0.00)
[0.7653812788017325]
Test: [0/1]	Time  0.246 ( 0.246)	Loss 9.7425e-01 (9.7425e-01)	Acc@1   0.67 (  0.67)	Acc@5   0.00 (  0.00)
 * Acc@1 0.674 Acc@5 0.000
Test: [0/1]	Time  0.298 ( 0.298)	Loss 2.1746e-01 (2.1746e-01)	Acc@1   0.43 (  0.43)	Acc@5   0.00 (  0.00)
 * Acc@1 0.430 Acc@5 0.000
27
TRAINING
Epoch: [27][0/1]	Time  1.001 ( 1.001)	Data  0.306 ( 0.306)	Loss 9.7553e-02 (9.7553e-02)	Acc@1   0.79 (  0.79)	Acc@5   0.00 (  0.00)
[0.7901613190324385]
Test: [0/1]	Time  0.261 ( 0.261)	Loss 9.6754e-01 (9.6754e-01)	Acc@1   0.69 (  0.69)	Acc@5   0.00 (  0.00)
 * Acc@1 0.689 Acc@5 0.000
Test: [0/1]	Time  0.310 ( 0.310)	Loss 2.1072e-01 (2.1072e-01)	Acc@1   0.45 (  0.45)	Acc@5   0.00 (  0.00)
 * Acc@1 0.451 Acc@5 0.000
28
TRAINING
Epoch: [28][0/1]	Time  0.969 ( 0.969)	Data  0.276 ( 0.276)	Loss 9.5297e-02 (9.5297e-02)	Acc@1   0.81 (  0.81)	Acc@5   0.00 (  0.00)
[0.8133517282876266]
Test: [0/1]	Time  0.244 ( 0.244)	Loss 9.6267e-01 (9.6267e-01)	Acc@1   0.70 (  0.70)	Acc@5   0.00 (  0.00)
 * Acc@1 0.700 Acc@5 0.000
Test: [0/1]	Time  0.297 ( 0.297)	Loss 2.0605e-01 (2.0605e-01)	Acc@1   0.47 (  0.47)	Acc@5   0.00 (  0.00)
 * Acc@1 0.473 Acc@5 0.000
29
TRAINING
Epoch: [29][0/1]	Time  0.960 ( 0.960)	Data  0.269 ( 0.269)	Loss 9.5224e-02 (9.5224e-02)	Acc@1   0.83 (  0.83)	Acc@5   0.00 (  0.00)
[0.8309781404718979]
Test: [0/1]	Time  0.257 ( 0.257)	Loss 9.5944e-01 (9.5944e-01)	Acc@1   0.70 (  0.70)	Acc@5   0.00 (  0.00)
 * Acc@1 0.700 Acc@5 0.000
Test: [0/1]	Time  0.303 ( 0.303)	Loss 2.0065e-01 (2.0065e-01)	Acc@1   0.50 (  0.50)	Acc@5   0.00 (  0.00)
 * Acc@1 0.496 Acc@5 0.000
30
TRAINING
Epoch: [30][0/1]	Time  0.937 ( 0.937)	Data  0.252 ( 0.252)	Loss 9.4216e-02 (9.4216e-02)	Acc@1   0.84 (  0.84)	Acc@5   0.00 (  0.00)
[0.843227832462278]
Test: [0/1]	Time  0.239 ( 0.239)	Loss 9.5756e-01 (9.5756e-01)	Acc@1   0.70 (  0.70)	Acc@5   0.00 (  0.00)
 * Acc@1 0.697 Acc@5 0.000
Test: [0/1]	Time  0.290 ( 0.290)	Loss 1.9326e-01 (1.9326e-01)	Acc@1   0.52 (  0.52)	Acc@5   0.00 (  0.00)
 * Acc@1 0.521 Acc@5 0.000
31
TRAINING
Epoch: [31][0/1]	Time  0.958 ( 0.958)	Data  0.268 ( 0.268)	Loss 9.0862e-02 (9.0862e-02)	Acc@1   0.85 (  0.85)	Acc@5   0.00 (  0.00)
[0.8536931476873926]
Test: [0/1]	Time  0.256 ( 0.256)	Loss 9.5681e-01 (9.5681e-01)	Acc@1   0.69 (  0.69)	Acc@5   0.00 (  0.00)
 * Acc@1 0.694 Acc@5 0.000
Test: [0/1]	Time  0.306 ( 0.306)	Loss 1.8455e-01 (1.8455e-01)	Acc@1   0.55 (  0.55)	Acc@5   0.00 (  0.00)
 * Acc@1 0.547 Acc@5 0.000
32
TRAINING
Epoch: [32][0/1]	Time  0.997 ( 0.997)	Data  0.284 ( 0.284)	Loss 8.5840e-02 (8.5840e-02)	Acc@1   0.86 (  0.86)	Acc@5   0.00 (  0.00)
[0.8636982486442255]
Test: [0/1]	Time  0.261 ( 0.261)	Loss 9.5694e-01 (9.5694e-01)	Acc@1   0.69 (  0.69)	Acc@5   0.00 (  0.00)
 * Acc@1 0.688 Acc@5 0.000
Test: [0/1]	Time  0.309 ( 0.309)	Loss 1.7633e-01 (1.7633e-01)	Acc@1   0.57 (  0.57)	Acc@5   0.00 (  0.00)
 * Acc@1 0.573 Acc@5 0.000
33
TRAINING
Epoch: [33][0/1]	Time  0.971 ( 0.971)	Data  0.277 ( 0.277)	Loss 8.1053e-02 (8.1053e-02)	Acc@1   0.87 (  0.87)	Acc@5   0.00 (  0.00)
[0.8710537245212444]
Test: [0/1]	Time  0.248 ( 0.248)	Loss 9.5766e-01 (9.5766e-01)	Acc@1   0.68 (  0.68)	Acc@5   0.00 (  0.00)
 * Acc@1 0.676 Acc@5 0.000
Test: [0/1]	Time  0.330 ( 0.330)	Loss 1.7025e-01 (1.7025e-01)	Acc@1   0.60 (  0.60)	Acc@5   0.00 (  0.00)
 * Acc@1 0.601 Acc@5 0.000
34
TRAINING
Epoch: [34][0/1]	Time  0.996 ( 0.996)	Data  0.307 ( 0.307)	Loss 7.8238e-02 (7.8238e-02)	Acc@1   0.87 (  0.87)	Acc@5   0.00 (  0.00)
[0.874265378390785]
Test: [0/1]	Time  0.260 ( 0.260)	Loss 9.5854e-01 (9.5854e-01)	Acc@1   0.66 (  0.66)	Acc@5   0.00 (  0.00)
 * Acc@1 0.664 Acc@5 0.000
Test: [0/1]	Time  0.320 ( 0.320)	Loss 1.6684e-01 (1.6684e-01)	Acc@1   0.63 (  0.63)	Acc@5   0.00 (  0.00)
 * Acc@1 0.627 Acc@5 0.000
35
TRAINING
Epoch: [35][0/1]	Time  0.983 ( 0.983)	Data  0.271 ( 0.271)	Loss 7.7952e-02 (7.7952e-02)	Acc@1   0.88 (  0.88)	Acc@5   0.00 (  0.00)
[0.8751074002917835]
Test: [0/1]	Time  0.260 ( 0.260)	Loss 9.5910e-01 (9.5910e-01)	Acc@1   0.65 (  0.65)	Acc@5   0.00 (  0.00)
 * Acc@1 0.653 Acc@5 0.000
Test: [0/1]	Time  0.311 ( 0.311)	Loss 1.6540e-01 (1.6540e-01)	Acc@1   0.65 (  0.65)	Acc@5   0.00 (  0.00)
 * Acc@1 0.649 Acc@5 0.000
36
TRAINING
Epoch: [36][0/1]	Time  0.988 ( 0.988)	Data  0.291 ( 0.291)	Loss 7.9435e-02 (7.9435e-02)	Acc@1   0.87 (  0.87)	Acc@5   0.00 (  0.00)
[0.8745516287270436]
Test: [0/1]	Time  0.257 ( 0.257)	Loss 9.5893e-01 (9.5893e-01)	Acc@1   0.64 (  0.64)	Acc@5   0.00 (  0.00)
 * Acc@1 0.643 Acc@5 0.000
Test: [0/1]	Time  0.307 ( 0.307)	Loss 1.6459e-01 (1.6459e-01)	Acc@1   0.67 (  0.67)	Acc@5   0.00 (  0.00)
 * Acc@1 0.668 Acc@5 0.000
37
TRAINING
Epoch: [37][0/1]	Time  0.976 ( 0.976)	Data  0.280 ( 0.280)	Loss 8.1269e-02 (8.1269e-02)	Acc@1   0.87 (  0.87)	Acc@5   0.00 (  0.00)
[0.8732610667488038]
Test: [0/1]	Time  0.254 ( 0.254)	Loss 9.5781e-01 (9.5781e-01)	Acc@1   0.63 (  0.63)	Acc@5   0.00 (  0.00)
 * Acc@1 0.634 Acc@5 0.000
Test: [0/1]	Time  0.303 ( 0.303)	Loss 1.6330e-01 (1.6330e-01)	Acc@1   0.68 (  0.68)	Acc@5   0.00 (  0.00)
 * Acc@1 0.683 Acc@5 0.000
38
TRAINING
Epoch: [38][0/1]	Time  0.989 ( 0.989)	Data  0.297 ( 0.297)	Loss 8.2282e-02 (8.2282e-02)	Acc@1   0.87 (  0.87)	Acc@5   0.00 (  0.00)
[0.8725517812322774]
Test: [0/1]	Time  0.258 ( 0.258)	Loss 9.5579e-01 (9.5579e-01)	Acc@1   0.63 (  0.63)	Acc@5   0.00 (  0.00)
 * Acc@1 0.626 Acc@5 0.000
Test: [0/1]	Time  0.311 ( 0.311)	Loss 1.6122e-01 (1.6122e-01)	Acc@1   0.69 (  0.69)	Acc@5   0.00 (  0.00)
 * Acc@1 0.694 Acc@5 0.000
39
TRAINING
Epoch: [39][0/1]	Time  1.029 ( 1.029)	Data  0.332 ( 0.332)	Loss 8.2140e-02 (8.2140e-02)	Acc@1   0.87 (  0.87)	Acc@5   0.00 (  0.00)
[0.870987710656327]
Test: [0/1]	Time  0.254 ( 0.254)	Loss 9.5315e-01 (9.5315e-01)	Acc@1   0.62 (  0.62)	Acc@5   0.00 (  0.00)
 * Acc@1 0.619 Acc@5 0.000
Test: [0/1]	Time  0.300 ( 0.300)	Loss 1.5880e-01 (1.5880e-01)	Acc@1   0.70 (  0.70)	Acc@5   0.00 (  0.00)
 * Acc@1 0.703 Acc@5 0.000
40
TRAINING
Epoch: [40][0/1]	Time  1.003 ( 1.003)	Data  0.298 ( 0.298)	Loss 8.1335e-02 (8.1335e-02)	Acc@1   0.87 (  0.87)	Acc@5   0.00 (  0.00)
[0.8693409090268795]
Test: [0/1]	Time  0.267 ( 0.267)	Loss 9.5027e-01 (9.5027e-01)	Acc@1   0.61 (  0.61)	Acc@5   0.00 (  0.00)
 * Acc@1 0.612 Acc@5 0.000
Test: [0/1]	Time  0.324 ( 0.324)	Loss 1.5681e-01 (1.5681e-01)	Acc@1   0.71 (  0.71)	Acc@5   0.00 (  0.00)
 * Acc@1 0.709 Acc@5 0.000
41
TRAINING
Epoch: [41][0/1]	Time  0.993 ( 0.993)	Data  0.306 ( 0.306)	Loss 8.0700e-02 (8.0700e-02)	Acc@1   0.87 (  0.87)	Acc@5   0.00 (  0.00)
[0.868990356725429]
Test: [0/1]	Time  0.270 ( 0.270)	Loss 9.4756e-01 (9.4756e-01)	Acc@1   0.61 (  0.61)	Acc@5   0.00 (  0.00)
 * Acc@1 0.607 Acc@5 0.000
Test: [0/1]	Time  0.322 ( 0.322)	Loss 1.5582e-01 (1.5582e-01)	Acc@1   0.71 (  0.71)	Acc@5   0.00 (  0.00)
 * Acc@1 0.715 Acc@5 0.000
42
TRAINING
Epoch: [42][0/1]	Time  0.959 ( 0.959)	Data  0.264 ( 0.264)	Loss 8.0816e-02 (8.0816e-02)	Acc@1   0.87 (  0.87)	Acc@5   0.00 (  0.00)
[0.8697304025514957]
Test: [0/1]	Time  0.262 ( 0.262)	Loss 9.4528e-01 (9.4528e-01)	Acc@1   0.60 (  0.60)	Acc@5   0.00 (  0.00)
 * Acc@1 0.603 Acc@5 0.000
Test: [0/1]	Time  0.309 ( 0.309)	Loss 1.5583e-01 (1.5583e-01)	Acc@1   0.72 (  0.72)	Acc@5   0.00 (  0.00)
 * Acc@1 0.721 Acc@5 0.000
43
TRAINING
Epoch: [43][0/1]	Time  0.994 ( 0.994)	Data  0.295 ( 0.295)	Loss 8.1693e-02 (8.1693e-02)	Acc@1   0.87 (  0.87)	Acc@5   0.00 (  0.00)
[0.8711545070108344]
Test: [0/1]	Time  0.262 ( 0.262)	Loss 9.4359e-01 (9.4359e-01)	Acc@1   0.60 (  0.60)	Acc@5   0.00 (  0.00)
 * Acc@1 0.601 Acc@5 0.000
Test: [0/1]	Time  0.309 ( 0.309)	Loss 1.5637e-01 (1.5637e-01)	Acc@1   0.73 (  0.73)	Acc@5   0.00 (  0.00)
 * Acc@1 0.727 Acc@5 0.000
44
TRAINING
Epoch: [44][0/1]	Time  0.967 ( 0.967)	Data  0.270 ( 0.270)	Loss 8.2844e-02 (8.2844e-02)	Acc@1   0.87 (  0.87)	Acc@5   0.00 (  0.00)
[0.8734323898702686]
Test: [0/1]	Time  0.247 ( 0.247)	Loss 9.4256e-01 (9.4256e-01)	Acc@1   0.60 (  0.60)	Acc@5   0.00 (  0.00)
 * Acc@1 0.599 Acc@5 0.000
Test: [0/1]	Time  0.299 ( 0.299)	Loss 1.5684e-01 (1.5684e-01)	Acc@1   0.73 (  0.73)	Acc@5   0.00 (  0.00)
 * Acc@1 0.733 Acc@5 0.000
45
TRAINING
Epoch: [45][0/1]	Time  0.981 ( 0.981)	Data  0.276 ( 0.276)	Loss 8.3649e-02 (8.3649e-02)	Acc@1   0.88 (  0.88)	Acc@5   0.00 (  0.00)
[0.8763037490878416]
Test: [0/1]	Time  0.250 ( 0.250)	Loss 9.4217e-01 (9.4217e-01)	Acc@1   0.60 (  0.60)	Acc@5   0.00 (  0.00)
 * Acc@1 0.599 Acc@5 0.000
Test: [0/1]	Time  0.299 ( 0.299)	Loss 1.5687e-01 (1.5687e-01)	Acc@1   0.74 (  0.74)	Acc@5   0.00 (  0.00)
 * Acc@1 0.739 Acc@5 0.000
46
TRAINING
Epoch: [46][0/1]	Time  0.999 ( 0.999)	Data  0.301 ( 0.301)	Loss 8.3733e-02 (8.3733e-02)	Acc@1   0.88 (  0.88)	Acc@5   0.00 (  0.00)
[0.8794222941277288]
Test: [0/1]	Time  0.261 ( 0.261)	Loss 9.4237e-01 (9.4237e-01)	Acc@1   0.60 (  0.60)	Acc@5   0.00 (  0.00)
 * Acc@1 0.602 Acc@5 0.000
Test: [0/1]	Time  0.314 ( 0.314)	Loss 1.5646e-01 (1.5646e-01)	Acc@1   0.74 (  0.74)	Acc@5   0.00 (  0.00)
 * Acc@1 0.742 Acc@5 0.000
47
TRAINING
Epoch: [47][0/1]	Time  0.979 ( 0.979)	Data  0.287 ( 0.287)	Loss 8.3144e-02 (8.3144e-02)	Acc@1   0.88 (  0.88)	Acc@5   0.00 (  0.00)
[0.883121844498385]
Test: [0/1]	Time  0.253 ( 0.253)	Loss 9.4308e-01 (9.4308e-01)	Acc@1   0.61 (  0.61)	Acc@5   0.00 (  0.00)
 * Acc@1 0.606 Acc@5 0.000
Test: [0/1]	Time  0.310 ( 0.310)	Loss 1.5592e-01 (1.5592e-01)	Acc@1   0.74 (  0.74)	Acc@5   0.00 (  0.00)
 * Acc@1 0.742 Acc@5 0.000
48
TRAINING
Epoch: [48][0/1]	Time  0.984 ( 0.984)	Data  0.290 ( 0.290)	Loss 8.2253e-02 (8.2253e-02)	Acc@1   0.89 (  0.89)	Acc@5   0.00 (  0.00)
[0.887181514380278]
Test: [0/1]	Time  0.267 ( 0.267)	Loss 9.4415e-01 (9.4415e-01)	Acc@1   0.61 (  0.61)	Acc@5   0.00 (  0.00)
 * Acc@1 0.610 Acc@5 0.000
Test: [0/1]	Time  0.322 ( 0.322)	Loss 1.5560e-01 (1.5560e-01)	Acc@1   0.74 (  0.74)	Acc@5   0.00 (  0.00)
 * Acc@1 0.741 Acc@5 0.000
49
TRAINING
Epoch: [49][0/1]	Time  0.961 ( 0.961)	Data  0.284 ( 0.284)	Loss 8.1495e-02 (8.1495e-02)	Acc@1   0.89 (  0.89)	Acc@5   0.00 (  0.00)
[0.8908647219598309]
Test: [0/1]	Time  0.243 ( 0.243)	Loss 9.4540e-01 (9.4540e-01)	Acc@1   0.61 (  0.61)	Acc@5   0.00 (  0.00)
 * Acc@1 0.614 Acc@5 0.000
Test: [0/1]	Time  0.294 ( 0.294)	Loss 1.5570e-01 (1.5570e-01)	Acc@1   0.74 (  0.74)	Acc@5   0.00 (  0.00)
 * Acc@1 0.740 Acc@5 0.000
50
TRAINING
Epoch: [50][0/1]	Time  0.952 ( 0.952)	Data  0.257 ( 0.257)	Loss 8.1123e-02 (8.1123e-02)	Acc@1   0.89 (  0.89)	Acc@5   0.00 (  0.00)
[0.8947058477852371]
Test: [0/1]	Time  0.237 ( 0.237)	Loss 9.4661e-01 (9.4661e-01)	Acc@1   0.62 (  0.62)	Acc@5   0.00 (  0.00)
 * Acc@1 0.618 Acc@5 0.000
Test: [0/1]	Time  0.292 ( 0.292)	Loss 1.5615e-01 (1.5615e-01)	Acc@1   0.74 (  0.74)	Acc@5   0.00 (  0.00)
 * Acc@1 0.740 Acc@5 0.000
51
TRAINING
Epoch: [51][0/1]	Time  0.941 ( 0.941)	Data  0.265 ( 0.265)	Loss 8.1108e-02 (8.1108e-02)	Acc@1   0.90 (  0.90)	Acc@5   0.00 (  0.00)
[0.8985813043994286]
Test: [0/1]	Time  0.237 ( 0.237)	Loss 9.4761e-01 (9.4761e-01)	Acc@1   0.62 (  0.62)	Acc@5   0.00 (  0.00)
 * Acc@1 0.622 Acc@5 0.000
Test: [0/1]	Time  0.287 ( 0.287)	Loss 1.5671e-01 (1.5671e-01)	Acc@1   0.74 (  0.74)	Acc@5   0.00 (  0.00)
 * Acc@1 0.740 Acc@5 0.000
52
TRAINING
Epoch: [52][0/1]	Time  0.925 ( 0.925)	Data  0.251 ( 0.251)	Loss 8.1228e-02 (8.1228e-02)	Acc@1   0.90 (  0.90)	Acc@5   0.00 (  0.00)
[0.9023958475111264]
Test: [0/1]	Time  0.276 ( 0.276)	Loss 9.4826e-01 (9.4826e-01)	Acc@1   0.63 (  0.63)	Acc@5   0.00 (  0.00)
 * Acc@1 0.626 Acc@5 0.000
Test: [0/1]	Time  0.318 ( 0.318)	Loss 1.5714e-01 (1.5714e-01)	Acc@1   0.74 (  0.74)	Acc@5   0.00 (  0.00)
 * Acc@1 0.739 Acc@5 0.000
53
TRAINING
Epoch: [53][0/1]	Time  0.968 ( 0.968)	Data  0.293 ( 0.293)	Loss 8.1235e-02 (8.1235e-02)	Acc@1   0.91 (  0.91)	Acc@5   0.00 (  0.00)
[0.9060752270727475]
Test: [0/1]	Time  0.242 ( 0.242)	Loss 9.4854e-01 (9.4854e-01)	Acc@1   0.63 (  0.63)	Acc@5   0.00 (  0.00)
 * Acc@1 0.631 Acc@5 0.000
Test: [0/1]	Time  0.298 ( 0.298)	Loss 1.5732e-01 (1.5732e-01)	Acc@1   0.74 (  0.74)	Acc@5   0.00 (  0.00)
 * Acc@1 0.739 Acc@5 0.000
54
TRAINING
Epoch: [54][0/1]	Time  0.971 ( 0.971)	Data  0.280 ( 0.280)	Loss 8.1016e-02 (8.1016e-02)	Acc@1   0.91 (  0.91)	Acc@5   0.00 (  0.00)
[0.9095567874429409]
Test: [0/1]	Time  0.240 ( 0.240)	Loss 9.4848e-01 (9.4848e-01)	Acc@1   0.64 (  0.64)	Acc@5   0.00 (  0.00)
 * Acc@1 0.636 Acc@5 0.000
Test: [0/1]	Time  0.298 ( 0.298)	Loss 1.5729e-01 (1.5729e-01)	Acc@1   0.74 (  0.74)	Acc@5   0.00 (  0.00)
 * Acc@1 0.739 Acc@5 0.000
55
TRAINING
Epoch: [55][0/1]	Time  0.961 ( 0.961)	Data  0.282 ( 0.282)	Loss 8.0626e-02 (8.0626e-02)	Acc@1   0.91 (  0.91)	Acc@5   0.00 (  0.00)
[0.9127855167846326]
Test: [0/1]	Time  0.242 ( 0.242)	Loss 9.4820e-01 (9.4820e-01)	Acc@1   0.64 (  0.64)	Acc@5   0.00 (  0.00)
 * Acc@1 0.641 Acc@5 0.000
Test: [0/1]	Time  0.295 ( 0.295)	Loss 1.5719e-01 (1.5719e-01)	Acc@1   0.74 (  0.74)	Acc@5   0.00 (  0.00)
 * Acc@1 0.738 Acc@5 0.000
56
TRAINING
Epoch: [56][0/1]	Time  0.955 ( 0.955)	Data  0.282 ( 0.282)	Loss 8.0226e-02 (8.0226e-02)	Acc@1   0.92 (  0.92)	Acc@5   0.00 (  0.00)
[0.9157174964632251]
Test: [0/1]	Time  0.243 ( 0.243)	Loss 9.4784e-01 (9.4784e-01)	Acc@1   0.65 (  0.65)	Acc@5   0.00 (  0.00)
 * Acc@1 0.646 Acc@5 0.000
Test: [0/1]	Time  0.295 ( 0.295)	Loss 1.5716e-01 (1.5716e-01)	Acc@1   0.74 (  0.74)	Acc@5   0.00 (  0.00)
 * Acc@1 0.737 Acc@5 0.000
57
TRAINING
Epoch: [57][0/1]	Time  0.955 ( 0.955)	Data  0.279 ( 0.279)	Loss 7.9961e-02 (7.9961e-02)	Acc@1   0.92 (  0.92)	Acc@5   0.00 (  0.00)
[0.9180403577303857]
Test: [0/1]	Time  0.241 ( 0.241)	Loss 9.4753e-01 (9.4753e-01)	Acc@1   0.65 (  0.65)	Acc@5   0.00 (  0.00)
 * Acc@1 0.651 Acc@5 0.000
Test: [0/1]	Time  0.296 ( 0.296)	Loss 1.5724e-01 (1.5724e-01)	Acc@1   0.74 (  0.74)	Acc@5   0.00 (  0.00)
 * Acc@1 0.736 Acc@5 0.000
58
TRAINING
Epoch: [58][0/1]	Time  0.959 ( 0.959)	Data  0.270 ( 0.270)	Loss 7.9877e-02 (7.9877e-02)	Acc@1   0.92 (  0.92)	Acc@5   0.00 (  0.00)
[0.9197701173757377]
Test: [0/1]	Time  0.240 ( 0.240)	Loss 9.4738e-01 (9.4738e-01)	Acc@1   0.66 (  0.66)	Acc@5   0.00 (  0.00)
 * Acc@1 0.656 Acc@5 0.000
Test: [0/1]	Time  0.293 ( 0.293)	Loss 1.5739e-01 (1.5739e-01)	Acc@1   0.74 (  0.74)	Acc@5   0.00 (  0.00)
 * Acc@1 0.735 Acc@5 0.000
59
TRAINING
Epoch: [59][0/1]	Time  0.943 ( 0.943)	Data  0.270 ( 0.270)	Loss 7.9904e-02 (7.9904e-02)	Acc@1   0.92 (  0.92)	Acc@5   0.00 (  0.00)
[0.9212506779334748]
Test: [0/1]	Time  0.238 ( 0.238)	Loss 9.4746e-01 (9.4746e-01)	Acc@1   0.66 (  0.66)	Acc@5   0.00 (  0.00)
 * Acc@1 0.660 Acc@5 0.000
Test: [0/1]	Time  0.290 ( 0.290)	Loss 1.5750e-01 (1.5750e-01)	Acc@1   0.74 (  0.74)	Acc@5   0.00 (  0.00)
 * Acc@1 0.736 Acc@5 0.000
60
TRAINING
Epoch: [60][0/1]	Time  0.961 ( 0.961)	Data  0.249 ( 0.249)	Loss 7.9917e-02 (7.9917e-02)	Acc@1   0.92 (  0.92)	Acc@5   0.00 (  0.00)
[0.9229117598598278]
Test: [0/1]	Time  0.235 ( 0.235)	Loss 9.4778e-01 (9.4778e-01)	Acc@1   0.66 (  0.66)	Acc@5   0.00 (  0.00)
 * Acc@1 0.664 Acc@5 0.000
Test: [0/1]	Time  0.286 ( 0.286)	Loss 1.5749e-01 (1.5749e-01)	Acc@1   0.74 (  0.74)	Acc@5   0.00 (  0.00)
 * Acc@1 0.736 Acc@5 0.000
61
TRAINING
Epoch: [61][0/1]	Time  0.934 ( 0.934)	Data  0.261 ( 0.261)	Loss 7.9817e-02 (7.9817e-02)	Acc@1   0.93 (  0.93)	Acc@5   0.00 (  0.00)
[0.9250249897279461]
Test: [0/1]	Time  0.233 ( 0.233)	Loss 9.4835e-01 (9.4835e-01)	Acc@1   0.67 (  0.67)	Acc@5   0.00 (  0.00)
 * Acc@1 0.668 Acc@5 0.000
Test: [0/1]	Time  0.288 ( 0.288)	Loss 1.5733e-01 (1.5733e-01)	Acc@1   0.74 (  0.74)	Acc@5   0.00 (  0.00)
 * Acc@1 0.737 Acc@5 0.000
62
TRAINING
Epoch: [62][0/1]	Time  0.956 ( 0.956)	Data  0.263 ( 0.263)	Loss 7.9582e-02 (7.9582e-02)	Acc@1   0.93 (  0.93)	Acc@5   0.00 (  0.00)
[0.9270141447742133]
Test: [0/1]	Time  0.245 ( 0.245)	Loss 9.4911e-01 (9.4911e-01)	Acc@1   0.67 (  0.67)	Acc@5   0.00 (  0.00)
 * Acc@1 0.671 Acc@5 0.000
Test: [0/1]	Time  0.298 ( 0.298)	Loss 1.5708e-01 (1.5708e-01)	Acc@1   0.74 (  0.74)	Acc@5   0.00 (  0.00)
 * Acc@1 0.738 Acc@5 0.000
63
TRAINING
Epoch: [63][0/1]	Time  0.930 ( 0.930)	Data  0.256 ( 0.256)	Loss 7.9269e-02 (7.9269e-02)	Acc@1   0.93 (  0.93)	Acc@5   0.00 (  0.00)
[0.928677643749327]
Test: [0/1]	Time  0.236 ( 0.236)	Loss 9.5000e-01 (9.5000e-01)	Acc@1   0.67 (  0.67)	Acc@5   0.00 (  0.00)
 * Acc@1 0.674 Acc@5 0.000
Test: [0/1]	Time  0.289 ( 0.289)	Loss 1.5683e-01 (1.5683e-01)	Acc@1   0.74 (  0.74)	Acc@5   0.00 (  0.00)
 * Acc@1 0.739 Acc@5 0.000
64
TRAINING
Epoch: [64][0/1]	Time  0.977 ( 0.977)	Data  0.300 ( 0.300)	Loss 7.8968e-02 (7.8968e-02)	Acc@1   0.93 (  0.93)	Acc@5   0.00 (  0.00)
[0.9297005309146635]
Test: [0/1]	Time  0.238 ( 0.238)	Loss 9.5090e-01 (9.5090e-01)	Acc@1   0.68 (  0.68)	Acc@5   0.00 (  0.00)
 * Acc@1 0.677 Acc@5 0.000
Test: [0/1]	Time  0.320 ( 0.320)	Loss 1.5662e-01 (1.5662e-01)	Acc@1   0.74 (  0.74)	Acc@5   0.00 (  0.00)
 * Acc@1 0.740 Acc@5 0.000
65
TRAINING
Epoch: [65][0/1]	Time  0.941 ( 0.941)	Data  0.269 ( 0.269)	Loss 7.8747e-02 (7.8747e-02)	Acc@1   0.93 (  0.93)	Acc@5   0.00 (  0.00)
[0.9307996058302297]
Test: [0/1]	Time  0.240 ( 0.240)	Loss 9.5174e-01 (9.5174e-01)	Acc@1   0.68 (  0.68)	Acc@5   0.00 (  0.00)
 * Acc@1 0.680 Acc@5 0.000
Test: [0/1]	Time  0.294 ( 0.294)	Loss 1.5649e-01 (1.5649e-01)	Acc@1   0.74 (  0.74)	Acc@5   0.00 (  0.00)
 * Acc@1 0.742 Acc@5 0.000
66
TRAINING
Epoch: [66][0/1]	Time  0.942 ( 0.942)	Data  0.269 ( 0.269)	Loss 7.8622e-02 (7.8622e-02)	Acc@1   0.93 (  0.93)	Acc@5   0.00 (  0.00)
[0.9313823605598903]
Test: [0/1]	Time  0.239 ( 0.239)	Loss 9.5243e-01 (9.5243e-01)	Acc@1   0.68 (  0.68)	Acc@5   0.00 (  0.00)
 * Acc@1 0.682 Acc@5 0.000
Test: [0/1]	Time  0.294 ( 0.294)	Loss 1.5638e-01 (1.5638e-01)	Acc@1   0.74 (  0.74)	Acc@5   0.00 (  0.00)
 * Acc@1 0.743 Acc@5 0.000
67
TRAINING
Epoch: [67][0/1]	Time  0.973 ( 0.973)	Data  0.260 ( 0.260)	Loss 7.8561e-02 (7.8561e-02)	Acc@1   0.93 (  0.93)	Acc@5   0.00 (  0.00)
[0.9320292710648297]
Test: [0/1]	Time  0.246 ( 0.246)	Loss 9.5290e-01 (9.5290e-01)	Acc@1   0.68 (  0.68)	Acc@5   0.00 (  0.00)
 * Acc@1 0.685 Acc@5 0.000
Test: [0/1]	Time  0.295 ( 0.295)	Loss 1.5627e-01 (1.5627e-01)	Acc@1   0.74 (  0.74)	Acc@5   0.00 (  0.00)
 * Acc@1 0.745 Acc@5 0.000
68
TRAINING
Epoch: [68][0/1]	Time  0.992 ( 0.992)	Data  0.279 ( 0.279)	Loss 7.8513e-02 (7.8513e-02)	Acc@1   0.93 (  0.93)	Acc@5   0.00 (  0.00)
[0.9325625524683924]
Test: [0/1]	Time  0.261 ( 0.261)	Loss 9.5314e-01 (9.5314e-01)	Acc@1   0.69 (  0.69)	Acc@5   0.00 (  0.00)
 * Acc@1 0.688 Acc@5 0.000
Test: [0/1]	Time  0.313 ( 0.313)	Loss 1.5610e-01 (1.5610e-01)	Acc@1   0.75 (  0.75)	Acc@5   0.00 (  0.00)
 * Acc@1 0.746 Acc@5 0.000
69
TRAINING
Epoch: [69][0/1]	Time  0.979 ( 0.979)	Data  0.281 ( 0.281)	Loss 7.8442e-02 (7.8442e-02)	Acc@1   0.93 (  0.93)	Acc@5   0.00 (  0.00)
[0.9330007639979956]
Test: [0/1]	Time  0.249 ( 0.249)	Loss 9.5316e-01 (9.5316e-01)	Acc@1   0.69 (  0.69)	Acc@5   0.00 (  0.00)
 * Acc@1 0.691 Acc@5 0.000
Test: [0/1]	Time  0.302 ( 0.302)	Loss 1.5590e-01 (1.5590e-01)	Acc@1   0.75 (  0.75)	Acc@5   0.00 (  0.00)
 * Acc@1 0.748 Acc@5 0.000
70
TRAINING
Epoch: [70][0/1]	Time  0.967 ( 0.967)	Data  0.255 ( 0.255)	Loss 7.8345e-02 (7.8345e-02)	Acc@1   0.93 (  0.93)	Acc@5   0.00 (  0.00)
[0.9333600912887621]
Test: [0/1]	Time  0.257 ( 0.257)	Loss 9.5301e-01 (9.5301e-01)	Acc@1   0.69 (  0.69)	Acc@5   0.00 (  0.00)
 * Acc@1 0.692 Acc@5 0.000
Test: [0/1]	Time  0.311 ( 0.311)	Loss 1.5568e-01 (1.5568e-01)	Acc@1   0.75 (  0.75)	Acc@5   0.00 (  0.00)
 * Acc@1 0.749 Acc@5 0.000
71
TRAINING
Epoch: [71][0/1]	Time  1.015 ( 1.015)	Data  0.313 ( 0.313)	Loss 7.8248e-02 (7.8248e-02)	Acc@1   0.93 (  0.93)	Acc@5   0.00 (  0.00)
[0.9336526406008006]
Test: [0/1]	Time  0.265 ( 0.265)	Loss 9.5276e-01 (9.5276e-01)	Acc@1   0.69 (  0.69)	Acc@5   0.00 (  0.00)
 * Acc@1 0.694 Acc@5 0.000
Test: [0/1]	Time  0.317 ( 0.317)	Loss 1.5548e-01 (1.5548e-01)	Acc@1   0.75 (  0.75)	Acc@5   0.00 (  0.00)
 * Acc@1 0.750 Acc@5 0.000
72
TRAINING
Epoch: [72][0/1]	Time  0.937 ( 0.937)	Data  0.244 ( 0.244)	Loss 7.8180e-02 (7.8180e-02)	Acc@1   0.93 (  0.93)	Acc@5   0.00 (  0.00)
[0.9337994159932629]
Test: [0/1]	Time  0.268 ( 0.268)	Loss 9.5247e-01 (9.5247e-01)	Acc@1   0.70 (  0.70)	Acc@5   0.00 (  0.00)
 * Acc@1 0.696 Acc@5 0.000
Test: [0/1]	Time  0.317 ( 0.317)	Loss 1.5532e-01 (1.5532e-01)	Acc@1   0.75 (  0.75)	Acc@5   0.00 (  0.00)
 * Acc@1 0.751 Acc@5 0.000
73
TRAINING
Epoch: [73][0/1]	Time  0.957 ( 0.957)	Data  0.270 ( 0.270)	Loss 7.8154e-02 (7.8154e-02)	Acc@1   0.93 (  0.93)	Acc@5   0.00 (  0.00)
[0.9338046523267904]
Test: [0/1]	Time  0.251 ( 0.251)	Loss 9.5222e-01 (9.5222e-01)	Acc@1   0.70 (  0.70)	Acc@5   0.00 (  0.00)
 * Acc@1 0.698 Acc@5 0.000
Test: [0/1]	Time  0.304 ( 0.304)	Loss 1.5520e-01 (1.5520e-01)	Acc@1   0.75 (  0.75)	Acc@5   0.00 (  0.00)
 * Acc@1 0.753 Acc@5 0.000
74
TRAINING
Epoch: [74][0/1]	Time  0.977 ( 0.977)	Data  0.278 ( 0.278)	Loss 7.8162e-02 (7.8162e-02)	Acc@1   0.93 (  0.93)	Acc@5   0.00 (  0.00)
[0.9338141727726851]
Test: [0/1]	Time  0.251 ( 0.251)	Loss 9.5205e-01 (9.5205e-01)	Acc@1   0.70 (  0.70)	Acc@5   0.00 (  0.00)
 * Acc@1 0.699 Acc@5 0.000
Test: [0/1]	Time  0.310 ( 0.310)	Loss 1.5510e-01 (1.5510e-01)	Acc@1   0.75 (  0.75)	Acc@5   0.00 (  0.00)
 * Acc@1 0.754 Acc@5 0.000
75
TRAINING
Epoch: [75][0/1]	Time  1.003 ( 1.003)	Data  0.306 ( 0.306)	Loss 7.8177e-02 (7.8177e-02)	Acc@1   0.93 (  0.93)	Acc@5   0.00 (  0.00)
[0.9338677996274152]
Test: [0/1]	Time  0.255 ( 0.255)	Loss 9.5198e-01 (9.5198e-01)	Acc@1   0.70 (  0.70)	Acc@5   0.00 (  0.00)
 * Acc@1 0.701 Acc@5 0.000
Test: [0/1]	Time  0.306 ( 0.306)	Loss 1.5500e-01 (1.5500e-01)	Acc@1   0.75 (  0.75)	Acc@5   0.00 (  0.00)
 * Acc@1 0.754 Acc@5 0.000
76
TRAINING
Epoch: [76][0/1]	Time  0.977 ( 0.977)	Data  0.290 ( 0.290)	Loss 7.8175e-02 (7.8175e-02)	Acc@1   0.93 (  0.93)	Acc@5   0.00 (  0.00)
[0.933873801568212]
Test: [0/1]	Time  0.254 ( 0.254)	Loss 9.5202e-01 (9.5202e-01)	Acc@1   0.70 (  0.70)	Acc@5   0.00 (  0.00)
 * Acc@1 0.702 Acc@5 0.000
Test: [0/1]	Time  0.301 ( 0.301)	Loss 1.5489e-01 (1.5489e-01)	Acc@1   0.76 (  0.76)	Acc@5   0.00 (  0.00)
 * Acc@1 0.755 Acc@5 0.000
77
TRAINING
Epoch: [77][0/1]	Time  0.976 ( 0.976)	Data  0.278 ( 0.278)	Loss 7.8144e-02 (7.8144e-02)	Acc@1   0.93 (  0.93)	Acc@5   0.00 (  0.00)
[0.9338471471354127]
Test: [0/1]	Time  0.269 ( 0.269)	Loss 9.5216e-01 (9.5216e-01)	Acc@1   0.70 (  0.70)	Acc@5   0.00 (  0.00)
 * Acc@1 0.703 Acc@5 0.000
Test: [0/1]	Time  0.321 ( 0.321)	Loss 1.5478e-01 (1.5478e-01)	Acc@1   0.76 (  0.76)	Acc@5   0.00 (  0.00)
 * Acc@1 0.756 Acc@5 0.000
78
TRAINING
Epoch: [78][0/1]	Time  0.990 ( 0.990)	Data  0.284 ( 0.284)	Loss 7.8090e-02 (7.8090e-02)	Acc@1   0.93 (  0.93)	Acc@5   0.00 (  0.00)
[0.9336957923175297]
Test: [0/1]	Time  0.248 ( 0.248)	Loss 9.5237e-01 (9.5237e-01)	Acc@1   0.70 (  0.70)	Acc@5   0.00 (  0.00)
 * Acc@1 0.704 Acc@5 0.000
Test: [0/1]	Time  0.294 ( 0.294)	Loss 1.5467e-01 (1.5467e-01)	Acc@1   0.76 (  0.76)	Acc@5   0.00 (  0.00)
 * Acc@1 0.757 Acc@5 0.000
79
TRAINING
Epoch: [79][0/1]	Time  0.995 ( 0.995)	Data  0.281 ( 0.281)	Loss 7.8030e-02 (7.8030e-02)	Acc@1   0.93 (  0.93)	Acc@5   0.00 (  0.00)
[0.9333147300421043]
Test: [0/1]	Time  0.249 ( 0.249)	Loss 9.5260e-01 (9.5260e-01)	Acc@1   0.71 (  0.71)	Acc@5   0.00 (  0.00)
 * Acc@1 0.705 Acc@5 0.000
Test: [0/1]	Time  0.299 ( 0.299)	Loss 1.5459e-01 (1.5459e-01)	Acc@1   0.76 (  0.76)	Acc@5   0.00 (  0.00)
 * Acc@1 0.758 Acc@5 0.000
80
TRAINING
Epoch: [80][0/1]	Time  0.951 ( 0.951)	Data  0.262 ( 0.262)	Loss 7.7981e-02 (7.7981e-02)	Acc@1   0.93 (  0.93)	Acc@5   0.00 (  0.00)
[0.9330557209660003]
Test: [0/1]	Time  0.243 ( 0.243)	Loss 9.5282e-01 (9.5282e-01)	Acc@1   0.71 (  0.71)	Acc@5   0.00 (  0.00)
 * Acc@1 0.706 Acc@5 0.000
Test: [0/1]	Time  0.294 ( 0.294)	Loss 1.5453e-01 (1.5453e-01)	Acc@1   0.76 (  0.76)	Acc@5   0.00 (  0.00)
 * Acc@1 0.758 Acc@5 0.000
81
TRAINING
Epoch: [81][0/1]	Time  0.976 ( 0.976)	Data  0.285 ( 0.285)	Loss 7.7951e-02 (7.7951e-02)	Acc@1   0.93 (  0.93)	Acc@5   0.00 (  0.00)
[0.9330053946290751]
Test: [0/1]	Time  0.262 ( 0.262)	Loss 9.5298e-01 (9.5298e-01)	Acc@1   0.71 (  0.71)	Acc@5   0.00 (  0.00)
 * Acc@1 0.707 Acc@5 0.000
Test: [0/1]	Time  0.314 ( 0.314)	Loss 1.5448e-01 (1.5448e-01)	Acc@1   0.76 (  0.76)	Acc@5   0.00 (  0.00)
 * Acc@1 0.759 Acc@5 0.000
82
TRAINING
Epoch: [82][0/1]	Time  0.971 ( 0.971)	Data  0.274 ( 0.274)	Loss 7.7937e-02 (7.7937e-02)	Acc@1   0.93 (  0.93)	Acc@5   0.00 (  0.00)
[0.9329715484907235]
Test: [0/1]	Time  0.246 ( 0.246)	Loss 9.5305e-01 (9.5305e-01)	Acc@1   0.71 (  0.71)	Acc@5   0.00 (  0.00)
 * Acc@1 0.708 Acc@5 0.000
Test: [0/1]	Time  0.298 ( 0.298)	Loss 1.5444e-01 (1.5444e-01)	Acc@1   0.76 (  0.76)	Acc@5   0.00 (  0.00)
 * Acc@1 0.760 Acc@5 0.000
83
TRAINING
Epoch: [83][0/1]	Time  0.974 ( 0.974)	Data  0.274 ( 0.274)	Loss 7.7929e-02 (7.7929e-02)	Acc@1   0.93 (  0.93)	Acc@5   0.00 (  0.00)
[0.9329532661362382]
Test: [0/1]	Time  0.247 ( 0.247)	Loss 9.5302e-01 (9.5302e-01)	Acc@1   0.71 (  0.71)	Acc@5   0.00 (  0.00)
 * Acc@1 0.709 Acc@5 0.000
Test: [0/1]	Time  0.301 ( 0.301)	Loss 1.5438e-01 (1.5438e-01)	Acc@1   0.76 (  0.76)	Acc@5   0.00 (  0.00)
 * Acc@1 0.761 Acc@5 0.000
84
TRAINING
Epoch: [84][0/1]	Time  1.010 ( 1.010)	Data  0.298 ( 0.298)	Loss 7.7920e-02 (7.7920e-02)	Acc@1   0.93 (  0.93)	Acc@5   0.00 (  0.00)
[0.9329497263444144]
Test: [0/1]	Time  0.253 ( 0.253)	Loss 9.5290e-01 (9.5290e-01)	Acc@1   0.71 (  0.71)	Acc@5   0.00 (  0.00)
 * Acc@1 0.709 Acc@5 0.000
Test: [0/1]	Time  0.305 ( 0.305)	Loss 1.5432e-01 (1.5432e-01)	Acc@1   0.76 (  0.76)	Acc@5   0.00 (  0.00)
 * Acc@1 0.761 Acc@5 0.000
85
TRAINING
Epoch: [85][0/1]	Time  1.000 ( 1.000)	Data  0.281 ( 0.281)	Loss 7.7905e-02 (7.7905e-02)	Acc@1   0.93 (  0.93)	Acc@5   0.00 (  0.00)
[0.9329558756268648]
Test: [0/1]	Time  0.244 ( 0.244)	Loss 9.5269e-01 (9.5269e-01)	Acc@1   0.71 (  0.71)	Acc@5   0.00 (  0.00)
 * Acc@1 0.710 Acc@5 0.000
Test: [0/1]	Time  0.298 ( 0.298)	Loss 1.5425e-01 (1.5425e-01)	Acc@1   0.76 (  0.76)	Acc@5   0.00 (  0.00)
 * Acc@1 0.762 Acc@5 0.000
86
TRAINING
Epoch: [86][0/1]	Time  0.991 ( 0.991)	Data  0.303 ( 0.303)	Loss 7.7888e-02 (7.7888e-02)	Acc@1   0.93 (  0.93)	Acc@5   0.00 (  0.00)
[0.932915241127654]
Test: [0/1]	Time  0.263 ( 0.263)	Loss 9.5243e-01 (9.5243e-01)	Acc@1   0.71 (  0.71)	Acc@5   0.00 (  0.00)
 * Acc@1 0.711 Acc@5 0.000
Test: [0/1]	Time  0.312 ( 0.312)	Loss 1.5418e-01 (1.5418e-01)	Acc@1   0.76 (  0.76)	Acc@5   0.00 (  0.00)
 * Acc@1 0.763 Acc@5 0.000
87
TRAINING
Epoch: [87][0/1]	Time  0.982 ( 0.982)	Data  0.271 ( 0.271)	Loss 7.7874e-02 (7.7874e-02)	Acc@1   0.93 (  0.93)	Acc@5   0.00 (  0.00)
[0.9328934943555138]
Test: [0/1]	Time  0.253 ( 0.253)	Loss 9.5215e-01 (9.5215e-01)	Acc@1   0.71 (  0.71)	Acc@5   0.00 (  0.00)
 * Acc@1 0.711 Acc@5 0.000
Test: [0/1]	Time  0.302 ( 0.302)	Loss 1.5411e-01 (1.5411e-01)	Acc@1   0.76 (  0.76)	Acc@5   0.00 (  0.00)
 * Acc@1 0.763 Acc@5 0.000
88
TRAINING
Epoch: [88][0/1]	Time  0.950 ( 0.950)	Data  0.250 ( 0.250)	Loss 7.7867e-02 (7.7867e-02)	Acc@1   0.93 (  0.93)	Acc@5   0.00 (  0.00)
[0.932892137482018]
Test: [0/1]	Time  0.241 ( 0.241)	Loss 9.5189e-01 (9.5189e-01)	Acc@1   0.71 (  0.71)	Acc@5   0.00 (  0.00)
 * Acc@1 0.711 Acc@5 0.000
Test: [0/1]	Time  0.287 ( 0.287)	Loss 1.5406e-01 (1.5406e-01)	Acc@1   0.76 (  0.76)	Acc@5   0.00 (  0.00)
 * Acc@1 0.764 Acc@5 0.000
89
TRAINING
Epoch: [89][0/1]	Time  0.976 ( 0.976)	Data  0.277 ( 0.277)	Loss 7.7864e-02 (7.7864e-02)	Acc@1   0.93 (  0.93)	Acc@5   0.00 (  0.00)
[0.9329118494301152]
Test: [0/1]	Time  0.248 ( 0.248)	Loss 9.5166e-01 (9.5166e-01)	Acc@1   0.71 (  0.71)	Acc@5   0.00 (  0.00)
 * Acc@1 0.712 Acc@5 0.000
Test: [0/1]	Time  0.300 ( 0.300)	Loss 1.5401e-01 (1.5401e-01)	Acc@1   0.76 (  0.76)	Acc@5   0.00 (  0.00)
 * Acc@1 0.765 Acc@5 0.000
90
TRAINING
Epoch: [90][0/1]	Time  0.967 ( 0.967)	Data  0.273 ( 0.273)	Loss 7.7862e-02 (7.7862e-02)	Acc@1   0.93 (  0.93)	Acc@5   0.00 (  0.00)
[0.9329523107787681]
Test: [0/1]	Time  0.252 ( 0.252)	Loss 9.5148e-01 (9.5148e-01)	Acc@1   0.71 (  0.71)	Acc@5   0.00 (  0.00)
 * Acc@1 0.712 Acc@5 0.000
Test: [0/1]	Time  0.305 ( 0.305)	Loss 1.5396e-01 (1.5396e-01)	Acc@1   0.77 (  0.77)	Acc@5   0.00 (  0.00)
 * Acc@1 0.765 Acc@5 0.000
91
TRAINING
Epoch: [91][0/1]	Time  0.980 ( 0.980)	Data  0.292 ( 0.292)	Loss 7.7855e-02 (7.7855e-02)	Acc@1   0.93 (  0.93)	Acc@5   0.00 (  0.00)
[0.9330120296011204]
Test: [0/1]	Time  0.262 ( 0.262)	Loss 9.5137e-01 (9.5137e-01)	Acc@1   0.71 (  0.71)	Acc@5   0.00 (  0.00)
 * Acc@1 0.712 Acc@5 0.000
Test: [0/1]	Time  0.299 ( 0.299)	Loss 1.5392e-01 (1.5392e-01)	Acc@1   0.77 (  0.77)	Acc@5   0.00 (  0.00)
 * Acc@1 0.766 Acc@5 0.000
92
TRAINING
Epoch: [92][0/1]	Time  0.996 ( 0.996)	Data  0.299 ( 0.299)	Loss 7.7840e-02 (7.7840e-02)	Acc@1   0.93 (  0.93)	Acc@5   0.00 (  0.00)
[0.9330882967224234]
Test: [0/1]	Time  0.250 ( 0.250)	Loss 9.5131e-01 (9.5131e-01)	Acc@1   0.71 (  0.71)	Acc@5   0.00 (  0.00)
 * Acc@1 0.712 Acc@5 0.000
Test: [0/1]	Time  0.303 ( 0.303)	Loss 1.5387e-01 (1.5387e-01)	Acc@1   0.77 (  0.77)	Acc@5   0.00 (  0.00)
 * Acc@1 0.767 Acc@5 0.000
93
TRAINING
Epoch: [93][0/1]	Time  0.989 ( 0.989)	Data  0.295 ( 0.295)	Loss 7.7817e-02 (7.7817e-02)	Acc@1   0.93 (  0.93)	Acc@5   0.00 (  0.00)
[0.9331773637537412]
Test: [0/1]	Time  0.253 ( 0.253)	Loss 9.5130e-01 (9.5130e-01)	Acc@1   0.71 (  0.71)	Acc@5   0.00 (  0.00)
 * Acc@1 0.712 Acc@5 0.000
Test: [0/1]	Time  0.308 ( 0.308)	Loss 1.5383e-01 (1.5383e-01)	Acc@1   0.77 (  0.77)	Acc@5   0.00 (  0.00)
 * Acc@1 0.767 Acc@5 0.000
94
TRAINING
Epoch: [94][0/1]	Time  0.968 ( 0.968)	Data  0.276 ( 0.276)	Loss 7.7789e-02 (7.7789e-02)	Acc@1   0.93 (  0.93)	Acc@5   0.00 (  0.00)
[0.9332748407697999]
Test: [0/1]	Time  0.250 ( 0.250)	Loss 9.5132e-01 (9.5132e-01)	Acc@1   0.71 (  0.71)	Acc@5   0.00 (  0.00)
 * Acc@1 0.712 Acc@5 0.000
Test: [0/1]	Time  0.303 ( 0.303)	Loss 1.5379e-01 (1.5379e-01)	Acc@1   0.77 (  0.77)	Acc@5   0.00 (  0.00)
 * Acc@1 0.767 Acc@5 0.000
95
TRAINING
Epoch: [95][0/1]	Time  0.974 ( 0.974)	Data  0.268 ( 0.268)	Loss 7.7762e-02 (7.7762e-02)	Acc@1   0.93 (  0.93)	Acc@5   0.00 (  0.00)
[0.9333762136622057]
Test: [0/1]	Time  0.248 ( 0.248)	Loss 9.5135e-01 (9.5135e-01)	Acc@1   0.71 (  0.71)	Acc@5   0.00 (  0.00)
 * Acc@1 0.712 Acc@5 0.000
Test: [0/1]	Time  0.299 ( 0.299)	Loss 1.5376e-01 (1.5376e-01)	Acc@1   0.77 (  0.77)	Acc@5   0.00 (  0.00)
 * Acc@1 0.768 Acc@5 0.000
96
TRAINING
Epoch: [96][0/1]	Time  0.989 ( 0.989)	Data  0.295 ( 0.295)	Loss 7.7739e-02 (7.7739e-02)	Acc@1   0.93 (  0.93)	Acc@5   0.00 (  0.00)
[0.9334773374813349]
Test: [0/1]	Time  0.255 ( 0.255)	Loss 9.5136e-01 (9.5136e-01)	Acc@1   0.71 (  0.71)	Acc@5   0.00 (  0.00)
 * Acc@1 0.712 Acc@5 0.000
Test: [0/1]	Time  0.308 ( 0.308)	Loss 1.5374e-01 (1.5374e-01)	Acc@1   0.77 (  0.77)	Acc@5   0.00 (  0.00)
 * Acc@1 0.768 Acc@5 0.000
97
TRAINING
Epoch: [97][0/1]	Time  0.974 ( 0.974)	Data  0.274 ( 0.274)	Loss 7.7719e-02 (7.7719e-02)	Acc@1   0.93 (  0.93)	Acc@5   0.00 (  0.00)
[0.9335747879204525]
Test: [0/1]	Time  0.247 ( 0.247)	Loss 9.5136e-01 (9.5136e-01)	Acc@1   0.71 (  0.71)	Acc@5   0.00 (  0.00)
 * Acc@1 0.712 Acc@5 0.000
Test: [0/1]	Time  0.301 ( 0.301)	Loss 1.5372e-01 (1.5372e-01)	Acc@1   0.77 (  0.77)	Acc@5   0.00 (  0.00)
 * Acc@1 0.769 Acc@5 0.000
98
TRAINING
Epoch: [98][0/1]	Time  0.985 ( 0.985)	Data  0.280 ( 0.280)	Loss 7.7704e-02 (7.7704e-02)	Acc@1   0.93 (  0.93)	Acc@5   0.00 (  0.00)
[0.9336660246753526]
Test: [0/1]	Time  0.265 ( 0.265)	Loss 9.5132e-01 (9.5132e-01)	Acc@1   0.71 (  0.71)	Acc@5   0.00 (  0.00)
 * Acc@1 0.712 Acc@5 0.000
Test: [0/1]	Time  0.315 ( 0.315)	Loss 1.5370e-01 (1.5370e-01)	Acc@1   0.77 (  0.77)	Acc@5   0.00 (  0.00)
 * Acc@1 0.769 Acc@5 0.000
99
TRAINING
Epoch: [99][0/1]	Time  1.022 ( 1.022)	Data  0.316 ( 0.316)	Loss 7.7690e-02 (7.7690e-02)	Acc@1   0.93 (  0.93)	Acc@5   0.00 (  0.00)
[0.9337493938801018]
Test: [0/1]	Time  0.305 ( 0.305)	Loss 9.5124e-01 (9.5124e-01)	Acc@1   0.71 (  0.71)	Acc@5   0.00 (  0.00)
 * Acc@1 0.711 Acc@5 0.000
Test: [0/1]	Time  0.316 ( 0.316)	Loss 1.5368e-01 (1.5368e-01)	Acc@1   0.77 (  0.77)	Acc@5   0.00 (  0.00)
 * Acc@1 0.769 Acc@5 0.000
=> using pre-trained model 'st_resnet'
s/ohp/session_1
torch.Size([640, 3, 224, 224])
(640, 22)
attach reg
0
TRAINING
/home/helenr6/Adv_mapper/train_split.py:125: UserWarning: You have chosen to seed training. This will turn on the CUDNN deterministic setting, which can slow down your training considerably! You may see unexpected behavior when restarting from checkpoints.
  warnings.warn('You have chosen to seed training. '
/localscratch/helenr6.6279052.0/env/lib/python3.7/site-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  cpuset_checked))
Epoch: [0][0/1]	Time  5.286 ( 5.286)	Data  1.830 ( 1.830)	Loss 1.7803e+00 (1.7803e+00)	Acc@1   0.00 (  0.00)	Acc@5   0.00 (  0.00)
[0.00043187387183845315]
Test: [0/1]	Time  0.434 ( 0.434)	Loss 1.1623e+00 (1.1623e+00)	Acc@1   0.04 (  0.04)	Acc@5   0.00 (  0.00)
 * Acc@1 0.037 Acc@5 0.000
Test: [0/1]	Time  0.555 ( 0.555)	Loss 9.3872e-01 (9.3872e-01)	Acc@1  -0.03 ( -0.03)	Acc@5   0.00 (  0.00)
 * Acc@1 -0.030 Acc@5 0.000
1
TRAINING
Epoch: [1][0/1]	Time  0.940 ( 0.940)	Data  0.245 ( 0.245)	Loss 1.6837e+00 (1.6837e+00)	Acc@1   0.00 (  0.00)	Acc@5   0.00 (  0.00)
[0.003269683157989085]
Test: [0/1]	Time  0.238 ( 0.238)	Loss 1.1713e+00 (1.1713e+00)	Acc@1   0.04 (  0.04)	Acc@5   0.00 (  0.00)
 * Acc@1 0.041 Acc@5 0.000
Test: [0/1]	Time  0.303 ( 0.303)	Loss 8.9042e-01 (8.9042e-01)	Acc@1  -0.02 ( -0.02)	Acc@5   0.00 (  0.00)
 * Acc@1 -0.023 Acc@5 0.000
2
TRAINING
Epoch: [2][0/1]	Time  0.944 ( 0.944)	Data  0.257 ( 0.257)	Loss 1.5397e+00 (1.5397e+00)	Acc@1   0.01 (  0.01)	Acc@5   0.00 (  0.00)
[0.008744949120930646]
Test: [0/1]	Time  0.236 ( 0.236)	Loss 1.1833e+00 (1.1833e+00)	Acc@1   0.05 (  0.05)	Acc@5   0.00 (  0.00)
 * Acc@1 0.047 Acc@5 0.000
Test: [0/1]	Time  0.313 ( 0.313)	Loss 8.5595e-01 (8.5595e-01)	Acc@1  -0.01 ( -0.01)	Acc@5   0.00 (  0.00)
 * Acc@1 -0.013 Acc@5 0.000
3
TRAINING
Epoch: [3][0/1]	Time  0.959 ( 0.959)	Data  0.283 ( 0.283)	Loss 1.4035e+00 (1.4035e+00)	Acc@1   0.02 (  0.02)	Acc@5   0.00 (  0.00)
[0.0184358579560088]
Test: [0/1]	Time  0.245 ( 0.245)	Loss 1.1973e+00 (1.1973e+00)	Acc@1   0.05 (  0.05)	Acc@5   0.00 (  0.00)
 * Acc@1 0.052 Acc@5 0.000
Test: [0/1]	Time  0.294 ( 0.294)	Loss 8.4945e-01 (8.4945e-01)	Acc@1   0.00 (  0.00)	Acc@5   0.00 (  0.00)
 * Acc@1 0.002 Acc@5 0.000
4
TRAINING
Epoch: [4][0/1]	Time  0.954 ( 0.954)	Data  0.257 ( 0.257)	Loss 1.3060e+00 (1.3060e+00)	Acc@1   0.03 (  0.03)	Acc@5   0.00 (  0.00)
[0.028103526419560647]
Test: [0/1]	Time  0.244 ( 0.244)	Loss 1.2091e+00 (1.2091e+00)	Acc@1   0.07 (  0.07)	Acc@5   0.00 (  0.00)
 * Acc@1 0.074 Acc@5 0.000
Test: [0/1]	Time  0.293 ( 0.293)	Loss 8.6347e-01 (8.6347e-01)	Acc@1   0.02 (  0.02)	Acc@5   0.00 (  0.00)
 * Acc@1 0.019 Acc@5 0.000
5
TRAINING
Epoch: [5][0/1]	Time  1.008 ( 1.008)	Data  0.324 ( 0.324)	Loss 1.2438e+00 (1.2438e+00)	Acc@1   0.04 (  0.04)	Acc@5   0.00 (  0.00)
[0.042332183987303]
Test: [0/1]	Time  0.264 ( 0.264)	Loss 1.2134e+00 (1.2134e+00)	Acc@1   0.09 (  0.09)	Acc@5   0.00 (  0.00)
 * Acc@1 0.093 Acc@5 0.000
Test: [0/1]	Time  0.316 ( 0.316)	Loss 8.7538e-01 (8.7538e-01)	Acc@1   0.04 (  0.04)	Acc@5   0.00 (  0.00)
 * Acc@1 0.037 Acc@5 0.000
6
TRAINING
Epoch: [6][0/1]	Time  1.008 ( 1.008)	Data  0.300 ( 0.300)	Loss 1.1902e+00 (1.1902e+00)	Acc@1   0.06 (  0.06)	Acc@5   0.00 (  0.00)
[0.061787866228607394]
Test: [0/1]	Time  0.272 ( 0.272)	Loss 1.2060e+00 (1.2060e+00)	Acc@1   0.12 (  0.12)	Acc@5   0.00 (  0.00)
 * Acc@1 0.119 Acc@5 0.000
Test: [0/1]	Time  0.322 ( 0.322)	Loss 8.6244e-01 (8.6244e-01)	Acc@1   0.06 (  0.06)	Acc@5   0.00 (  0.00)
 * Acc@1 0.059 Acc@5 0.000
7
TRAINING
Epoch: [7][0/1]	Time  0.999 ( 0.999)	Data  0.284 ( 0.284)	Loss 1.1171e+00 (1.1171e+00)	Acc@1   0.08 (  0.08)	Acc@5   0.00 (  0.00)
[0.08412110756015764]
Test: [0/1]	Time  0.265 ( 0.265)	Loss 1.1856e+00 (1.1856e+00)	Acc@1   0.15 (  0.15)	Acc@5   0.00 (  0.00)
 * Acc@1 0.146 Acc@5 0.000
Test: [0/1]	Time  0.320 ( 0.320)	Loss 8.1527e-01 (8.1527e-01)	Acc@1   0.08 (  0.08)	Acc@5   0.00 (  0.00)
 * Acc@1 0.081 Acc@5 0.000
8
TRAINING
Epoch: [8][0/1]	Time  1.026 ( 1.026)	Data  0.334 ( 0.334)	Loss 1.0133e+00 (1.0133e+00)	Acc@1   0.11 (  0.11)	Acc@5   0.00 (  0.00)
[0.10918852180122562]
Test: [0/1]	Time  0.251 ( 0.251)	Loss 1.1547e+00 (1.1547e+00)	Acc@1   0.16 (  0.16)	Acc@5   0.00 (  0.00)
 * Acc@1 0.165 Acc@5 0.000
Test: [0/1]	Time  0.309 ( 0.309)	Loss 7.4204e-01 (7.4204e-01)	Acc@1   0.10 (  0.10)	Acc@5   0.00 (  0.00)
 * Acc@1 0.097 Acc@5 0.000
9
TRAINING
Epoch: [9][0/1]	Time  1.041 ( 1.041)	Data  0.308 ( 0.308)	Loss 8.8901e-01 (8.8901e-01)	Acc@1   0.13 (  0.13)	Acc@5   0.00 (  0.00)
[0.13033156839648252]
Test: [0/1]	Time  0.265 ( 0.265)	Loss 1.1185e+00 (1.1185e+00)	Acc@1   0.20 (  0.20)	Acc@5   0.00 (  0.00)
 * Acc@1 0.197 Acc@5 0.000
Test: [0/1]	Time  0.318 ( 0.318)	Loss 6.6250e-01 (6.6250e-01)	Acc@1   0.11 (  0.11)	Acc@5   0.00 (  0.00)
 * Acc@1 0.113 Acc@5 0.000
10
TRAINING
Epoch: [10][0/1]	Time  0.978 ( 0.978)	Data  0.276 ( 0.276)	Loss 7.6697e-01 (7.6697e-01)	Acc@1   0.15 (  0.15)	Acc@5   0.00 (  0.00)
[0.15356214065713153]
Test: [0/1]	Time  0.256 ( 0.256)	Loss 1.0826e+00 (1.0826e+00)	Acc@1   0.24 (  0.24)	Acc@5   0.00 (  0.00)
 * Acc@1 0.236 Acc@5 0.000
Test: [0/1]	Time  0.311 ( 0.311)	Loss 5.9596e-01 (5.9596e-01)	Acc@1   0.13 (  0.13)	Acc@5   0.00 (  0.00)
 * Acc@1 0.128 Acc@5 0.000
11
TRAINING
Epoch: [11][0/1]	Time  0.995 ( 0.995)	Data  0.277 ( 0.277)	Loss 6.6736e-01 (6.6736e-01)	Acc@1   0.18 (  0.18)	Acc@5   0.00 (  0.00)
[0.1842717379099404]
Test: [0/1]	Time  0.247 ( 0.247)	Loss 1.0514e+00 (1.0514e+00)	Acc@1   0.27 (  0.27)	Acc@5   0.00 (  0.00)
 * Acc@1 0.271 Acc@5 0.000
Test: [0/1]	Time  0.306 ( 0.306)	Loss 5.5141e-01 (5.5141e-01)	Acc@1   0.14 (  0.14)	Acc@5   0.00 (  0.00)
 * Acc@1 0.142 Acc@5 0.000
12
TRAINING
Epoch: [12][0/1]	Time  1.042 ( 1.042)	Data  0.354 ( 0.354)	Loss 5.9708e-01 (5.9708e-01)	Acc@1   0.22 (  0.22)	Acc@5   0.00 (  0.00)
[0.21720169779065657]
Test: [0/1]	Time  0.265 ( 0.265)	Loss 1.0267e+00 (1.0267e+00)	Acc@1   0.31 (  0.31)	Acc@5   0.00 (  0.00)
 * Acc@1 0.307 Acc@5 0.000
Test: [0/1]	Time  0.321 ( 0.321)	Loss 5.2493e-01 (5.2493e-01)	Acc@1   0.16 (  0.16)	Acc@5   0.00 (  0.00)
 * Acc@1 0.157 Acc@5 0.000
13
TRAINING
Epoch: [13][0/1]	Time  1.052 ( 1.052)	Data  0.334 ( 0.334)	Loss 5.4837e-01 (5.4837e-01)	Acc@1   0.25 (  0.25)	Acc@5   0.00 (  0.00)
[0.25217851131767877]
Test: [0/1]	Time  0.279 ( 0.279)	Loss 1.0088e+00 (1.0088e+00)	Acc@1   0.34 (  0.34)	Acc@5   0.00 (  0.00)
 * Acc@1 0.342 Acc@5 0.000
Test: [0/1]	Time  0.329 ( 0.329)	Loss 5.0475e-01 (5.0475e-01)	Acc@1   0.18 (  0.18)	Acc@5   0.00 (  0.00)
 * Acc@1 0.177 Acc@5 0.000
14
TRAINING
Epoch: [14][0/1]	Time  1.029 ( 1.029)	Data  0.342 ( 0.342)	Loss 5.0594e-01 (5.0594e-01)	Acc@1   0.29 (  0.29)	Acc@5   0.00 (  0.00)
[0.28939822235022195]
Test: [0/1]	Time  0.256 ( 0.256)	Loss 9.9679e-01 (9.9679e-01)	Acc@1   0.37 (  0.37)	Acc@5   0.00 (  0.00)
 * Acc@1 0.374 Acc@5 0.000
Test: [0/1]	Time  0.316 ( 0.316)	Loss 4.7974e-01 (4.7974e-01)	Acc@1   0.20 (  0.20)	Acc@5   0.00 (  0.00)
 * Acc@1 0.198 Acc@5 0.000
15
TRAINING
Epoch: [15][0/1]	Time  1.027 ( 1.027)	Data  0.290 ( 0.290)	Loss 4.5707e-01 (4.5707e-01)	Acc@1   0.33 (  0.33)	Acc@5   0.00 (  0.00)
[0.32849909198258276]
Test: [0/1]	Time  0.259 ( 0.259)	Loss 9.8977e-01 (9.8977e-01)	Acc@1   0.40 (  0.40)	Acc@5   0.00 (  0.00)
 * Acc@1 0.404 Acc@5 0.000
Test: [0/1]	Time  0.314 ( 0.314)	Loss 4.4581e-01 (4.4581e-01)	Acc@1   0.21 (  0.21)	Acc@5   0.00 (  0.00)
 * Acc@1 0.210 Acc@5 0.000
16
TRAINING
Epoch: [16][0/1]	Time  0.983 ( 0.983)	Data  0.288 ( 0.288)	Loss 3.9833e-01 (3.9833e-01)	Acc@1   0.36 (  0.36)	Acc@5   0.00 (  0.00)
[0.3633505783541758]
Test: [0/1]	Time  0.260 ( 0.260)	Loss 9.8716e-01 (9.8716e-01)	Acc@1   0.43 (  0.43)	Acc@5   0.00 (  0.00)
 * Acc@1 0.430 Acc@5 0.000
Test: [0/1]	Time  0.313 ( 0.313)	Loss 4.0698e-01 (4.0698e-01)	Acc@1   0.22 (  0.22)	Acc@5   0.00 (  0.00)
 * Acc@1 0.222 Acc@5 0.000
17
TRAINING
Epoch: [17][0/1]	Time  1.017 ( 1.017)	Data  0.302 ( 0.302)	Loss 3.3567e-01 (3.3567e-01)	Acc@1   0.40 (  0.40)	Acc@5   0.00 (  0.00)
[0.39829676087046995]
Test: [0/1]	Time  0.266 ( 0.266)	Loss 9.8832e-01 (9.8832e-01)	Acc@1   0.45 (  0.45)	Acc@5   0.00 (  0.00)
 * Acc@1 0.453 Acc@5 0.000
Test: [0/1]	Time  0.320 ( 0.320)	Loss 3.7133e-01 (3.7133e-01)	Acc@1   0.25 (  0.25)	Acc@5   0.00 (  0.00)
 * Acc@1 0.254 Acc@5 0.000
18
TRAINING
Epoch: [18][0/1]	Time  1.043 ( 1.043)	Data  0.346 ( 0.346)	Loss 2.7919e-01 (2.7919e-01)	Acc@1   0.44 (  0.44)	Acc@5   0.00 (  0.00)
[0.43705271212446273]
Test: [0/1]	Time  0.276 ( 0.276)	Loss 9.9216e-01 (9.9216e-01)	Acc@1   0.47 (  0.47)	Acc@5   0.00 (  0.00)
 * Acc@1 0.473 Acc@5 0.000
Test: [0/1]	Time  0.329 ( 0.329)	Loss 3.4520e-01 (3.4520e-01)	Acc@1   0.29 (  0.29)	Acc@5   0.00 (  0.00)
 * Acc@1 0.286 Acc@5 0.000
19
TRAINING
Epoch: [19][0/1]	Time  0.997 ( 0.997)	Data  0.306 ( 0.306)	Loss 2.3649e-01 (2.3649e-01)	Acc@1   0.48 (  0.48)	Acc@5   0.00 (  0.00)
[0.4791111744001172]
Test: [0/1]	Time  0.257 ( 0.257)	Loss 9.9691e-01 (9.9691e-01)	Acc@1   0.51 (  0.51)	Acc@5   0.00 (  0.00)
 * Acc@1 0.507 Acc@5 0.000
Test: [0/1]	Time  0.314 ( 0.314)	Loss 3.2942e-01 (3.2942e-01)	Acc@1   0.31 (  0.31)	Acc@5   0.00 (  0.00)
 * Acc@1 0.311 Acc@5 0.000
20
TRAINING
Epoch: [20][0/1]	Time  1.004 ( 1.004)	Data  0.300 ( 0.300)	Loss 2.0875e-01 (2.0875e-01)	Acc@1   0.52 (  0.52)	Acc@5   0.00 (  0.00)
[0.5223948304766024]
Test: [0/1]	Time  0.262 ( 0.262)	Loss 1.0005e+00 (1.0005e+00)	Acc@1   0.53 (  0.53)	Acc@5   0.00 (  0.00)
 * Acc@1 0.535 Acc@5 0.000
Test: [0/1]	Time  0.322 ( 0.322)	Loss 3.1944e-01 (3.1944e-01)	Acc@1   0.33 (  0.33)	Acc@5   0.00 (  0.00)
 * Acc@1 0.334 Acc@5 0.000
21
TRAINING
Epoch: [21][0/1]	Time  1.016 ( 1.016)	Data  0.328 ( 0.328)	Loss 1.9114e-01 (1.9114e-01)	Acc@1   0.57 (  0.57)	Acc@5   0.00 (  0.00)
[0.5650777811028442]
Test: [0/1]	Time  0.274 ( 0.274)	Loss 1.0010e+00 (1.0010e+00)	Acc@1   0.56 (  0.56)	Acc@5   0.00 (  0.00)
 * Acc@1 0.562 Acc@5 0.000
Test: [0/1]	Time  0.329 ( 0.329)	Loss 3.0867e-01 (3.0867e-01)	Acc@1   0.36 (  0.36)	Acc@5   0.00 (  0.00)
 * Acc@1 0.356 Acc@5 0.000
22
TRAINING
Epoch: [22][0/1]	Time  1.033 ( 1.033)	Data  0.307 ( 0.307)	Loss 1.7659e-01 (1.7659e-01)	Acc@1   0.61 (  0.61)	Acc@5   0.00 (  0.00)
[0.6115611812740487]
Test: [0/1]	Time  0.271 ( 0.271)	Loss 9.9771e-01 (9.9771e-01)	Acc@1   0.59 (  0.59)	Acc@5   0.00 (  0.00)
 * Acc@1 0.590 Acc@5 0.000
Test: [0/1]	Time  0.322 ( 0.322)	Loss 2.9264e-01 (2.9264e-01)	Acc@1   0.38 (  0.38)	Acc@5   0.00 (  0.00)
 * Acc@1 0.380 Acc@5 0.000
23
TRAINING
Epoch: [23][0/1]	Time  1.002 ( 1.002)	Data  0.300 ( 0.300)	Loss 1.6009e-01 (1.6009e-01)	Acc@1   0.66 (  0.66)	Acc@5   0.00 (  0.00)
[0.6570996708066017]
Test: [0/1]	Time  0.262 ( 0.262)	Loss 9.9091e-01 (9.9091e-01)	Acc@1   0.62 (  0.62)	Acc@5   0.00 (  0.00)
 * Acc@1 0.619 Acc@5 0.000
Test: [0/1]	Time  0.309 ( 0.309)	Loss 2.7119e-01 (2.7119e-01)	Acc@1   0.40 (  0.40)	Acc@5   0.00 (  0.00)
 * Acc@1 0.404 Acc@5 0.000
24
TRAINING
Epoch: [24][0/1]	Time  1.003 ( 1.003)	Data  0.282 ( 0.282)	Loss 1.4089e-01 (1.4089e-01)	Acc@1   0.70 (  0.70)	Acc@5   0.00 (  0.00)
[0.6997397001631664]
Test: [0/1]	Time  0.248 ( 0.248)	Loss 9.8191e-01 (9.8191e-01)	Acc@1   0.64 (  0.64)	Acc@5   0.00 (  0.00)
 * Acc@1 0.644 Acc@5 0.000
Test: [0/1]	Time  0.303 ( 0.303)	Loss 2.4790e-01 (2.4790e-01)	Acc@1   0.43 (  0.43)	Acc@5   0.00 (  0.00)
 * Acc@1 0.427 Acc@5 0.000
25
TRAINING
Epoch: [25][0/1]	Time  0.983 ( 0.983)	Data  0.286 ( 0.286)	Loss 1.2191e-01 (1.2191e-01)	Acc@1   0.74 (  0.74)	Acc@5   0.00 (  0.00)
[0.7382676497178413]
Test: [0/1]	Time  0.260 ( 0.260)	Loss 9.7235e-01 (9.7235e-01)	Acc@1   0.67 (  0.67)	Acc@5   0.00 (  0.00)
 * Acc@1 0.666 Acc@5 0.000
Test: [0/1]	Time  0.315 ( 0.315)	Loss 2.2746e-01 (2.2746e-01)	Acc@1   0.45 (  0.45)	Acc@5   0.00 (  0.00)
 * Acc@1 0.448 Acc@5 0.000
26
TRAINING
Epoch: [26][0/1]	Time  1.035 ( 1.035)	Data  0.303 ( 0.303)	Loss 1.0703e-01 (1.0703e-01)	Acc@1   0.77 (  0.77)	Acc@5   0.00 (  0.00)
[0.7658761673794251]
Test: [0/1]	Time  0.261 ( 0.261)	Loss 9.6366e-01 (9.6366e-01)	Acc@1   0.68 (  0.68)	Acc@5   0.00 (  0.00)
 * Acc@1 0.678 Acc@5 0.000
Test: [0/1]	Time  0.308 ( 0.308)	Loss 2.1285e-01 (2.1285e-01)	Acc@1   0.47 (  0.47)	Acc@5   0.00 (  0.00)
 * Acc@1 0.472 Acc@5 0.000
27
TRAINING
Epoch: [27][0/1]	Time  0.988 ( 0.988)	Data  0.290 ( 0.290)	Loss 9.8476e-02 (9.8476e-02)	Acc@1   0.79 (  0.79)	Acc@5   0.00 (  0.00)
[0.7937362420435632]
Test: [0/1]	Time  0.252 ( 0.252)	Loss 9.5671e-01 (9.5671e-01)	Acc@1   0.69 (  0.69)	Acc@5   0.00 (  0.00)
 * Acc@1 0.685 Acc@5 0.000
Test: [0/1]	Time  0.328 ( 0.328)	Loss 2.0401e-01 (2.0401e-01)	Acc@1   0.50 (  0.50)	Acc@5   0.00 (  0.00)
 * Acc@1 0.499 Acc@5 0.000
28
TRAINING
Epoch: [28][0/1]	Time  1.009 ( 1.009)	Data  0.295 ( 0.295)	Loss 9.5546e-02 (9.5546e-02)	Acc@1   0.81 (  0.81)	Acc@5   0.00 (  0.00)
[0.8136293331610098]
Test: [0/1]	Time  0.253 ( 0.253)	Loss 9.5176e-01 (9.5176e-01)	Acc@1   0.69 (  0.69)	Acc@5   0.00 (  0.00)
 * Acc@1 0.689 Acc@5 0.000
Test: [0/1]	Time  0.309 ( 0.309)	Loss 1.9850e-01 (1.9850e-01)	Acc@1   0.53 (  0.53)	Acc@5   0.00 (  0.00)
 * Acc@1 0.526 Acc@5 0.000
29
TRAINING
Epoch: [29][0/1]	Time  1.032 ( 1.032)	Data  0.312 ( 0.312)	Loss 9.5380e-02 (9.5380e-02)	Acc@1   0.83 (  0.83)	Acc@5   0.00 (  0.00)
[0.8278350201989235]
Test: [0/1]	Time  0.273 ( 0.273)	Loss 9.4868e-01 (9.4868e-01)	Acc@1   0.69 (  0.69)	Acc@5   0.00 (  0.00)
 * Acc@1 0.687 Acc@5 0.000
Test: [0/1]	Time  0.325 ( 0.325)	Loss 1.9329e-01 (1.9329e-01)	Acc@1   0.55 (  0.55)	Acc@5   0.00 (  0.00)
 * Acc@1 0.554 Acc@5 0.000
30
TRAINING
Epoch: [30][0/1]	Time  0.998 ( 0.998)	Data  0.274 ( 0.274)	Loss 9.4808e-02 (9.4808e-02)	Acc@1   0.84 (  0.84)	Acc@5   0.00 (  0.00)
[0.8418159889439669]
Test: [0/1]	Time  0.262 ( 0.262)	Loss 9.4719e-01 (9.4719e-01)	Acc@1   0.68 (  0.68)	Acc@5   0.00 (  0.00)
 * Acc@1 0.684 Acc@5 0.000
Test: [0/1]	Time  0.310 ( 0.310)	Loss 1.8663e-01 (1.8663e-01)	Acc@1   0.58 (  0.58)	Acc@5   0.00 (  0.00)
 * Acc@1 0.579 Acc@5 0.000
31
TRAINING
Epoch: [31][0/1]	Time  0.982 ( 0.982)	Data  0.280 ( 0.280)	Loss 9.2076e-02 (9.2076e-02)	Acc@1   0.85 (  0.85)	Acc@5   0.00 (  0.00)
[0.8524433537458218]
Test: [0/1]	Time  0.260 ( 0.260)	Loss 9.4701e-01 (9.4701e-01)	Acc@1   0.68 (  0.68)	Acc@5   0.00 (  0.00)
 * Acc@1 0.682 Acc@5 0.000
Test: [0/1]	Time  0.307 ( 0.307)	Loss 1.7869e-01 (1.7869e-01)	Acc@1   0.60 (  0.60)	Acc@5   0.00 (  0.00)
 * Acc@1 0.604 Acc@5 0.000
32
TRAINING
Epoch: [32][0/1]	Time  1.000 ( 1.000)	Data  0.305 ( 0.305)	Loss 8.7476e-02 (8.7476e-02)	Acc@1   0.86 (  0.86)	Acc@5   0.00 (  0.00)
[0.8625561072385576]
Test: [0/1]	Time  0.270 ( 0.270)	Loss 9.4788e-01 (9.4788e-01)	Acc@1   0.68 (  0.68)	Acc@5   0.00 (  0.00)
 * Acc@1 0.679 Acc@5 0.000
Test: [0/1]	Time  0.315 ( 0.315)	Loss 1.7107e-01 (1.7107e-01)	Acc@1   0.63 (  0.63)	Acc@5   0.00 (  0.00)
 * Acc@1 0.629 Acc@5 0.000
33
TRAINING
Epoch: [33][0/1]	Time  1.034 ( 1.034)	Data  0.341 ( 0.341)	Loss 8.2706e-02 (8.2706e-02)	Acc@1   0.87 (  0.87)	Acc@5   0.00 (  0.00)
[0.869719744264496]
Test: [0/1]	Time  0.335 ( 0.335)	Loss 9.4947e-01 (9.4947e-01)	Acc@1   0.68 (  0.68)	Acc@5   0.00 (  0.00)
 * Acc@1 0.677 Acc@5 0.000
Test: [0/1]	Time  0.364 ( 0.364)	Loss 1.6543e-01 (1.6543e-01)	Acc@1   0.65 (  0.65)	Acc@5   0.00 (  0.00)
 * Acc@1 0.652 Acc@5 0.000
34
TRAINING
Epoch: [34][0/1]	Time  0.994 ( 0.994)	Data  0.285 ( 0.285)	Loss 7.9573e-02 (7.9573e-02)	Acc@1   0.87 (  0.87)	Acc@5   0.00 (  0.00)
[0.8739466599450603]
Test: [0/1]	Time  0.295 ( 0.295)	Loss 9.5131e-01 (9.5131e-01)	Acc@1   0.67 (  0.67)	Acc@5   0.00 (  0.00)
 * Acc@1 0.674 Acc@5 0.000
Test: [0/1]	Time  0.342 ( 0.342)	Loss 1.6247e-01 (1.6247e-01)	Acc@1   0.67 (  0.67)	Acc@5   0.00 (  0.00)
 * Acc@1 0.667 Acc@5 0.000
35
TRAINING
Epoch: [35][0/1]	Time  0.981 ( 0.981)	Data  0.280 ( 0.280)	Loss 7.8891e-02 (7.8891e-02)	Acc@1   0.88 (  0.88)	Acc@5   0.00 (  0.00)
[0.8763421789828076]
Test: [0/1]	Time  0.272 ( 0.272)	Loss 9.5286e-01 (9.5286e-01)	Acc@1   0.67 (  0.67)	Acc@5   0.00 (  0.00)
 * Acc@1 0.671 Acc@5 0.000
Test: [0/1]	Time  0.326 ( 0.326)	Loss 1.6160e-01 (1.6160e-01)	Acc@1   0.68 (  0.68)	Acc@5   0.00 (  0.00)
 * Acc@1 0.680 Acc@5 0.000
36
TRAINING
Epoch: [36][0/1]	Time  0.988 ( 0.988)	Data  0.292 ( 0.292)	Loss 8.0170e-02 (8.0170e-02)	Acc@1   0.88 (  0.88)	Acc@5   0.00 (  0.00)
[0.8769122933914144]
Test: [0/1]	Time  0.260 ( 0.260)	Loss 9.5365e-01 (9.5365e-01)	Acc@1   0.67 (  0.67)	Acc@5   0.00 (  0.00)
 * Acc@1 0.668 Acc@5 0.000
Test: [0/1]	Time  0.312 ( 0.312)	Loss 1.6139e-01 (1.6139e-01)	Acc@1   0.69 (  0.69)	Acc@5   0.00 (  0.00)
 * Acc@1 0.693 Acc@5 0.000
37
TRAINING
Epoch: [37][0/1]	Time  0.983 ( 0.983)	Data  0.292 ( 0.292)	Loss 8.2099e-02 (8.2099e-02)	Acc@1   0.88 (  0.88)	Acc@5   0.00 (  0.00)
[0.8762478119465822]
Test: [0/1]	Time  0.255 ( 0.255)	Loss 9.5338e-01 (9.5338e-01)	Acc@1   0.66 (  0.66)	Acc@5   0.00 (  0.00)
 * Acc@1 0.664 Acc@5 0.000
Test: [0/1]	Time  0.311 ( 0.311)	Loss 1.6057e-01 (1.6057e-01)	Acc@1   0.70 (  0.70)	Acc@5   0.00 (  0.00)
 * Acc@1 0.704 Acc@5 0.000
38
TRAINING
Epoch: [38][0/1]	Time  1.003 ( 1.003)	Data  0.299 ( 0.299)	Loss 8.3420e-02 (8.3420e-02)	Acc@1   0.87 (  0.87)	Acc@5   0.00 (  0.00)
[0.8740930007563812]
Test: [0/1]	Time  0.276 ( 0.276)	Loss 9.5202e-01 (9.5202e-01)	Acc@1   0.66 (  0.66)	Acc@5   0.00 (  0.00)
 * Acc@1 0.661 Acc@5 0.000
Test: [0/1]	Time  0.307 ( 0.307)	Loss 1.5861e-01 (1.5861e-01)	Acc@1   0.71 (  0.71)	Acc@5   0.00 (  0.00)
 * Acc@1 0.713 Acc@5 0.000
39
TRAINING
Epoch: [39][0/1]	Time  0.983 ( 0.983)	Data  0.289 ( 0.289)	Loss 8.3591e-02 (8.3591e-02)	Acc@1   0.87 (  0.87)	Acc@5   0.00 (  0.00)
[0.8714795736080387]
Test: [0/1]	Time  0.263 ( 0.263)	Loss 9.4981e-01 (9.4981e-01)	Acc@1   0.66 (  0.66)	Acc@5   0.00 (  0.00)
 * Acc@1 0.658 Acc@5 0.000
Test: [0/1]	Time  0.314 ( 0.314)	Loss 1.5590e-01 (1.5590e-01)	Acc@1   0.72 (  0.72)	Acc@5   0.00 (  0.00)
 * Acc@1 0.720 Acc@5 0.000
40
TRAINING
Epoch: [40][0/1]	Time  0.964 ( 0.964)	Data  0.270 ( 0.270)	Loss 8.2917e-02 (8.2917e-02)	Acc@1   0.87 (  0.87)	Acc@5   0.00 (  0.00)
[0.8711916173751147]
Test: [0/1]	Time  0.255 ( 0.255)	Loss 9.4716e-01 (9.4716e-01)	Acc@1   0.65 (  0.65)	Acc@5   0.00 (  0.00)
 * Acc@1 0.654 Acc@5 0.000
Test: [0/1]	Time  0.306 ( 0.306)	Loss 1.5331e-01 (1.5331e-01)	Acc@1   0.73 (  0.73)	Acc@5   0.00 (  0.00)
 * Acc@1 0.727 Acc@5 0.000
41
TRAINING
Epoch: [41][0/1]	Time  0.970 ( 0.970)	Data  0.260 ( 0.260)	Loss 8.2172e-02 (8.2172e-02)	Acc@1   0.87 (  0.87)	Acc@5   0.00 (  0.00)
[0.8707594984253753]
Test: [0/1]	Time  0.246 ( 0.246)	Loss 9.4450e-01 (9.4450e-01)	Acc@1   0.65 (  0.65)	Acc@5   0.00 (  0.00)
 * Acc@1 0.651 Acc@5 0.000
Test: [0/1]	Time  0.374 ( 0.374)	Loss 1.5161e-01 (1.5161e-01)	Acc@1   0.73 (  0.73)	Acc@5   0.00 (  0.00)
 * Acc@1 0.732 Acc@5 0.000
42
TRAINING
Epoch: [42][0/1]	Time  1.016 ( 1.016)	Data  0.316 ( 0.316)	Loss 8.2027e-02 (8.2027e-02)	Acc@1   0.87 (  0.87)	Acc@5   0.00 (  0.00)
[0.8709500460748612]
Test: [0/1]	Time  0.274 ( 0.274)	Loss 9.4217e-01 (9.4217e-01)	Acc@1   0.65 (  0.65)	Acc@5   0.00 (  0.00)
 * Acc@1 0.648 Acc@5 0.000
Test: [0/1]	Time  0.344 ( 0.344)	Loss 1.5105e-01 (1.5105e-01)	Acc@1   0.74 (  0.74)	Acc@5   0.00 (  0.00)
 * Acc@1 0.737 Acc@5 0.000
43
TRAINING
Epoch: [43][0/1]	Time  1.018 ( 1.018)	Data  0.307 ( 0.307)	Loss 8.2649e-02 (8.2649e-02)	Acc@1   0.87 (  0.87)	Acc@5   0.00 (  0.00)
[0.8719807401131867]
Test: [0/1]	Time  0.267 ( 0.267)	Loss 9.4040e-01 (9.4040e-01)	Acc@1   0.64 (  0.64)	Acc@5   0.00 (  0.00)
 * Acc@1 0.644 Acc@5 0.000
Test: [0/1]	Time  0.316 ( 0.316)	Loss 1.5129e-01 (1.5129e-01)	Acc@1   0.74 (  0.74)	Acc@5   0.00 (  0.00)
 * Acc@1 0.740 Acc@5 0.000
44
TRAINING
Epoch: [44][0/1]	Time  1.010 ( 1.010)	Data  0.316 ( 0.316)	Loss 8.3684e-02 (8.3684e-02)	Acc@1   0.87 (  0.87)	Acc@5   0.00 (  0.00)
[0.8737255961600584]
Test: [0/1]	Time  0.264 ( 0.264)	Loss 9.3929e-01 (9.3929e-01)	Acc@1   0.64 (  0.64)	Acc@5   0.00 (  0.00)
 * Acc@1 0.642 Acc@5 0.000
Test: [0/1]	Time  0.315 ( 0.315)	Loss 1.5172e-01 (1.5172e-01)	Acc@1   0.74 (  0.74)	Acc@5   0.00 (  0.00)
 * Acc@1 0.743 Acc@5 0.000
45
TRAINING
Epoch: [45][0/1]	Time  1.014 ( 1.014)	Data  0.317 ( 0.317)	Loss 8.4540e-02 (8.4540e-02)	Acc@1   0.88 (  0.88)	Acc@5   0.00 (  0.00)
[0.8756779847872527]
Test: [0/1]	Time  0.267 ( 0.267)	Loss 9.3884e-01 (9.3884e-01)	Acc@1   0.64 (  0.64)	Acc@5   0.00 (  0.00)
 * Acc@1 0.640 Acc@5 0.000
Test: [0/1]	Time  0.317 ( 0.317)	Loss 1.5187e-01 (1.5187e-01)	Acc@1   0.75 (  0.75)	Acc@5   0.00 (  0.00)
 * Acc@1 0.745 Acc@5 0.000
46
TRAINING
Epoch: [46][0/1]	Time  0.995 ( 0.995)	Data  0.297 ( 0.297)	Loss 8.4769e-02 (8.4769e-02)	Acc@1   0.88 (  0.88)	Acc@5   0.00 (  0.00)
[0.8781664296697858]
Test: [0/1]	Time  0.272 ( 0.272)	Loss 9.3902e-01 (9.3902e-01)	Acc@1   0.64 (  0.64)	Acc@5   0.00 (  0.00)
 * Acc@1 0.639 Acc@5 0.000
Test: [0/1]	Time  0.324 ( 0.324)	Loss 1.5162e-01 (1.5162e-01)	Acc@1   0.75 (  0.75)	Acc@5   0.00 (  0.00)
 * Acc@1 0.747 Acc@5 0.000
47
TRAINING
Epoch: [47][0/1]	Time  0.983 ( 0.983)	Data  0.290 ( 0.290)	Loss 8.4304e-02 (8.4304e-02)	Acc@1   0.88 (  0.88)	Acc@5   0.00 (  0.00)
[0.8817351665987128]
Test: [0/1]	Time  0.263 ( 0.263)	Loss 9.3973e-01 (9.3973e-01)	Acc@1   0.64 (  0.64)	Acc@5   0.00 (  0.00)
 * Acc@1 0.638 Acc@5 0.000
Test: [0/1]	Time  0.319 ( 0.319)	Loss 1.5119e-01 (1.5119e-01)	Acc@1   0.75 (  0.75)	Acc@5   0.00 (  0.00)
 * Acc@1 0.748 Acc@5 0.000
48
TRAINING
Epoch: [48][0/1]	Time  0.986 ( 0.986)	Data  0.288 ( 0.288)	Loss 8.3432e-02 (8.3432e-02)	Acc@1   0.89 (  0.89)	Acc@5   0.00 (  0.00)
[0.8857228926056325]
Test: [0/1]	Time  0.263 ( 0.263)	Loss 9.4082e-01 (9.4082e-01)	Acc@1   0.64 (  0.64)	Acc@5   0.00 (  0.00)
 * Acc@1 0.637 Acc@5 0.000
Test: [0/1]	Time  0.325 ( 0.325)	Loss 1.5094e-01 (1.5094e-01)	Acc@1   0.75 (  0.75)	Acc@5   0.00 (  0.00)
 * Acc@1 0.748 Acc@5 0.000
49
TRAINING
Epoch: [49][0/1]	Time  1.025 ( 1.025)	Data  0.310 ( 0.310)	Loss 8.2582e-02 (8.2582e-02)	Acc@1   0.89 (  0.89)	Acc@5   0.00 (  0.00)
[0.8897892872374153]
Test: [0/1]	Time  0.260 ( 0.260)	Loss 9.4210e-01 (9.4210e-01)	Acc@1   0.64 (  0.64)	Acc@5   0.00 (  0.00)
 * Acc@1 0.637 Acc@5 0.000
Test: [0/1]	Time  0.319 ( 0.319)	Loss 1.5110e-01 (1.5110e-01)	Acc@1   0.75 (  0.75)	Acc@5   0.00 (  0.00)
 * Acc@1 0.749 Acc@5 0.000
50
TRAINING
Epoch: [50][0/1]	Time  0.992 ( 0.992)	Data  0.280 ( 0.280)	Loss 8.2066e-02 (8.2066e-02)	Acc@1   0.89 (  0.89)	Acc@5   0.00 (  0.00)
[0.893655310401968]
Test: [0/1]	Time  0.260 ( 0.260)	Loss 9.4335e-01 (9.4335e-01)	Acc@1   0.64 (  0.64)	Acc@5   0.00 (  0.00)
 * Acc@1 0.637 Acc@5 0.000
Test: [0/1]	Time  0.311 ( 0.311)	Loss 1.5166e-01 (1.5166e-01)	Acc@1   0.75 (  0.75)	Acc@5   0.00 (  0.00)
 * Acc@1 0.749 Acc@5 0.000
51
TRAINING
Epoch: [51][0/1]	Time  1.006 ( 1.006)	Data  0.307 ( 0.307)	Loss 8.1941e-02 (8.1941e-02)	Acc@1   0.90 (  0.90)	Acc@5   0.00 (  0.00)
[0.8971936408116784]
Test: [0/1]	Time  0.292 ( 0.292)	Loss 9.4436e-01 (9.4436e-01)	Acc@1   0.64 (  0.64)	Acc@5   0.00 (  0.00)
 * Acc@1 0.638 Acc@5 0.000
Test: [0/1]	Time  0.343 ( 0.343)	Loss 1.5239e-01 (1.5239e-01)	Acc@1   0.75 (  0.75)	Acc@5   0.00 (  0.00)
 * Acc@1 0.749 Acc@5 0.000
52
TRAINING
Epoch: [52][0/1]	Time  1.004 ( 1.004)	Data  0.291 ( 0.291)	Loss 8.2034e-02 (8.2034e-02)	Acc@1   0.90 (  0.90)	Acc@5   0.00 (  0.00)
[0.9005059909341688]
Test: [0/1]	Time  0.243 ( 0.243)	Loss 9.4499e-01 (9.4499e-01)	Acc@1   0.64 (  0.64)	Acc@5   0.00 (  0.00)
 * Acc@1 0.639 Acc@5 0.000
Test: [0/1]	Time  0.306 ( 0.306)	Loss 1.5299e-01 (1.5299e-01)	Acc@1   0.75 (  0.75)	Acc@5   0.00 (  0.00)
 * Acc@1 0.750 Acc@5 0.000
53
TRAINING
Epoch: [53][0/1]	Time  0.994 ( 0.994)	Data  0.294 ( 0.294)	Loss 8.2096e-02 (8.2096e-02)	Acc@1   0.90 (  0.90)	Acc@5   0.00 (  0.00)
[0.9034319587964115]
Test: [0/1]	Time  0.257 ( 0.257)	Loss 9.4516e-01 (9.4516e-01)	Acc@1   0.64 (  0.64)	Acc@5   0.00 (  0.00)
 * Acc@1 0.641 Acc@5 0.000
Test: [0/1]	Time  0.311 ( 0.311)	Loss 1.5327e-01 (1.5327e-01)	Acc@1   0.75 (  0.75)	Acc@5   0.00 (  0.00)
 * Acc@1 0.750 Acc@5 0.000
54
TRAINING
Epoch: [54][0/1]	Time  1.012 ( 1.012)	Data  0.313 ( 0.313)	Loss 8.1962e-02 (8.1962e-02)	Acc@1   0.91 (  0.91)	Acc@5   0.00 (  0.00)
[0.9061190736855242]
Test: [0/1]	Time  0.270 ( 0.270)	Loss 9.4489e-01 (9.4489e-01)	Acc@1   0.64 (  0.64)	Acc@5   0.00 (  0.00)
 * Acc@1 0.643 Acc@5 0.000
Test: [0/1]	Time  0.320 ( 0.320)	Loss 1.5323e-01 (1.5323e-01)	Acc@1   0.75 (  0.75)	Acc@5   0.00 (  0.00)
 * Acc@1 0.750 Acc@5 0.000
55
TRAINING
Epoch: [55][0/1]	Time  1.020 ( 1.020)	Data  0.311 ( 0.311)	Loss 8.1630e-02 (8.1630e-02)	Acc@1   0.91 (  0.91)	Acc@5   0.00 (  0.00)
[0.9085808265549378]
Test: [0/1]	Time  0.281 ( 0.281)	Loss 9.4431e-01 (9.4431e-01)	Acc@1   0.65 (  0.65)	Acc@5   0.00 (  0.00)
 * Acc@1 0.646 Acc@5 0.000
Test: [0/1]	Time  0.331 ( 0.331)	Loss 1.5302e-01 (1.5302e-01)	Acc@1   0.75 (  0.75)	Acc@5   0.00 (  0.00)
 * Acc@1 0.750 Acc@5 0.000
56
TRAINING
Epoch: [56][0/1]	Time  0.947 ( 0.947)	Data  0.272 ( 0.272)	Loss 8.1227e-02 (8.1227e-02)	Acc@1   0.91 (  0.91)	Acc@5   0.00 (  0.00)
[0.9108219069248682]
Test: [0/1]	Time  0.251 ( 0.251)	Loss 9.4356e-01 (9.4356e-01)	Acc@1   0.65 (  0.65)	Acc@5   0.00 (  0.00)
 * Acc@1 0.649 Acc@5 0.000
Test: [0/1]	Time  0.293 ( 0.293)	Loss 1.5280e-01 (1.5280e-01)	Acc@1   0.75 (  0.75)	Acc@5   0.00 (  0.00)
 * Acc@1 0.751 Acc@5 0.000
57
TRAINING
Epoch: [57][0/1]	Time  0.999 ( 0.999)	Data  0.300 ( 0.300)	Loss 8.0909e-02 (8.0909e-02)	Acc@1   0.91 (  0.91)	Acc@5   0.00 (  0.00)
[0.9128481448547878]
Test: [0/1]	Time  0.258 ( 0.258)	Loss 9.4280e-01 (9.4280e-01)	Acc@1   0.65 (  0.65)	Acc@5   0.00 (  0.00)
 * Acc@1 0.652 Acc@5 0.000
Test: [0/1]	Time  0.312 ( 0.312)	Loss 1.5272e-01 (1.5272e-01)	Acc@1   0.75 (  0.75)	Acc@5   0.00 (  0.00)
 * Acc@1 0.752 Acc@5 0.000
58
TRAINING
Epoch: [58][0/1]	Time  1.004 ( 1.004)	Data  0.299 ( 0.299)	Loss 8.0759e-02 (8.0759e-02)	Acc@1   0.91 (  0.91)	Acc@5   0.00 (  0.00)
[0.9146771683206004]
Test: [0/1]	Time  0.264 ( 0.264)	Loss 9.4217e-01 (9.4217e-01)	Acc@1   0.66 (  0.66)	Acc@5   0.00 (  0.00)
 * Acc@1 0.655 Acc@5 0.000
Test: [0/1]	Time  0.312 ( 0.312)	Loss 1.5275e-01 (1.5275e-01)	Acc@1   0.75 (  0.75)	Acc@5   0.00 (  0.00)
 * Acc@1 0.752 Acc@5 0.000
59
TRAINING
Epoch: [59][0/1]	Time  0.971 ( 0.971)	Data  0.259 ( 0.259)	Loss 8.0746e-02 (8.0746e-02)	Acc@1   0.92 (  0.92)	Acc@5   0.00 (  0.00)
[0.9168186117641932]
Test: [0/1]	Time  0.288 ( 0.288)	Loss 9.4175e-01 (9.4175e-01)	Acc@1   0.66 (  0.66)	Acc@5   0.00 (  0.00)
 * Acc@1 0.659 Acc@5 0.000
Test: [0/1]	Time  0.326 ( 0.326)	Loss 1.5282e-01 (1.5282e-01)	Acc@1   0.75 (  0.75)	Acc@5   0.00 (  0.00)
 * Acc@1 0.753 Acc@5 0.000
60
TRAINING
Epoch: [60][0/1]	Time  1.030 ( 1.030)	Data  0.321 ( 0.321)	Loss 8.0765e-02 (8.0765e-02)	Acc@1   0.92 (  0.92)	Acc@5   0.00 (  0.00)
[0.9190144125635171]
Test: [0/1]	Time  0.265 ( 0.265)	Loss 9.4159e-01 (9.4159e-01)	Acc@1   0.66 (  0.66)	Acc@5   0.00 (  0.00)
 * Acc@1 0.662 Acc@5 0.000
Test: [0/1]	Time  0.321 ( 0.321)	Loss 1.5284e-01 (1.5284e-01)	Acc@1   0.75 (  0.75)	Acc@5   0.00 (  0.00)
 * Acc@1 0.754 Acc@5 0.000
61
TRAINING
Epoch: [61][0/1]	Time  1.062 ( 1.062)	Data  0.365 ( 0.365)	Loss 8.0705e-02 (8.0705e-02)	Acc@1   0.92 (  0.92)	Acc@5   0.00 (  0.00)
[0.9210759263691525]
Test: [0/1]	Time  0.289 ( 0.289)	Loss 9.4170e-01 (9.4170e-01)	Acc@1   0.67 (  0.67)	Acc@5   0.00 (  0.00)
 * Acc@1 0.665 Acc@5 0.000
Test: [0/1]	Time  0.336 ( 0.336)	Loss 1.5276e-01 (1.5276e-01)	Acc@1   0.75 (  0.75)	Acc@5   0.00 (  0.00)
 * Acc@1 0.755 Acc@5 0.000
62
TRAINING
Epoch: [62][0/1]	Time  0.992 ( 0.992)	Data  0.308 ( 0.308)	Loss 8.0516e-02 (8.0516e-02)	Acc@1   0.92 (  0.92)	Acc@5   0.00 (  0.00)
[0.9229981689715481]
Test: [0/1]	Time  0.265 ( 0.265)	Loss 9.4206e-01 (9.4206e-01)	Acc@1   0.67 (  0.67)	Acc@5   0.00 (  0.00)
 * Acc@1 0.669 Acc@5 0.000
Test: [0/1]	Time  0.318 ( 0.318)	Loss 1.5260e-01 (1.5260e-01)	Acc@1   0.76 (  0.76)	Acc@5   0.00 (  0.00)
 * Acc@1 0.756 Acc@5 0.000
63
TRAINING
Epoch: [63][0/1]	Time  1.030 ( 1.030)	Data  0.319 ( 0.319)	Loss 8.0227e-02 (8.0227e-02)	Acc@1   0.92 (  0.92)	Acc@5   0.00 (  0.00)
[0.924755647613423]
Test: [0/1]	Time  0.277 ( 0.277)	Loss 9.4259e-01 (9.4259e-01)	Acc@1   0.67 (  0.67)	Acc@5   0.00 (  0.00)
 * Acc@1 0.672 Acc@5 0.000
Test: [0/1]	Time  0.322 ( 0.322)	Loss 1.5242e-01 (1.5242e-01)	Acc@1   0.76 (  0.76)	Acc@5   0.00 (  0.00)
 * Acc@1 0.757 Acc@5 0.000
64
TRAINING
Epoch: [64][0/1]	Time  1.002 ( 1.002)	Data  0.306 ( 0.306)	Loss 7.9917e-02 (7.9917e-02)	Acc@1   0.93 (  0.93)	Acc@5   0.00 (  0.00)
[0.9263133027407469]
Test: [0/1]	Time  0.256 ( 0.256)	Loss 9.4320e-01 (9.4320e-01)	Acc@1   0.68 (  0.68)	Acc@5   0.00 (  0.00)
 * Acc@1 0.676 Acc@5 0.000
Test: [0/1]	Time  0.316 ( 0.316)	Loss 1.5229e-01 (1.5229e-01)	Acc@1   0.76 (  0.76)	Acc@5   0.00 (  0.00)
 * Acc@1 0.758 Acc@5 0.000
65
TRAINING
Epoch: [65][0/1]	Time  1.006 ( 1.006)	Data  0.303 ( 0.303)	Loss 7.9666e-02 (7.9666e-02)	Acc@1   0.93 (  0.93)	Acc@5   0.00 (  0.00)
[0.9276422546329851]
Test: [0/1]	Time  0.262 ( 0.262)	Loss 9.4380e-01 (9.4380e-01)	Acc@1   0.68 (  0.68)	Acc@5   0.00 (  0.00)
 * Acc@1 0.679 Acc@5 0.000
Test: [0/1]	Time  0.332 ( 0.332)	Loss 1.5223e-01 (1.5223e-01)	Acc@1   0.76 (  0.76)	Acc@5   0.00 (  0.00)
 * Acc@1 0.758 Acc@5 0.000
66
TRAINING
Epoch: [66][0/1]	Time  1.025 ( 1.025)	Data  0.309 ( 0.309)	Loss 7.9511e-02 (7.9511e-02)	Acc@1   0.93 (  0.93)	Acc@5   0.00 (  0.00)
[0.9286744250774106]
Test: [0/1]	Time  0.265 ( 0.265)	Loss 9.4428e-01 (9.4428e-01)	Acc@1   0.68 (  0.68)	Acc@5   0.00 (  0.00)
 * Acc@1 0.680 Acc@5 0.000
Test: [0/1]	Time  0.317 ( 0.317)	Loss 1.5221e-01 (1.5221e-01)	Acc@1   0.76 (  0.76)	Acc@5   0.00 (  0.00)
 * Acc@1 0.759 Acc@5 0.000
67
TRAINING
Epoch: [67][0/1]	Time  1.080 ( 1.080)	Data  0.368 ( 0.368)	Loss 7.9438e-02 (7.9438e-02)	Acc@1   0.93 (  0.93)	Acc@5   0.00 (  0.00)
[0.9288235041477848]
Test: [0/1]	Time  0.293 ( 0.293)	Loss 9.4458e-01 (9.4458e-01)	Acc@1   0.68 (  0.68)	Acc@5   0.00 (  0.00)
 * Acc@1 0.682 Acc@5 0.000
Test: [0/1]	Time  0.339 ( 0.339)	Loss 1.5216e-01 (1.5216e-01)	Acc@1   0.76 (  0.76)	Acc@5   0.00 (  0.00)
 * Acc@1 0.760 Acc@5 0.000
68
TRAINING
Epoch: [68][0/1]	Time  1.008 ( 1.008)	Data  0.311 ( 0.311)	Loss 7.9401e-02 (7.9401e-02)	Acc@1   0.93 (  0.93)	Acc@5   0.00 (  0.00)
[0.9287031462682933]
Test: [0/1]	Time  0.275 ( 0.275)	Loss 9.4466e-01 (9.4466e-01)	Acc@1   0.68 (  0.68)	Acc@5   0.00 (  0.00)
 * Acc@1 0.684 Acc@5 0.000
Test: [0/1]	Time  0.322 ( 0.322)	Loss 1.5204e-01 (1.5204e-01)	Acc@1   0.76 (  0.76)	Acc@5   0.00 (  0.00)
 * Acc@1 0.761 Acc@5 0.000
69
TRAINING
Epoch: [69][0/1]	Time  0.995 ( 0.995)	Data  0.305 ( 0.305)	Loss 7.9356e-02 (7.9356e-02)	Acc@1   0.93 (  0.93)	Acc@5   0.00 (  0.00)
[0.9286344334472232]
Test: [0/1]	Time  0.265 ( 0.265)	Loss 9.4453e-01 (9.4453e-01)	Acc@1   0.69 (  0.69)	Acc@5   0.00 (  0.00)
 * Acc@1 0.686 Acc@5 0.000
Test: [0/1]	Time  0.318 ( 0.318)	Loss 1.5184e-01 (1.5184e-01)	Acc@1   0.76 (  0.76)	Acc@5   0.00 (  0.00)
 * Acc@1 0.761 Acc@5 0.000
70
TRAINING
Epoch: [70][0/1]	Time  0.959 ( 0.959)	Data  0.271 ( 0.271)	Loss 7.9287e-02 (7.9287e-02)	Acc@1   0.93 (  0.93)	Acc@5   0.00 (  0.00)
[0.9287743606730543]
Test: [0/1]	Time  0.252 ( 0.252)	Loss 9.4421e-01 (9.4421e-01)	Acc@1   0.69 (  0.69)	Acc@5   0.00 (  0.00)
 * Acc@1 0.687 Acc@5 0.000
Test: [0/1]	Time  0.308 ( 0.308)	Loss 1.5158e-01 (1.5158e-01)	Acc@1   0.76 (  0.76)	Acc@5   0.00 (  0.00)
 * Acc@1 0.762 Acc@5 0.000
71
TRAINING
Epoch: [71][0/1]	Time  1.010 ( 1.010)	Data  0.317 ( 0.317)	Loss 7.9206e-02 (7.9206e-02)	Acc@1   0.93 (  0.93)	Acc@5   0.00 (  0.00)
[0.9288955194483185]
Test: [0/1]	Time  0.268 ( 0.268)	Loss 9.4376e-01 (9.4376e-01)	Acc@1   0.69 (  0.69)	Acc@5   0.00 (  0.00)
 * Acc@1 0.689 Acc@5 0.000
Test: [0/1]	Time  0.310 ( 0.310)	Loss 1.5131e-01 (1.5131e-01)	Acc@1   0.76 (  0.76)	Acc@5   0.00 (  0.00)
 * Acc@1 0.763 Acc@5 0.000
72
TRAINING
Epoch: [72][0/1]	Time  1.016 ( 1.016)	Data  0.318 ( 0.318)	Loss 7.9140e-02 (7.9140e-02)	Acc@1   0.93 (  0.93)	Acc@5   0.00 (  0.00)
[0.9289344505187361]
Test: [0/1]	Time  0.281 ( 0.281)	Loss 9.4326e-01 (9.4326e-01)	Acc@1   0.69 (  0.69)	Acc@5   0.00 (  0.00)
 * Acc@1 0.691 Acc@5 0.000
Test: [0/1]	Time  0.330 ( 0.330)	Loss 1.5106e-01 (1.5106e-01)	Acc@1   0.76 (  0.76)	Acc@5   0.00 (  0.00)
 * Acc@1 0.764 Acc@5 0.000
73
TRAINING
Epoch: [73][0/1]	Time  1.029 ( 1.029)	Data  0.331 ( 0.331)	Loss 7.9110e-02 (7.9110e-02)	Acc@1   0.93 (  0.93)	Acc@5   0.00 (  0.00)
[0.9289791892258132]
Test: [0/1]	Time  0.250 ( 0.250)	Loss 9.4279e-01 (9.4279e-01)	Acc@1   0.69 (  0.69)	Acc@5   0.00 (  0.00)
 * Acc@1 0.693 Acc@5 0.000
Test: [0/1]	Time  0.301 ( 0.301)	Loss 1.5086e-01 (1.5086e-01)	Acc@1   0.76 (  0.76)	Acc@5   0.00 (  0.00)
 * Acc@1 0.764 Acc@5 0.000
74
TRAINING
Epoch: [74][0/1]	Time  1.018 ( 1.018)	Data  0.312 ( 0.312)	Loss 7.9116e-02 (7.9116e-02)	Acc@1   0.93 (  0.93)	Acc@5   0.00 (  0.00)
[0.9291440005833285]
Test: [0/1]	Time  0.273 ( 0.273)	Loss 9.4241e-01 (9.4241e-01)	Acc@1   0.70 (  0.70)	Acc@5   0.00 (  0.00)
 * Acc@1 0.695 Acc@5 0.000
Test: [0/1]	Time  0.323 ( 0.323)	Loss 1.5070e-01 (1.5070e-01)	Acc@1   0.76 (  0.76)	Acc@5   0.00 (  0.00)
 * Acc@1 0.765 Acc@5 0.000
75
TRAINING
Epoch: [75][0/1]	Time  1.005 ( 1.005)	Data  0.311 ( 0.311)	Loss 7.9141e-02 (7.9141e-02)	Acc@1   0.93 (  0.93)	Acc@5   0.00 (  0.00)
[0.9293072547139306]
Test: [0/1]	Time  0.251 ( 0.251)	Loss 9.4215e-01 (9.4215e-01)	Acc@1   0.70 (  0.70)	Acc@5   0.00 (  0.00)
 * Acc@1 0.697 Acc@5 0.000
Test: [0/1]	Time  0.303 ( 0.303)	Loss 1.5056e-01 (1.5056e-01)	Acc@1   0.77 (  0.77)	Acc@5   0.00 (  0.00)
 * Acc@1 0.766 Acc@5 0.000
76
TRAINING
Epoch: [76][0/1]	Time  1.018 ( 1.018)	Data  0.317 ( 0.317)	Loss 7.9157e-02 (7.9157e-02)	Acc@1   0.93 (  0.93)	Acc@5   0.00 (  0.00)
[0.9294603369035619]
Test: [0/1]	Time  0.267 ( 0.267)	Loss 9.4202e-01 (9.4202e-01)	Acc@1   0.70 (  0.70)	Acc@5   0.00 (  0.00)
 * Acc@1 0.699 Acc@5 0.000
Test: [0/1]	Time  0.320 ( 0.320)	Loss 1.5044e-01 (1.5044e-01)	Acc@1   0.77 (  0.77)	Acc@5   0.00 (  0.00)
 * Acc@1 0.766 Acc@5 0.000
77
TRAINING
Epoch: [77][0/1]	Time  1.035 ( 1.035)	Data  0.321 ( 0.321)	Loss 7.9148e-02 (7.9148e-02)	Acc@1   0.93 (  0.93)	Acc@5   0.00 (  0.00)
[0.9293515136103148]
Test: [0/1]	Time  0.270 ( 0.270)	Loss 9.4203e-01 (9.4203e-01)	Acc@1   0.70 (  0.70)	Acc@5   0.00 (  0.00)
 * Acc@1 0.700 Acc@5 0.000
Test: [0/1]	Time  0.320 ( 0.320)	Loss 1.5032e-01 (1.5032e-01)	Acc@1   0.77 (  0.77)	Acc@5   0.00 (  0.00)
 * Acc@1 0.767 Acc@5 0.000
78
TRAINING
Epoch: [78][0/1]	Time  1.007 ( 1.007)	Data  0.295 ( 0.295)	Loss 7.9110e-02 (7.9110e-02)	Acc@1   0.93 (  0.93)	Acc@5   0.00 (  0.00)
[0.9292688318585944]
Test: [0/1]	Time  0.268 ( 0.268)	Loss 9.4215e-01 (9.4215e-01)	Acc@1   0.70 (  0.70)	Acc@5   0.00 (  0.00)
 * Acc@1 0.701 Acc@5 0.000
Test: [0/1]	Time  0.327 ( 0.327)	Loss 1.5022e-01 (1.5022e-01)	Acc@1   0.77 (  0.77)	Acc@5   0.00 (  0.00)
 * Acc@1 0.768 Acc@5 0.000
79
TRAINING
Epoch: [79][0/1]	Time  1.036 ( 1.036)	Data  0.343 ( 0.343)	Loss 7.9056e-02 (7.9056e-02)	Acc@1   0.93 (  0.93)	Acc@5   0.00 (  0.00)
[0.9292277177875616]
Test: [0/1]	Time  0.277 ( 0.277)	Loss 9.4234e-01 (9.4234e-01)	Acc@1   0.70 (  0.70)	Acc@5   0.00 (  0.00)
 * Acc@1 0.703 Acc@5 0.000
Test: [0/1]	Time  0.331 ( 0.331)	Loss 1.5015e-01 (1.5015e-01)	Acc@1   0.77 (  0.77)	Acc@5   0.00 (  0.00)
 * Acc@1 0.769 Acc@5 0.000
80
TRAINING
Epoch: [80][0/1]	Time  0.997 ( 0.997)	Data  0.306 ( 0.306)	Loss 7.9004e-02 (7.9004e-02)	Acc@1   0.93 (  0.93)	Acc@5   0.00 (  0.00)
[0.929221642314467]
Test: [0/1]	Time  0.268 ( 0.268)	Loss 9.4255e-01 (9.4255e-01)	Acc@1   0.70 (  0.70)	Acc@5   0.00 (  0.00)
 * Acc@1 0.704 Acc@5 0.000
Test: [0/1]	Time  0.312 ( 0.312)	Loss 1.5010e-01 (1.5010e-01)	Acc@1   0.77 (  0.77)	Acc@5   0.00 (  0.00)
 * Acc@1 0.769 Acc@5 0.000
81
TRAINING
Epoch: [81][0/1]	Time  1.032 ( 1.032)	Data  0.332 ( 0.332)	Loss 7.8966e-02 (7.8966e-02)	Acc@1   0.93 (  0.93)	Acc@5   0.00 (  0.00)
[0.9292441374760378]
Test: [0/1]	Time  0.277 ( 0.277)	Loss 9.4273e-01 (9.4273e-01)	Acc@1   0.70 (  0.70)	Acc@5   0.00 (  0.00)
 * Acc@1 0.705 Acc@5 0.000
Test: [0/1]	Time  0.325 ( 0.325)	Loss 1.5007e-01 (1.5007e-01)	Acc@1   0.77 (  0.77)	Acc@5   0.00 (  0.00)
 * Acc@1 0.770 Acc@5 0.000
82
TRAINING
Epoch: [82][0/1]	Time  1.007 ( 1.007)	Data  0.317 ( 0.317)	Loss 7.8945e-02 (7.8945e-02)	Acc@1   0.93 (  0.93)	Acc@5   0.00 (  0.00)
[0.9292899952768009]
Test: [0/1]	Time  0.286 ( 0.286)	Loss 9.4285e-01 (9.4285e-01)	Acc@1   0.71 (  0.71)	Acc@5   0.00 (  0.00)
 * Acc@1 0.706 Acc@5 0.000
Test: [0/1]	Time  0.334 ( 0.334)	Loss 1.5004e-01 (1.5004e-01)	Acc@1   0.77 (  0.77)	Acc@5   0.00 (  0.00)
 * Acc@1 0.770 Acc@5 0.000
83
TRAINING
Epoch: [83][0/1]	Time  0.999 ( 0.999)	Data  0.286 ( 0.286)	Loss 7.8935e-02 (7.8935e-02)	Acc@1   0.93 (  0.93)	Acc@5   0.00 (  0.00)
[0.9293553033277462]
Test: [0/1]	Time  0.255 ( 0.255)	Loss 9.4288e-01 (9.4288e-01)	Acc@1   0.71 (  0.71)	Acc@5   0.00 (  0.00)
 * Acc@1 0.707 Acc@5 0.000
Test: [0/1]	Time  0.302 ( 0.302)	Loss 1.5000e-01 (1.5000e-01)	Acc@1   0.77 (  0.77)	Acc@5   0.00 (  0.00)
 * Acc@1 0.770 Acc@5 0.000
84
TRAINING
Epoch: [84][0/1]	Time  1.013 ( 1.013)	Data  0.315 ( 0.315)	Loss 7.8927e-02 (7.8927e-02)	Acc@1   0.93 (  0.93)	Acc@5   0.00 (  0.00)
[0.9294367074821649]
Test: [0/1]	Time  0.264 ( 0.264)	Loss 9.4281e-01 (9.4281e-01)	Acc@1   0.71 (  0.71)	Acc@5   0.00 (  0.00)
 * Acc@1 0.708 Acc@5 0.000
Test: [0/1]	Time  0.318 ( 0.318)	Loss 1.4994e-01 (1.4994e-01)	Acc@1   0.77 (  0.77)	Acc@5   0.00 (  0.00)
 * Acc@1 0.770 Acc@5 0.000
85
TRAINING
Epoch: [85][0/1]	Time  1.021 ( 1.021)	Data  0.304 ( 0.304)	Loss 7.8915e-02 (7.8915e-02)	Acc@1   0.93 (  0.93)	Acc@5   0.00 (  0.00)
[0.9295306092614949]
Test: [0/1]	Time  0.259 ( 0.259)	Loss 9.4265e-01 (9.4265e-01)	Acc@1   0.71 (  0.71)	Acc@5   0.00 (  0.00)
 * Acc@1 0.709 Acc@5 0.000
Test: [0/1]	Time  0.307 ( 0.307)	Loss 1.4987e-01 (1.4987e-01)	Acc@1   0.77 (  0.77)	Acc@5   0.00 (  0.00)
 * Acc@1 0.771 Acc@5 0.000
86
TRAINING
Epoch: [86][0/1]	Time  0.999 ( 0.999)	Data  0.293 ( 0.293)	Loss 7.8899e-02 (7.8899e-02)	Acc@1   0.93 (  0.93)	Acc@5   0.00 (  0.00)
[0.9296328673475016]
Test: [0/1]	Time  0.259 ( 0.259)	Loss 9.4243e-01 (9.4243e-01)	Acc@1   0.71 (  0.71)	Acc@5   0.00 (  0.00)
 * Acc@1 0.709 Acc@5 0.000
Test: [0/1]	Time  0.313 ( 0.313)	Loss 1.4978e-01 (1.4978e-01)	Acc@1   0.77 (  0.77)	Acc@5   0.00 (  0.00)
 * Acc@1 0.771 Acc@5 0.000
87
TRAINING
Epoch: [87][0/1]	Time  0.983 ( 0.983)	Data  0.294 ( 0.294)	Loss 7.8883e-02 (7.8883e-02)	Acc@1   0.93 (  0.93)	Acc@5   0.00 (  0.00)
[0.9297391428254453]
Test: [0/1]	Time  0.289 ( 0.289)	Loss 9.4217e-01 (9.4217e-01)	Acc@1   0.71 (  0.71)	Acc@5   0.00 (  0.00)
 * Acc@1 0.710 Acc@5 0.000
Test: [0/1]	Time  0.327 ( 0.327)	Loss 1.4970e-01 (1.4970e-01)	Acc@1   0.77 (  0.77)	Acc@5   0.00 (  0.00)
 * Acc@1 0.771 Acc@5 0.000
88
TRAINING
Epoch: [88][0/1]	Time  0.999 ( 0.999)	Data  0.300 ( 0.300)	Loss 7.8871e-02 (7.8871e-02)	Acc@1   0.93 (  0.93)	Acc@5   0.00 (  0.00)
[0.9298456046028091]
Test: [0/1]	Time  0.256 ( 0.256)	Loss 9.4192e-01 (9.4192e-01)	Acc@1   0.71 (  0.71)	Acc@5   0.00 (  0.00)
 * Acc@1 0.711 Acc@5 0.000
Test: [0/1]	Time  0.311 ( 0.311)	Loss 1.4962e-01 (1.4962e-01)	Acc@1   0.77 (  0.77)	Acc@5   0.00 (  0.00)
 * Acc@1 0.771 Acc@5 0.000
89
TRAINING
Epoch: [89][0/1]	Time  1.035 ( 1.035)	Data  0.321 ( 0.321)	Loss 7.8865e-02 (7.8865e-02)	Acc@1   0.93 (  0.93)	Acc@5   0.00 (  0.00)
[0.9299495325909616]
Test: [0/1]	Time  0.265 ( 0.265)	Loss 9.4169e-01 (9.4169e-01)	Acc@1   0.71 (  0.71)	Acc@5   0.00 (  0.00)
 * Acc@1 0.711 Acc@5 0.000
Test: [0/1]	Time  0.322 ( 0.322)	Loss 1.4956e-01 (1.4956e-01)	Acc@1   0.77 (  0.77)	Acc@5   0.00 (  0.00)
 * Acc@1 0.772 Acc@5 0.000
90
TRAINING
Epoch: [90][0/1]	Time  0.956 ( 0.956)	Data  0.268 ( 0.268)	Loss 7.8862e-02 (7.8862e-02)	Acc@1   0.93 (  0.93)	Acc@5   0.00 (  0.00)
[0.9300494780706466]
Test: [0/1]	Time  0.249 ( 0.249)	Loss 9.4151e-01 (9.4151e-01)	Acc@1   0.71 (  0.71)	Acc@5   0.00 (  0.00)
 * Acc@1 0.712 Acc@5 0.000
Test: [0/1]	Time  0.300 ( 0.300)	Loss 1.4951e-01 (1.4951e-01)	Acc@1   0.77 (  0.77)	Acc@5   0.00 (  0.00)
 * Acc@1 0.772 Acc@5 0.000
91
TRAINING
Epoch: [91][0/1]	Time  0.973 ( 0.973)	Data  0.279 ( 0.279)	Loss 7.8857e-02 (7.8857e-02)	Acc@1   0.93 (  0.93)	Acc@5   0.00 (  0.00)
[0.9301449391766569]
Test: [0/1]	Time  0.257 ( 0.257)	Loss 9.4139e-01 (9.4139e-01)	Acc@1   0.71 (  0.71)	Acc@5   0.00 (  0.00)
 * Acc@1 0.712 Acc@5 0.000
Test: [0/1]	Time  0.312 ( 0.312)	Loss 1.4948e-01 (1.4948e-01)	Acc@1   0.77 (  0.77)	Acc@5   0.00 (  0.00)
 * Acc@1 0.772 Acc@5 0.000
92
TRAINING
Epoch: [92][0/1]	Time  1.066 ( 1.066)	Data  0.356 ( 0.356)	Loss 7.8844e-02 (7.8844e-02)	Acc@1   0.93 (  0.93)	Acc@5   0.00 (  0.00)
[0.9302357830225912]
Test: [0/1]	Time  0.284 ( 0.284)	Loss 9.4135e-01 (9.4135e-01)	Acc@1   0.71 (  0.71)	Acc@5   0.00 (  0.00)
 * Acc@1 0.712 Acc@5 0.000
Test: [0/1]	Time  0.338 ( 0.338)	Loss 1.4945e-01 (1.4945e-01)	Acc@1   0.77 (  0.77)	Acc@5   0.00 (  0.00)
 * Acc@1 0.772 Acc@5 0.000
93
TRAINING
Epoch: [93][0/1]	Time  1.002 ( 1.002)	Data  0.305 ( 0.305)	Loss 7.8824e-02 (7.8824e-02)	Acc@1   0.93 (  0.93)	Acc@5   0.00 (  0.00)
[0.9303217438537943]
Test: [0/1]	Time  0.265 ( 0.265)	Loss 9.4135e-01 (9.4135e-01)	Acc@1   0.71 (  0.71)	Acc@5   0.00 (  0.00)
 * Acc@1 0.712 Acc@5 0.000
Test: [0/1]	Time  0.320 ( 0.320)	Loss 1.4943e-01 (1.4943e-01)	Acc@1   0.77 (  0.77)	Acc@5   0.00 (  0.00)
 * Acc@1 0.773 Acc@5 0.000
94
TRAINING
Epoch: [94][0/1]	Time  0.987 ( 0.987)	Data  0.298 ( 0.298)	Loss 7.8797e-02 (7.8797e-02)	Acc@1   0.93 (  0.93)	Acc@5   0.00 (  0.00)
[0.9304022254475945]
Test: [0/1]	Time  0.263 ( 0.263)	Loss 9.4140e-01 (9.4140e-01)	Acc@1   0.71 (  0.71)	Acc@5   0.00 (  0.00)
 * Acc@1 0.712 Acc@5 0.000
Test: [0/1]	Time  0.315 ( 0.315)	Loss 1.4942e-01 (1.4942e-01)	Acc@1   0.77 (  0.77)	Acc@5   0.00 (  0.00)
 * Acc@1 0.773 Acc@5 0.000
95
TRAINING
Epoch: [95][0/1]	Time  1.009 ( 1.009)	Data  0.301 ( 0.301)	Loss 7.8767e-02 (7.8767e-02)	Acc@1   0.93 (  0.93)	Acc@5   0.00 (  0.00)
[0.9304764296594263]
Test: [0/1]	Time  0.254 ( 0.254)	Loss 9.4147e-01 (9.4147e-01)	Acc@1   0.71 (  0.71)	Acc@5   0.00 (  0.00)
 * Acc@1 0.712 Acc@5 0.000
Test: [0/1]	Time  0.309 ( 0.309)	Loss 1.4942e-01 (1.4942e-01)	Acc@1   0.77 (  0.77)	Acc@5   0.00 (  0.00)
 * Acc@1 0.773 Acc@5 0.000
96
TRAINING
Epoch: [96][0/1]	Time  0.981 ( 0.981)	Data  0.281 ( 0.281)	Loss 7.8739e-02 (7.8739e-02)	Acc@1   0.93 (  0.93)	Acc@5   0.00 (  0.00)
[0.9305436569268639]
Test: [0/1]	Time  0.284 ( 0.284)	Loss 9.4154e-01 (9.4154e-01)	Acc@1   0.71 (  0.71)	Acc@5   0.00 (  0.00)
 * Acc@1 0.712 Acc@5 0.000
Test: [0/1]	Time  0.323 ( 0.323)	Loss 1.4943e-01 (1.4943e-01)	Acc@1   0.77 (  0.77)	Acc@5   0.00 (  0.00)
 * Acc@1 0.773 Acc@5 0.000
97
TRAINING
Epoch: [97][0/1]	Time  0.968 ( 0.968)	Data  0.273 ( 0.273)	Loss 7.8715e-02 (7.8715e-02)	Acc@1   0.93 (  0.93)	Acc@5   0.00 (  0.00)
[0.9306035703547616]
Test: [0/1]	Time  0.262 ( 0.262)	Loss 9.4159e-01 (9.4159e-01)	Acc@1   0.71 (  0.71)	Acc@5   0.00 (  0.00)
 * Acc@1 0.712 Acc@5 0.000
Test: [0/1]	Time  0.327 ( 0.327)	Loss 1.4943e-01 (1.4943e-01)	Acc@1   0.77 (  0.77)	Acc@5   0.00 (  0.00)
 * Acc@1 0.773 Acc@5 0.000
98
TRAINING
Epoch: [98][0/1]	Time  0.986 ( 0.986)	Data  0.298 ( 0.298)	Loss 7.8695e-02 (7.8695e-02)	Acc@1   0.93 (  0.93)	Acc@5   0.00 (  0.00)
[0.9306562869821311]
Test: [0/1]	Time  0.270 ( 0.270)	Loss 9.4161e-01 (9.4161e-01)	Acc@1   0.71 (  0.71)	Acc@5   0.00 (  0.00)
 * Acc@1 0.712 Acc@5 0.000
Test: [0/1]	Time  0.318 ( 0.318)	Loss 1.4943e-01 (1.4943e-01)	Acc@1   0.77 (  0.77)	Acc@5   0.00 (  0.00)
 * Acc@1 0.773 Acc@5 0.000
99
TRAINING
Epoch: [99][0/1]	Time  0.978 ( 0.978)	Data  0.284 ( 0.284)	Loss 7.8678e-02 (7.8678e-02)	Acc@1   0.93 (  0.93)	Acc@5   0.00 (  0.00)
[0.9307022899128219]
Test: [0/1]	Time  0.264 ( 0.264)	Loss 9.4159e-01 (9.4159e-01)	Acc@1   0.71 (  0.71)	Acc@5   0.00 (  0.00)
 * Acc@1 0.712 Acc@5 0.000
Test: [0/1]	Time  0.311 ( 0.311)	Loss 1.4942e-01 (1.4942e-01)	Acc@1   0.77 (  0.77)	Acc@5   0.00 (  0.00)
 * Acc@1 0.773 Acc@5 0.000
=> using pre-trained model 'st_resnet'
s/ohp/session_1
torch.Size([640, 3, 224, 224])
(640, 22)
attach reg
0
TRAINING
/home/helenr6/Adv_mapper/train_split.py:125: UserWarning: You have chosen to seed training. This will turn on the CUDNN deterministic setting, which can slow down your training considerably! You may see unexpected behavior when restarting from checkpoints.
  warnings.warn('You have chosen to seed training. '
/localscratch/helenr6.6279052.0/env/lib/python3.7/site-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  cpuset_checked))
Epoch: [0][0/1]	Time  5.309 ( 5.309)	Data  1.887 ( 1.887)	Loss 1.7777e+00 (1.7777e+00)	Acc@1  -0.02 ( -0.02)	Acc@5   0.00 (  0.00)
[-0.019492115482306414]
Test: [0/1]	Time  0.444 ( 0.444)	Loss 1.1620e+00 (1.1620e+00)	Acc@1   0.04 (  0.04)	Acc@5   0.00 (  0.00)
 * Acc@1 0.038 Acc@5 0.000
Test: [0/1]	Time  0.555 ( 0.555)	Loss 9.3206e-01 (9.3206e-01)	Acc@1   0.04 (  0.04)	Acc@5   0.00 (  0.00)
 * Acc@1 0.040 Acc@5 0.000
1
TRAINING
Epoch: [1][0/1]	Time  1.022 ( 1.022)	Data  0.288 ( 0.288)	Loss 1.6809e+00 (1.6809e+00)	Acc@1  -0.02 ( -0.02)	Acc@5   0.00 (  0.00)
[-0.016601307443326378]
Test: [0/1]	Time  0.256 ( 0.256)	Loss 1.1704e+00 (1.1704e+00)	Acc@1   0.04 (  0.04)	Acc@5   0.00 (  0.00)
 * Acc@1 0.042 Acc@5 0.000
Test: [0/1]	Time  0.313 ( 0.313)	Loss 8.8216e-01 (8.8216e-01)	Acc@1   0.05 (  0.05)	Acc@5   0.00 (  0.00)
 * Acc@1 0.048 Acc@5 0.000
2
TRAINING
Epoch: [2][0/1]	Time  1.008 ( 1.008)	Data  0.273 ( 0.273)	Loss 1.5378e+00 (1.5378e+00)	Acc@1  -0.01 ( -0.01)	Acc@5   0.00 (  0.00)
[-0.01105342045313612]
Test: [0/1]	Time  0.256 ( 0.256)	Loss 1.1817e+00 (1.1817e+00)	Acc@1   0.05 (  0.05)	Acc@5   0.00 (  0.00)
 * Acc@1 0.048 Acc@5 0.000
Test: [0/1]	Time  0.302 ( 0.302)	Loss 8.4306e-01 (8.4306e-01)	Acc@1   0.07 (  0.07)	Acc@5   0.00 (  0.00)
 * Acc@1 0.067 Acc@5 0.000
3
TRAINING
Epoch: [3][0/1]	Time  1.075 ( 1.075)	Data  0.337 ( 0.337)	Loss 1.4045e+00 (1.4045e+00)	Acc@1  -0.00 ( -0.00)	Acc@5   0.00 (  0.00)
[-0.0030459351175197874]
Test: [0/1]	Time  0.295 ( 0.295)	Loss 1.1946e+00 (1.1946e+00)	Acc@1   0.06 (  0.06)	Acc@5   0.00 (  0.00)
 * Acc@1 0.055 Acc@5 0.000
Test: [0/1]	Time  0.358 ( 0.358)	Loss 8.2837e-01 (8.2837e-01)	Acc@1   0.07 (  0.07)	Acc@5   0.00 (  0.00)
 * Acc@1 0.073 Acc@5 0.000
4
TRAINING
Epoch: [4][0/1]	Time  1.036 ( 1.036)	Data  0.316 ( 0.316)	Loss 1.3113e+00 (1.3113e+00)	Acc@1   0.01 (  0.01)	Acc@5   0.00 (  0.00)
[0.01420062050896583]
Test: [0/1]	Time  0.270 ( 0.270)	Loss 1.2048e+00 (1.2048e+00)	Acc@1   0.08 (  0.08)	Acc@5   0.00 (  0.00)
 * Acc@1 0.077 Acc@5 0.000
Test: [0/1]	Time  0.320 ( 0.320)	Loss 8.3159e-01 (8.3159e-01)	Acc@1   0.08 (  0.08)	Acc@5   0.00 (  0.00)
 * Acc@1 0.080 Acc@5 0.000
5
TRAINING
Epoch: [5][0/1]	Time  1.017 ( 1.017)	Data  0.293 ( 0.293)	Loss 1.2527e+00 (1.2527e+00)	Acc@1   0.03 (  0.03)	Acc@5   0.00 (  0.00)
[0.02907020700119687]
Test: [0/1]	Time  0.261 ( 0.261)	Loss 1.2073e+00 (1.2073e+00)	Acc@1   0.09 (  0.09)	Acc@5   0.00 (  0.00)
 * Acc@1 0.089 Acc@5 0.000
Test: [0/1]	Time  0.309 ( 0.309)	Loss 8.3257e-01 (8.3257e-01)	Acc@1   0.10 (  0.10)	Acc@5   0.00 (  0.00)
 * Acc@1 0.097 Acc@5 0.000
6
TRAINING
Epoch: [6][0/1]	Time  1.030 ( 1.030)	Data  0.300 ( 0.300)	Loss 1.2001e+00 (1.2001e+00)	Acc@1   0.05 (  0.05)	Acc@5   0.00 (  0.00)
[0.0466525497231233]
Test: [0/1]	Time  0.275 ( 0.275)	Loss 1.1979e+00 (1.1979e+00)	Acc@1   0.11 (  0.11)	Acc@5   0.00 (  0.00)
 * Acc@1 0.114 Acc@5 0.000
Test: [0/1]	Time  0.324 ( 0.324)	Loss 8.1158e-01 (8.1158e-01)	Acc@1   0.11 (  0.11)	Acc@5   0.00 (  0.00)
 * Acc@1 0.112 Acc@5 0.000
7
TRAINING
Epoch: [7][0/1]	Time  0.984 ( 0.984)	Data  0.261 ( 0.261)	Loss 1.1248e+00 (1.1248e+00)	Acc@1   0.07 (  0.07)	Acc@5   0.00 (  0.00)
[0.0668474719547701]
Test: [0/1]	Time  0.273 ( 0.273)	Loss 1.1760e+00 (1.1760e+00)	Acc@1   0.14 (  0.14)	Acc@5   0.00 (  0.00)
 * Acc@1 0.140 Acc@5 0.000
Test: [0/1]	Time  0.319 ( 0.319)	Loss 7.6140e-01 (7.6140e-01)	Acc@1   0.12 (  0.12)	Acc@5   0.00 (  0.00)
 * Acc@1 0.125 Acc@5 0.000
8
TRAINING
Epoch: [8][0/1]	Time  1.015 ( 1.015)	Data  0.297 ( 0.297)	Loss 1.0168e+00 (1.0168e+00)	Acc@1   0.09 (  0.09)	Acc@5   0.00 (  0.00)
[0.09119564019373352]
Test: [0/1]	Time  0.264 ( 0.264)	Loss 1.1446e+00 (1.1446e+00)	Acc@1   0.16 (  0.16)	Acc@5   0.00 (  0.00)
 * Acc@1 0.163 Acc@5 0.000
Test: [0/1]	Time  0.325 ( 0.325)	Loss 6.9106e-01 (6.9106e-01)	Acc@1   0.14 (  0.14)	Acc@5   0.00 (  0.00)
 * Acc@1 0.138 Acc@5 0.000
9
TRAINING
Epoch: [9][0/1]	Time  1.028 ( 1.028)	Data  0.298 ( 0.298)	Loss 8.8863e-01 (8.8863e-01)	Acc@1   0.12 (  0.12)	Acc@5   0.00 (  0.00)
[0.12154997241584217]
Test: [0/1]	Time  0.279 ( 0.279)	Loss 1.1090e+00 (1.1090e+00)	Acc@1   0.20 (  0.20)	Acc@5   0.00 (  0.00)
 * Acc@1 0.201 Acc@5 0.000
Test: [0/1]	Time  0.336 ( 0.336)	Loss 6.1899e-01 (6.1899e-01)	Acc@1   0.16 (  0.16)	Acc@5   0.00 (  0.00)
 * Acc@1 0.156 Acc@5 0.000
10
TRAINING
Epoch: [10][0/1]	Time  0.990 ( 0.990)	Data  0.280 ( 0.280)	Loss 7.6460e-01 (7.6460e-01)	Acc@1   0.14 (  0.14)	Acc@5   0.00 (  0.00)
[0.14436984167494013]
Test: [0/1]	Time  0.258 ( 0.258)	Loss 1.0748e+00 (1.0748e+00)	Acc@1   0.24 (  0.24)	Acc@5   0.00 (  0.00)
 * Acc@1 0.236 Acc@5 0.000
Test: [0/1]	Time  0.309 ( 0.309)	Loss 5.6184e-01 (5.6184e-01)	Acc@1   0.18 (  0.18)	Acc@5   0.00 (  0.00)
 * Acc@1 0.175 Acc@5 0.000
11
TRAINING
Epoch: [11][0/1]	Time  1.035 ( 1.035)	Data  0.328 ( 0.328)	Loss 6.6511e-01 (6.6511e-01)	Acc@1   0.17 (  0.17)	Acc@5   0.00 (  0.00)
[0.17323487066419258]
Test: [0/1]	Time  0.288 ( 0.288)	Loss 1.0459e+00 (1.0459e+00)	Acc@1   0.27 (  0.27)	Acc@5   0.00 (  0.00)
 * Acc@1 0.274 Acc@5 0.000
Test: [0/1]	Time  0.336 ( 0.336)	Loss 5.2570e-01 (5.2570e-01)	Acc@1   0.19 (  0.19)	Acc@5   0.00 (  0.00)
 * Acc@1 0.193 Acc@5 0.000
12
TRAINING
Epoch: [12][0/1]	Time  1.021 ( 1.021)	Data  0.320 ( 0.320)	Loss 5.9579e-01 (5.9579e-01)	Acc@1   0.21 (  0.21)	Acc@5   0.00 (  0.00)
[0.20600690035980657]
Test: [0/1]	Time  0.280 ( 0.280)	Loss 1.0237e+00 (1.0237e+00)	Acc@1   0.31 (  0.31)	Acc@5   0.00 (  0.00)
 * Acc@1 0.311 Acc@5 0.000
Test: [0/1]	Time  0.333 ( 0.333)	Loss 5.0478e-01 (5.0478e-01)	Acc@1   0.20 (  0.20)	Acc@5   0.00 (  0.00)
 * Acc@1 0.203 Acc@5 0.000
13
TRAINING
Epoch: [13][0/1]	Time  1.097 ( 1.097)	Data  0.371 ( 0.371)	Loss 5.4724e-01 (5.4724e-01)	Acc@1   0.24 (  0.24)	Acc@5   0.00 (  0.00)
[0.2356162704802225]
Test: [0/1]	Time  0.263 ( 0.263)	Loss 1.0078e+00 (1.0078e+00)	Acc@1   0.35 (  0.35)	Acc@5   0.00 (  0.00)
 * Acc@1 0.348 Acc@5 0.000
Test: [0/1]	Time  0.311 ( 0.311)	Loss 4.8708e-01 (4.8708e-01)	Acc@1   0.21 (  0.21)	Acc@5   0.00 (  0.00)
 * Acc@1 0.214 Acc@5 0.000
14
TRAINING
Epoch: [14][0/1]	Time  1.073 ( 1.073)	Data  0.327 ( 0.327)	Loss 5.0331e-01 (5.0331e-01)	Acc@1   0.27 (  0.27)	Acc@5   0.00 (  0.00)
[0.2706590807791127]
Test: [0/1]	Time  0.255 ( 0.255)	Loss 9.9709e-01 (9.9709e-01)	Acc@1   0.38 (  0.38)	Acc@5   0.00 (  0.00)
 * Acc@1 0.383 Acc@5 0.000
Test: [0/1]	Time  0.301 ( 0.301)	Loss 4.6248e-01 (4.6248e-01)	Acc@1   0.23 (  0.23)	Acc@5   0.00 (  0.00)
 * Acc@1 0.227 Acc@5 0.000
15
TRAINING
Epoch: [15][0/1]	Time  0.995 ( 0.995)	Data  0.300 ( 0.300)	Loss 4.5180e-01 (4.5180e-01)	Acc@1   0.31 (  0.31)	Acc@5   0.00 (  0.00)
[0.3112681813053543]
Test: [0/1]	Time  0.277 ( 0.277)	Loss 9.9069e-01 (9.9069e-01)	Acc@1   0.42 (  0.42)	Acc@5   0.00 (  0.00)
 * Acc@1 0.415 Acc@5 0.000
Test: [0/1]	Time  0.328 ( 0.328)	Loss 4.2838e-01 (4.2838e-01)	Acc@1   0.25 (  0.25)	Acc@5   0.00 (  0.00)
 * Acc@1 0.247 Acc@5 0.000
16
TRAINING
Epoch: [16][0/1]	Time  1.005 ( 1.005)	Data  0.292 ( 0.292)	Loss 3.9069e-01 (3.9069e-01)	Acc@1   0.35 (  0.35)	Acc@5   0.00 (  0.00)
[0.3534927187311243]
Test: [0/1]	Time  0.266 ( 0.266)	Loss 9.8800e-01 (9.8800e-01)	Acc@1   0.44 (  0.44)	Acc@5   0.00 (  0.00)
 * Acc@1 0.444 Acc@5 0.000
Test: [0/1]	Time  0.311 ( 0.311)	Loss 3.8977e-01 (3.8977e-01)	Acc@1   0.27 (  0.27)	Acc@5   0.00 (  0.00)
 * Acc@1 0.268 Acc@5 0.000
17
TRAINING
Epoch: [17][0/1]	Time  1.025 ( 1.025)	Data  0.304 ( 0.304)	Loss 3.2730e-01 (3.2730e-01)	Acc@1   0.40 (  0.40)	Acc@5   0.00 (  0.00)
[0.39709229720514405]
Test: [0/1]	Time  0.264 ( 0.264)	Loss 9.8852e-01 (9.8852e-01)	Acc@1   0.47 (  0.47)	Acc@5   0.00 (  0.00)
 * Acc@1 0.470 Acc@5 0.000
Test: [0/1]	Time  0.314 ( 0.314)	Loss 3.5481e-01 (3.5481e-01)	Acc@1   0.28 (  0.28)	Acc@5   0.00 (  0.00)
 * Acc@1 0.279 Acc@5 0.000
18
TRAINING
Epoch: [18][0/1]	Time  0.998 ( 0.998)	Data  0.300 ( 0.300)	Loss 2.7211e-01 (2.7211e-01)	Acc@1   0.44 (  0.44)	Acc@5   0.00 (  0.00)
[0.43809132052431476]
Test: [0/1]	Time  0.265 ( 0.265)	Loss 9.9125e-01 (9.9125e-01)	Acc@1   0.50 (  0.50)	Acc@5   0.00 (  0.00)
 * Acc@1 0.504 Acc@5 0.000
Test: [0/1]	Time  0.312 ( 0.312)	Loss 3.2922e-01 (3.2922e-01)	Acc@1   0.30 (  0.30)	Acc@5   0.00 (  0.00)
 * Acc@1 0.302 Acc@5 0.000
19
TRAINING
Epoch: [19][0/1]	Time  1.007 ( 1.007)	Data  0.300 ( 0.300)	Loss 2.3195e-01 (2.3195e-01)	Acc@1   0.48 (  0.48)	Acc@5   0.00 (  0.00)
[0.47970977798611275]
Test: [0/1]	Time  0.262 ( 0.262)	Loss 9.9459e-01 (9.9459e-01)	Acc@1   0.54 (  0.54)	Acc@5   0.00 (  0.00)
 * Acc@1 0.541 Acc@5 0.000
Test: [0/1]	Time  0.316 ( 0.316)	Loss 3.1321e-01 (3.1321e-01)	Acc@1   0.32 (  0.32)	Acc@5   0.00 (  0.00)
 * Acc@1 0.324 Acc@5 0.000
20
TRAINING
Epoch: [20][0/1]	Time  0.977 ( 0.977)	Data  0.270 ( 0.270)	Loss 2.0656e-01 (2.0656e-01)	Acc@1   0.52 (  0.52)	Acc@5   0.00 (  0.00)
[0.5223451909244972]
Test: [0/1]	Time  0.255 ( 0.255)	Loss 9.9662e-01 (9.9662e-01)	Acc@1   0.57 (  0.57)	Acc@5   0.00 (  0.00)
 * Acc@1 0.570 Acc@5 0.000
Test: [0/1]	Time  0.306 ( 0.306)	Loss 3.0218e-01 (3.0218e-01)	Acc@1   0.34 (  0.34)	Acc@5   0.00 (  0.00)
 * Acc@1 0.344 Acc@5 0.000
21
TRAINING
Epoch: [21][0/1]	Time  0.949 ( 0.949)	Data  0.252 ( 0.252)	Loss 1.8996e-01 (1.8996e-01)	Acc@1   0.57 (  0.57)	Acc@5   0.00 (  0.00)
[0.5693612171386544]
Test: [0/1]	Time  0.247 ( 0.247)	Loss 9.9583e-01 (9.9583e-01)	Acc@1   0.60 (  0.60)	Acc@5   0.00 (  0.00)
 * Acc@1 0.599 Acc@5 0.000
Test: [0/1]	Time  0.296 ( 0.296)	Loss 2.9030e-01 (2.9030e-01)	Acc@1   0.37 (  0.37)	Acc@5   0.00 (  0.00)
 * Acc@1 0.367 Acc@5 0.000
22
TRAINING
Epoch: [22][0/1]	Time  1.044 ( 1.044)	Data  0.340 ( 0.340)	Loss 1.7485e-01 (1.7485e-01)	Acc@1   0.62 (  0.62)	Acc@5   0.00 (  0.00)
[0.6171117730744047]
Test: [0/1]	Time  0.273 ( 0.273)	Loss 9.9168e-01 (9.9168e-01)	Acc@1   0.63 (  0.63)	Acc@5   0.00 (  0.00)
 * Acc@1 0.629 Acc@5 0.000
Test: [0/1]	Time  0.329 ( 0.329)	Loss 2.7417e-01 (2.7417e-01)	Acc@1   0.39 (  0.39)	Acc@5   0.00 (  0.00)
 * Acc@1 0.390 Acc@5 0.000
23
TRAINING
Epoch: [23][0/1]	Time  0.992 ( 0.992)	Data  0.290 ( 0.290)	Loss 1.5690e-01 (1.5690e-01)	Acc@1   0.66 (  0.66)	Acc@5   0.00 (  0.00)
[0.6616907860696626]
Test: [0/1]	Time  0.257 ( 0.257)	Loss 9.8474e-01 (9.8474e-01)	Acc@1   0.66 (  0.66)	Acc@5   0.00 (  0.00)
 * Acc@1 0.656 Acc@5 0.000
Test: [0/1]	Time  0.304 ( 0.304)	Loss 2.5446e-01 (2.5446e-01)	Acc@1   0.41 (  0.41)	Acc@5   0.00 (  0.00)
 * Acc@1 0.409 Acc@5 0.000
24
TRAINING
Epoch: [24][0/1]	Time  1.003 ( 1.003)	Data  0.303 ( 0.303)	Loss 1.3650e-01 (1.3650e-01)	Acc@1   0.70 (  0.70)	Acc@5   0.00 (  0.00)
[0.7047335093332179]
Test: [0/1]	Time  0.262 ( 0.262)	Loss 9.7634e-01 (9.7634e-01)	Acc@1   0.68 (  0.68)	Acc@5   0.00 (  0.00)
 * Acc@1 0.676 Acc@5 0.000
Test: [0/1]	Time  0.315 ( 0.315)	Loss 2.3479e-01 (2.3479e-01)	Acc@1   0.43 (  0.43)	Acc@5   0.00 (  0.00)
 * Acc@1 0.426 Acc@5 0.000
25
TRAINING
Epoch: [25][0/1]	Time  0.982 ( 0.982)	Data  0.284 ( 0.284)	Loss 1.1735e-01 (1.1735e-01)	Acc@1   0.74 (  0.74)	Acc@5   0.00 (  0.00)
[0.7431204863360517]
Test: [0/1]	Time  0.260 ( 0.260)	Loss 9.6797e-01 (9.6797e-01)	Acc@1   0.69 (  0.69)	Acc@5   0.00 (  0.00)
 * Acc@1 0.694 Acc@5 0.000
Test: [0/1]	Time  0.344 ( 0.344)	Loss 2.1900e-01 (2.1900e-01)	Acc@1   0.44 (  0.44)	Acc@5   0.00 (  0.00)
 * Acc@1 0.443 Acc@5 0.000
26
TRAINING
Epoch: [26][0/1]	Time  0.994 ( 0.994)	Data  0.301 ( 0.301)	Loss 1.0341e-01 (1.0341e-01)	Acc@1   0.78 (  0.78)	Acc@5   0.00 (  0.00)
[0.7757082560483372]
Test: [0/1]	Time  0.281 ( 0.281)	Loss 9.6075e-01 (9.6075e-01)	Acc@1   0.71 (  0.71)	Acc@5   0.00 (  0.00)
 * Acc@1 0.709 Acc@5 0.000
Test: [0/1]	Time  0.367 ( 0.367)	Loss 2.0887e-01 (2.0887e-01)	Acc@1   0.47 (  0.47)	Acc@5   0.00 (  0.00)
 * Acc@1 0.466 Acc@5 0.000
27
TRAINING
Epoch: [27][0/1]	Time  1.043 ( 1.043)	Data  0.323 ( 0.323)	Loss 9.6284e-02 (9.6284e-02)	Acc@1   0.80 (  0.80)	Acc@5   0.00 (  0.00)
[0.7990981684874261]
Test: [0/1]	Time  0.285 ( 0.285)	Loss 9.5524e-01 (9.5524e-01)	Acc@1   0.72 (  0.72)	Acc@5   0.00 (  0.00)
 * Acc@1 0.718 Acc@5 0.000
Test: [0/1]	Time  0.319 ( 0.319)	Loss 2.0331e-01 (2.0331e-01)	Acc@1   0.49 (  0.49)	Acc@5   0.00 (  0.00)
 * Acc@1 0.487 Acc@5 0.000
28
TRAINING
Epoch: [28][0/1]	Time  0.999 ( 0.999)	Data  0.304 ( 0.304)	Loss 9.4447e-02 (9.4447e-02)	Acc@1   0.82 (  0.82)	Acc@5   0.00 (  0.00)
[0.8186512888319191]
Test: [0/1]	Time  0.261 ( 0.261)	Loss 9.5143e-01 (9.5143e-01)	Acc@1   0.72 (  0.72)	Acc@5   0.00 (  0.00)
 * Acc@1 0.720 Acc@5 0.000
Test: [0/1]	Time  0.313 ( 0.313)	Loss 1.9947e-01 (1.9947e-01)	Acc@1   0.51 (  0.51)	Acc@5   0.00 (  0.00)
 * Acc@1 0.505 Acc@5 0.000
29
TRAINING
Epoch: [29][0/1]	Time  0.984 ( 0.984)	Data  0.290 ( 0.290)	Loss 9.4531e-02 (9.4531e-02)	Acc@1   0.83 (  0.83)	Acc@5   0.00 (  0.00)
[0.8344568589993745]
Test: [0/1]	Time  0.277 ( 0.277)	Loss 9.4905e-01 (9.4905e-01)	Acc@1   0.72 (  0.72)	Acc@5   0.00 (  0.00)
 * Acc@1 0.723 Acc@5 0.000
Test: [0/1]	Time  0.312 ( 0.312)	Loss 1.9463e-01 (1.9463e-01)	Acc@1   0.52 (  0.52)	Acc@5   0.00 (  0.00)
 * Acc@1 0.523 Acc@5 0.000
30
TRAINING
Epoch: [30][0/1]	Time  0.978 ( 0.978)	Data  0.275 ( 0.275)	Loss 9.3431e-02 (9.3431e-02)	Acc@1   0.85 (  0.85)	Acc@5   0.00 (  0.00)
[0.8454770536424978]
Test: [0/1]	Time  0.254 ( 0.254)	Loss 9.4782e-01 (9.4782e-01)	Acc@1   0.72 (  0.72)	Acc@5   0.00 (  0.00)
 * Acc@1 0.721 Acc@5 0.000
Test: [0/1]	Time  0.301 ( 0.301)	Loss 1.8769e-01 (1.8769e-01)	Acc@1   0.54 (  0.54)	Acc@5   0.00 (  0.00)
 * Acc@1 0.541 Acc@5 0.000
31
TRAINING
Epoch: [31][0/1]	Time  1.001 ( 1.001)	Data  0.306 ( 0.306)	Loss 8.9920e-02 (8.9920e-02)	Acc@1   0.86 (  0.86)	Acc@5   0.00 (  0.00)
[0.8567686491955864]
Test: [0/1]	Time  0.269 ( 0.269)	Loss 9.4755e-01 (9.4755e-01)	Acc@1   0.72 (  0.72)	Acc@5   0.00 (  0.00)
 * Acc@1 0.717 Acc@5 0.000
Test: [0/1]	Time  0.309 ( 0.309)	Loss 1.7946e-01 (1.7946e-01)	Acc@1   0.56 (  0.56)	Acc@5   0.00 (  0.00)
 * Acc@1 0.561 Acc@5 0.000
32
TRAINING
Epoch: [32][0/1]	Time  0.984 ( 0.984)	Data  0.261 ( 0.261)	Loss 8.4882e-02 (8.4882e-02)	Acc@1   0.87 (  0.87)	Acc@5   0.00 (  0.00)
[0.866140912113676]
Test: [0/1]	Time  0.272 ( 0.272)	Loss 9.4806e-01 (9.4806e-01)	Acc@1   0.71 (  0.71)	Acc@5   0.00 (  0.00)
 * Acc@1 0.706 Acc@5 0.000
Test: [0/1]	Time  0.339 ( 0.339)	Loss 1.7179e-01 (1.7179e-01)	Acc@1   0.58 (  0.58)	Acc@5   0.00 (  0.00)
 * Acc@1 0.582 Acc@5 0.000
33
TRAINING
Epoch: [33][0/1]	Time  1.040 ( 1.040)	Data  0.324 ( 0.324)	Loss 8.0308e-02 (8.0308e-02)	Acc@1   0.87 (  0.87)	Acc@5   0.00 (  0.00)
[0.8718321119716923]
Test: [0/1]	Time  0.274 ( 0.274)	Loss 9.4909e-01 (9.4909e-01)	Acc@1   0.69 (  0.69)	Acc@5   0.00 (  0.00)
 * Acc@1 0.694 Acc@5 0.000
Test: [0/1]	Time  0.330 ( 0.330)	Loss 1.6621e-01 (1.6621e-01)	Acc@1   0.60 (  0.60)	Acc@5   0.00 (  0.00)
 * Acc@1 0.602 Acc@5 0.000
34
TRAINING
Epoch: [34][0/1]	Time  0.990 ( 0.990)	Data  0.297 ( 0.297)	Loss 7.7858e-02 (7.7858e-02)	Acc@1   0.87 (  0.87)	Acc@5   0.00 (  0.00)
[0.8748667663855217]
Test: [0/1]	Time  0.262 ( 0.262)	Loss 9.5024e-01 (9.5024e-01)	Acc@1   0.68 (  0.68)	Acc@5   0.00 (  0.00)
 * Acc@1 0.682 Acc@5 0.000
Test: [0/1]	Time  0.308 ( 0.308)	Loss 1.6314e-01 (1.6314e-01)	Acc@1   0.62 (  0.62)	Acc@5   0.00 (  0.00)
 * Acc@1 0.622 Acc@5 0.000
35
TRAINING
Epoch: [35][0/1]	Time  0.987 ( 0.987)	Data  0.290 ( 0.290)	Loss 7.7908e-02 (7.7908e-02)	Acc@1   0.88 (  0.88)	Acc@5   0.00 (  0.00)
[0.8775749428338235]
Test: [0/1]	Time  0.272 ( 0.272)	Loss 9.5106e-01 (9.5106e-01)	Acc@1   0.67 (  0.67)	Acc@5   0.00 (  0.00)
 * Acc@1 0.670 Acc@5 0.000
Test: [0/1]	Time  0.326 ( 0.326)	Loss 1.6181e-01 (1.6181e-01)	Acc@1   0.64 (  0.64)	Acc@5   0.00 (  0.00)
 * Acc@1 0.641 Acc@5 0.000
36
TRAINING
Epoch: [36][0/1]	Time  1.015 ( 1.015)	Data  0.296 ( 0.296)	Loss 7.9535e-02 (7.9535e-02)	Acc@1   0.88 (  0.88)	Acc@5   0.00 (  0.00)
[0.8795213327475878]
Test: [0/1]	Time  0.258 ( 0.258)	Loss 9.5116e-01 (9.5116e-01)	Acc@1   0.66 (  0.66)	Acc@5   0.00 (  0.00)
 * Acc@1 0.658 Acc@5 0.000
Test: [0/1]	Time  0.320 ( 0.320)	Loss 1.6093e-01 (1.6093e-01)	Acc@1   0.66 (  0.66)	Acc@5   0.00 (  0.00)
 * Acc@1 0.658 Acc@5 0.000
37
TRAINING
Epoch: [37][0/1]	Time  1.009 ( 1.009)	Data  0.300 ( 0.300)	Loss 8.1275e-02 (8.1275e-02)	Acc@1   0.88 (  0.88)	Acc@5   0.00 (  0.00)
[0.8793915073297285]
Test: [0/1]	Time  0.264 ( 0.264)	Loss 9.5035e-01 (9.5035e-01)	Acc@1   0.65 (  0.65)	Acc@5   0.00 (  0.00)
 * Acc@1 0.647 Acc@5 0.000
Test: [0/1]	Time  0.317 ( 0.317)	Loss 1.5957e-01 (1.5957e-01)	Acc@1   0.67 (  0.67)	Acc@5   0.00 (  0.00)
 * Acc@1 0.672 Acc@5 0.000
38
TRAINING
Epoch: [38][0/1]	Time  1.021 ( 1.021)	Data  0.311 ( 0.311)	Loss 8.2040e-02 (8.2040e-02)	Acc@1   0.88 (  0.88)	Acc@5   0.00 (  0.00)
[0.8784017328678586]
Test: [0/1]	Time  0.271 ( 0.271)	Loss 9.4869e-01 (9.4869e-01)	Acc@1   0.64 (  0.64)	Acc@5   0.00 (  0.00)
 * Acc@1 0.637 Acc@5 0.000
Test: [0/1]	Time  0.315 ( 0.315)	Loss 1.5758e-01 (1.5758e-01)	Acc@1   0.69 (  0.69)	Acc@5   0.00 (  0.00)
 * Acc@1 0.687 Acc@5 0.000
39
TRAINING
Epoch: [39][0/1]	Time  0.985 ( 0.985)	Data  0.289 ( 0.289)	Loss 8.1652e-02 (8.1652e-02)	Acc@1   0.88 (  0.88)	Acc@5   0.00 (  0.00)
[0.8776774842194206]
Test: [0/1]	Time  0.280 ( 0.280)	Loss 9.4647e-01 (9.4647e-01)	Acc@1   0.63 (  0.63)	Acc@5   0.00 (  0.00)
 * Acc@1 0.627 Acc@5 0.000
Test: [0/1]	Time  0.345 ( 0.345)	Loss 1.5550e-01 (1.5550e-01)	Acc@1   0.70 (  0.70)	Acc@5   0.00 (  0.00)
 * Acc@1 0.700 Acc@5 0.000
40
TRAINING
Epoch: [40][0/1]	Time  0.978 ( 0.978)	Data  0.267 ( 0.267)	Loss 8.0733e-02 (8.0733e-02)	Acc@1   0.88 (  0.88)	Acc@5   0.00 (  0.00)
[0.8773206502064599]
Test: [0/1]	Time  0.267 ( 0.267)	Loss 9.4405e-01 (9.4405e-01)	Acc@1   0.62 (  0.62)	Acc@5   0.00 (  0.00)
 * Acc@1 0.618 Acc@5 0.000
Test: [0/1]	Time  0.316 ( 0.316)	Loss 1.5410e-01 (1.5410e-01)	Acc@1   0.71 (  0.71)	Acc@5   0.00 (  0.00)
 * Acc@1 0.712 Acc@5 0.000
41
TRAINING
Epoch: [41][0/1]	Time  1.025 ( 1.025)	Data  0.329 ( 0.329)	Loss 8.0154e-02 (8.0154e-02)	Acc@1   0.88 (  0.88)	Acc@5   0.00 (  0.00)
[0.8769350140496922]
Test: [0/1]	Time  0.273 ( 0.273)	Loss 9.4180e-01 (9.4180e-01)	Acc@1   0.61 (  0.61)	Acc@5   0.00 (  0.00)
 * Acc@1 0.610 Acc@5 0.000
Test: [0/1]	Time  0.323 ( 0.323)	Loss 1.5377e-01 (1.5377e-01)	Acc@1   0.72 (  0.72)	Acc@5   0.00 (  0.00)
 * Acc@1 0.721 Acc@5 0.000
42
TRAINING
Epoch: [42][0/1]	Time  1.054 ( 1.054)	Data  0.330 ( 0.330)	Loss 8.0438e-02 (8.0438e-02)	Acc@1   0.88 (  0.88)	Acc@5   0.00 (  0.00)
[0.8770670773307581]
Test: [0/1]	Time  0.274 ( 0.274)	Loss 9.3996e-01 (9.3996e-01)	Acc@1   0.60 (  0.60)	Acc@5   0.00 (  0.00)
 * Acc@1 0.603 Acc@5 0.000
Test: [0/1]	Time  0.375 ( 0.375)	Loss 1.5437e-01 (1.5437e-01)	Acc@1   0.73 (  0.73)	Acc@5   0.00 (  0.00)
 * Acc@1 0.725 Acc@5 0.000
43
TRAINING
Epoch: [43][0/1]	Time  1.035 ( 1.035)	Data  0.284 ( 0.284)	Loss 8.1492e-02 (8.1492e-02)	Acc@1   0.88 (  0.88)	Acc@5   0.00 (  0.00)
[0.8770342856474495]
Test: [0/1]	Time  0.281 ( 0.281)	Loss 9.3865e-01 (9.3865e-01)	Acc@1   0.60 (  0.60)	Acc@5   0.00 (  0.00)
 * Acc@1 0.603 Acc@5 0.000
Test: [0/1]	Time  0.328 ( 0.328)	Loss 1.5530e-01 (1.5530e-01)	Acc@1   0.73 (  0.73)	Acc@5   0.00 (  0.00)
 * Acc@1 0.726 Acc@5 0.000
44
TRAINING
Epoch: [44][0/1]	Time  0.994 ( 0.994)	Data  0.290 ( 0.290)	Loss 8.2750e-02 (8.2750e-02)	Acc@1   0.88 (  0.88)	Acc@5   0.00 (  0.00)
[0.877686019649322]
Test: [0/1]	Time  0.285 ( 0.285)	Loss 9.3793e-01 (9.3793e-01)	Acc@1   0.60 (  0.60)	Acc@5   0.00 (  0.00)
 * Acc@1 0.602 Acc@5 0.000
Test: [0/1]	Time  0.377 ( 0.377)	Loss 1.5593e-01 (1.5593e-01)	Acc@1   0.73 (  0.73)	Acc@5   0.00 (  0.00)
 * Acc@1 0.729 Acc@5 0.000
45
TRAINING
Epoch: [45][0/1]	Time  0.976 ( 0.976)	Data  0.275 ( 0.275)	Loss 8.3576e-02 (8.3576e-02)	Acc@1   0.88 (  0.88)	Acc@5   0.00 (  0.00)
[0.8790907447450871]
Test: [0/1]	Time  0.257 ( 0.257)	Loss 9.3778e-01 (9.3778e-01)	Acc@1   0.60 (  0.60)	Acc@5   0.00 (  0.00)
 * Acc@1 0.599 Acc@5 0.000
Test: [0/1]	Time  0.307 ( 0.307)	Loss 1.5592e-01 (1.5592e-01)	Acc@1   0.73 (  0.73)	Acc@5   0.00 (  0.00)
 * Acc@1 0.730 Acc@5 0.000
46
TRAINING
Epoch: [46][0/1]	Time  0.979 ( 0.979)	Data  0.282 ( 0.282)	Loss 8.3638e-02 (8.3638e-02)	Acc@1   0.88 (  0.88)	Acc@5   0.00 (  0.00)
[0.8812376634382975]
Test: [0/1]	Time  0.335 ( 0.335)	Loss 9.3817e-01 (9.3817e-01)	Acc@1   0.60 (  0.60)	Acc@5   0.00 (  0.00)
 * Acc@1 0.596 Acc@5 0.000
Test: [0/1]	Time  0.302 ( 0.302)	Loss 1.5535e-01 (1.5535e-01)	Acc@1   0.73 (  0.73)	Acc@5   0.00 (  0.00)
 * Acc@1 0.730 Acc@5 0.000
47
TRAINING
Epoch: [47][0/1]	Time  0.976 ( 0.976)	Data  0.273 ( 0.273)	Loss 8.3049e-02 (8.3049e-02)	Acc@1   0.88 (  0.88)	Acc@5   0.00 (  0.00)
[0.884045456143554]
Test: [0/1]	Time  0.273 ( 0.273)	Loss 9.3900e-01 (9.3900e-01)	Acc@1   0.59 (  0.59)	Acc@5   0.00 (  0.00)
 * Acc@1 0.591 Acc@5 0.000
Test: [0/1]	Time  0.319 ( 0.319)	Loss 1.5459e-01 (1.5459e-01)	Acc@1   0.73 (  0.73)	Acc@5   0.00 (  0.00)
 * Acc@1 0.731 Acc@5 0.000
48
TRAINING
Epoch: [48][0/1]	Time  1.011 ( 1.011)	Data  0.300 ( 0.300)	Loss 8.2217e-02 (8.2217e-02)	Acc@1   0.89 (  0.89)	Acc@5   0.00 (  0.00)
[0.8873796403321175]
Test: [0/1]	Time  0.265 ( 0.265)	Loss 9.4012e-01 (9.4012e-01)	Acc@1   0.59 (  0.59)	Acc@5   0.00 (  0.00)
 * Acc@1 0.586 Acc@5 0.000
Test: [0/1]	Time  0.313 ( 0.313)	Loss 1.5402e-01 (1.5402e-01)	Acc@1   0.73 (  0.73)	Acc@5   0.00 (  0.00)
 * Acc@1 0.732 Acc@5 0.000
49
TRAINING
Epoch: [49][0/1]	Time  0.950 ( 0.950)	Data  0.253 ( 0.253)	Loss 8.1568e-02 (8.1568e-02)	Acc@1   0.89 (  0.89)	Acc@5   0.00 (  0.00)
[0.891075101200616]
Test: [0/1]	Time  0.280 ( 0.280)	Loss 9.4136e-01 (9.4136e-01)	Acc@1   0.59 (  0.59)	Acc@5   0.00 (  0.00)
 * Acc@1 0.590 Acc@5 0.000
Test: [0/1]	Time  0.326 ( 0.326)	Loss 1.5385e-01 (1.5385e-01)	Acc@1   0.73 (  0.73)	Acc@5   0.00 (  0.00)
 * Acc@1 0.733 Acc@5 0.000
50
TRAINING
Epoch: [50][0/1]	Time  0.971 ( 0.971)	Data  0.278 ( 0.278)	Loss 8.1307e-02 (8.1307e-02)	Acc@1   0.89 (  0.89)	Acc@5   0.00 (  0.00)
[0.8949591149628102]
Test: [0/1]	Time  0.255 ( 0.255)	Loss 9.4251e-01 (9.4251e-01)	Acc@1   0.59 (  0.59)	Acc@5   0.00 (  0.00)
 * Acc@1 0.595 Acc@5 0.000
Test: [0/1]	Time  0.305 ( 0.305)	Loss 1.5401e-01 (1.5401e-01)	Acc@1   0.73 (  0.73)	Acc@5   0.00 (  0.00)
 * Acc@1 0.735 Acc@5 0.000
51
TRAINING
Epoch: [51][0/1]	Time  1.043 ( 1.043)	Data  0.325 ( 0.325)	Loss 8.1356e-02 (8.1356e-02)	Acc@1   0.90 (  0.90)	Acc@5   0.00 (  0.00)
[0.8984940270984771]
Test: [0/1]	Time  0.273 ( 0.273)	Loss 9.4340e-01 (9.4340e-01)	Acc@1   0.60 (  0.60)	Acc@5   0.00 (  0.00)
 * Acc@1 0.599 Acc@5 0.000
Test: [0/1]	Time  0.323 ( 0.323)	Loss 1.5430e-01 (1.5430e-01)	Acc@1   0.73 (  0.73)	Acc@5   0.00 (  0.00)
 * Acc@1 0.735 Acc@5 0.000
52
TRAINING
Epoch: [52][0/1]	Time  1.027 ( 1.027)	Data  0.314 ( 0.314)	Loss 8.1468e-02 (8.1468e-02)	Acc@1   0.90 (  0.90)	Acc@5   0.00 (  0.00)
[0.9021403181871718]
Test: [0/1]	Time  0.274 ( 0.274)	Loss 9.4391e-01 (9.4391e-01)	Acc@1   0.60 (  0.60)	Acc@5   0.00 (  0.00)
 * Acc@1 0.604 Acc@5 0.000
Test: [0/1]	Time  0.319 ( 0.319)	Loss 1.5452e-01 (1.5452e-01)	Acc@1   0.73 (  0.73)	Acc@5   0.00 (  0.00)
 * Acc@1 0.734 Acc@5 0.000
53
TRAINING
Epoch: [53][0/1]	Time  0.946 ( 0.946)	Data  0.267 ( 0.267)	Loss 8.1412e-02 (8.1412e-02)	Acc@1   0.91 (  0.91)	Acc@5   0.00 (  0.00)
[0.9060872292808088]
Test: [0/1]	Time  0.246 ( 0.246)	Loss 9.4402e-01 (9.4402e-01)	Acc@1   0.61 (  0.61)	Acc@5   0.00 (  0.00)
 * Acc@1 0.609 Acc@5 0.000
Test: [0/1]	Time  0.297 ( 0.297)	Loss 1.5457e-01 (1.5457e-01)	Acc@1   0.73 (  0.73)	Acc@5   0.00 (  0.00)
 * Acc@1 0.735 Acc@5 0.000
54
TRAINING
Epoch: [54][0/1]	Time  0.960 ( 0.960)	Data  0.250 ( 0.250)	Loss 8.1114e-02 (8.1114e-02)	Acc@1   0.91 (  0.91)	Acc@5   0.00 (  0.00)
[0.9095654701241553]
Test: [0/1]	Time  0.293 ( 0.293)	Loss 9.4378e-01 (9.4378e-01)	Acc@1   0.61 (  0.61)	Acc@5   0.00 (  0.00)
 * Acc@1 0.614 Acc@5 0.000
Test: [0/1]	Time  0.333 ( 0.333)	Loss 1.5453e-01 (1.5453e-01)	Acc@1   0.74 (  0.74)	Acc@5   0.00 (  0.00)
 * Acc@1 0.736 Acc@5 0.000
55
TRAINING
Epoch: [55][0/1]	Time  1.010 ( 1.010)	Data  0.303 ( 0.303)	Loss 8.0669e-02 (8.0669e-02)	Acc@1   0.91 (  0.91)	Acc@5   0.00 (  0.00)
[0.9125441283897869]
Test: [0/1]	Time  0.258 ( 0.258)	Loss 9.4334e-01 (9.4334e-01)	Acc@1   0.62 (  0.62)	Acc@5   0.00 (  0.00)
 * Acc@1 0.619 Acc@5 0.000
Test: [0/1]	Time  0.313 ( 0.313)	Loss 1.5454e-01 (1.5454e-01)	Acc@1   0.74 (  0.74)	Acc@5   0.00 (  0.00)
 * Acc@1 0.736 Acc@5 0.000
56
TRAINING
Epoch: [56][0/1]	Time  0.964 ( 0.964)	Data  0.272 ( 0.272)	Loss 8.0258e-02 (8.0258e-02)	Acc@1   0.92 (  0.92)	Acc@5   0.00 (  0.00)
[0.915187052084093]
Test: [0/1]	Time  0.254 ( 0.254)	Loss 9.4282e-01 (9.4282e-01)	Acc@1   0.62 (  0.62)	Acc@5   0.00 (  0.00)
 * Acc@1 0.624 Acc@5 0.000
Test: [0/1]	Time  0.305 ( 0.305)	Loss 1.5468e-01 (1.5468e-01)	Acc@1   0.74 (  0.74)	Acc@5   0.00 (  0.00)
 * Acc@1 0.737 Acc@5 0.000
57
TRAINING
Epoch: [57][0/1]	Time  0.998 ( 0.998)	Data  0.291 ( 0.291)	Loss 8.0018e-02 (8.0018e-02)	Acc@1   0.92 (  0.92)	Acc@5   0.00 (  0.00)
[0.9175063528069729]
Test: [0/1]	Time  0.257 ( 0.257)	Loss 9.4238e-01 (9.4238e-01)	Acc@1   0.63 (  0.63)	Acc@5   0.00 (  0.00)
 * Acc@1 0.629 Acc@5 0.000
Test: [0/1]	Time  0.309 ( 0.309)	Loss 1.5495e-01 (1.5495e-01)	Acc@1   0.74 (  0.74)	Acc@5   0.00 (  0.00)
 * Acc@1 0.737 Acc@5 0.000
58
TRAINING
Epoch: [58][0/1]	Time  1.009 ( 1.009)	Data  0.303 ( 0.303)	Loss 7.9966e-02 (7.9966e-02)	Acc@1   0.92 (  0.92)	Acc@5   0.00 (  0.00)
[0.9195297887215759]
Test: [0/1]	Time  0.265 ( 0.265)	Loss 9.4212e-01 (9.4212e-01)	Acc@1   0.63 (  0.63)	Acc@5   0.00 (  0.00)
 * Acc@1 0.634 Acc@5 0.000
Test: [0/1]	Time  0.329 ( 0.329)	Loss 1.5524e-01 (1.5524e-01)	Acc@1   0.74 (  0.74)	Acc@5   0.00 (  0.00)
 * Acc@1 0.737 Acc@5 0.000
59
TRAINING
Epoch: [59][0/1]	Time  0.965 ( 0.965)	Data  0.283 ( 0.283)	Loss 8.0010e-02 (8.0010e-02)	Acc@1   0.92 (  0.92)	Acc@5   0.00 (  0.00)
[0.9220916493398459]
Test: [0/1]	Time  0.260 ( 0.260)	Loss 9.4208e-01 (9.4208e-01)	Acc@1   0.64 (  0.64)	Acc@5   0.00 (  0.00)
 * Acc@1 0.638 Acc@5 0.000
Test: [0/1]	Time  0.306 ( 0.306)	Loss 1.5543e-01 (1.5543e-01)	Acc@1   0.74 (  0.74)	Acc@5   0.00 (  0.00)
 * Acc@1 0.737 Acc@5 0.000
60
TRAINING
Epoch: [60][0/1]	Time  0.961 ( 0.961)	Data  0.244 ( 0.244)	Loss 8.0015e-02 (8.0015e-02)	Acc@1   0.92 (  0.92)	Acc@5   0.00 (  0.00)
[0.9243172539725175]
Test: [0/1]	Time  0.249 ( 0.249)	Loss 9.4230e-01 (9.4230e-01)	Acc@1   0.64 (  0.64)	Acc@5   0.00 (  0.00)
 * Acc@1 0.641 Acc@5 0.000
Test: [0/1]	Time  0.299 ( 0.299)	Loss 1.5543e-01 (1.5543e-01)	Acc@1   0.74 (  0.74)	Acc@5   0.00 (  0.00)
 * Acc@1 0.736 Acc@5 0.000
61
TRAINING
Epoch: [61][0/1]	Time  0.941 ( 0.941)	Data  0.247 ( 0.247)	Loss 7.9891e-02 (7.9891e-02)	Acc@1   0.93 (  0.93)	Acc@5   0.00 (  0.00)
[0.9262322699713402]
Test: [0/1]	Time  0.241 ( 0.241)	Loss 9.4275e-01 (9.4275e-01)	Acc@1   0.64 (  0.64)	Acc@5   0.00 (  0.00)
 * Acc@1 0.644 Acc@5 0.000
Test: [0/1]	Time  0.290 ( 0.290)	Loss 1.5525e-01 (1.5525e-01)	Acc@1   0.74 (  0.74)	Acc@5   0.00 (  0.00)
 * Acc@1 0.736 Acc@5 0.000
62
TRAINING
Epoch: [62][0/1]	Time  0.936 ( 0.936)	Data  0.251 ( 0.251)	Loss 7.9633e-02 (7.9633e-02)	Acc@1   0.93 (  0.93)	Acc@5   0.00 (  0.00)
[0.9278792817447101]
Test: [0/1]	Time  0.279 ( 0.279)	Loss 9.4339e-01 (9.4339e-01)	Acc@1   0.65 (  0.65)	Acc@5   0.00 (  0.00)
 * Acc@1 0.647 Acc@5 0.000
Test: [0/1]	Time  0.318 ( 0.318)	Loss 1.5496e-01 (1.5496e-01)	Acc@1   0.74 (  0.74)	Acc@5   0.00 (  0.00)
 * Acc@1 0.736 Acc@5 0.000
63
TRAINING
Epoch: [63][0/1]	Time  0.964 ( 0.964)	Data  0.267 ( 0.267)	Loss 7.9312e-02 (7.9312e-02)	Acc@1   0.93 (  0.93)	Acc@5   0.00 (  0.00)
[0.9289866166128715]
Test: [0/1]	Time  0.247 ( 0.247)	Loss 9.4413e-01 (9.4413e-01)	Acc@1   0.65 (  0.65)	Acc@5   0.00 (  0.00)
 * Acc@1 0.649 Acc@5 0.000
Test: [0/1]	Time  0.295 ( 0.295)	Loss 1.5465e-01 (1.5465e-01)	Acc@1   0.74 (  0.74)	Acc@5   0.00 (  0.00)
 * Acc@1 0.736 Acc@5 0.000
64
TRAINING
Epoch: [64][0/1]	Time  0.933 ( 0.933)	Data  0.251 ( 0.251)	Loss 7.9019e-02 (7.9019e-02)	Acc@1   0.93 (  0.93)	Acc@5   0.00 (  0.00)
[0.9293262665174353]
Test: [0/1]	Time  0.241 ( 0.241)	Loss 9.4488e-01 (9.4488e-01)	Acc@1   0.65 (  0.65)	Acc@5   0.00 (  0.00)
 * Acc@1 0.651 Acc@5 0.000
Test: [0/1]	Time  0.291 ( 0.291)	Loss 1.5440e-01 (1.5440e-01)	Acc@1   0.74 (  0.74)	Acc@5   0.00 (  0.00)
 * Acc@1 0.735 Acc@5 0.000
65
TRAINING
Epoch: [65][0/1]	Time  0.928 ( 0.928)	Data  0.248 ( 0.248)	Loss 7.8813e-02 (7.8813e-02)	Acc@1   0.93 (  0.93)	Acc@5   0.00 (  0.00)
[0.929442802454014]
Test: [0/1]	Time  0.237 ( 0.237)	Loss 9.4553e-01 (9.4553e-01)	Acc@1   0.65 (  0.65)	Acc@5   0.00 (  0.00)
 * Acc@1 0.653 Acc@5 0.000
Test: [0/1]	Time  0.291 ( 0.291)	Loss 1.5421e-01 (1.5421e-01)	Acc@1   0.74 (  0.74)	Acc@5   0.00 (  0.00)
 * Acc@1 0.735 Acc@5 0.000
66
TRAINING
Epoch: [66][0/1]	Time  0.945 ( 0.945)	Data  0.250 ( 0.250)	Loss 7.8697e-02 (7.8697e-02)	Acc@1   0.93 (  0.93)	Acc@5   0.00 (  0.00)
[0.9295012104587395]
Test: [0/1]	Time  0.240 ( 0.240)	Loss 9.4602e-01 (9.4602e-01)	Acc@1   0.66 (  0.66)	Acc@5   0.00 (  0.00)
 * Acc@1 0.655 Acc@5 0.000
Test: [0/1]	Time  0.290 ( 0.290)	Loss 1.5407e-01 (1.5407e-01)	Acc@1   0.74 (  0.74)	Acc@5   0.00 (  0.00)
 * Acc@1 0.735 Acc@5 0.000
67
TRAINING
Epoch: [67][0/1]	Time  0.941 ( 0.941)	Data  0.251 ( 0.251)	Loss 7.8628e-02 (7.8628e-02)	Acc@1   0.93 (  0.93)	Acc@5   0.00 (  0.00)
[0.9299056657067909]
Test: [0/1]	Time  0.239 ( 0.239)	Loss 9.4628e-01 (9.4628e-01)	Acc@1   0.66 (  0.66)	Acc@5   0.00 (  0.00)
 * Acc@1 0.657 Acc@5 0.000
Test: [0/1]	Time  0.289 ( 0.289)	Loss 1.5393e-01 (1.5393e-01)	Acc@1   0.74 (  0.74)	Acc@5   0.00 (  0.00)
 * Acc@1 0.735 Acc@5 0.000
68
TRAINING
Epoch: [68][0/1]	Time  0.939 ( 0.939)	Data  0.252 ( 0.252)	Loss 7.8557e-02 (7.8557e-02)	Acc@1   0.93 (  0.93)	Acc@5   0.00 (  0.00)
[0.9303261055099908]
Test: [0/1]	Time  0.239 ( 0.239)	Loss 9.4633e-01 (9.4633e-01)	Acc@1   0.66 (  0.66)	Acc@5   0.00 (  0.00)
 * Acc@1 0.659 Acc@5 0.000
Test: [0/1]	Time  0.288 ( 0.288)	Loss 1.5378e-01 (1.5378e-01)	Acc@1   0.74 (  0.74)	Acc@5   0.00 (  0.00)
 * Acc@1 0.736 Acc@5 0.000
69
TRAINING
Epoch: [69][0/1]	Time  0.934 ( 0.934)	Data  0.251 ( 0.251)	Loss 7.8456e-02 (7.8456e-02)	Acc@1   0.93 (  0.93)	Acc@5   0.00 (  0.00)
[0.9306667682045375]
Test: [0/1]	Time  0.240 ( 0.240)	Loss 9.4617e-01 (9.4617e-01)	Acc@1   0.66 (  0.66)	Acc@5   0.00 (  0.00)
 * Acc@1 0.660 Acc@5 0.000
Test: [0/1]	Time  0.292 ( 0.292)	Loss 1.5363e-01 (1.5363e-01)	Acc@1   0.74 (  0.74)	Acc@5   0.00 (  0.00)
 * Acc@1 0.736 Acc@5 0.000
70
TRAINING
Epoch: [70][0/1]	Time  0.962 ( 0.962)	Data  0.241 ( 0.241)	Loss 7.8334e-02 (7.8334e-02)	Acc@1   0.93 (  0.93)	Acc@5   0.00 (  0.00)
[0.9309351824838568]
Test: [0/1]	Time  0.237 ( 0.237)	Loss 9.4586e-01 (9.4586e-01)	Acc@1   0.66 (  0.66)	Acc@5   0.00 (  0.00)
 * Acc@1 0.662 Acc@5 0.000
Test: [0/1]	Time  0.291 ( 0.291)	Loss 1.5348e-01 (1.5348e-01)	Acc@1   0.74 (  0.74)	Acc@5   0.00 (  0.00)
 * Acc@1 0.737 Acc@5 0.000
71
TRAINING
Epoch: [71][0/1]	Time  0.934 ( 0.934)	Data  0.251 ( 0.251)	Loss 7.8222e-02 (7.8222e-02)	Acc@1   0.93 (  0.93)	Acc@5   0.00 (  0.00)
[0.9311296962239084]
Test: [0/1]	Time  0.243 ( 0.243)	Loss 9.4548e-01 (9.4548e-01)	Acc@1   0.66 (  0.66)	Acc@5   0.00 (  0.00)
 * Acc@1 0.663 Acc@5 0.000
Test: [0/1]	Time  0.295 ( 0.295)	Loss 1.5338e-01 (1.5338e-01)	Acc@1   0.74 (  0.74)	Acc@5   0.00 (  0.00)
 * Acc@1 0.737 Acc@5 0.000
72
TRAINING
Epoch: [72][0/1]	Time  0.980 ( 0.980)	Data  0.271 ( 0.271)	Loss 7.8149e-02 (7.8149e-02)	Acc@1   0.93 (  0.93)	Acc@5   0.00 (  0.00)
[0.9312515376267678]
Test: [0/1]	Time  0.256 ( 0.256)	Loss 9.4509e-01 (9.4509e-01)	Acc@1   0.66 (  0.66)	Acc@5   0.00 (  0.00)
 * Acc@1 0.665 Acc@5 0.000
Test: [0/1]	Time  0.304 ( 0.304)	Loss 1.5330e-01 (1.5330e-01)	Acc@1   0.74 (  0.74)	Acc@5   0.00 (  0.00)
 * Acc@1 0.738 Acc@5 0.000
73
TRAINING
Epoch: [73][0/1]	Time  1.047 ( 1.047)	Data  0.333 ( 0.333)	Loss 7.8123e-02 (7.8123e-02)	Acc@1   0.93 (  0.93)	Acc@5   0.00 (  0.00)
[0.9313137708034991]
Test: [0/1]	Time  0.269 ( 0.269)	Loss 9.4476e-01 (9.4476e-01)	Acc@1   0.67 (  0.67)	Acc@5   0.00 (  0.00)
 * Acc@1 0.666 Acc@5 0.000
Test: [0/1]	Time  0.322 ( 0.322)	Loss 1.5325e-01 (1.5325e-01)	Acc@1   0.74 (  0.74)	Acc@5   0.00 (  0.00)
 * Acc@1 0.739 Acc@5 0.000
74
TRAINING
Epoch: [74][0/1]	Time  1.008 ( 1.008)	Data  0.302 ( 0.302)	Loss 7.8127e-02 (7.8127e-02)	Acc@1   0.93 (  0.93)	Acc@5   0.00 (  0.00)
[0.931341321106782]
Test: [0/1]	Time  0.287 ( 0.287)	Loss 9.4453e-01 (9.4453e-01)	Acc@1   0.67 (  0.67)	Acc@5   0.00 (  0.00)
 * Acc@1 0.666 Acc@5 0.000
Test: [0/1]	Time  0.335 ( 0.335)	Loss 1.5319e-01 (1.5319e-01)	Acc@1   0.74 (  0.74)	Acc@5   0.00 (  0.00)
 * Acc@1 0.739 Acc@5 0.000
75
TRAINING
Epoch: [75][0/1]	Time  1.014 ( 1.014)	Data  0.304 ( 0.304)	Loss 7.8135e-02 (7.8135e-02)	Acc@1   0.93 (  0.93)	Acc@5   0.00 (  0.00)
[0.9313627535398394]
Test: [0/1]	Time  0.267 ( 0.267)	Loss 9.4442e-01 (9.4442e-01)	Acc@1   0.67 (  0.67)	Acc@5   0.00 (  0.00)
 * Acc@1 0.667 Acc@5 0.000
Test: [0/1]	Time  0.316 ( 0.316)	Loss 1.5309e-01 (1.5309e-01)	Acc@1   0.74 (  0.74)	Acc@5   0.00 (  0.00)
 * Acc@1 0.740 Acc@5 0.000
76
TRAINING
Epoch: [76][0/1]	Time  0.987 ( 0.987)	Data  0.288 ( 0.288)	Loss 7.8120e-02 (7.8120e-02)	Acc@1   0.93 (  0.93)	Acc@5   0.00 (  0.00)
[0.9313885309105004]
Test: [0/1]	Time  0.257 ( 0.257)	Loss 9.4444e-01 (9.4444e-01)	Acc@1   0.67 (  0.67)	Acc@5   0.00 (  0.00)
 * Acc@1 0.667 Acc@5 0.000
Test: [0/1]	Time  0.315 ( 0.315)	Loss 1.5295e-01 (1.5295e-01)	Acc@1   0.74 (  0.74)	Acc@5   0.00 (  0.00)
 * Acc@1 0.740 Acc@5 0.000
77
TRAINING
Epoch: [77][0/1]	Time  1.006 ( 1.006)	Data  0.291 ( 0.291)	Loss 7.8077e-02 (7.8077e-02)	Acc@1   0.93 (  0.93)	Acc@5   0.00 (  0.00)
[0.9313616145675544]
Test: [0/1]	Time  0.256 ( 0.256)	Loss 9.4456e-01 (9.4456e-01)	Acc@1   0.67 (  0.67)	Acc@5   0.00 (  0.00)
 * Acc@1 0.667 Acc@5 0.000
Test: [0/1]	Time  0.305 ( 0.305)	Loss 1.5279e-01 (1.5279e-01)	Acc@1   0.74 (  0.74)	Acc@5   0.00 (  0.00)
 * Acc@1 0.740 Acc@5 0.000
78
TRAINING
Epoch: [78][0/1]	Time  0.966 ( 0.966)	Data  0.271 ( 0.271)	Loss 7.8016e-02 (7.8016e-02)	Acc@1   0.93 (  0.93)	Acc@5   0.00 (  0.00)
[0.9313500265843476]
Test: [0/1]	Time  0.251 ( 0.251)	Loss 9.4475e-01 (9.4475e-01)	Acc@1   0.67 (  0.67)	Acc@5   0.00 (  0.00)
 * Acc@1 0.667 Acc@5 0.000
Test: [0/1]	Time  0.302 ( 0.302)	Loss 1.5262e-01 (1.5262e-01)	Acc@1   0.74 (  0.74)	Acc@5   0.00 (  0.00)
 * Acc@1 0.740 Acc@5 0.000
79
TRAINING
Epoch: [79][0/1]	Time  0.950 ( 0.950)	Data  0.267 ( 0.267)	Loss 7.7955e-02 (7.7955e-02)	Acc@1   0.93 (  0.93)	Acc@5   0.00 (  0.00)
[0.9313560022948326]
Test: [0/1]	Time  0.239 ( 0.239)	Loss 9.4496e-01 (9.4496e-01)	Acc@1   0.67 (  0.67)	Acc@5   0.00 (  0.00)
 * Acc@1 0.666 Acc@5 0.000
Test: [0/1]	Time  0.295 ( 0.295)	Loss 1.5247e-01 (1.5247e-01)	Acc@1   0.74 (  0.74)	Acc@5   0.00 (  0.00)
 * Acc@1 0.740 Acc@5 0.000
80
TRAINING
Epoch: [80][0/1]	Time  0.950 ( 0.950)	Data  0.248 ( 0.248)	Loss 7.7908e-02 (7.7908e-02)	Acc@1   0.93 (  0.93)	Acc@5   0.00 (  0.00)
[0.9313818226308423]
Test: [0/1]	Time  0.236 ( 0.236)	Loss 9.4515e-01 (9.4515e-01)	Acc@1   0.67 (  0.67)	Acc@5   0.00 (  0.00)
 * Acc@1 0.668 Acc@5 0.000
Test: [0/1]	Time  0.291 ( 0.291)	Loss 1.5234e-01 (1.5234e-01)	Acc@1   0.74 (  0.74)	Acc@5   0.00 (  0.00)
 * Acc@1 0.740 Acc@5 0.000
81
TRAINING
Epoch: [81][0/1]	Time  0.931 ( 0.931)	Data  0.250 ( 0.250)	Loss 7.7882e-02 (7.7882e-02)	Acc@1   0.93 (  0.93)	Acc@5   0.00 (  0.00)
[0.931429963603606]
Test: [0/1]	Time  0.236 ( 0.236)	Loss 9.4529e-01 (9.4529e-01)	Acc@1   0.67 (  0.67)	Acc@5   0.00 (  0.00)
 * Acc@1 0.669 Acc@5 0.000
Test: [0/1]	Time  0.290 ( 0.290)	Loss 1.5224e-01 (1.5224e-01)	Acc@1   0.74 (  0.74)	Acc@5   0.00 (  0.00)
 * Acc@1 0.740 Acc@5 0.000
82
TRAINING
Epoch: [82][0/1]	Time  0.930 ( 0.930)	Data  0.250 ( 0.250)	Loss 7.7869e-02 (7.7869e-02)	Acc@1   0.93 (  0.93)	Acc@5   0.00 (  0.00)
[0.9315071883698613]
Test: [0/1]	Time  0.236 ( 0.236)	Loss 9.4533e-01 (9.4533e-01)	Acc@1   0.67 (  0.67)	Acc@5   0.00 (  0.00)
 * Acc@1 0.671 Acc@5 0.000
Test: [0/1]	Time  0.288 ( 0.288)	Loss 1.5215e-01 (1.5215e-01)	Acc@1   0.74 (  0.74)	Acc@5   0.00 (  0.00)
 * Acc@1 0.740 Acc@5 0.000
83
TRAINING
Epoch: [83][0/1]	Time  1.032 ( 1.032)	Data  0.337 ( 0.337)	Loss 7.7861e-02 (7.7861e-02)	Acc@1   0.93 (  0.93)	Acc@5   0.00 (  0.00)
[0.9317357747165589]
Test: [0/1]	Time  0.271 ( 0.271)	Loss 9.4528e-01 (9.4528e-01)	Acc@1   0.67 (  0.67)	Acc@5   0.00 (  0.00)
 * Acc@1 0.672 Acc@5 0.000
Test: [0/1]	Time  0.327 ( 0.327)	Loss 1.5207e-01 (1.5207e-01)	Acc@1   0.74 (  0.74)	Acc@5   0.00 (  0.00)
 * Acc@1 0.740 Acc@5 0.000
84
TRAINING
Epoch: [84][0/1]	Time  1.037 ( 1.037)	Data  0.345 ( 0.345)	Loss 7.7848e-02 (7.7848e-02)	Acc@1   0.93 (  0.93)	Acc@5   0.00 (  0.00)
[0.9320044293662253]
Test: [0/1]	Time  0.274 ( 0.274)	Loss 9.4514e-01 (9.4514e-01)	Acc@1   0.67 (  0.67)	Acc@5   0.00 (  0.00)
 * Acc@1 0.673 Acc@5 0.000
Test: [0/1]	Time  0.334 ( 0.334)	Loss 1.5201e-01 (1.5201e-01)	Acc@1   0.74 (  0.74)	Acc@5   0.00 (  0.00)
 * Acc@1 0.741 Acc@5 0.000
85
TRAINING
Epoch: [85][0/1]	Time  1.023 ( 1.023)	Data  0.316 ( 0.316)	Loss 7.7832e-02 (7.7832e-02)	Acc@1   0.93 (  0.93)	Acc@5   0.00 (  0.00)
[0.932291376058164]
Test: [0/1]	Time  0.267 ( 0.267)	Loss 9.4493e-01 (9.4493e-01)	Acc@1   0.67 (  0.67)	Acc@5   0.00 (  0.00)
 * Acc@1 0.674 Acc@5 0.000
Test: [0/1]	Time  0.331 ( 0.331)	Loss 1.5196e-01 (1.5196e-01)	Acc@1   0.74 (  0.74)	Acc@5   0.00 (  0.00)
 * Acc@1 0.741 Acc@5 0.000
86
TRAINING
Epoch: [86][0/1]	Time  1.022 ( 1.022)	Data  0.312 ( 0.312)	Loss 7.7815e-02 (7.7815e-02)	Acc@1   0.93 (  0.93)	Acc@5   0.00 (  0.00)
[0.9324241752995915]
Test: [0/1]	Time  0.268 ( 0.268)	Loss 9.4468e-01 (9.4468e-01)	Acc@1   0.67 (  0.67)	Acc@5   0.00 (  0.00)
 * Acc@1 0.675 Acc@5 0.000
Test: [0/1]	Time  0.316 ( 0.316)	Loss 1.5192e-01 (1.5192e-01)	Acc@1   0.74 (  0.74)	Acc@5   0.00 (  0.00)
 * Acc@1 0.742 Acc@5 0.000
87
TRAINING
Epoch: [87][0/1]	Time  1.031 ( 1.031)	Data  0.325 ( 0.325)	Loss 7.7803e-02 (7.7803e-02)	Acc@1   0.93 (  0.93)	Acc@5   0.00 (  0.00)
[0.9325485962718072]
Test: [0/1]	Time  0.273 ( 0.273)	Loss 9.4442e-01 (9.4442e-01)	Acc@1   0.68 (  0.68)	Acc@5   0.00 (  0.00)
 * Acc@1 0.676 Acc@5 0.000
Test: [0/1]	Time  0.324 ( 0.324)	Loss 1.5189e-01 (1.5189e-01)	Acc@1   0.74 (  0.74)	Acc@5   0.00 (  0.00)
 * Acc@1 0.742 Acc@5 0.000
88
TRAINING
Epoch: [88][0/1]	Time  0.995 ( 0.995)	Data  0.303 ( 0.303)	Loss 7.7799e-02 (7.7799e-02)	Acc@1   0.93 (  0.93)	Acc@5   0.00 (  0.00)
[0.9326604683585598]
Test: [0/1]	Time  0.259 ( 0.259)	Loss 9.4419e-01 (9.4419e-01)	Acc@1   0.68 (  0.68)	Acc@5   0.00 (  0.00)
 * Acc@1 0.676 Acc@5 0.000
Test: [0/1]	Time  0.316 ( 0.316)	Loss 1.5187e-01 (1.5187e-01)	Acc@1   0.74 (  0.74)	Acc@5   0.00 (  0.00)
 * Acc@1 0.743 Acc@5 0.000
89
TRAINING
Epoch: [89][0/1]	Time  1.014 ( 1.014)	Data  0.299 ( 0.299)	Loss 7.7799e-02 (7.7799e-02)	Acc@1   0.93 (  0.93)	Acc@5   0.00 (  0.00)
[0.9327591441586627]
Test: [0/1]	Time  0.263 ( 0.263)	Loss 9.4400e-01 (9.4400e-01)	Acc@1   0.68 (  0.68)	Acc@5   0.00 (  0.00)
 * Acc@1 0.677 Acc@5 0.000
Test: [0/1]	Time  0.310 ( 0.310)	Loss 1.5185e-01 (1.5185e-01)	Acc@1   0.74 (  0.74)	Acc@5   0.00 (  0.00)
 * Acc@1 0.743 Acc@5 0.000
90
TRAINING
Epoch: [90][0/1]	Time  1.002 ( 1.002)	Data  0.269 ( 0.269)	Loss 7.7798e-02 (7.7798e-02)	Acc@1   0.93 (  0.93)	Acc@5   0.00 (  0.00)
[0.9328466271974015]
Test: [0/1]	Time  0.260 ( 0.260)	Loss 9.4387e-01 (9.4387e-01)	Acc@1   0.68 (  0.68)	Acc@5   0.00 (  0.00)
 * Acc@1 0.677 Acc@5 0.000
Test: [0/1]	Time  0.307 ( 0.307)	Loss 1.5183e-01 (1.5183e-01)	Acc@1   0.74 (  0.74)	Acc@5   0.00 (  0.00)
 * Acc@1 0.743 Acc@5 0.000
91
TRAINING
Epoch: [91][0/1]	Time  1.054 ( 1.054)	Data  0.352 ( 0.352)	Loss 7.7789e-02 (7.7789e-02)	Acc@1   0.93 (  0.93)	Acc@5   0.00 (  0.00)
[0.9329255948641992]
Test: [0/1]	Time  0.281 ( 0.281)	Loss 9.4381e-01 (9.4381e-01)	Acc@1   0.68 (  0.68)	Acc@5   0.00 (  0.00)
 * Acc@1 0.678 Acc@5 0.000
Test: [0/1]	Time  0.336 ( 0.336)	Loss 1.5179e-01 (1.5179e-01)	Acc@1   0.74 (  0.74)	Acc@5   0.00 (  0.00)
 * Acc@1 0.744 Acc@5 0.000
92
TRAINING
Epoch: [92][0/1]	Time  1.003 ( 1.003)	Data  0.283 ( 0.283)	Loss 7.7772e-02 (7.7772e-02)	Acc@1   0.93 (  0.93)	Acc@5   0.00 (  0.00)
[0.9329976318835613]
Test: [0/1]	Time  0.269 ( 0.269)	Loss 9.4380e-01 (9.4380e-01)	Acc@1   0.68 (  0.68)	Acc@5   0.00 (  0.00)
 * Acc@1 0.678 Acc@5 0.000
Test: [0/1]	Time  0.323 ( 0.323)	Loss 1.5175e-01 (1.5175e-01)	Acc@1   0.74 (  0.74)	Acc@5   0.00 (  0.00)
 * Acc@1 0.744 Acc@5 0.000
93
TRAINING
Epoch: [93][0/1]	Time  1.004 ( 1.004)	Data  0.298 ( 0.298)	Loss 7.7747e-02 (7.7747e-02)	Acc@1   0.93 (  0.93)	Acc@5   0.00 (  0.00)
[0.9330626238216568]
Test: [0/1]	Time  0.262 ( 0.262)	Loss 9.4382e-01 (9.4382e-01)	Acc@1   0.68 (  0.68)	Acc@5   0.00 (  0.00)
 * Acc@1 0.678 Acc@5 0.000
Test: [0/1]	Time  0.316 ( 0.316)	Loss 1.5170e-01 (1.5170e-01)	Acc@1   0.74 (  0.74)	Acc@5   0.00 (  0.00)
 * Acc@1 0.744 Acc@5 0.000
94
TRAINING
Epoch: [94][0/1]	Time  1.001 ( 1.001)	Data  0.297 ( 0.297)	Loss 7.7718e-02 (7.7718e-02)	Acc@1   0.93 (  0.93)	Acc@5   0.00 (  0.00)
[0.9331194102841771]
Test: [0/1]	Time  0.283 ( 0.283)	Loss 9.4387e-01 (9.4387e-01)	Acc@1   0.68 (  0.68)	Acc@5   0.00 (  0.00)
 * Acc@1 0.678 Acc@5 0.000
Test: [0/1]	Time  0.325 ( 0.325)	Loss 1.5165e-01 (1.5165e-01)	Acc@1   0.74 (  0.74)	Acc@5   0.00 (  0.00)
 * Acc@1 0.744 Acc@5 0.000
95
TRAINING
Epoch: [95][0/1]	Time  1.020 ( 1.020)	Data  0.299 ( 0.299)	Loss 7.7690e-02 (7.7690e-02)	Acc@1   0.93 (  0.93)	Acc@5   0.00 (  0.00)
[0.933167051214886]
Test: [0/1]	Time  0.260 ( 0.260)	Loss 9.4392e-01 (9.4392e-01)	Acc@1   0.68 (  0.68)	Acc@5   0.00 (  0.00)
 * Acc@1 0.678 Acc@5 0.000
Test: [0/1]	Time  0.314 ( 0.314)	Loss 1.5161e-01 (1.5161e-01)	Acc@1   0.74 (  0.74)	Acc@5   0.00 (  0.00)
 * Acc@1 0.744 Acc@5 0.000
96
TRAINING
Epoch: [96][0/1]	Time  0.997 ( 0.997)	Data  0.300 ( 0.300)	Loss 7.7666e-02 (7.7666e-02)	Acc@1   0.93 (  0.93)	Acc@5   0.00 (  0.00)
[0.9332058329848187]
Test: [0/1]	Time  0.257 ( 0.257)	Loss 9.4394e-01 (9.4394e-01)	Acc@1   0.68 (  0.68)	Acc@5   0.00 (  0.00)
 * Acc@1 0.679 Acc@5 0.000
Test: [0/1]	Time  0.314 ( 0.314)	Loss 1.5159e-01 (1.5159e-01)	Acc@1   0.74 (  0.74)	Acc@5   0.00 (  0.00)
 * Acc@1 0.745 Acc@5 0.000
97
TRAINING
Epoch: [97][0/1]	Time  1.065 ( 1.065)	Data  0.345 ( 0.345)	Loss 7.7646e-02 (7.7646e-02)	Acc@1   0.93 (  0.93)	Acc@5   0.00 (  0.00)
[0.9332374655338935]
Test: [0/1]	Time  0.271 ( 0.271)	Loss 9.4394e-01 (9.4394e-01)	Acc@1   0.68 (  0.68)	Acc@5   0.00 (  0.00)
 * Acc@1 0.679 Acc@5 0.000
Test: [0/1]	Time  0.325 ( 0.325)	Loss 1.5156e-01 (1.5156e-01)	Acc@1   0.74 (  0.74)	Acc@5   0.00 (  0.00)
 * Acc@1 0.745 Acc@5 0.000
98
TRAINING
Epoch: [98][0/1]	Time  1.011 ( 1.011)	Data  0.315 ( 0.315)	Loss 7.7629e-02 (7.7629e-02)	Acc@1   0.93 (  0.93)	Acc@5   0.00 (  0.00)
[0.9332645001334576]
Test: [0/1]	Time  0.267 ( 0.267)	Loss 9.4389e-01 (9.4389e-01)	Acc@1   0.68 (  0.68)	Acc@5   0.00 (  0.00)
 * Acc@1 0.679 Acc@5 0.000
Test: [0/1]	Time  0.316 ( 0.316)	Loss 1.5155e-01 (1.5155e-01)	Acc@1   0.74 (  0.74)	Acc@5   0.00 (  0.00)
 * Acc@1 0.745 Acc@5 0.000
99
TRAINING
Epoch: [99][0/1]	Time  1.023 ( 1.023)	Data  0.305 ( 0.305)	Loss 7.7612e-02 (7.7612e-02)	Acc@1   0.93 (  0.93)	Acc@5   0.00 (  0.00)
[0.9332894412569812]
Test: [0/1]	Time  0.258 ( 0.258)	Loss 9.4381e-01 (9.4381e-01)	Acc@1   0.68 (  0.68)	Acc@5   0.00 (  0.00)
 * Acc@1 0.679 Acc@5 0.000
Test: [0/1]	Time  0.307 ( 0.307)	Loss 1.5154e-01 (1.5154e-01)	Acc@1   0.75 (  0.75)	Acc@5   0.00 (  0.00)
 * Acc@1 0.745 Acc@5 0.000
=> using pre-trained model 'st_resnet'
s/ohp/session_1
torch.Size([640, 3, 224, 224])
(640, 22)
attach reg
0
TRAINING
/home/helenr6/Adv_mapper/train_split.py:125: UserWarning: You have chosen to seed training. This will turn on the CUDNN deterministic setting, which can slow down your training considerably! You may see unexpected behavior when restarting from checkpoints.
  warnings.warn('You have chosen to seed training. '
/localscratch/helenr6.6279052.0/env/lib/python3.7/site-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  cpuset_checked))
Epoch: [0][0/1]	Time  5.012 ( 5.012)	Data  1.616 ( 1.616)	Loss 1.6636e+00 (1.6636e+00)	Acc@1   0.03 (  0.03)	Acc@5   0.00 (  0.00)
[0.029473555662344643]
Test: [0/1]	Time  0.433 ( 0.433)	Loss 1.1932e+00 (1.1932e+00)	Acc@1   0.02 (  0.02)	Acc@5   0.00 (  0.00)
 * Acc@1 0.021 Acc@5 0.000
Test: [0/1]	Time  0.549 ( 0.549)	Loss 9.8901e-01 (9.8901e-01)	Acc@1  -0.01 ( -0.01)	Acc@5   0.00 (  0.00)
 * Acc@1 -0.007 Acc@5 0.000
1
TRAINING
Epoch: [1][0/1]	Time  0.994 ( 0.994)	Data  0.296 ( 0.296)	Loss 1.5935e+00 (1.5935e+00)	Acc@1   0.03 (  0.03)	Acc@5   0.00 (  0.00)
[0.032125161190007995]
Test: [0/1]	Time  0.259 ( 0.259)	Loss 1.1839e+00 (1.1839e+00)	Acc@1   0.03 (  0.03)	Acc@5   0.00 (  0.00)
 * Acc@1 0.027 Acc@5 0.000
Test: [0/1]	Time  0.317 ( 0.317)	Loss 9.3883e-01 (9.3883e-01)	Acc@1   0.00 (  0.00)	Acc@5   0.00 (  0.00)
 * Acc@1 0.004 Acc@5 0.000
2
TRAINING
Epoch: [2][0/1]	Time  0.976 ( 0.976)	Data  0.264 ( 0.264)	Loss 1.4860e+00 (1.4860e+00)	Acc@1   0.04 (  0.04)	Acc@5   0.00 (  0.00)
[0.03720554943602013]
Test: [0/1]	Time  0.248 ( 0.248)	Loss 1.1720e+00 (1.1720e+00)	Acc@1   0.03 (  0.03)	Acc@5   0.00 (  0.00)
 * Acc@1 0.026 Acc@5 0.000
Test: [0/1]	Time  0.304 ( 0.304)	Loss 8.9197e-01 (8.9197e-01)	Acc@1   0.01 (  0.01)	Acc@5   0.00 (  0.00)
 * Acc@1 0.009 Acc@5 0.000
3
TRAINING
Epoch: [3][0/1]	Time  0.988 ( 0.988)	Data  0.263 ( 0.263)	Loss 1.3780e+00 (1.3780e+00)	Acc@1   0.04 (  0.04)	Acc@5   0.00 (  0.00)
[0.044542881154659944]
Test: [0/1]	Time  0.260 ( 0.260)	Loss 1.1603e+00 (1.1603e+00)	Acc@1   0.03 (  0.03)	Acc@5   0.00 (  0.00)
 * Acc@1 0.032 Acc@5 0.000
Test: [0/1]	Time  0.301 ( 0.301)	Loss 8.6097e-01 (8.6097e-01)	Acc@1   0.02 (  0.02)	Acc@5   0.00 (  0.00)
 * Acc@1 0.016 Acc@5 0.000
4
TRAINING
Epoch: [4][0/1]	Time  0.970 ( 0.970)	Data  0.266 ( 0.266)	Loss 1.2906e+00 (1.2906e+00)	Acc@1   0.05 (  0.05)	Acc@5   0.00 (  0.00)
[0.054004934848571065]
Test: [0/1]	Time  0.245 ( 0.245)	Loss 1.1499e+00 (1.1499e+00)	Acc@1   0.04 (  0.04)	Acc@5   0.00 (  0.00)
 * Acc@1 0.042 Acc@5 0.000
Test: [0/1]	Time  0.303 ( 0.303)	Loss 8.4408e-01 (8.4408e-01)	Acc@1   0.03 (  0.03)	Acc@5   0.00 (  0.00)
 * Acc@1 0.028 Acc@5 0.000
5
TRAINING
Epoch: [5][0/1]	Time  0.973 ( 0.973)	Data  0.279 ( 0.279)	Loss 1.2222e+00 (1.2222e+00)	Acc@1   0.07 (  0.07)	Acc@5   0.00 (  0.00)
[0.06855259156696146]
Test: [0/1]	Time  0.249 ( 0.249)	Loss 1.1398e+00 (1.1398e+00)	Acc@1   0.07 (  0.07)	Acc@5   0.00 (  0.00)
 * Acc@1 0.071 Acc@5 0.000
Test: [0/1]	Time  0.299 ( 0.299)	Loss 8.2899e-01 (8.2899e-01)	Acc@1   0.04 (  0.04)	Acc@5   0.00 (  0.00)
 * Acc@1 0.042 Acc@5 0.000
6
TRAINING
Epoch: [6][0/1]	Time  1.001 ( 1.001)	Data  0.279 ( 0.279)	Loss 1.1565e+00 (1.1565e+00)	Acc@1   0.08 (  0.08)	Acc@5   0.00 (  0.00)
[0.08012293656486827]
Test: [0/1]	Time  0.253 ( 0.253)	Loss 1.1288e+00 (1.1288e+00)	Acc@1   0.11 (  0.11)	Acc@5   0.00 (  0.00)
 * Acc@1 0.114 Acc@5 0.000
Test: [0/1]	Time  0.314 ( 0.314)	Loss 8.0219e-01 (8.0219e-01)	Acc@1   0.05 (  0.05)	Acc@5   0.00 (  0.00)
 * Acc@1 0.052 Acc@5 0.000
7
TRAINING
Epoch: [7][0/1]	Time  0.993 ( 0.993)	Data  0.278 ( 0.278)	Loss 1.0764e+00 (1.0764e+00)	Acc@1   0.09 (  0.09)	Acc@5   0.00 (  0.00)
[0.09440458443330398]
Test: [0/1]	Time  0.251 ( 0.251)	Loss 1.1162e+00 (1.1162e+00)	Acc@1   0.14 (  0.14)	Acc@5   0.00 (  0.00)
 * Acc@1 0.141 Acc@5 0.000
Test: [0/1]	Time  0.298 ( 0.298)	Loss 7.5789e-01 (7.5789e-01)	Acc@1   0.06 (  0.06)	Acc@5   0.00 (  0.00)
 * Acc@1 0.063 Acc@5 0.000
8
TRAINING
Epoch: [8][0/1]	Time  0.982 ( 0.982)	Data  0.270 ( 0.270)	Loss 9.7593e-01 (9.7593e-01)	Acc@1   0.11 (  0.11)	Acc@5   0.00 (  0.00)
[0.11183413313428013]
Test: [0/1]	Time  0.255 ( 0.255)	Loss 1.1026e+00 (1.1026e+00)	Acc@1   0.18 (  0.18)	Acc@5   0.00 (  0.00)
 * Acc@1 0.184 Acc@5 0.000
Test: [0/1]	Time  0.303 ( 0.303)	Loss 7.0086e-01 (7.0086e-01)	Acc@1   0.08 (  0.08)	Acc@5   0.00 (  0.00)
 * Acc@1 0.075 Acc@5 0.000
9
TRAINING
Epoch: [9][0/1]	Time  1.004 ( 1.004)	Data  0.284 ( 0.284)	Loss 8.6283e-01 (8.6283e-01)	Acc@1   0.13 (  0.13)	Acc@5   0.00 (  0.00)
[0.13130855133927727]
Test: [0/1]	Time  0.256 ( 0.256)	Loss 1.0895e+00 (1.0895e+00)	Acc@1   0.23 (  0.23)	Acc@5   0.00 (  0.00)
 * Acc@1 0.230 Acc@5 0.000
Test: [0/1]	Time  0.312 ( 0.312)	Loss 6.4256e-01 (6.4256e-01)	Acc@1   0.09 (  0.09)	Acc@5   0.00 (  0.00)
 * Acc@1 0.089 Acc@5 0.000
10
TRAINING
Epoch: [10][0/1]	Time  0.981 ( 0.981)	Data  0.258 ( 0.258)	Loss 7.5264e-01 (7.5264e-01)	Acc@1   0.15 (  0.15)	Acc@5   0.00 (  0.00)
[0.15094781050121797]
Test: [0/1]	Time  0.243 ( 0.243)	Loss 1.0782e+00 (1.0782e+00)	Acc@1   0.27 (  0.27)	Acc@5   0.00 (  0.00)
 * Acc@1 0.269 Acc@5 0.000
Test: [0/1]	Time  0.298 ( 0.298)	Loss 5.9384e-01 (5.9384e-01)	Acc@1   0.10 (  0.10)	Acc@5   0.00 (  0.00)
 * Acc@1 0.104 Acc@5 0.000
11
TRAINING
Epoch: [11][0/1]	Time  0.964 ( 0.964)	Data  0.253 ( 0.253)	Loss 6.5897e-01 (6.5897e-01)	Acc@1   0.17 (  0.17)	Acc@5   0.00 (  0.00)
[0.17223801137464317]
Test: [0/1]	Time  0.242 ( 0.242)	Loss 1.0689e+00 (1.0689e+00)	Acc@1   0.30 (  0.30)	Acc@5   0.00 (  0.00)
 * Acc@1 0.304 Acc@5 0.000
Test: [0/1]	Time  0.303 ( 0.303)	Loss 5.5884e-01 (5.5884e-01)	Acc@1   0.12 (  0.12)	Acc@5   0.00 (  0.00)
 * Acc@1 0.119 Acc@5 0.000
12
TRAINING
Epoch: [12][0/1]	Time  1.008 ( 1.008)	Data  0.316 ( 0.316)	Loss 5.8647e-01 (5.8647e-01)	Acc@1   0.21 (  0.21)	Acc@5   0.00 (  0.00)
[0.20926901694213285]
Test: [0/1]	Time  0.248 ( 0.248)	Loss 1.0612e+00 (1.0612e+00)	Acc@1   0.34 (  0.34)	Acc@5   0.00 (  0.00)
 * Acc@1 0.339 Acc@5 0.000
Test: [0/1]	Time  0.302 ( 0.302)	Loss 5.3373e-01 (5.3373e-01)	Acc@1   0.13 (  0.13)	Acc@5   0.00 (  0.00)
 * Acc@1 0.135 Acc@5 0.000
13
TRAINING
Epoch: [13][0/1]	Time  1.105 ( 1.105)	Data  0.368 ( 0.368)	Loss 5.3013e-01 (5.3013e-01)	Acc@1   0.25 (  0.25)	Acc@5   0.00 (  0.00)
[0.253411481253179]
Test: [0/1]	Time  0.268 ( 0.268)	Loss 1.0537e+00 (1.0537e+00)	Acc@1   0.38 (  0.38)	Acc@5   0.00 (  0.00)
 * Acc@1 0.382 Acc@5 0.000
Test: [0/1]	Time  0.328 ( 0.328)	Loss 5.1026e-01 (5.1026e-01)	Acc@1   0.16 (  0.16)	Acc@5   0.00 (  0.00)
 * Acc@1 0.159 Acc@5 0.000
14
TRAINING
Epoch: [14][0/1]	Time  1.046 ( 1.046)	Data  0.341 ( 0.341)	Loss 4.8009e-01 (4.8009e-01)	Acc@1   0.28 (  0.28)	Acc@5   0.00 (  0.00)
[0.284659039394226]
Test: [0/1]	Time  0.259 ( 0.259)	Loss 1.0456e+00 (1.0456e+00)	Acc@1   0.41 (  0.41)	Acc@5   0.00 (  0.00)
 * Acc@1 0.409 Acc@5 0.000
Test: [0/1]	Time  0.307 ( 0.307)	Loss 4.8123e-01 (4.8123e-01)	Acc@1   0.18 (  0.18)	Acc@5   0.00 (  0.00)
 * Acc@1 0.184 Acc@5 0.000
15
TRAINING
Epoch: [15][0/1]	Time  1.014 ( 1.014)	Data  0.305 ( 0.305)	Loss 4.2821e-01 (4.2821e-01)	Acc@1   0.33 (  0.33)	Acc@5   0.00 (  0.00)
[0.3289995667230733]
Test: [0/1]	Time  0.281 ( 0.281)	Loss 1.0367e+00 (1.0367e+00)	Acc@1   0.44 (  0.44)	Acc@5   0.00 (  0.00)
 * Acc@1 0.443 Acc@5 0.000
Test: [0/1]	Time  0.323 ( 0.323)	Loss 4.4457e-01 (4.4457e-01)	Acc@1   0.21 (  0.21)	Acc@5   0.00 (  0.00)
 * Acc@1 0.209 Acc@5 0.000
16
TRAINING
Epoch: [16][0/1]	Time  1.059 ( 1.059)	Data  0.329 ( 0.329)	Loss 3.7241e-01 (3.7241e-01)	Acc@1   0.37 (  0.37)	Acc@5   0.00 (  0.00)
[0.3712744159603406]
Test: [0/1]	Time  0.267 ( 0.267)	Loss 1.0276e+00 (1.0276e+00)	Acc@1   0.48 (  0.48)	Acc@5   0.00 (  0.00)
 * Acc@1 0.476 Acc@5 0.000
Test: [0/1]	Time  0.334 ( 0.334)	Loss 4.0372e-01 (4.0372e-01)	Acc@1   0.23 (  0.23)	Acc@5   0.00 (  0.00)
 * Acc@1 0.229 Acc@5 0.000
17
TRAINING
Epoch: [17][0/1]	Time  1.024 ( 1.024)	Data  0.293 ( 0.293)	Loss 3.1658e-01 (3.1658e-01)	Acc@1   0.41 (  0.41)	Acc@5   0.00 (  0.00)
[0.41323724458917244]
Test: [0/1]	Time  0.284 ( 0.284)	Loss 1.0193e+00 (1.0193e+00)	Acc@1   0.51 (  0.51)	Acc@5   0.00 (  0.00)
 * Acc@1 0.507 Acc@5 0.000
Test: [0/1]	Time  0.347 ( 0.347)	Loss 3.6487e-01 (3.6487e-01)	Acc@1   0.24 (  0.24)	Acc@5   0.00 (  0.00)
 * Acc@1 0.245 Acc@5 0.000
18
TRAINING
Epoch: [18][0/1]	Time  1.022 ( 1.022)	Data  0.312 ( 0.312)	Loss 2.6711e-01 (2.6711e-01)	Acc@1   0.46 (  0.46)	Acc@5   0.00 (  0.00)
[0.46143954059159387]
Test: [0/1]	Time  0.272 ( 0.272)	Loss 1.0125e+00 (1.0125e+00)	Acc@1   0.54 (  0.54)	Acc@5   0.00 (  0.00)
 * Acc@1 0.535 Acc@5 0.000
Test: [0/1]	Time  0.322 ( 0.322)	Loss 3.3294e-01 (3.3294e-01)	Acc@1   0.27 (  0.27)	Acc@5   0.00 (  0.00)
 * Acc@1 0.268 Acc@5 0.000
19
TRAINING
Epoch: [19][0/1]	Time  1.022 ( 1.022)	Data  0.293 ( 0.293)	Loss 2.2858e-01 (2.2858e-01)	Acc@1   0.51 (  0.51)	Acc@5   0.00 (  0.00)
[0.5061863999745814]
Test: [0/1]	Time  0.252 ( 0.252)	Loss 1.0072e+00 (1.0072e+00)	Acc@1   0.56 (  0.56)	Acc@5   0.00 (  0.00)
 * Acc@1 0.561 Acc@5 0.000
Test: [0/1]	Time  0.304 ( 0.304)	Loss 3.0914e-01 (3.0914e-01)	Acc@1   0.29 (  0.29)	Acc@5   0.00 (  0.00)
 * Acc@1 0.291 Acc@5 0.000
20
TRAINING
Epoch: [20][0/1]	Time  0.968 ( 0.968)	Data  0.261 ( 0.261)	Loss 2.0134e-01 (2.0134e-01)	Acc@1   0.55 (  0.55)	Acc@5   0.00 (  0.00)
[0.5538046291279244]
Test: [0/1]	Time  0.270 ( 0.270)	Loss 1.0031e+00 (1.0031e+00)	Acc@1   0.58 (  0.58)	Acc@5   0.00 (  0.00)
 * Acc@1 0.578 Acc@5 0.000
Test: [0/1]	Time  0.319 ( 0.319)	Loss 2.9105e-01 (2.9105e-01)	Acc@1   0.31 (  0.31)	Acc@5   0.00 (  0.00)
 * Acc@1 0.314 Acc@5 0.000
21
TRAINING
Epoch: [21][0/1]	Time  0.998 ( 0.998)	Data  0.276 ( 0.276)	Loss 1.8192e-01 (1.8192e-01)	Acc@1   0.60 (  0.60)	Acc@5   0.00 (  0.00)
[0.6018795160000117]
Test: [0/1]	Time  0.265 ( 0.265)	Loss 9.9953e-01 (9.9953e-01)	Acc@1   0.59 (  0.59)	Acc@5   0.00 (  0.00)
 * Acc@1 0.586 Acc@5 0.000
Test: [0/1]	Time  0.321 ( 0.321)	Loss 2.7483e-01 (2.7483e-01)	Acc@1   0.34 (  0.34)	Acc@5   0.00 (  0.00)
 * Acc@1 0.341 Acc@5 0.000
22
TRAINING
Epoch: [22][0/1]	Time  1.024 ( 1.024)	Data  0.306 ( 0.306)	Loss 1.6554e-01 (1.6554e-01)	Acc@1   0.65 (  0.65)	Acc@5   0.00 (  0.00)
[0.6468093600894598]
Test: [0/1]	Time  0.263 ( 0.263)	Loss 9.9594e-01 (9.9594e-01)	Acc@1   0.59 (  0.59)	Acc@5   0.00 (  0.00)
 * Acc@1 0.592 Acc@5 0.000
Test: [0/1]	Time  0.319 ( 0.319)	Loss 2.5775e-01 (2.5775e-01)	Acc@1   0.37 (  0.37)	Acc@5   0.00 (  0.00)
 * Acc@1 0.372 Acc@5 0.000
23
TRAINING
Epoch: [23][0/1]	Time  1.039 ( 1.039)	Data  0.313 ( 0.313)	Loss 1.4892e-01 (1.4892e-01)	Acc@1   0.69 (  0.69)	Acc@5   0.00 (  0.00)
[0.6855011976003749]
Test: [0/1]	Time  0.263 ( 0.263)	Loss 9.9225e-01 (9.9225e-01)	Acc@1   0.60 (  0.60)	Acc@5   0.00 (  0.00)
 * Acc@1 0.596 Acc@5 0.000
Test: [0/1]	Time  0.315 ( 0.315)	Loss 2.3965e-01 (2.3965e-01)	Acc@1   0.40 (  0.40)	Acc@5   0.00 (  0.00)
 * Acc@1 0.402 Acc@5 0.000
24
TRAINING
Epoch: [24][0/1]	Time  0.995 ( 0.995)	Data  0.292 ( 0.292)	Loss 1.3163e-01 (1.3163e-01)	Acc@1   0.72 (  0.72)	Acc@5   0.00 (  0.00)
[0.7208150117810969]
Test: [0/1]	Time  0.259 ( 0.259)	Loss 9.8866e-01 (9.8866e-01)	Acc@1   0.60 (  0.60)	Acc@5   0.00 (  0.00)
 * Acc@1 0.597 Acc@5 0.000
Test: [0/1]	Time  0.312 ( 0.312)	Loss 2.2243e-01 (2.2243e-01)	Acc@1   0.43 (  0.43)	Acc@5   0.00 (  0.00)
 * Acc@1 0.431 Acc@5 0.000
25
TRAINING
Epoch: [25][0/1]	Time  1.009 ( 1.009)	Data  0.306 ( 0.306)	Loss 1.1553e-01 (1.1553e-01)	Acc@1   0.75 (  0.75)	Acc@5   0.00 (  0.00)
[0.7515987932361461]
Test: [0/1]	Time  0.264 ( 0.264)	Loss 9.8546e-01 (9.8546e-01)	Acc@1   0.60 (  0.60)	Acc@5   0.00 (  0.00)
 * Acc@1 0.597 Acc@5 0.000
Test: [0/1]	Time  0.324 ( 0.324)	Loss 2.0846e-01 (2.0846e-01)	Acc@1   0.45 (  0.45)	Acc@5   0.00 (  0.00)
 * Acc@1 0.455 Acc@5 0.000
26
TRAINING
Epoch: [26][0/1]	Time  1.024 ( 1.024)	Data  0.327 ( 0.327)	Loss 1.0306e-01 (1.0306e-01)	Acc@1   0.78 (  0.78)	Acc@5   0.00 (  0.00)
[0.7806239005438409]
Test: [0/1]	Time  0.270 ( 0.270)	Loss 9.8274e-01 (9.8274e-01)	Acc@1   0.60 (  0.60)	Acc@5   0.00 (  0.00)
 * Acc@1 0.595 Acc@5 0.000
Test: [0/1]	Time  0.335 ( 0.335)	Loss 1.9892e-01 (1.9892e-01)	Acc@1   0.48 (  0.48)	Acc@5   0.00 (  0.00)
 * Acc@1 0.475 Acc@5 0.000
27
TRAINING
Epoch: [27][0/1]	Time  0.959 ( 0.959)	Data  0.263 ( 0.263)	Loss 9.5440e-02 (9.5440e-02)	Acc@1   0.81 (  0.81)	Acc@5   0.00 (  0.00)
[0.8055699449497049]
Test: [0/1]	Time  0.277 ( 0.277)	Loss 9.8042e-01 (9.8042e-01)	Acc@1   0.59 (  0.59)	Acc@5   0.00 (  0.00)
 * Acc@1 0.593 Acc@5 0.000
Test: [0/1]	Time  0.322 ( 0.322)	Loss 1.9305e-01 (1.9305e-01)	Acc@1   0.49 (  0.49)	Acc@5   0.00 (  0.00)
 * Acc@1 0.494 Acc@5 0.000
28
TRAINING
Epoch: [28][0/1]	Time  0.978 ( 0.978)	Data  0.275 ( 0.275)	Loss 9.1997e-02 (9.1997e-02)	Acc@1   0.83 (  0.83)	Acc@5   0.00 (  0.00)
[0.8262404758938999]
Test: [0/1]	Time  0.263 ( 0.263)	Loss 9.7820e-01 (9.7820e-01)	Acc@1   0.60 (  0.60)	Acc@5   0.00 (  0.00)
 * Acc@1 0.602 Acc@5 0.000
Test: [0/1]	Time  0.320 ( 0.320)	Loss 1.8877e-01 (1.8877e-01)	Acc@1   0.51 (  0.51)	Acc@5   0.00 (  0.00)
 * Acc@1 0.512 Acc@5 0.000
29
TRAINING
Epoch: [29][0/1]	Time  1.026 ( 1.026)	Data  0.311 ( 0.311)	Loss 9.0709e-02 (9.0709e-02)	Acc@1   0.84 (  0.84)	Acc@5   0.00 (  0.00)
[0.8449420273952915]
Test: [0/1]	Time  0.273 ( 0.273)	Loss 9.7578e-01 (9.7578e-01)	Acc@1   0.62 (  0.62)	Acc@5   0.00 (  0.00)
 * Acc@1 0.620 Acc@5 0.000
Test: [0/1]	Time  0.317 ( 0.317)	Loss 1.8391e-01 (1.8391e-01)	Acc@1   0.53 (  0.53)	Acc@5   0.00 (  0.00)
 * Acc@1 0.532 Acc@5 0.000
30
TRAINING
Epoch: [30][0/1]	Time  0.991 ( 0.991)	Data  0.266 ( 0.266)	Loss 8.9449e-02 (8.9449e-02)	Acc@1   0.86 (  0.86)	Acc@5   0.00 (  0.00)
[0.8570426359701131]
Test: [0/1]	Time  0.251 ( 0.251)	Loss 9.7302e-01 (9.7302e-01)	Acc@1   0.63 (  0.63)	Acc@5   0.00 (  0.00)
 * Acc@1 0.633 Acc@5 0.000
Test: [0/1]	Time  0.306 ( 0.306)	Loss 1.7739e-01 (1.7739e-01)	Acc@1   0.56 (  0.56)	Acc@5   0.00 (  0.00)
 * Acc@1 0.556 Acc@5 0.000
31
TRAINING
Epoch: [31][0/1]	Time  0.978 ( 0.978)	Data  0.257 ( 0.257)	Loss 8.7083e-02 (8.7083e-02)	Acc@1   0.87 (  0.87)	Acc@5   0.00 (  0.00)
[0.8659630555475086]
Test: [0/1]	Time  0.245 ( 0.245)	Loss 9.6999e-01 (9.6999e-01)	Acc@1   0.64 (  0.64)	Acc@5   0.00 (  0.00)
 * Acc@1 0.640 Acc@5 0.000
Test: [0/1]	Time  0.291 ( 0.291)	Loss 1.6955e-01 (1.6955e-01)	Acc@1   0.58 (  0.58)	Acc@5   0.00 (  0.00)
 * Acc@1 0.578 Acc@5 0.000
32
TRAINING
Epoch: [32][0/1]	Time  0.972 ( 0.972)	Data  0.263 ( 0.263)	Loss 8.3817e-02 (8.3817e-02)	Acc@1   0.87 (  0.87)	Acc@5   0.00 (  0.00)
[0.8736806808062598]
Test: [0/1]	Time  0.255 ( 0.255)	Loss 9.6690e-01 (9.6690e-01)	Acc@1   0.64 (  0.64)	Acc@5   0.00 (  0.00)
 * Acc@1 0.644 Acc@5 0.000
Test: [0/1]	Time  0.309 ( 0.309)	Loss 1.6169e-01 (1.6169e-01)	Acc@1   0.60 (  0.60)	Acc@5   0.00 (  0.00)
 * Acc@1 0.599 Acc@5 0.000
33
TRAINING
Epoch: [33][0/1]	Time  0.969 ( 0.969)	Data  0.270 ( 0.270)	Loss 8.0733e-02 (8.0733e-02)	Acc@1   0.88 (  0.88)	Acc@5   0.00 (  0.00)
[0.8775214630100518]
Test: [0/1]	Time  0.247 ( 0.247)	Loss 9.6396e-01 (9.6396e-01)	Acc@1   0.65 (  0.65)	Acc@5   0.00 (  0.00)
 * Acc@1 0.647 Acc@5 0.000
Test: [0/1]	Time  0.306 ( 0.306)	Loss 1.5518e-01 (1.5518e-01)	Acc@1   0.62 (  0.62)	Acc@5   0.00 (  0.00)
 * Acc@1 0.619 Acc@5 0.000
34
TRAINING
Epoch: [34][0/1]	Time  0.988 ( 0.988)	Data  0.274 ( 0.274)	Loss 7.8928e-02 (7.8928e-02)	Acc@1   0.88 (  0.88)	Acc@5   0.00 (  0.00)
[0.8803795288086039]
Test: [0/1]	Time  0.246 ( 0.246)	Loss 9.6128e-01 (9.6128e-01)	Acc@1   0.65 (  0.65)	Acc@5   0.00 (  0.00)
 * Acc@1 0.649 Acc@5 0.000
Test: [0/1]	Time  0.301 ( 0.301)	Loss 1.5070e-01 (1.5070e-01)	Acc@1   0.64 (  0.64)	Acc@5   0.00 (  0.00)
 * Acc@1 0.637 Acc@5 0.000
35
TRAINING
Epoch: [35][0/1]	Time  0.975 ( 0.975)	Data  0.266 ( 0.266)	Loss 7.8818e-02 (7.8818e-02)	Acc@1   0.88 (  0.88)	Acc@5   0.00 (  0.00)
[0.8818653347013536]
Test: [0/1]	Time  0.247 ( 0.247)	Loss 9.5889e-01 (9.5889e-01)	Acc@1   0.65 (  0.65)	Acc@5   0.00 (  0.00)
 * Acc@1 0.650 Acc@5 0.000
Test: [0/1]	Time  0.307 ( 0.307)	Loss 1.4807e-01 (1.4807e-01)	Acc@1   0.65 (  0.65)	Acc@5   0.00 (  0.00)
 * Acc@1 0.648 Acc@5 0.000
36
TRAINING
Epoch: [36][0/1]	Time  0.978 ( 0.978)	Data  0.268 ( 0.268)	Loss 7.9983e-02 (7.9983e-02)	Acc@1   0.88 (  0.88)	Acc@5   0.00 (  0.00)
[0.8828108568283471]
Test: [0/1]	Time  0.239 ( 0.239)	Loss 9.5671e-01 (9.5671e-01)	Acc@1   0.65 (  0.65)	Acc@5   0.00 (  0.00)
 * Acc@1 0.652 Acc@5 0.000
Test: [0/1]	Time  0.289 ( 0.289)	Loss 1.4650e-01 (1.4650e-01)	Acc@1   0.66 (  0.66)	Acc@5   0.00 (  0.00)
 * Acc@1 0.661 Acc@5 0.000
37
TRAINING
Epoch: [37][0/1]	Time  0.988 ( 0.988)	Data  0.260 ( 0.260)	Loss 8.1520e-02 (8.1520e-02)	Acc@1   0.88 (  0.88)	Acc@5   0.00 (  0.00)
[0.8828992815832752]
Test: [0/1]	Time  0.262 ( 0.262)	Loss 9.5467e-01 (9.5467e-01)	Acc@1   0.65 (  0.65)	Acc@5   0.00 (  0.00)
 * Acc@1 0.655 Acc@5 0.000
Test: [0/1]	Time  0.311 ( 0.311)	Loss 1.4525e-01 (1.4525e-01)	Acc@1   0.67 (  0.67)	Acc@5   0.00 (  0.00)
 * Acc@1 0.671 Acc@5 0.000
38
TRAINING
Epoch: [38][0/1]	Time  0.970 ( 0.970)	Data  0.276 ( 0.276)	Loss 8.2617e-02 (8.2617e-02)	Acc@1   0.88 (  0.88)	Acc@5   0.00 (  0.00)
[0.8823126306255444]
Test: [0/1]	Time  0.255 ( 0.255)	Loss 9.5274e-01 (9.5274e-01)	Acc@1   0.66 (  0.66)	Acc@5   0.00 (  0.00)
 * Acc@1 0.658 Acc@5 0.000
Test: [0/1]	Time  0.305 ( 0.305)	Loss 1.4397e-01 (1.4397e-01)	Acc@1   0.68 (  0.68)	Acc@5   0.00 (  0.00)
 * Acc@1 0.678 Acc@5 0.000
39
TRAINING
Epoch: [39][0/1]	Time  0.988 ( 0.988)	Data  0.270 ( 0.270)	Loss 8.2961e-02 (8.2961e-02)	Acc@1   0.88 (  0.88)	Acc@5   0.00 (  0.00)
[0.8813554734669697]
Test: [0/1]	Time  0.256 ( 0.256)	Loss 9.5096e-01 (9.5096e-01)	Acc@1   0.66 (  0.66)	Acc@5   0.00 (  0.00)
 * Acc@1 0.662 Acc@5 0.000
Test: [0/1]	Time  0.322 ( 0.322)	Loss 1.4281e-01 (1.4281e-01)	Acc@1   0.68 (  0.68)	Acc@5   0.00 (  0.00)
 * Acc@1 0.684 Acc@5 0.000
40
TRAINING
Epoch: [40][0/1]	Time  1.000 ( 1.000)	Data  0.285 ( 0.285)	Loss 8.2785e-02 (8.2785e-02)	Acc@1   0.88 (  0.88)	Acc@5   0.00 (  0.00)
[0.8803171813509948]
Test: [0/1]	Time  0.259 ( 0.259)	Loss 9.4938e-01 (9.4938e-01)	Acc@1   0.67 (  0.67)	Acc@5   0.00 (  0.00)
 * Acc@1 0.666 Acc@5 0.000
Test: [0/1]	Time  0.314 ( 0.314)	Loss 1.4212e-01 (1.4212e-01)	Acc@1   0.69 (  0.69)	Acc@5   0.00 (  0.00)
 * Acc@1 0.688 Acc@5 0.000
41
TRAINING
Epoch: [41][0/1]	Time  0.982 ( 0.982)	Data  0.262 ( 0.262)	Loss 8.2597e-02 (8.2597e-02)	Acc@1   0.88 (  0.88)	Acc@5   0.00 (  0.00)
[0.8794614535151075]
Test: [0/1]	Time  0.246 ( 0.246)	Loss 9.4800e-01 (9.4800e-01)	Acc@1   0.67 (  0.67)	Acc@5   0.00 (  0.00)
 * Acc@1 0.669 Acc@5 0.000
Test: [0/1]	Time  0.304 ( 0.304)	Loss 1.4216e-01 (1.4216e-01)	Acc@1   0.69 (  0.69)	Acc@5   0.00 (  0.00)
 * Acc@1 0.693 Acc@5 0.000
42
TRAINING
Epoch: [42][0/1]	Time  0.965 ( 0.965)	Data  0.261 ( 0.261)	Loss 8.2800e-02 (8.2800e-02)	Acc@1   0.88 (  0.88)	Acc@5   0.00 (  0.00)
[0.8790192447187728]
Test: [0/1]	Time  0.246 ( 0.246)	Loss 9.4682e-01 (9.4682e-01)	Acc@1   0.67 (  0.67)	Acc@5   0.00 (  0.00)
 * Acc@1 0.673 Acc@5 0.000
Test: [0/1]	Time  0.299 ( 0.299)	Loss 1.4282e-01 (1.4282e-01)	Acc@1   0.70 (  0.70)	Acc@5   0.00 (  0.00)
 * Acc@1 0.698 Acc@5 0.000
43
TRAINING
Epoch: [43][0/1]	Time  0.977 ( 0.977)	Data  0.261 ( 0.261)	Loss 8.3458e-02 (8.3458e-02)	Acc@1   0.88 (  0.88)	Acc@5   0.00 (  0.00)
[0.879178174027992]
Test: [0/1]	Time  0.255 ( 0.255)	Loss 9.4575e-01 (9.4575e-01)	Acc@1   0.68 (  0.68)	Acc@5   0.00 (  0.00)
 * Acc@1 0.676 Acc@5 0.000
Test: [0/1]	Time  0.305 ( 0.305)	Loss 1.4371e-01 (1.4371e-01)	Acc@1   0.70 (  0.70)	Acc@5   0.00 (  0.00)
 * Acc@1 0.700 Acc@5 0.000
44
TRAINING
Epoch: [44][0/1]	Time  0.965 ( 0.965)	Data  0.254 ( 0.254)	Loss 8.4304e-02 (8.4304e-02)	Acc@1   0.88 (  0.88)	Acc@5   0.00 (  0.00)
[0.8811022589734294]
Test: [0/1]	Time  0.243 ( 0.243)	Loss 9.4473e-01 (9.4473e-01)	Acc@1   0.68 (  0.68)	Acc@5   0.00 (  0.00)
 * Acc@1 0.677 Acc@5 0.000
Test: [0/1]	Time  0.298 ( 0.298)	Loss 1.4433e-01 (1.4433e-01)	Acc@1   0.70 (  0.70)	Acc@5   0.00 (  0.00)
 * Acc@1 0.700 Acc@5 0.000
45
TRAINING
Epoch: [45][0/1]	Time  0.967 ( 0.967)	Data  0.251 ( 0.251)	Loss 8.4942e-02 (8.4942e-02)	Acc@1   0.88 (  0.88)	Acc@5   0.00 (  0.00)
[0.8836014050914422]
Test: [0/1]	Time  0.249 ( 0.249)	Loss 9.4372e-01 (9.4372e-01)	Acc@1   0.68 (  0.68)	Acc@5   0.00 (  0.00)
 * Acc@1 0.678 Acc@5 0.000
Test: [0/1]	Time  0.297 ( 0.297)	Loss 1.4438e-01 (1.4438e-01)	Acc@1   0.70 (  0.70)	Acc@5   0.00 (  0.00)
 * Acc@1 0.701 Acc@5 0.000
46
TRAINING
Epoch: [46][0/1]	Time  0.952 ( 0.952)	Data  0.239 ( 0.239)	Loss 8.5102e-02 (8.5102e-02)	Acc@1   0.89 (  0.89)	Acc@5   0.00 (  0.00)
[0.8865593166083598]
Test: [0/1]	Time  0.259 ( 0.259)	Loss 9.4272e-01 (9.4272e-01)	Acc@1   0.68 (  0.68)	Acc@5   0.00 (  0.00)
 * Acc@1 0.678 Acc@5 0.000
Test: [0/1]	Time  0.303 ( 0.303)	Loss 1.4386e-01 (1.4386e-01)	Acc@1   0.70 (  0.70)	Acc@5   0.00 (  0.00)
 * Acc@1 0.700 Acc@5 0.000
47
TRAINING
Epoch: [47][0/1]	Time  0.980 ( 0.980)	Data  0.254 ( 0.254)	Loss 8.4768e-02 (8.4768e-02)	Acc@1   0.89 (  0.89)	Acc@5   0.00 (  0.00)
[0.8898738737501666]
Test: [0/1]	Time  0.237 ( 0.237)	Loss 9.4180e-01 (9.4180e-01)	Acc@1   0.68 (  0.68)	Acc@5   0.00 (  0.00)
 * Acc@1 0.677 Acc@5 0.000
Test: [0/1]	Time  0.291 ( 0.291)	Loss 1.4302e-01 (1.4302e-01)	Acc@1   0.70 (  0.70)	Acc@5   0.00 (  0.00)
 * Acc@1 0.700 Acc@5 0.000
48
TRAINING
Epoch: [48][0/1]	Time  0.941 ( 0.941)	Data  0.260 ( 0.260)	Loss 8.4155e-02 (8.4155e-02)	Acc@1   0.89 (  0.89)	Acc@5   0.00 (  0.00)
[0.8934050084497733]
Test: [0/1]	Time  0.241 ( 0.241)	Loss 9.4098e-01 (9.4098e-01)	Acc@1   0.68 (  0.68)	Acc@5   0.00 (  0.00)
 * Acc@1 0.676 Acc@5 0.000
Test: [0/1]	Time  0.288 ( 0.288)	Loss 1.4219e-01 (1.4219e-01)	Acc@1   0.70 (  0.70)	Acc@5   0.00 (  0.00)
 * Acc@1 0.699 Acc@5 0.000
49
TRAINING
Epoch: [49][0/1]	Time  0.939 ( 0.939)	Data  0.251 ( 0.251)	Loss 8.3549e-02 (8.3549e-02)	Acc@1   0.90 (  0.90)	Acc@5   0.00 (  0.00)
[0.8970065008046388]
Test: [0/1]	Time  0.236 ( 0.236)	Loss 9.4032e-01 (9.4032e-01)	Acc@1   0.67 (  0.67)	Acc@5   0.00 (  0.00)
 * Acc@1 0.674 Acc@5 0.000
Test: [0/1]	Time  0.292 ( 0.292)	Loss 1.4162e-01 (1.4162e-01)	Acc@1   0.70 (  0.70)	Acc@5   0.00 (  0.00)
 * Acc@1 0.697 Acc@5 0.000
50
TRAINING
Epoch: [50][0/1]	Time  0.952 ( 0.952)	Data  0.235 ( 0.235)	Loss 8.3145e-02 (8.3145e-02)	Acc@1   0.90 (  0.90)	Acc@5   0.00 (  0.00)
[0.900558433872171]
Test: [0/1]	Time  0.235 ( 0.235)	Loss 9.3983e-01 (9.3983e-01)	Acc@1   0.67 (  0.67)	Acc@5   0.00 (  0.00)
 * Acc@1 0.672 Acc@5 0.000
Test: [0/1]	Time  0.284 ( 0.284)	Loss 1.4138e-01 (1.4138e-01)	Acc@1   0.70 (  0.70)	Acc@5   0.00 (  0.00)
 * Acc@1 0.695 Acc@5 0.000
51
TRAINING
Epoch: [51][0/1]	Time  0.943 ( 0.943)	Data  0.261 ( 0.261)	Loss 8.2967e-02 (8.2967e-02)	Acc@1   0.90 (  0.90)	Acc@5   0.00 (  0.00)
[0.9039862350918213]
Test: [0/1]	Time  0.237 ( 0.237)	Loss 9.3950e-01 (9.3950e-01)	Acc@1   0.67 (  0.67)	Acc@5   0.00 (  0.00)
 * Acc@1 0.670 Acc@5 0.000
Test: [0/1]	Time  0.285 ( 0.285)	Loss 1.4139e-01 (1.4139e-01)	Acc@1   0.69 (  0.69)	Acc@5   0.00 (  0.00)
 * Acc@1 0.692 Acc@5 0.000
52
TRAINING
Epoch: [52][0/1]	Time  0.928 ( 0.928)	Data  0.247 ( 0.247)	Loss 8.2899e-02 (8.2899e-02)	Acc@1   0.91 (  0.91)	Acc@5   0.00 (  0.00)
[0.906677532756627]
Test: [0/1]	Time  0.235 ( 0.235)	Loss 9.3930e-01 (9.3930e-01)	Acc@1   0.67 (  0.67)	Acc@5   0.00 (  0.00)
 * Acc@1 0.668 Acc@5 0.000
Test: [0/1]	Time  0.288 ( 0.288)	Loss 1.4150e-01 (1.4150e-01)	Acc@1   0.69 (  0.69)	Acc@5   0.00 (  0.00)
 * Acc@1 0.689 Acc@5 0.000
53
TRAINING
Epoch: [53][0/1]	Time  0.926 ( 0.926)	Data  0.244 ( 0.244)	Loss 8.2785e-02 (8.2785e-02)	Acc@1   0.91 (  0.91)	Acc@5   0.00 (  0.00)
[0.9090014983906374]
Test: [0/1]	Time  0.239 ( 0.239)	Loss 9.3922e-01 (9.3922e-01)	Acc@1   0.67 (  0.67)	Acc@5   0.00 (  0.00)
 * Acc@1 0.667 Acc@5 0.000
Test: [0/1]	Time  0.290 ( 0.290)	Loss 1.4160e-01 (1.4160e-01)	Acc@1   0.69 (  0.69)	Acc@5   0.00 (  0.00)
 * Acc@1 0.687 Acc@5 0.000
54
TRAINING
Epoch: [54][0/1]	Time  0.922 ( 0.922)	Data  0.242 ( 0.242)	Loss 8.2535e-02 (8.2535e-02)	Acc@1   0.91 (  0.91)	Acc@5   0.00 (  0.00)
[0.9112067370320494]
Test: [0/1]	Time  0.240 ( 0.240)	Loss 9.3922e-01 (9.3922e-01)	Acc@1   0.67 (  0.67)	Acc@5   0.00 (  0.00)
 * Acc@1 0.668 Acc@5 0.000
Test: [0/1]	Time  0.288 ( 0.288)	Loss 1.4168e-01 (1.4168e-01)	Acc@1   0.68 (  0.68)	Acc@5   0.00 (  0.00)
 * Acc@1 0.685 Acc@5 0.000
55
TRAINING
Epoch: [55][0/1]	Time  0.943 ( 0.943)	Data  0.243 ( 0.243)	Loss 8.2168e-02 (8.2168e-02)	Acc@1   0.91 (  0.91)	Acc@5   0.00 (  0.00)
[0.9132983217505826]
Test: [0/1]	Time  0.241 ( 0.241)	Loss 9.3933e-01 (9.3933e-01)	Acc@1   0.67 (  0.67)	Acc@5   0.00 (  0.00)
 * Acc@1 0.670 Acc@5 0.000
Test: [0/1]	Time  0.284 ( 0.284)	Loss 1.4180e-01 (1.4180e-01)	Acc@1   0.68 (  0.68)	Acc@5   0.00 (  0.00)
 * Acc@1 0.684 Acc@5 0.000
56
TRAINING
Epoch: [56][0/1]	Time  0.923 ( 0.923)	Data  0.241 ( 0.241)	Loss 8.1774e-02 (8.1774e-02)	Acc@1   0.92 (  0.92)	Acc@5   0.00 (  0.00)
[0.9165577442954217]
Test: [0/1]	Time  0.236 ( 0.236)	Loss 9.3952e-01 (9.3952e-01)	Acc@1   0.67 (  0.67)	Acc@5   0.00 (  0.00)
 * Acc@1 0.672 Acc@5 0.000
Test: [0/1]	Time  0.288 ( 0.288)	Loss 1.4198e-01 (1.4198e-01)	Acc@1   0.68 (  0.68)	Acc@5   0.00 (  0.00)
 * Acc@1 0.683 Acc@5 0.000
57
TRAINING
Epoch: [57][0/1]	Time  0.947 ( 0.947)	Data  0.248 ( 0.248)	Loss 8.1454e-02 (8.1454e-02)	Acc@1   0.92 (  0.92)	Acc@5   0.00 (  0.00)
[0.919621137021635]
Test: [0/1]	Time  0.233 ( 0.233)	Loss 9.3978e-01 (9.3978e-01)	Acc@1   0.67 (  0.67)	Acc@5   0.00 (  0.00)
 * Acc@1 0.674 Acc@5 0.000
Test: [0/1]	Time  0.288 ( 0.288)	Loss 1.4224e-01 (1.4224e-01)	Acc@1   0.68 (  0.68)	Acc@5   0.00 (  0.00)
 * Acc@1 0.682 Acc@5 0.000
58
TRAINING
Epoch: [58][0/1]	Time  0.930 ( 0.930)	Data  0.250 ( 0.250)	Loss 8.1251e-02 (8.1251e-02)	Acc@1   0.92 (  0.92)	Acc@5   0.00 (  0.00)
[0.9224013928145103]
Test: [0/1]	Time  0.232 ( 0.232)	Loss 9.4009e-01 (9.4009e-01)	Acc@1   0.68 (  0.68)	Acc@5   0.00 (  0.00)
 * Acc@1 0.676 Acc@5 0.000
Test: [0/1]	Time  0.288 ( 0.288)	Loss 1.4251e-01 (1.4251e-01)	Acc@1   0.68 (  0.68)	Acc@5   0.00 (  0.00)
 * Acc@1 0.681 Acc@5 0.000
59
TRAINING
Epoch: [59][0/1]	Time  0.931 ( 0.931)	Data  0.248 ( 0.248)	Loss 8.1133e-02 (8.1133e-02)	Acc@1   0.92 (  0.92)	Acc@5   0.00 (  0.00)
[0.9240352377910913]
Test: [0/1]	Time  0.242 ( 0.242)	Loss 9.4042e-01 (9.4042e-01)	Acc@1   0.68 (  0.68)	Acc@5   0.00 (  0.00)
 * Acc@1 0.678 Acc@5 0.000
Test: [0/1]	Time  0.285 ( 0.285)	Loss 1.4270e-01 (1.4270e-01)	Acc@1   0.68 (  0.68)	Acc@5   0.00 (  0.00)
 * Acc@1 0.681 Acc@5 0.000
60
TRAINING
Epoch: [60][0/1]	Time  0.942 ( 0.942)	Data  0.238 ( 0.238)	Loss 8.1026e-02 (8.1026e-02)	Acc@1   0.93 (  0.93)	Acc@5   0.00 (  0.00)
[0.9253542193319986]
Test: [0/1]	Time  0.237 ( 0.237)	Loss 9.4076e-01 (9.4076e-01)	Acc@1   0.68 (  0.68)	Acc@5   0.00 (  0.00)
 * Acc@1 0.680 Acc@5 0.000
Test: [0/1]	Time  0.288 ( 0.288)	Loss 1.4272e-01 (1.4272e-01)	Acc@1   0.68 (  0.68)	Acc@5   0.00 (  0.00)
 * Acc@1 0.681 Acc@5 0.000
61
TRAINING
Epoch: [61][0/1]	Time  0.926 ( 0.926)	Data  0.242 ( 0.242)	Loss 8.0860e-02 (8.0860e-02)	Acc@1   0.93 (  0.93)	Acc@5   0.00 (  0.00)
[0.9264245635972119]
Test: [0/1]	Time  0.248 ( 0.248)	Loss 9.4109e-01 (9.4109e-01)	Acc@1   0.68 (  0.68)	Acc@5   0.00 (  0.00)
 * Acc@1 0.682 Acc@5 0.000
Test: [0/1]	Time  0.294 ( 0.294)	Loss 1.4257e-01 (1.4257e-01)	Acc@1   0.68 (  0.68)	Acc@5   0.00 (  0.00)
 * Acc@1 0.681 Acc@5 0.000
62
TRAINING
Epoch: [62][0/1]	Time  0.942 ( 0.942)	Data  0.257 ( 0.257)	Loss 8.0610e-02 (8.0610e-02)	Acc@1   0.93 (  0.93)	Acc@5   0.00 (  0.00)
[0.9279975535716478]
Test: [0/1]	Time  0.238 ( 0.238)	Loss 9.4143e-01 (9.4143e-01)	Acc@1   0.68 (  0.68)	Acc@5   0.00 (  0.00)
 * Acc@1 0.685 Acc@5 0.000
Test: [0/1]	Time  0.288 ( 0.288)	Loss 1.4228e-01 (1.4228e-01)	Acc@1   0.68 (  0.68)	Acc@5   0.00 (  0.00)
 * Acc@1 0.681 Acc@5 0.000
63
TRAINING
Epoch: [63][0/1]	Time  0.948 ( 0.948)	Data  0.245 ( 0.245)	Loss 8.0302e-02 (8.0302e-02)	Acc@1   0.93 (  0.93)	Acc@5   0.00 (  0.00)
[0.9295412612783012]
Test: [0/1]	Time  0.252 ( 0.252)	Loss 9.4176e-01 (9.4176e-01)	Acc@1   0.69 (  0.69)	Acc@5   0.00 (  0.00)
 * Acc@1 0.687 Acc@5 0.000
Test: [0/1]	Time  0.294 ( 0.294)	Loss 1.4192e-01 (1.4192e-01)	Acc@1   0.68 (  0.68)	Acc@5   0.00 (  0.00)
 * Acc@1 0.682 Acc@5 0.000
64
TRAINING
Epoch: [64][0/1]	Time  0.941 ( 0.941)	Data  0.243 ( 0.243)	Loss 7.9993e-02 (7.9993e-02)	Acc@1   0.93 (  0.93)	Acc@5   0.00 (  0.00)
[0.9308601922447431]
Test: [0/1]	Time  0.238 ( 0.238)	Loss 9.4209e-01 (9.4209e-01)	Acc@1   0.69 (  0.69)	Acc@5   0.00 (  0.00)
 * Acc@1 0.689 Acc@5 0.000
Test: [0/1]	Time  0.292 ( 0.292)	Loss 1.4157e-01 (1.4157e-01)	Acc@1   0.68 (  0.68)	Acc@5   0.00 (  0.00)
 * Acc@1 0.683 Acc@5 0.000
65
TRAINING
Epoch: [65][0/1]	Time  0.956 ( 0.956)	Data  0.275 ( 0.275)	Loss 7.9735e-02 (7.9735e-02)	Acc@1   0.93 (  0.93)	Acc@5   0.00 (  0.00)
[0.931765809252723]
Test: [0/1]	Time  0.243 ( 0.243)	Loss 9.4242e-01 (9.4242e-01)	Acc@1   0.69 (  0.69)	Acc@5   0.00 (  0.00)
 * Acc@1 0.691 Acc@5 0.000
Test: [0/1]	Time  0.295 ( 0.295)	Loss 1.4128e-01 (1.4128e-01)	Acc@1   0.68 (  0.68)	Acc@5   0.00 (  0.00)
 * Acc@1 0.683 Acc@5 0.000
66
TRAINING
Epoch: [66][0/1]	Time  0.946 ( 0.946)	Data  0.265 ( 0.265)	Loss 7.9549e-02 (7.9549e-02)	Acc@1   0.93 (  0.93)	Acc@5   0.00 (  0.00)
[0.9321486383100277]
Test: [0/1]	Time  0.250 ( 0.250)	Loss 9.4275e-01 (9.4275e-01)	Acc@1   0.69 (  0.69)	Acc@5   0.00 (  0.00)
 * Acc@1 0.693 Acc@5 0.000
Test: [0/1]	Time  0.292 ( 0.292)	Loss 1.4105e-01 (1.4105e-01)	Acc@1   0.68 (  0.68)	Acc@5   0.00 (  0.00)
 * Acc@1 0.684 Acc@5 0.000
67
TRAINING
Epoch: [67][0/1]	Time  0.950 ( 0.950)	Data  0.264 ( 0.264)	Loss 7.9422e-02 (7.9422e-02)	Acc@1   0.93 (  0.93)	Acc@5   0.00 (  0.00)
[0.932447878958557]
Test: [0/1]	Time  0.239 ( 0.239)	Loss 9.4305e-01 (9.4305e-01)	Acc@1   0.69 (  0.69)	Acc@5   0.00 (  0.00)
 * Acc@1 0.695 Acc@5 0.000
Test: [0/1]	Time  0.295 ( 0.295)	Loss 1.4087e-01 (1.4087e-01)	Acc@1   0.69 (  0.69)	Acc@5   0.00 (  0.00)
 * Acc@1 0.686 Acc@5 0.000
68
TRAINING
Epoch: [68][0/1]	Time  0.942 ( 0.942)	Data  0.259 ( 0.259)	Loss 7.9324e-02 (7.9324e-02)	Acc@1   0.93 (  0.93)	Acc@5   0.00 (  0.00)
[0.9327007134292663]
Test: [0/1]	Time  0.244 ( 0.244)	Loss 9.4333e-01 (9.4333e-01)	Acc@1   0.70 (  0.70)	Acc@5   0.00 (  0.00)
 * Acc@1 0.696 Acc@5 0.000
Test: [0/1]	Time  0.292 ( 0.292)	Loss 1.4072e-01 (1.4072e-01)	Acc@1   0.69 (  0.69)	Acc@5   0.00 (  0.00)
 * Acc@1 0.688 Acc@5 0.000
69
TRAINING
Epoch: [69][0/1]	Time  0.952 ( 0.952)	Data  0.263 ( 0.263)	Loss 7.9231e-02 (7.9231e-02)	Acc@1   0.93 (  0.93)	Acc@5   0.00 (  0.00)
[0.9328910392785119]
Test: [0/1]	Time  0.245 ( 0.245)	Loss 9.4359e-01 (9.4359e-01)	Acc@1   0.70 (  0.70)	Acc@5   0.00 (  0.00)
 * Acc@1 0.698 Acc@5 0.000
Test: [0/1]	Time  0.292 ( 0.292)	Loss 1.4059e-01 (1.4059e-01)	Acc@1   0.69 (  0.69)	Acc@5   0.00 (  0.00)
 * Acc@1 0.689 Acc@5 0.000
70
TRAINING
Epoch: [70][0/1]	Time  0.942 ( 0.942)	Data  0.236 ( 0.236)	Loss 7.9134e-02 (7.9134e-02)	Acc@1   0.93 (  0.93)	Acc@5   0.00 (  0.00)
[0.9330353704100276]
Test: [0/1]	Time  0.233 ( 0.233)	Loss 9.4381e-01 (9.4381e-01)	Acc@1   0.70 (  0.70)	Acc@5   0.00 (  0.00)
 * Acc@1 0.699 Acc@5 0.000
Test: [0/1]	Time  0.287 ( 0.287)	Loss 1.4048e-01 (1.4048e-01)	Acc@1   0.69 (  0.69)	Acc@5   0.00 (  0.00)
 * Acc@1 0.690 Acc@5 0.000
71
TRAINING
Epoch: [71][0/1]	Time  0.927 ( 0.927)	Data  0.246 ( 0.246)	Loss 7.9043e-02 (7.9043e-02)	Acc@1   0.93 (  0.93)	Acc@5   0.00 (  0.00)
[0.9331998497193084]
Test: [0/1]	Time  0.236 ( 0.236)	Loss 9.4400e-01 (9.4400e-01)	Acc@1   0.70 (  0.70)	Acc@5   0.00 (  0.00)
 * Acc@1 0.700 Acc@5 0.000
Test: [0/1]	Time  0.286 ( 0.286)	Loss 1.4040e-01 (1.4040e-01)	Acc@1   0.69 (  0.69)	Acc@5   0.00 (  0.00)
 * Acc@1 0.691 Acc@5 0.000
72
TRAINING
Epoch: [72][0/1]	Time  0.926 ( 0.926)	Data  0.244 ( 0.244)	Loss 7.8974e-02 (7.8974e-02)	Acc@1   0.93 (  0.93)	Acc@5   0.00 (  0.00)
[0.9333672036569469]
Test: [0/1]	Time  0.237 ( 0.237)	Loss 9.4415e-01 (9.4415e-01)	Acc@1   0.70 (  0.70)	Acc@5   0.00 (  0.00)
 * Acc@1 0.701 Acc@5 0.000
Test: [0/1]	Time  0.287 ( 0.287)	Loss 1.4035e-01 (1.4035e-01)	Acc@1   0.69 (  0.69)	Acc@5   0.00 (  0.00)
 * Acc@1 0.692 Acc@5 0.000
73
TRAINING
Epoch: [73][0/1]	Time  0.939 ( 0.939)	Data  0.248 ( 0.248)	Loss 7.8939e-02 (7.8939e-02)	Acc@1   0.93 (  0.93)	Acc@5   0.00 (  0.00)
[0.9335164720167675]
Test: [0/1]	Time  0.237 ( 0.237)	Loss 9.4428e-01 (9.4428e-01)	Acc@1   0.70 (  0.70)	Acc@5   0.00 (  0.00)
 * Acc@1 0.702 Acc@5 0.000
Test: [0/1]	Time  0.287 ( 0.287)	Loss 1.4032e-01 (1.4032e-01)	Acc@1   0.69 (  0.69)	Acc@5   0.00 (  0.00)
 * Acc@1 0.693 Acc@5 0.000
74
TRAINING
Epoch: [74][0/1]	Time  0.954 ( 0.954)	Data  0.274 ( 0.274)	Loss 7.8931e-02 (7.8931e-02)	Acc@1   0.93 (  0.93)	Acc@5   0.00 (  0.00)
[0.9336292045467016]
Test: [0/1]	Time  0.241 ( 0.241)	Loss 9.4437e-01 (9.4437e-01)	Acc@1   0.70 (  0.70)	Acc@5   0.00 (  0.00)
 * Acc@1 0.703 Acc@5 0.000
Test: [0/1]	Time  0.294 ( 0.294)	Loss 1.4028e-01 (1.4028e-01)	Acc@1   0.69 (  0.69)	Acc@5   0.00 (  0.00)
 * Acc@1 0.695 Acc@5 0.000
75
TRAINING
Epoch: [75][0/1]	Time  0.947 ( 0.947)	Data  0.265 ( 0.265)	Loss 7.8935e-02 (7.8935e-02)	Acc@1   0.93 (  0.93)	Acc@5   0.00 (  0.00)
[0.9336933100298557]
Test: [0/1]	Time  0.240 ( 0.240)	Loss 9.4444e-01 (9.4444e-01)	Acc@1   0.70 (  0.70)	Acc@5   0.00 (  0.00)
 * Acc@1 0.703 Acc@5 0.000
Test: [0/1]	Time  0.301 ( 0.301)	Loss 1.4021e-01 (1.4021e-01)	Acc@1   0.70 (  0.70)	Acc@5   0.00 (  0.00)
 * Acc@1 0.696 Acc@5 0.000
76
TRAINING
Epoch: [76][0/1]	Time  0.946 ( 0.946)	Data  0.266 ( 0.266)	Loss 7.8934e-02 (7.8934e-02)	Acc@1   0.93 (  0.93)	Acc@5   0.00 (  0.00)
[0.9337044318721099]
Test: [0/1]	Time  0.243 ( 0.243)	Loss 9.4447e-01 (9.4447e-01)	Acc@1   0.70 (  0.70)	Acc@5   0.00 (  0.00)
 * Acc@1 0.704 Acc@5 0.000
Test: [0/1]	Time  0.294 ( 0.294)	Loss 1.4011e-01 (1.4011e-01)	Acc@1   0.70 (  0.70)	Acc@5   0.00 (  0.00)
 * Acc@1 0.698 Acc@5 0.000
77
TRAINING
Epoch: [77][0/1]	Time  0.946 ( 0.946)	Data  0.263 ( 0.263)	Loss 7.8915e-02 (7.8915e-02)	Acc@1   0.93 (  0.93)	Acc@5   0.00 (  0.00)
[0.9336656079641816]
Test: [0/1]	Time  0.248 ( 0.248)	Loss 9.4448e-01 (9.4448e-01)	Acc@1   0.70 (  0.70)	Acc@5   0.00 (  0.00)
 * Acc@1 0.704 Acc@5 0.000
Test: [0/1]	Time  0.301 ( 0.301)	Loss 1.3997e-01 (1.3997e-01)	Acc@1   0.70 (  0.70)	Acc@5   0.00 (  0.00)
 * Acc@1 0.699 Acc@5 0.000
78
TRAINING
Epoch: [78][0/1]	Time  0.947 ( 0.947)	Data  0.265 ( 0.265)	Loss 7.8879e-02 (7.8879e-02)	Acc@1   0.93 (  0.93)	Acc@5   0.00 (  0.00)
[0.9335861448378929]
Test: [0/1]	Time  0.245 ( 0.245)	Loss 9.4448e-01 (9.4448e-01)	Acc@1   0.70 (  0.70)	Acc@5   0.00 (  0.00)
 * Acc@1 0.705 Acc@5 0.000
Test: [0/1]	Time  0.294 ( 0.294)	Loss 1.3981e-01 (1.3981e-01)	Acc@1   0.70 (  0.70)	Acc@5   0.00 (  0.00)
 * Acc@1 0.701 Acc@5 0.000
79
TRAINING
Epoch: [79][0/1]	Time  0.976 ( 0.976)	Data  0.266 ( 0.266)	Loss 7.8835e-02 (7.8835e-02)	Acc@1   0.93 (  0.93)	Acc@5   0.00 (  0.00)
[0.933480243438745]
Test: [0/1]	Time  0.262 ( 0.262)	Loss 9.4446e-01 (9.4446e-01)	Acc@1   0.71 (  0.71)	Acc@5   0.00 (  0.00)
 * Acc@1 0.705 Acc@5 0.000
Test: [0/1]	Time  0.307 ( 0.307)	Loss 1.3966e-01 (1.3966e-01)	Acc@1   0.70 (  0.70)	Acc@5   0.00 (  0.00)
 * Acc@1 0.702 Acc@5 0.000
80
TRAINING
Epoch: [80][0/1]	Time  0.967 ( 0.967)	Data  0.268 ( 0.268)	Loss 7.8796e-02 (7.8796e-02)	Acc@1   0.93 (  0.93)	Acc@5   0.00 (  0.00)
[0.9333654007719161]
Test: [0/1]	Time  0.275 ( 0.275)	Loss 9.4442e-01 (9.4442e-01)	Acc@1   0.71 (  0.71)	Acc@5   0.00 (  0.00)
 * Acc@1 0.705 Acc@5 0.000
Test: [0/1]	Time  0.325 ( 0.325)	Loss 1.3953e-01 (1.3953e-01)	Acc@1   0.70 (  0.70)	Acc@5   0.00 (  0.00)
 * Acc@1 0.704 Acc@5 0.000
81
TRAINING
Epoch: [81][0/1]	Time  0.966 ( 0.966)	Data  0.271 ( 0.271)	Loss 7.8768e-02 (7.8768e-02)	Acc@1   0.93 (  0.93)	Acc@5   0.00 (  0.00)
[0.9332603820361907]
Test: [0/1]	Time  0.277 ( 0.277)	Loss 9.4436e-01 (9.4436e-01)	Acc@1   0.71 (  0.71)	Acc@5   0.00 (  0.00)
 * Acc@1 0.705 Acc@5 0.000
Test: [0/1]	Time  0.321 ( 0.321)	Loss 1.3941e-01 (1.3941e-01)	Acc@1   0.71 (  0.71)	Acc@5   0.00 (  0.00)
 * Acc@1 0.705 Acc@5 0.000
82
TRAINING
Epoch: [82][0/1]	Time  0.982 ( 0.982)	Data  0.282 ( 0.282)	Loss 7.8752e-02 (7.8752e-02)	Acc@1   0.93 (  0.93)	Acc@5   0.00 (  0.00)
[0.9331827249409468]
Test: [0/1]	Time  0.260 ( 0.260)	Loss 9.4429e-01 (9.4429e-01)	Acc@1   0.71 (  0.71)	Acc@5   0.00 (  0.00)
 * Acc@1 0.705 Acc@5 0.000
Test: [0/1]	Time  0.309 ( 0.309)	Loss 1.3933e-01 (1.3933e-01)	Acc@1   0.71 (  0.71)	Acc@5   0.00 (  0.00)
 * Acc@1 0.707 Acc@5 0.000
83
TRAINING
Epoch: [83][0/1]	Time  1.014 ( 1.014)	Data  0.301 ( 0.301)	Loss 7.8746e-02 (7.8746e-02)	Acc@1   0.93 (  0.93)	Acc@5   0.00 (  0.00)
[0.9331461142153001]
Test: [0/1]	Time  0.266 ( 0.266)	Loss 9.4420e-01 (9.4420e-01)	Acc@1   0.71 (  0.71)	Acc@5   0.00 (  0.00)
 * Acc@1 0.705 Acc@5 0.000
Test: [0/1]	Time  0.314 ( 0.314)	Loss 1.3927e-01 (1.3927e-01)	Acc@1   0.71 (  0.71)	Acc@5   0.00 (  0.00)
 * Acc@1 0.708 Acc@5 0.000
84
TRAINING
Epoch: [84][0/1]	Time  1.008 ( 1.008)	Data  0.287 ( 0.287)	Loss 7.8742e-02 (7.8742e-02)	Acc@1   0.93 (  0.93)	Acc@5   0.00 (  0.00)
[0.9331582466577262]
Test: [0/1]	Time  0.262 ( 0.262)	Loss 9.4410e-01 (9.4410e-01)	Acc@1   0.71 (  0.71)	Acc@5   0.00 (  0.00)
 * Acc@1 0.705 Acc@5 0.000
Test: [0/1]	Time  0.316 ( 0.316)	Loss 1.3922e-01 (1.3922e-01)	Acc@1   0.71 (  0.71)	Acc@5   0.00 (  0.00)
 * Acc@1 0.709 Acc@5 0.000
85
TRAINING
Epoch: [85][0/1]	Time  0.977 ( 0.977)	Data  0.270 ( 0.270)	Loss 7.8738e-02 (7.8738e-02)	Acc@1   0.93 (  0.93)	Acc@5   0.00 (  0.00)
[0.9332197920362357]
Test: [0/1]	Time  0.272 ( 0.272)	Loss 9.4399e-01 (9.4399e-01)	Acc@1   0.71 (  0.71)	Acc@5   0.00 (  0.00)
 * Acc@1 0.705 Acc@5 0.000
Test: [0/1]	Time  0.314 ( 0.314)	Loss 1.3919e-01 (1.3919e-01)	Acc@1   0.71 (  0.71)	Acc@5   0.00 (  0.00)
 * Acc@1 0.711 Acc@5 0.000
86
TRAINING
Epoch: [86][0/1]	Time  0.978 ( 0.978)	Data  0.257 ( 0.257)	Loss 7.8734e-02 (7.8734e-02)	Acc@1   0.93 (  0.93)	Acc@5   0.00 (  0.00)
[0.9333247438857548]
Test: [0/1]	Time  0.241 ( 0.241)	Loss 9.4386e-01 (9.4386e-01)	Acc@1   0.71 (  0.71)	Acc@5   0.00 (  0.00)
 * Acc@1 0.705 Acc@5 0.000
Test: [0/1]	Time  0.292 ( 0.292)	Loss 1.3918e-01 (1.3918e-01)	Acc@1   0.71 (  0.71)	Acc@5   0.00 (  0.00)
 * Acc@1 0.712 Acc@5 0.000
87
TRAINING
Epoch: [87][0/1]	Time  1.040 ( 1.040)	Data  0.336 ( 0.336)	Loss 7.8733e-02 (7.8733e-02)	Acc@1   0.93 (  0.93)	Acc@5   0.00 (  0.00)
[0.9334620144471184]
Test: [0/1]	Time  0.273 ( 0.273)	Loss 9.4373e-01 (9.4373e-01)	Acc@1   0.71 (  0.71)	Acc@5   0.00 (  0.00)
 * Acc@1 0.705 Acc@5 0.000
Test: [0/1]	Time  0.333 ( 0.333)	Loss 1.3918e-01 (1.3918e-01)	Acc@1   0.71 (  0.71)	Acc@5   0.00 (  0.00)
 * Acc@1 0.713 Acc@5 0.000
88
TRAINING
Epoch: [88][0/1]	Time  1.004 ( 1.004)	Data  0.299 ( 0.299)	Loss 7.8736e-02 (7.8736e-02)	Acc@1   0.93 (  0.93)	Acc@5   0.00 (  0.00)
[0.9336177733687165]
Test: [0/1]	Time  0.263 ( 0.263)	Loss 9.4360e-01 (9.4360e-01)	Acc@1   0.71 (  0.71)	Acc@5   0.00 (  0.00)
 * Acc@1 0.705 Acc@5 0.000
Test: [0/1]	Time  0.313 ( 0.313)	Loss 1.3919e-01 (1.3919e-01)	Acc@1   0.71 (  0.71)	Acc@5   0.00 (  0.00)
 * Acc@1 0.713 Acc@5 0.000
89
TRAINING
Epoch: [89][0/1]	Time  1.028 ( 1.028)	Data  0.321 ( 0.321)	Loss 7.8742e-02 (7.8742e-02)	Acc@1   0.93 (  0.93)	Acc@5   0.00 (  0.00)
[0.933777901951444]
Test: [0/1]	Time  0.279 ( 0.279)	Loss 9.4347e-01 (9.4347e-01)	Acc@1   0.71 (  0.71)	Acc@5   0.00 (  0.00)
 * Acc@1 0.705 Acc@5 0.000
Test: [0/1]	Time  0.326 ( 0.326)	Loss 1.3920e-01 (1.3920e-01)	Acc@1   0.71 (  0.71)	Acc@5   0.00 (  0.00)
 * Acc@1 0.714 Acc@5 0.000
90
TRAINING
Epoch: [90][0/1]	Time  0.987 ( 0.987)	Data  0.280 ( 0.280)	Loss 7.8750e-02 (7.8750e-02)	Acc@1   0.93 (  0.93)	Acc@5   0.00 (  0.00)
[0.9339300451172345]
Test: [0/1]	Time  0.264 ( 0.264)	Loss 9.4334e-01 (9.4334e-01)	Acc@1   0.71 (  0.71)	Acc@5   0.00 (  0.00)
 * Acc@1 0.705 Acc@5 0.000
Test: [0/1]	Time  0.323 ( 0.323)	Loss 1.3920e-01 (1.3920e-01)	Acc@1   0.71 (  0.71)	Acc@5   0.00 (  0.00)
 * Acc@1 0.714 Acc@5 0.000
91
TRAINING
Epoch: [91][0/1]	Time  1.041 ( 1.041)	Data  0.320 ( 0.320)	Loss 7.8754e-02 (7.8754e-02)	Acc@1   0.93 (  0.93)	Acc@5   0.00 (  0.00)
[0.9340649908344216]
Test: [0/1]	Time  0.290 ( 0.290)	Loss 9.4321e-01 (9.4321e-01)	Acc@1   0.71 (  0.71)	Acc@5   0.00 (  0.00)
 * Acc@1 0.705 Acc@5 0.000
Test: [0/1]	Time  0.338 ( 0.338)	Loss 1.3920e-01 (1.3920e-01)	Acc@1   0.71 (  0.71)	Acc@5   0.00 (  0.00)
 * Acc@1 0.715 Acc@5 0.000
92
TRAINING
Epoch: [92][0/1]	Time  1.079 ( 1.079)	Data  0.362 ( 0.362)	Loss 7.8751e-02 (7.8751e-02)	Acc@1   0.93 (  0.93)	Acc@5   0.00 (  0.00)
[0.9341773497885589]
Test: [0/1]	Time  0.277 ( 0.277)	Loss 9.4309e-01 (9.4309e-01)	Acc@1   0.70 (  0.70)	Acc@5   0.00 (  0.00)
 * Acc@1 0.705 Acc@5 0.000
Test: [0/1]	Time  0.333 ( 0.333)	Loss 1.3918e-01 (1.3918e-01)	Acc@1   0.72 (  0.72)	Acc@5   0.00 (  0.00)
 * Acc@1 0.715 Acc@5 0.000
93
TRAINING
Epoch: [93][0/1]	Time  1.011 ( 1.011)	Data  0.291 ( 0.291)	Loss 7.8742e-02 (7.8742e-02)	Acc@1   0.93 (  0.93)	Acc@5   0.00 (  0.00)
[0.9342656461047999]
Test: [0/1]	Time  0.267 ( 0.267)	Loss 9.4297e-01 (9.4297e-01)	Acc@1   0.70 (  0.70)	Acc@5   0.00 (  0.00)
 * Acc@1 0.705 Acc@5 0.000
Test: [0/1]	Time  0.312 ( 0.312)	Loss 1.3915e-01 (1.3915e-01)	Acc@1   0.72 (  0.72)	Acc@5   0.00 (  0.00)
 * Acc@1 0.715 Acc@5 0.000
94
TRAINING
Epoch: [94][0/1]	Time  0.949 ( 0.949)	Data  0.246 ( 0.246)	Loss 7.8727e-02 (7.8727e-02)	Acc@1   0.93 (  0.93)	Acc@5   0.00 (  0.00)
[0.9343319486580413]
Test: [0/1]	Time  0.276 ( 0.276)	Loss 9.4285e-01 (9.4285e-01)	Acc@1   0.70 (  0.70)	Acc@5   0.00 (  0.00)
 * Acc@1 0.705 Acc@5 0.000
Test: [0/1]	Time  0.320 ( 0.320)	Loss 1.3911e-01 (1.3911e-01)	Acc@1   0.72 (  0.72)	Acc@5   0.00 (  0.00)
 * Acc@1 0.716 Acc@5 0.000
95
TRAINING
Epoch: [95][0/1]	Time  0.951 ( 0.951)	Data  0.249 ( 0.249)	Loss 7.8710e-02 (7.8710e-02)	Acc@1   0.93 (  0.93)	Acc@5   0.00 (  0.00)
[0.9343811310728631]
Test: [0/1]	Time  0.242 ( 0.242)	Loss 9.4274e-01 (9.4274e-01)	Acc@1   0.70 (  0.70)	Acc@5   0.00 (  0.00)
 * Acc@1 0.705 Acc@5 0.000
Test: [0/1]	Time  0.292 ( 0.292)	Loss 1.3908e-01 (1.3908e-01)	Acc@1   0.72 (  0.72)	Acc@5   0.00 (  0.00)
 * Acc@1 0.716 Acc@5 0.000
96
TRAINING
Epoch: [96][0/1]	Time  1.025 ( 1.025)	Data  0.308 ( 0.308)	Loss 7.8694e-02 (7.8694e-02)	Acc@1   0.93 (  0.93)	Acc@5   0.00 (  0.00)
[0.9344198245155537]
Test: [0/1]	Time  0.261 ( 0.261)	Loss 9.4264e-01 (9.4264e-01)	Acc@1   0.70 (  0.70)	Acc@5   0.00 (  0.00)
 * Acc@1 0.705 Acc@5 0.000
Test: [0/1]	Time  0.315 ( 0.315)	Loss 1.3906e-01 (1.3906e-01)	Acc@1   0.72 (  0.72)	Acc@5   0.00 (  0.00)
 * Acc@1 0.716 Acc@5 0.000
97
TRAINING
Epoch: [97][0/1]	Time  0.947 ( 0.947)	Data  0.243 ( 0.243)	Loss 7.8681e-02 (7.8681e-02)	Acc@1   0.93 (  0.93)	Acc@5   0.00 (  0.00)
[0.9344551610523536]
Test: [0/1]	Time  0.315 ( 0.315)	Loss 9.4254e-01 (9.4254e-01)	Acc@1   0.70 (  0.70)	Acc@5   0.00 (  0.00)
 * Acc@1 0.705 Acc@5 0.000
Test: [0/1]	Time  0.340 ( 0.340)	Loss 1.3904e-01 (1.3904e-01)	Acc@1   0.72 (  0.72)	Acc@5   0.00 (  0.00)
 * Acc@1 0.716 Acc@5 0.000
98
TRAINING
Epoch: [98][0/1]	Time  1.000 ( 1.000)	Data  0.279 ( 0.279)	Loss 7.8670e-02 (7.8670e-02)	Acc@1   0.93 (  0.93)	Acc@5   0.00 (  0.00)
[0.93449347863734]
Test: [0/1]	Time  0.250 ( 0.250)	Loss 9.4245e-01 (9.4245e-01)	Acc@1   0.70 (  0.70)	Acc@5   0.00 (  0.00)
 * Acc@1 0.705 Acc@5 0.000
Test: [0/1]	Time  0.301 ( 0.301)	Loss 1.3902e-01 (1.3902e-01)	Acc@1   0.72 (  0.72)	Acc@5   0.00 (  0.00)
 * Acc@1 0.716 Acc@5 0.000
99
TRAINING
Epoch: [99][0/1]	Time  1.019 ( 1.019)	Data  0.325 ( 0.325)	Loss 7.8662e-02 (7.8662e-02)	Acc@1   0.93 (  0.93)	Acc@5   0.00 (  0.00)
[0.934539216534302]
Test: [0/1]	Time  0.267 ( 0.267)	Loss 9.4236e-01 (9.4236e-01)	Acc@1   0.70 (  0.70)	Acc@5   0.00 (  0.00)
 * Acc@1 0.705 Acc@5 0.000
Test: [0/1]	Time  0.322 ( 0.322)	Loss 1.3902e-01 (1.3902e-01)	Acc@1   0.72 (  0.72)	Acc@5   0.00 (  0.00)
 * Acc@1 0.717 Acc@5 0.000
=> using pre-trained model 'st_resnet'
s/ohp/session_1
torch.Size([640, 3, 224, 224])
(640, 22)
attach reg
0
TRAINING
/home/helenr6/Adv_mapper/train_split.py:125: UserWarning: You have chosen to seed training. This will turn on the CUDNN deterministic setting, which can slow down your training considerably! You may see unexpected behavior when restarting from checkpoints.
  warnings.warn('You have chosen to seed training. '
/localscratch/helenr6.6279052.0/env/lib/python3.7/site-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  cpuset_checked))
Epoch: [0][0/1]	Time  5.326 ( 5.326)	Data  1.918 ( 1.918)	Loss 1.6762e+00 (1.6762e+00)	Acc@1   0.01 (  0.01)	Acc@5   0.00 (  0.00)
[0.007658640355117946]
Test: [0/1]	Time  0.451 ( 0.451)	Loss 1.1933e+00 (1.1933e+00)	Acc@1   0.02 (  0.02)	Acc@5   0.00 (  0.00)
 * Acc@1 0.021 Acc@5 0.000
Test: [0/1]	Time  0.562 ( 0.562)	Loss 9.8444e-01 (9.8444e-01)	Acc@1   0.02 (  0.02)	Acc@5   0.00 (  0.00)
 * Acc@1 0.017 Acc@5 0.000
1
TRAINING
Epoch: [1][0/1]	Time  0.973 ( 0.973)	Data  0.268 ( 0.268)	Loss 1.6069e+00 (1.6069e+00)	Acc@1   0.01 (  0.01)	Acc@5   0.00 (  0.00)
[0.010226308239686961]
Test: [0/1]	Time  0.289 ( 0.289)	Loss 1.1843e+00 (1.1843e+00)	Acc@1   0.03 (  0.03)	Acc@5   0.00 (  0.00)
 * Acc@1 0.029 Acc@5 0.000
Test: [0/1]	Time  0.340 ( 0.340)	Loss 9.3043e-01 (9.3043e-01)	Acc@1   0.02 (  0.02)	Acc@5   0.00 (  0.00)
 * Acc@1 0.020 Acc@5 0.000
2
TRAINING
Epoch: [2][0/1]	Time  1.041 ( 1.041)	Data  0.306 ( 0.306)	Loss 1.5002e+00 (1.5002e+00)	Acc@1   0.02 (  0.02)	Acc@5   0.00 (  0.00)
[0.01531295464977535]
Test: [0/1]	Time  0.274 ( 0.274)	Loss 1.1725e+00 (1.1725e+00)	Acc@1   0.03 (  0.03)	Acc@5   0.00 (  0.00)
 * Acc@1 0.029 Acc@5 0.000
Test: [0/1]	Time  0.339 ( 0.339)	Loss 8.7927e-01 (8.7927e-01)	Acc@1   0.02 (  0.02)	Acc@5   0.00 (  0.00)
 * Acc@1 0.024 Acc@5 0.000
3
TRAINING
Epoch: [3][0/1]	Time  1.063 ( 1.063)	Data  0.338 ( 0.338)	Loss 1.3917e+00 (1.3917e+00)	Acc@1   0.02 (  0.02)	Acc@5   0.00 (  0.00)
[0.022921678678668914]
Test: [0/1]	Time  0.273 ( 0.273)	Loss 1.1608e+00 (1.1608e+00)	Acc@1   0.03 (  0.03)	Acc@5   0.00 (  0.00)
 * Acc@1 0.034 Acc@5 0.000
Test: [0/1]	Time  0.327 ( 0.327)	Loss 8.4455e-01 (8.4455e-01)	Acc@1   0.03 (  0.03)	Acc@5   0.00 (  0.00)
 * Acc@1 0.029 Acc@5 0.000
4
TRAINING
Epoch: [4][0/1]	Time  1.059 ( 1.059)	Data  0.342 ( 0.342)	Loss 1.3022e+00 (1.3022e+00)	Acc@1   0.04 (  0.04)	Acc@5   0.00 (  0.00)
[0.04098960972061199]
Test: [0/1]	Time  0.272 ( 0.272)	Loss 1.1501e+00 (1.1501e+00)	Acc@1   0.04 (  0.04)	Acc@5   0.00 (  0.00)
 * Acc@1 0.045 Acc@5 0.000
Test: [0/1]	Time  0.324 ( 0.324)	Loss 8.2527e-01 (8.2527e-01)	Acc@1   0.04 (  0.04)	Acc@5   0.00 (  0.00)
 * Acc@1 0.036 Acc@5 0.000
5
TRAINING
Epoch: [5][0/1]	Time  0.979 ( 0.979)	Data  0.294 ( 0.294)	Loss 1.2310e+00 (1.2310e+00)	Acc@1   0.06 (  0.06)	Acc@5   0.00 (  0.00)
[0.056179303902436764]
Test: [0/1]	Time  0.272 ( 0.272)	Loss 1.1396e+00 (1.1396e+00)	Acc@1   0.07 (  0.07)	Acc@5   0.00 (  0.00)
 * Acc@1 0.075 Acc@5 0.000
Test: [0/1]	Time  0.330 ( 0.330)	Loss 8.0986e-01 (8.0986e-01)	Acc@1   0.05 (  0.05)	Acc@5   0.00 (  0.00)
 * Acc@1 0.046 Acc@5 0.000
6
TRAINING
Epoch: [6][0/1]	Time  1.013 ( 1.013)	Data  0.295 ( 0.295)	Loss 1.1625e+00 (1.1625e+00)	Acc@1   0.07 (  0.07)	Acc@5   0.00 (  0.00)
[0.0716921647622586]
Test: [0/1]	Time  0.266 ( 0.266)	Loss 1.1282e+00 (1.1282e+00)	Acc@1   0.10 (  0.10)	Acc@5   0.00 (  0.00)
 * Acc@1 0.102 Acc@5 0.000
Test: [0/1]	Time  0.319 ( 0.319)	Loss 7.8512e-01 (7.8512e-01)	Acc@1   0.06 (  0.06)	Acc@5   0.00 (  0.00)
 * Acc@1 0.059 Acc@5 0.000
7
TRAINING
Epoch: [7][0/1]	Time  1.021 ( 1.021)	Data  0.300 ( 0.300)	Loss 1.0805e+00 (1.0805e+00)	Acc@1   0.09 (  0.09)	Acc@5   0.00 (  0.00)
[0.09000724389618135]
Test: [0/1]	Time  0.276 ( 0.276)	Loss 1.1153e+00 (1.1153e+00)	Acc@1   0.13 (  0.13)	Acc@5   0.00 (  0.00)
 * Acc@1 0.133 Acc@5 0.000
Test: [0/1]	Time  0.312 ( 0.312)	Loss 7.4482e-01 (7.4482e-01)	Acc@1   0.07 (  0.07)	Acc@5   0.00 (  0.00)
 * Acc@1 0.069 Acc@5 0.000
8
TRAINING
Epoch: [8][0/1]	Time  1.090 ( 1.090)	Data  0.375 ( 0.375)	Loss 9.7899e-01 (9.7899e-01)	Acc@1   0.11 (  0.11)	Acc@5   0.00 (  0.00)
[0.11128282582540838]
Test: [0/1]	Time  0.279 ( 0.279)	Loss 1.1014e+00 (1.1014e+00)	Acc@1   0.17 (  0.17)	Acc@5   0.00 (  0.00)
 * Acc@1 0.172 Acc@5 0.000
Test: [0/1]	Time  0.329 ( 0.329)	Loss 6.9292e-01 (6.9292e-01)	Acc@1   0.08 (  0.08)	Acc@5   0.00 (  0.00)
 * Acc@1 0.079 Acc@5 0.000
9
TRAINING
Epoch: [9][0/1]	Time  1.013 ( 1.013)	Data  0.313 ( 0.313)	Loss 8.6517e-01 (8.6517e-01)	Acc@1   0.14 (  0.14)	Acc@5   0.00 (  0.00)
[0.1350323942536816]
Test: [0/1]	Time  0.300 ( 0.300)	Loss 1.0881e+00 (1.0881e+00)	Acc@1   0.22 (  0.22)	Acc@5   0.00 (  0.00)
 * Acc@1 0.217 Acc@5 0.000
Test: [0/1]	Time  0.354 ( 0.354)	Loss 6.4007e-01 (6.4007e-01)	Acc@1   0.09 (  0.09)	Acc@5   0.00 (  0.00)
 * Acc@1 0.094 Acc@5 0.000
10
TRAINING
Epoch: [10][0/1]	Time  1.052 ( 1.052)	Data  0.305 ( 0.305)	Loss 7.5397e-01 (7.5397e-01)	Acc@1   0.16 (  0.16)	Acc@5   0.00 (  0.00)
[0.16152855631426277]
Test: [0/1]	Time  0.259 ( 0.259)	Loss 1.0766e+00 (1.0766e+00)	Acc@1   0.26 (  0.26)	Acc@5   0.00 (  0.00)
 * Acc@1 0.262 Acc@5 0.000
Test: [0/1]	Time  0.319 ( 0.319)	Loss 5.9654e-01 (5.9654e-01)	Acc@1   0.11 (  0.11)	Acc@5   0.00 (  0.00)
 * Acc@1 0.108 Acc@5 0.000
11
TRAINING
Epoch: [11][0/1]	Time  0.994 ( 0.994)	Data  0.280 ( 0.280)	Loss 6.5873e-01 (6.5873e-01)	Acc@1   0.19 (  0.19)	Acc@5   0.00 (  0.00)
[0.19373587062002115]
Test: [0/1]	Time  0.259 ( 0.259)	Loss 1.0673e+00 (1.0673e+00)	Acc@1   0.31 (  0.31)	Acc@5   0.00 (  0.00)
 * Acc@1 0.307 Acc@5 0.000
Test: [0/1]	Time  0.309 ( 0.309)	Loss 5.6629e-01 (5.6629e-01)	Acc@1   0.12 (  0.12)	Acc@5   0.00 (  0.00)
 * Acc@1 0.124 Acc@5 0.000
12
TRAINING
Epoch: [12][0/1]	Time  1.019 ( 1.019)	Data  0.318 ( 0.318)	Loss 5.8438e-01 (5.8438e-01)	Acc@1   0.23 (  0.23)	Acc@5   0.00 (  0.00)
[0.2267278912093698]
Test: [0/1]	Time  0.255 ( 0.255)	Loss 1.0596e+00 (1.0596e+00)	Acc@1   0.35 (  0.35)	Acc@5   0.00 (  0.00)
 * Acc@1 0.352 Acc@5 0.000
Test: [0/1]	Time  0.325 ( 0.325)	Loss 5.4553e-01 (5.4553e-01)	Acc@1   0.13 (  0.13)	Acc@5   0.00 (  0.00)
 * Acc@1 0.131 Acc@5 0.000
13
TRAINING
Epoch: [13][0/1]	Time  1.023 ( 1.023)	Data  0.326 ( 0.326)	Loss 5.2650e-01 (5.2650e-01)	Acc@1   0.26 (  0.26)	Acc@5   0.00 (  0.00)
[0.2589171023729946]
Test: [0/1]	Time  0.253 ( 0.253)	Loss 1.0523e+00 (1.0523e+00)	Acc@1   0.39 (  0.39)	Acc@5   0.00 (  0.00)
 * Acc@1 0.394 Acc@5 0.000
Test: [0/1]	Time  0.314 ( 0.314)	Loss 5.2597e-01 (5.2597e-01)	Acc@1   0.14 (  0.14)	Acc@5   0.00 (  0.00)
 * Acc@1 0.137 Acc@5 0.000
14
TRAINING
Epoch: [14][0/1]	Time  1.035 ( 1.035)	Data  0.332 ( 0.332)	Loss 4.7567e-01 (4.7567e-01)	Acc@1   0.30 (  0.30)	Acc@5   0.00 (  0.00)
[0.2961253046166139]
Test: [0/1]	Time  0.256 ( 0.256)	Loss 1.0444e+00 (1.0444e+00)	Acc@1   0.43 (  0.43)	Acc@5   0.00 (  0.00)
 * Acc@1 0.425 Acc@5 0.000
Test: [0/1]	Time  0.313 ( 0.313)	Loss 5.0028e-01 (5.0028e-01)	Acc@1   0.14 (  0.14)	Acc@5   0.00 (  0.00)
 * Acc@1 0.143 Acc@5 0.000
15
TRAINING
Epoch: [15][0/1]	Time  0.968 ( 0.968)	Data  0.262 ( 0.262)	Loss 4.2388e-01 (4.2388e-01)	Acc@1   0.33 (  0.33)	Acc@5   0.00 (  0.00)
[0.3329088506154954]
Test: [0/1]	Time  0.303 ( 0.303)	Loss 1.0355e+00 (1.0355e+00)	Acc@1   0.45 (  0.45)	Acc@5   0.00 (  0.00)
 * Acc@1 0.451 Acc@5 0.000
Test: [0/1]	Time  0.340 ( 0.340)	Loss 4.6608e-01 (4.6608e-01)	Acc@1   0.16 (  0.16)	Acc@5   0.00 (  0.00)
 * Acc@1 0.159 Acc@5 0.000
16
TRAINING
Epoch: [16][0/1]	Time  0.988 ( 0.988)	Data  0.276 ( 0.276)	Loss 3.6868e-01 (3.6868e-01)	Acc@1   0.38 (  0.38)	Acc@5   0.00 (  0.00)
[0.3781319385173335]
Test: [0/1]	Time  0.270 ( 0.270)	Loss 1.0263e+00 (1.0263e+00)	Acc@1   0.48 (  0.48)	Acc@5   0.00 (  0.00)
 * Acc@1 0.480 Acc@5 0.000
Test: [0/1]	Time  0.317 ( 0.317)	Loss 4.2659e-01 (4.2659e-01)	Acc@1   0.18 (  0.18)	Acc@5   0.00 (  0.00)
 * Acc@1 0.181 Acc@5 0.000
17
TRAINING
Epoch: [17][0/1]	Time  1.018 ( 1.018)	Data  0.301 ( 0.301)	Loss 3.1348e-01 (3.1348e-01)	Acc@1   0.42 (  0.42)	Acc@5   0.00 (  0.00)
[0.42072127484322297]
Test: [0/1]	Time  0.262 ( 0.262)	Loss 1.0174e+00 (1.0174e+00)	Acc@1   0.50 (  0.50)	Acc@5   0.00 (  0.00)
 * Acc@1 0.496 Acc@5 0.000
Test: [0/1]	Time  0.332 ( 0.332)	Loss 3.8798e-01 (3.8798e-01)	Acc@1   0.20 (  0.20)	Acc@5   0.00 (  0.00)
 * Acc@1 0.205 Acc@5 0.000
18
TRAINING
Epoch: [18][0/1]	Time  0.978 ( 0.978)	Data  0.277 ( 0.277)	Loss 2.6431e-01 (2.6431e-01)	Acc@1   0.47 (  0.47)	Acc@5   0.00 (  0.00)
[0.4655017917924543]
Test: [0/1]	Time  0.292 ( 0.292)	Loss 1.0098e+00 (1.0098e+00)	Acc@1   0.51 (  0.51)	Acc@5   0.00 (  0.00)
 * Acc@1 0.508 Acc@5 0.000
Test: [0/1]	Time  0.344 ( 0.344)	Loss 3.5552e-01 (3.5552e-01)	Acc@1   0.23 (  0.23)	Acc@5   0.00 (  0.00)
 * Acc@1 0.225 Acc@5 0.000
19
TRAINING
Epoch: [19][0/1]	Time  1.023 ( 1.023)	Data  0.314 ( 0.314)	Loss 2.2574e-01 (2.2574e-01)	Acc@1   0.51 (  0.51)	Acc@5   0.00 (  0.00)
[0.5116221915991421]
Test: [0/1]	Time  0.269 ( 0.269)	Loss 1.0037e+00 (1.0037e+00)	Acc@1   0.52 (  0.52)	Acc@5   0.00 (  0.00)
 * Acc@1 0.522 Acc@5 0.000
Test: [0/1]	Time  0.319 ( 0.319)	Loss 3.3096e-01 (3.3096e-01)	Acc@1   0.25 (  0.25)	Acc@5   0.00 (  0.00)
 * Acc@1 0.246 Acc@5 0.000
20
TRAINING
Epoch: [20][0/1]	Time  0.968 ( 0.968)	Data  0.276 ( 0.276)	Loss 1.9834e-01 (1.9834e-01)	Acc@1   0.56 (  0.56)	Acc@5   0.00 (  0.00)
[0.5565583514714065]
Test: [0/1]	Time  0.256 ( 0.256)	Loss 9.9881e-01 (9.9881e-01)	Acc@1   0.53 (  0.53)	Acc@5   0.00 (  0.00)
 * Acc@1 0.535 Acc@5 0.000
Test: [0/1]	Time  0.309 ( 0.309)	Loss 3.1235e-01 (3.1235e-01)	Acc@1   0.27 (  0.27)	Acc@5   0.00 (  0.00)
 * Acc@1 0.266 Acc@5 0.000
21
TRAINING
Epoch: [21][0/1]	Time  0.962 ( 0.962)	Data  0.270 ( 0.270)	Loss 1.7897e-01 (1.7897e-01)	Acc@1   0.60 (  0.60)	Acc@5   0.00 (  0.00)
[0.6002716370113261]
Test: [0/1]	Time  0.260 ( 0.260)	Loss 9.9466e-01 (9.9466e-01)	Acc@1   0.54 (  0.54)	Acc@5   0.00 (  0.00)
 * Acc@1 0.544 Acc@5 0.000
Test: [0/1]	Time  0.315 ( 0.315)	Loss 2.9608e-01 (2.9608e-01)	Acc@1   0.29 (  0.29)	Acc@5   0.00 (  0.00)
 * Acc@1 0.291 Acc@5 0.000
22
TRAINING
Epoch: [22][0/1]	Time  0.998 ( 0.998)	Data  0.298 ( 0.298)	Loss 1.6301e-01 (1.6301e-01)	Acc@1   0.64 (  0.64)	Acc@5   0.00 (  0.00)
[0.6417828068044342]
Test: [0/1]	Time  0.271 ( 0.271)	Loss 9.9081e-01 (9.9081e-01)	Acc@1   0.55 (  0.55)	Acc@5   0.00 (  0.00)
 * Acc@1 0.554 Acc@5 0.000
Test: [0/1]	Time  0.314 ( 0.314)	Loss 2.7937e-01 (2.7937e-01)	Acc@1   0.31 (  0.31)	Acc@5   0.00 (  0.00)
 * Acc@1 0.314 Acc@5 0.000
23
TRAINING
Epoch: [23][0/1]	Time  0.953 ( 0.953)	Data  0.260 ( 0.260)	Loss 1.4708e-01 (1.4708e-01)	Acc@1   0.68 (  0.68)	Acc@5   0.00 (  0.00)
[0.6802137078220543]
Test: [0/1]	Time  0.244 ( 0.244)	Loss 9.8718e-01 (9.8718e-01)	Acc@1   0.57 (  0.57)	Acc@5   0.00 (  0.00)
 * Acc@1 0.572 Acc@5 0.000
Test: [0/1]	Time  0.299 ( 0.299)	Loss 2.6182e-01 (2.6182e-01)	Acc@1   0.34 (  0.34)	Acc@5   0.00 (  0.00)
 * Acc@1 0.335 Acc@5 0.000
24
TRAINING
Epoch: [24][0/1]	Time  0.975 ( 0.975)	Data  0.265 ( 0.265)	Loss 1.3047e-01 (1.3047e-01)	Acc@1   0.71 (  0.71)	Acc@5   0.00 (  0.00)
[0.7147849053785635]
Test: [0/1]	Time  0.250 ( 0.250)	Loss 9.8389e-01 (9.8389e-01)	Acc@1   0.59 (  0.59)	Acc@5   0.00 (  0.00)
 * Acc@1 0.589 Acc@5 0.000
Test: [0/1]	Time  0.303 ( 0.303)	Loss 2.4509e-01 (2.4509e-01)	Acc@1   0.36 (  0.36)	Acc@5   0.00 (  0.00)
 * Acc@1 0.356 Acc@5 0.000
25
TRAINING
Epoch: [25][0/1]	Time  0.978 ( 0.978)	Data  0.285 ( 0.285)	Loss 1.1481e-01 (1.1481e-01)	Acc@1   0.74 (  0.74)	Acc@5   0.00 (  0.00)
[0.7445753682503601]
Test: [0/1]	Time  0.267 ( 0.267)	Loss 9.8111e-01 (9.8111e-01)	Acc@1   0.60 (  0.60)	Acc@5   0.00 (  0.00)
 * Acc@1 0.603 Acc@5 0.000
Test: [0/1]	Time  0.305 ( 0.305)	Loss 2.3142e-01 (2.3142e-01)	Acc@1   0.38 (  0.38)	Acc@5   0.00 (  0.00)
 * Acc@1 0.376 Acc@5 0.000
26
TRAINING
Epoch: [26][0/1]	Time  0.991 ( 0.991)	Data  0.284 ( 0.284)	Loss 1.0241e-01 (1.0241e-01)	Acc@1   0.77 (  0.77)	Acc@5   0.00 (  0.00)
[0.7717680988963294]
Test: [0/1]	Time  0.269 ( 0.269)	Loss 9.7887e-01 (9.7887e-01)	Acc@1   0.62 (  0.62)	Acc@5   0.00 (  0.00)
 * Acc@1 0.616 Acc@5 0.000
Test: [0/1]	Time  0.316 ( 0.316)	Loss 2.2198e-01 (2.2198e-01)	Acc@1   0.40 (  0.40)	Acc@5   0.00 (  0.00)
 * Acc@1 0.397 Acc@5 0.000
27
TRAINING
Epoch: [27][0/1]	Time  0.995 ( 0.995)	Data  0.294 ( 0.294)	Loss 9.4604e-02 (9.4604e-02)	Acc@1   0.79 (  0.79)	Acc@5   0.00 (  0.00)
[0.7940556453124461]
Test: [0/1]	Time  0.268 ( 0.268)	Loss 9.7699e-01 (9.7699e-01)	Acc@1   0.63 (  0.63)	Acc@5   0.00 (  0.00)
 * Acc@1 0.625 Acc@5 0.000
Test: [0/1]	Time  0.320 ( 0.320)	Loss 2.1610e-01 (2.1610e-01)	Acc@1   0.42 (  0.42)	Acc@5   0.00 (  0.00)
 * Acc@1 0.419 Acc@5 0.000
28
TRAINING
Epoch: [28][0/1]	Time  1.026 ( 1.026)	Data  0.299 ( 0.299)	Loss 9.0937e-02 (9.0937e-02)	Acc@1   0.81 (  0.81)	Acc@5   0.00 (  0.00)
[0.8133963277437946]
Test: [0/1]	Time  0.276 ( 0.276)	Loss 9.7513e-01 (9.7513e-01)	Acc@1   0.63 (  0.63)	Acc@5   0.00 (  0.00)
 * Acc@1 0.633 Acc@5 0.000
Test: [0/1]	Time  0.336 ( 0.336)	Loss 2.1173e-01 (2.1173e-01)	Acc@1   0.44 (  0.44)	Acc@5   0.00 (  0.00)
 * Acc@1 0.441 Acc@5 0.000
29
TRAINING
Epoch: [29][0/1]	Time  1.025 ( 1.025)	Data  0.306 ( 0.306)	Loss 8.9570e-02 (8.9570e-02)	Acc@1   0.83 (  0.83)	Acc@5   0.00 (  0.00)
[0.831584576253324]
Test: [0/1]	Time  0.278 ( 0.278)	Loss 9.7295e-01 (9.7295e-01)	Acc@1   0.64 (  0.64)	Acc@5   0.00 (  0.00)
 * Acc@1 0.641 Acc@5 0.000
Test: [0/1]	Time  0.322 ( 0.322)	Loss 2.0664e-01 (2.0664e-01)	Acc@1   0.46 (  0.46)	Acc@5   0.00 (  0.00)
 * Acc@1 0.463 Acc@5 0.000
30
TRAINING
Epoch: [30][0/1]	Time  0.990 ( 0.990)	Data  0.276 ( 0.276)	Loss 8.8427e-02 (8.8427e-02)	Acc@1   0.85 (  0.85)	Acc@5   0.00 (  0.00)
[0.8464724071741191]
Test: [0/1]	Time  0.264 ( 0.264)	Loss 9.7030e-01 (9.7030e-01)	Acc@1   0.65 (  0.65)	Acc@5   0.00 (  0.00)
 * Acc@1 0.650 Acc@5 0.000
Test: [0/1]	Time  0.307 ( 0.307)	Loss 1.9961e-01 (1.9961e-01)	Acc@1   0.49 (  0.49)	Acc@5   0.00 (  0.00)
 * Acc@1 0.487 Acc@5 0.000
31
TRAINING
Epoch: [31][0/1]	Time  0.989 ( 0.989)	Data  0.291 ( 0.291)	Loss 8.6289e-02 (8.6289e-02)	Acc@1   0.86 (  0.86)	Acc@5   0.00 (  0.00)
[0.8582517585800686]
Test: [0/1]	Time  0.264 ( 0.264)	Loss 9.6726e-01 (9.6726e-01)	Acc@1   0.66 (  0.66)	Acc@5   0.00 (  0.00)
 * Acc@1 0.660 Acc@5 0.000
Test: [0/1]	Time  0.310 ( 0.310)	Loss 1.9086e-01 (1.9086e-01)	Acc@1   0.51 (  0.51)	Acc@5   0.00 (  0.00)
 * Acc@1 0.512 Acc@5 0.000
32
TRAINING
Epoch: [32][0/1]	Time  0.976 ( 0.976)	Data  0.276 ( 0.276)	Loss 8.3210e-02 (8.3210e-02)	Acc@1   0.87 (  0.87)	Acc@5   0.00 (  0.00)
[0.8655326506979975]
Test: [0/1]	Time  0.258 ( 0.258)	Loss 9.6406e-01 (9.6406e-01)	Acc@1   0.67 (  0.67)	Acc@5   0.00 (  0.00)
 * Acc@1 0.669 Acc@5 0.000
Test: [0/1]	Time  0.306 ( 0.306)	Loss 1.8171e-01 (1.8171e-01)	Acc@1   0.54 (  0.54)	Acc@5   0.00 (  0.00)
 * Acc@1 0.537 Acc@5 0.000
33
TRAINING
Epoch: [33][0/1]	Time  0.986 ( 0.986)	Data  0.298 ( 0.298)	Loss 8.0161e-02 (8.0161e-02)	Acc@1   0.87 (  0.87)	Acc@5   0.00 (  0.00)
[0.8686503911526892]
Test: [0/1]	Time  0.255 ( 0.255)	Loss 9.6098e-01 (9.6098e-01)	Acc@1   0.68 (  0.68)	Acc@5   0.00 (  0.00)
 * Acc@1 0.677 Acc@5 0.000
Test: [0/1]	Time  0.312 ( 0.312)	Loss 1.7368e-01 (1.7368e-01)	Acc@1   0.56 (  0.56)	Acc@5   0.00 (  0.00)
 * Acc@1 0.562 Acc@5 0.000
34
TRAINING
Epoch: [34][0/1]	Time  0.988 ( 0.988)	Data  0.297 ( 0.297)	Loss 7.8229e-02 (7.8229e-02)	Acc@1   0.87 (  0.87)	Acc@5   0.00 (  0.00)
[0.8734527349827543]
Test: [0/1]	Time  0.265 ( 0.265)	Loss 9.5821e-01 (9.5821e-01)	Acc@1   0.68 (  0.68)	Acc@5   0.00 (  0.00)
 * Acc@1 0.683 Acc@5 0.000
Test: [0/1]	Time  0.315 ( 0.315)	Loss 1.6768e-01 (1.6768e-01)	Acc@1   0.58 (  0.58)	Acc@5   0.00 (  0.00)
 * Acc@1 0.584 Acc@5 0.000
35
TRAINING
Epoch: [35][0/1]	Time  0.985 ( 0.985)	Data  0.293 ( 0.293)	Loss 7.7917e-02 (7.7917e-02)	Acc@1   0.88 (  0.88)	Acc@5   0.00 (  0.00)
[0.876845447578762]
Test: [0/1]	Time  0.257 ( 0.257)	Loss 9.5583e-01 (9.5583e-01)	Acc@1   0.69 (  0.69)	Acc@5   0.00 (  0.00)
 * Acc@1 0.687 Acc@5 0.000
Test: [0/1]	Time  0.312 ( 0.312)	Loss 1.6373e-01 (1.6373e-01)	Acc@1   0.60 (  0.60)	Acc@5   0.00 (  0.00)
 * Acc@1 0.605 Acc@5 0.000
36
TRAINING
Epoch: [36][0/1]	Time  0.965 ( 0.965)	Data  0.267 ( 0.267)	Loss 7.8923e-02 (7.8923e-02)	Acc@1   0.88 (  0.88)	Acc@5   0.00 (  0.00)
[0.8778135050783933]
Test: [0/1]	Time  0.267 ( 0.267)	Loss 9.5379e-01 (9.5379e-01)	Acc@1   0.69 (  0.69)	Acc@5   0.00 (  0.00)
 * Acc@1 0.690 Acc@5 0.000
Test: [0/1]	Time  0.316 ( 0.316)	Loss 1.6122e-01 (1.6122e-01)	Acc@1   0.62 (  0.62)	Acc@5   0.00 (  0.00)
 * Acc@1 0.625 Acc@5 0.000
37
TRAINING
Epoch: [37][0/1]	Time  0.996 ( 0.996)	Data  0.290 ( 0.290)	Loss 8.0420e-02 (8.0420e-02)	Acc@1   0.88 (  0.88)	Acc@5   0.00 (  0.00)
[0.8769053698100767]
Test: [0/1]	Time  0.265 ( 0.265)	Loss 9.5201e-01 (9.5201e-01)	Acc@1   0.69 (  0.69)	Acc@5   0.00 (  0.00)
 * Acc@1 0.692 Acc@5 0.000
Test: [0/1]	Time  0.321 ( 0.321)	Loss 1.5942e-01 (1.5942e-01)	Acc@1   0.64 (  0.64)	Acc@5   0.00 (  0.00)
 * Acc@1 0.642 Acc@5 0.000
38
TRAINING
Epoch: [38][0/1]	Time  0.994 ( 0.994)	Data  0.292 ( 0.292)	Loss 8.1590e-02 (8.1590e-02)	Acc@1   0.87 (  0.87)	Acc@5   0.00 (  0.00)
[0.8749144936885331]
Test: [0/1]	Time  0.269 ( 0.269)	Loss 9.5044e-01 (9.5044e-01)	Acc@1   0.70 (  0.70)	Acc@5   0.00 (  0.00)
 * Acc@1 0.696 Acc@5 0.000
Test: [0/1]	Time  0.320 ( 0.320)	Loss 1.5791e-01 (1.5791e-01)	Acc@1   0.66 (  0.66)	Acc@5   0.00 (  0.00)
 * Acc@1 0.657 Acc@5 0.000
39
TRAINING
Epoch: [39][0/1]	Time  0.980 ( 0.980)	Data  0.262 ( 0.262)	Loss 8.2051e-02 (8.2051e-02)	Acc@1   0.87 (  0.87)	Acc@5   0.00 (  0.00)
[0.8728456243488047]
Test: [0/1]	Time  0.278 ( 0.278)	Loss 9.4907e-01 (9.4907e-01)	Acc@1   0.70 (  0.70)	Acc@5   0.00 (  0.00)
 * Acc@1 0.699 Acc@5 0.000
Test: [0/1]	Time  0.318 ( 0.318)	Loss 1.5675e-01 (1.5675e-01)	Acc@1   0.67 (  0.67)	Acc@5   0.00 (  0.00)
 * Acc@1 0.671 Acc@5 0.000
40
TRAINING
Epoch: [40][0/1]	Time  0.994 ( 0.994)	Data  0.288 ( 0.288)	Loss 8.1952e-02 (8.1952e-02)	Acc@1   0.87 (  0.87)	Acc@5   0.00 (  0.00)
[0.8718080363098404]
Test: [0/1]	Time  0.266 ( 0.266)	Loss 9.4790e-01 (9.4790e-01)	Acc@1   0.70 (  0.70)	Acc@5   0.00 (  0.00)
 * Acc@1 0.703 Acc@5 0.000
Test: [0/1]	Time  0.321 ( 0.321)	Loss 1.5620e-01 (1.5620e-01)	Acc@1   0.68 (  0.68)	Acc@5   0.00 (  0.00)
 * Acc@1 0.681 Acc@5 0.000
41
TRAINING
Epoch: [41][0/1]	Time  0.975 ( 0.975)	Data  0.275 ( 0.275)	Loss 8.1756e-02 (8.1756e-02)	Acc@1   0.87 (  0.87)	Acc@5   0.00 (  0.00)
[0.8720019974214968]
Test: [0/1]	Time  0.285 ( 0.285)	Loss 9.4693e-01 (9.4693e-01)	Acc@1   0.71 (  0.71)	Acc@5   0.00 (  0.00)
 * Acc@1 0.706 Acc@5 0.000
Test: [0/1]	Time  0.330 ( 0.330)	Loss 1.5646e-01 (1.5646e-01)	Acc@1   0.69 (  0.69)	Acc@5   0.00 (  0.00)
 * Acc@1 0.689 Acc@5 0.000
42
TRAINING
Epoch: [42][0/1]	Time  0.952 ( 0.952)	Data  0.250 ( 0.250)	Loss 8.1882e-02 (8.1882e-02)	Acc@1   0.87 (  0.87)	Acc@5   0.00 (  0.00)
[0.873392371943771]
Test: [0/1]	Time  0.258 ( 0.258)	Loss 9.4613e-01 (9.4613e-01)	Acc@1   0.71 (  0.71)	Acc@5   0.00 (  0.00)
 * Acc@1 0.709 Acc@5 0.000
Test: [0/1]	Time  0.301 ( 0.301)	Loss 1.5742e-01 (1.5742e-01)	Acc@1   0.69 (  0.69)	Acc@5   0.00 (  0.00)
 * Acc@1 0.694 Acc@5 0.000
43
TRAINING
Epoch: [43][0/1]	Time  0.936 ( 0.936)	Data  0.242 ( 0.242)	Loss 8.2450e-02 (8.2450e-02)	Acc@1   0.87 (  0.87)	Acc@5   0.00 (  0.00)
[0.8747140472643221]
Test: [0/1]	Time  0.237 ( 0.237)	Loss 9.4540e-01 (9.4540e-01)	Acc@1   0.71 (  0.71)	Acc@5   0.00 (  0.00)
 * Acc@1 0.711 Acc@5 0.000
Test: [0/1]	Time  0.290 ( 0.290)	Loss 1.5864e-01 (1.5864e-01)	Acc@1   0.70 (  0.70)	Acc@5   0.00 (  0.00)
 * Acc@1 0.697 Acc@5 0.000
44
TRAINING
Epoch: [44][0/1]	Time  0.962 ( 0.962)	Data  0.271 ( 0.271)	Loss 8.3248e-02 (8.3248e-02)	Acc@1   0.88 (  0.88)	Acc@5   0.00 (  0.00)
[0.8760306786854462]
Test: [0/1]	Time  0.261 ( 0.261)	Loss 9.4468e-01 (9.4468e-01)	Acc@1   0.71 (  0.71)	Acc@5   0.00 (  0.00)
 * Acc@1 0.713 Acc@5 0.000
Test: [0/1]	Time  0.311 ( 0.311)	Loss 1.5958e-01 (1.5958e-01)	Acc@1   0.70 (  0.70)	Acc@5   0.00 (  0.00)
 * Acc@1 0.699 Acc@5 0.000
45
TRAINING
Epoch: [45][0/1]	Time  1.002 ( 1.002)	Data  0.291 ( 0.291)	Loss 8.3908e-02 (8.3908e-02)	Acc@1   0.88 (  0.88)	Acc@5   0.00 (  0.00)
[0.8780119562034495]
Test: [0/1]	Time  0.263 ( 0.263)	Loss 9.4391e-01 (9.4391e-01)	Acc@1   0.71 (  0.71)	Acc@5   0.00 (  0.00)
 * Acc@1 0.715 Acc@5 0.000
Test: [0/1]	Time  0.320 ( 0.320)	Loss 1.5985e-01 (1.5985e-01)	Acc@1   0.70 (  0.70)	Acc@5   0.00 (  0.00)
 * Acc@1 0.700 Acc@5 0.000
46
TRAINING
Epoch: [46][0/1]	Time  0.995 ( 0.995)	Data  0.297 ( 0.297)	Loss 8.4138e-02 (8.4138e-02)	Acc@1   0.88 (  0.88)	Acc@5   0.00 (  0.00)
[0.880663574984544]
Test: [0/1]	Time  0.261 ( 0.261)	Loss 9.4312e-01 (9.4312e-01)	Acc@1   0.72 (  0.72)	Acc@5   0.00 (  0.00)
 * Acc@1 0.716 Acc@5 0.000
Test: [0/1]	Time  0.319 ( 0.319)	Loss 1.5938e-01 (1.5938e-01)	Acc@1   0.70 (  0.70)	Acc@5   0.00 (  0.00)
 * Acc@1 0.700 Acc@5 0.000
47
TRAINING
Epoch: [47][0/1]	Time  0.961 ( 0.961)	Data  0.278 ( 0.278)	Loss 8.3880e-02 (8.3880e-02)	Acc@1   0.88 (  0.88)	Acc@5   0.00 (  0.00)
[0.8839151999332522]
Test: [0/1]	Time  0.256 ( 0.256)	Loss 9.4235e-01 (9.4235e-01)	Acc@1   0.72 (  0.72)	Acc@5   0.00 (  0.00)
 * Acc@1 0.716 Acc@5 0.000
Test: [0/1]	Time  0.308 ( 0.308)	Loss 1.5841e-01 (1.5841e-01)	Acc@1   0.70 (  0.70)	Acc@5   0.00 (  0.00)
 * Acc@1 0.699 Acc@5 0.000
48
TRAINING
Epoch: [48][0/1]	Time  0.947 ( 0.947)	Data  0.272 ( 0.272)	Loss 8.3305e-02 (8.3305e-02)	Acc@1   0.89 (  0.89)	Acc@5   0.00 (  0.00)
[0.8875649093752186]
Test: [0/1]	Time  0.251 ( 0.251)	Loss 9.4165e-01 (9.4165e-01)	Acc@1   0.72 (  0.72)	Acc@5   0.00 (  0.00)
 * Acc@1 0.716 Acc@5 0.000
Test: [0/1]	Time  0.298 ( 0.298)	Loss 1.5730e-01 (1.5730e-01)	Acc@1   0.70 (  0.70)	Acc@5   0.00 (  0.00)
 * Acc@1 0.700 Acc@5 0.000
49
TRAINING
Epoch: [49][0/1]	Time  0.989 ( 0.989)	Data  0.301 ( 0.301)	Loss 8.2684e-02 (8.2684e-02)	Acc@1   0.89 (  0.89)	Acc@5   0.00 (  0.00)
[0.8914375906039106]
Test: [0/1]	Time  0.260 ( 0.260)	Loss 9.4107e-01 (9.4107e-01)	Acc@1   0.72 (  0.72)	Acc@5   0.00 (  0.00)
 * Acc@1 0.716 Acc@5 0.000
Test: [0/1]	Time  0.315 ( 0.315)	Loss 1.5639e-01 (1.5639e-01)	Acc@1   0.70 (  0.70)	Acc@5   0.00 (  0.00)
 * Acc@1 0.699 Acc@5 0.000
50
TRAINING
Epoch: [50][0/1]	Time  0.982 ( 0.982)	Data  0.274 ( 0.274)	Loss 8.2227e-02 (8.2227e-02)	Acc@1   0.90 (  0.90)	Acc@5   0.00 (  0.00)
[0.8953675326206261]
Test: [0/1]	Time  0.256 ( 0.256)	Loss 9.4064e-01 (9.4064e-01)	Acc@1   0.72 (  0.72)	Acc@5   0.00 (  0.00)
 * Acc@1 0.715 Acc@5 0.000
Test: [0/1]	Time  0.311 ( 0.311)	Loss 1.5583e-01 (1.5583e-01)	Acc@1   0.70 (  0.70)	Acc@5   0.00 (  0.00)
 * Acc@1 0.698 Acc@5 0.000
51
TRAINING
Epoch: [51][0/1]	Time  0.930 ( 0.930)	Data  0.255 ( 0.255)	Loss 8.1991e-02 (8.1991e-02)	Acc@1   0.90 (  0.90)	Acc@5   0.00 (  0.00)
[0.8992182172644954]
Test: [0/1]	Time  0.241 ( 0.241)	Loss 9.4035e-01 (9.4035e-01)	Acc@1   0.71 (  0.71)	Acc@5   0.00 (  0.00)
 * Acc@1 0.715 Acc@5 0.000
Test: [0/1]	Time  0.292 ( 0.292)	Loss 1.5562e-01 (1.5562e-01)	Acc@1   0.70 (  0.70)	Acc@5   0.00 (  0.00)
 * Acc@1 0.696 Acc@5 0.000
52
TRAINING
Epoch: [52][0/1]	Time  0.923 ( 0.923)	Data  0.249 ( 0.249)	Loss 8.1884e-02 (8.1884e-02)	Acc@1   0.90 (  0.90)	Acc@5   0.00 (  0.00)
[0.9028924968037599]
Test: [0/1]	Time  0.242 ( 0.242)	Loss 9.4019e-01 (9.4019e-01)	Acc@1   0.71 (  0.71)	Acc@5   0.00 (  0.00)
 * Acc@1 0.715 Acc@5 0.000
Test: [0/1]	Time  0.292 ( 0.292)	Loss 1.5562e-01 (1.5562e-01)	Acc@1   0.69 (  0.69)	Acc@5   0.00 (  0.00)
 * Acc@1 0.693 Acc@5 0.000
53
TRAINING
Epoch: [53][0/1]	Time  0.930 ( 0.930)	Data  0.247 ( 0.247)	Loss 8.1761e-02 (8.1761e-02)	Acc@1   0.91 (  0.91)	Acc@5   0.00 (  0.00)
[0.9061388734551324]
Test: [0/1]	Time  0.236 ( 0.236)	Loss 9.4012e-01 (9.4012e-01)	Acc@1   0.72 (  0.72)	Acc@5   0.00 (  0.00)
 * Acc@1 0.716 Acc@5 0.000
Test: [0/1]	Time  0.289 ( 0.289)	Loss 1.5575e-01 (1.5575e-01)	Acc@1   0.69 (  0.69)	Acc@5   0.00 (  0.00)
 * Acc@1 0.690 Acc@5 0.000
54
TRAINING
Epoch: [54][0/1]	Time  0.922 ( 0.922)	Data  0.248 ( 0.248)	Loss 8.1519e-02 (8.1519e-02)	Acc@1   0.91 (  0.91)	Acc@5   0.00 (  0.00)
[0.9088603103921988]
Test: [0/1]	Time  0.303 ( 0.303)	Loss 9.4014e-01 (9.4014e-01)	Acc@1   0.72 (  0.72)	Acc@5   0.00 (  0.00)
 * Acc@1 0.717 Acc@5 0.000
Test: [0/1]	Time  0.338 ( 0.338)	Loss 1.5597e-01 (1.5597e-01)	Acc@1   0.69 (  0.69)	Acc@5   0.00 (  0.00)
 * Acc@1 0.688 Acc@5 0.000
55
TRAINING
Epoch: [55][0/1]	Time  0.958 ( 0.958)	Data  0.285 ( 0.285)	Loss 8.1153e-02 (8.1153e-02)	Acc@1   0.91 (  0.91)	Acc@5   0.00 (  0.00)
[0.9114319045425368]
Test: [0/1]	Time  0.259 ( 0.259)	Loss 9.4024e-01 (9.4024e-01)	Acc@1   0.72 (  0.72)	Acc@5   0.00 (  0.00)
 * Acc@1 0.720 Acc@5 0.000
Test: [0/1]	Time  0.309 ( 0.309)	Loss 1.5628e-01 (1.5628e-01)	Acc@1   0.69 (  0.69)	Acc@5   0.00 (  0.00)
 * Acc@1 0.685 Acc@5 0.000
56
TRAINING
Epoch: [56][0/1]	Time  0.941 ( 0.941)	Data  0.266 ( 0.266)	Loss 8.0741e-02 (8.0741e-02)	Acc@1   0.91 (  0.91)	Acc@5   0.00 (  0.00)
[0.9138714075113531]
Test: [0/1]	Time  0.252 ( 0.252)	Loss 9.4040e-01 (9.4040e-01)	Acc@1   0.72 (  0.72)	Acc@5   0.00 (  0.00)
 * Acc@1 0.723 Acc@5 0.000
Test: [0/1]	Time  0.297 ( 0.297)	Loss 1.5671e-01 (1.5671e-01)	Acc@1   0.68 (  0.68)	Acc@5   0.00 (  0.00)
 * Acc@1 0.683 Acc@5 0.000
57
TRAINING
Epoch: [57][0/1]	Time  0.938 ( 0.938)	Data  0.262 ( 0.262)	Loss 8.0382e-02 (8.0382e-02)	Acc@1   0.92 (  0.92)	Acc@5   0.00 (  0.00)
[0.9161345083871977]
Test: [0/1]	Time  0.246 ( 0.246)	Loss 9.4062e-01 (9.4062e-01)	Acc@1   0.73 (  0.73)	Acc@5   0.00 (  0.00)
 * Acc@1 0.726 Acc@5 0.000
Test: [0/1]	Time  0.298 ( 0.298)	Loss 1.5722e-01 (1.5722e-01)	Acc@1   0.68 (  0.68)	Acc@5   0.00 (  0.00)
 * Acc@1 0.681 Acc@5 0.000
58
TRAINING
Epoch: [58][0/1]	Time  0.941 ( 0.941)	Data  0.266 ( 0.266)	Loss 8.0133e-02 (8.0133e-02)	Acc@1   0.92 (  0.92)	Acc@5   0.00 (  0.00)
[0.9182805438262138]
Test: [0/1]	Time  0.248 ( 0.248)	Loss 9.4087e-01 (9.4087e-01)	Acc@1   0.73 (  0.73)	Acc@5   0.00 (  0.00)
 * Acc@1 0.729 Acc@5 0.000
Test: [0/1]	Time  0.311 ( 0.311)	Loss 1.5774e-01 (1.5774e-01)	Acc@1   0.68 (  0.68)	Acc@5   0.00 (  0.00)
 * Acc@1 0.679 Acc@5 0.000
59
TRAINING
Epoch: [59][0/1]	Time  0.938 ( 0.938)	Data  0.263 ( 0.263)	Loss 7.9980e-02 (7.9980e-02)	Acc@1   0.92 (  0.92)	Acc@5   0.00 (  0.00)
[0.9199561845406647]
Test: [0/1]	Time  0.251 ( 0.251)	Loss 9.4113e-01 (9.4113e-01)	Acc@1   0.73 (  0.73)	Acc@5   0.00 (  0.00)
 * Acc@1 0.732 Acc@5 0.000
Test: [0/1]	Time  0.299 ( 0.299)	Loss 1.5814e-01 (1.5814e-01)	Acc@1   0.68 (  0.68)	Acc@5   0.00 (  0.00)
 * Acc@1 0.678 Acc@5 0.000
60
TRAINING
Epoch: [60][0/1]	Time  0.956 ( 0.956)	Data  0.242 ( 0.242)	Loss 7.9860e-02 (7.9860e-02)	Acc@1   0.92 (  0.92)	Acc@5   0.00 (  0.00)
[0.9214607838285394]
Test: [0/1]	Time  0.238 ( 0.238)	Loss 9.4137e-01 (9.4137e-01)	Acc@1   0.73 (  0.73)	Acc@5   0.00 (  0.00)
 * Acc@1 0.734 Acc@5 0.000
Test: [0/1]	Time  0.291 ( 0.291)	Loss 1.5831e-01 (1.5831e-01)	Acc@1   0.68 (  0.68)	Acc@5   0.00 (  0.00)
 * Acc@1 0.678 Acc@5 0.000
61
TRAINING
Epoch: [61][0/1]	Time  0.919 ( 0.919)	Data  0.248 ( 0.248)	Loss 7.9701e-02 (7.9701e-02)	Acc@1   0.92 (  0.92)	Acc@5   0.00 (  0.00)
[0.9226887066019336]
Test: [0/1]	Time  0.246 ( 0.246)	Loss 9.4159e-01 (9.4159e-01)	Acc@1   0.74 (  0.74)	Acc@5   0.00 (  0.00)
 * Acc@1 0.735 Acc@5 0.000
Test: [0/1]	Time  0.292 ( 0.292)	Loss 1.5822e-01 (1.5822e-01)	Acc@1   0.68 (  0.68)	Acc@5   0.00 (  0.00)
 * Acc@1 0.677 Acc@5 0.000
62
TRAINING
Epoch: [62][0/1]	Time  0.956 ( 0.956)	Data  0.281 ( 0.281)	Loss 7.9468e-02 (7.9468e-02)	Acc@1   0.92 (  0.92)	Acc@5   0.00 (  0.00)
[0.9236561750301482]
Test: [0/1]	Time  0.258 ( 0.258)	Loss 9.4179e-01 (9.4179e-01)	Acc@1   0.74 (  0.74)	Acc@5   0.00 (  0.00)
 * Acc@1 0.736 Acc@5 0.000
Test: [0/1]	Time  0.313 ( 0.313)	Loss 1.5789e-01 (1.5789e-01)	Acc@1   0.68 (  0.68)	Acc@5   0.00 (  0.00)
 * Acc@1 0.677 Acc@5 0.000
63
TRAINING
Epoch: [63][0/1]	Time  0.928 ( 0.928)	Data  0.254 ( 0.254)	Loss 7.9175e-02 (7.9175e-02)	Acc@1   0.92 (  0.92)	Acc@5   0.00 (  0.00)
[0.9249140381788704]
Test: [0/1]	Time  0.238 ( 0.238)	Loss 9.4198e-01 (9.4198e-01)	Acc@1   0.74 (  0.74)	Acc@5   0.00 (  0.00)
 * Acc@1 0.737 Acc@5 0.000
Test: [0/1]	Time  0.295 ( 0.295)	Loss 1.5743e-01 (1.5743e-01)	Acc@1   0.68 (  0.68)	Acc@5   0.00 (  0.00)
 * Acc@1 0.678 Acc@5 0.000
64
TRAINING
Epoch: [64][0/1]	Time  0.940 ( 0.940)	Data  0.247 ( 0.247)	Loss 7.8870e-02 (7.8870e-02)	Acc@1   0.93 (  0.93)	Acc@5   0.00 (  0.00)
[0.9261245370583785]
Test: [0/1]	Time  0.239 ( 0.239)	Loss 9.4216e-01 (9.4216e-01)	Acc@1   0.74 (  0.74)	Acc@5   0.00 (  0.00)
 * Acc@1 0.737 Acc@5 0.000
Test: [0/1]	Time  0.295 ( 0.295)	Loss 1.5692e-01 (1.5692e-01)	Acc@1   0.68 (  0.68)	Acc@5   0.00 (  0.00)
 * Acc@1 0.678 Acc@5 0.000
65
TRAINING
Epoch: [65][0/1]	Time  0.922 ( 0.922)	Data  0.249 ( 0.249)	Loss 7.8604e-02 (7.8604e-02)	Acc@1   0.93 (  0.93)	Acc@5   0.00 (  0.00)
[0.9271434514878303]
Test: [0/1]	Time  0.243 ( 0.243)	Loss 9.4233e-01 (9.4233e-01)	Acc@1   0.74 (  0.74)	Acc@5   0.00 (  0.00)
 * Acc@1 0.737 Acc@5 0.000
Test: [0/1]	Time  0.293 ( 0.293)	Loss 1.5646e-01 (1.5646e-01)	Acc@1   0.68 (  0.68)	Acc@5   0.00 (  0.00)
 * Acc@1 0.679 Acc@5 0.000
66
TRAINING
Epoch: [66][0/1]	Time  0.946 ( 0.946)	Data  0.244 ( 0.244)	Loss 7.8405e-02 (7.8405e-02)	Acc@1   0.93 (  0.93)	Acc@5   0.00 (  0.00)
[0.92745449580237]
Test: [0/1]	Time  0.244 ( 0.244)	Loss 9.4250e-01 (9.4250e-01)	Acc@1   0.74 (  0.74)	Acc@5   0.00 (  0.00)
 * Acc@1 0.737 Acc@5 0.000
Test: [0/1]	Time  0.292 ( 0.292)	Loss 1.5608e-01 (1.5608e-01)	Acc@1   0.68 (  0.68)	Acc@5   0.00 (  0.00)
 * Acc@1 0.679 Acc@5 0.000
67
TRAINING
Epoch: [67][0/1]	Time  0.925 ( 0.925)	Data  0.251 ( 0.251)	Loss 7.8269e-02 (7.8269e-02)	Acc@1   0.93 (  0.93)	Acc@5   0.00 (  0.00)
[0.9276679753729801]
Test: [0/1]	Time  0.241 ( 0.241)	Loss 9.4264e-01 (9.4264e-01)	Acc@1   0.74 (  0.74)	Acc@5   0.00 (  0.00)
 * Acc@1 0.736 Acc@5 0.000
Test: [0/1]	Time  0.290 ( 0.290)	Loss 1.5579e-01 (1.5579e-01)	Acc@1   0.68 (  0.68)	Acc@5   0.00 (  0.00)
 * Acc@1 0.680 Acc@5 0.000
68
TRAINING
Epoch: [68][0/1]	Time  0.930 ( 0.930)	Data  0.250 ( 0.250)	Loss 7.8170e-02 (7.8170e-02)	Acc@1   0.93 (  0.93)	Acc@5   0.00 (  0.00)
[0.9278918030239397]
Test: [0/1]	Time  0.242 ( 0.242)	Loss 9.4277e-01 (9.4277e-01)	Acc@1   0.74 (  0.74)	Acc@5   0.00 (  0.00)
 * Acc@1 0.736 Acc@5 0.000
Test: [0/1]	Time  0.292 ( 0.292)	Loss 1.5558e-01 (1.5558e-01)	Acc@1   0.68 (  0.68)	Acc@5   0.00 (  0.00)
 * Acc@1 0.681 Acc@5 0.000
69
TRAINING
Epoch: [69][0/1]	Time  0.923 ( 0.923)	Data  0.248 ( 0.248)	Loss 7.8079e-02 (7.8079e-02)	Acc@1   0.93 (  0.93)	Acc@5   0.00 (  0.00)
[0.9282069577621296]
Test: [0/1]	Time  0.237 ( 0.237)	Loss 9.4289e-01 (9.4289e-01)	Acc@1   0.74 (  0.74)	Acc@5   0.00 (  0.00)
 * Acc@1 0.737 Acc@5 0.000
Test: [0/1]	Time  0.293 ( 0.293)	Loss 1.5545e-01 (1.5545e-01)	Acc@1   0.68 (  0.68)	Acc@5   0.00 (  0.00)
 * Acc@1 0.682 Acc@5 0.000
70
TRAINING
Epoch: [70][0/1]	Time  0.948 ( 0.948)	Data  0.250 ( 0.250)	Loss 7.7984e-02 (7.7984e-02)	Acc@1   0.93 (  0.93)	Acc@5   0.00 (  0.00)
[0.9285008887013844]
Test: [0/1]	Time  0.247 ( 0.247)	Loss 9.4297e-01 (9.4297e-01)	Acc@1   0.74 (  0.74)	Acc@5   0.00 (  0.00)
 * Acc@1 0.737 Acc@5 0.000
Test: [0/1]	Time  0.294 ( 0.294)	Loss 1.5538e-01 (1.5538e-01)	Acc@1   0.68 (  0.68)	Acc@5   0.00 (  0.00)
 * Acc@1 0.682 Acc@5 0.000
71
TRAINING
Epoch: [71][0/1]	Time  0.924 ( 0.924)	Data  0.251 ( 0.251)	Loss 7.7890e-02 (7.7890e-02)	Acc@1   0.93 (  0.93)	Acc@5   0.00 (  0.00)
[0.9287806000755663]
Test: [0/1]	Time  0.240 ( 0.240)	Loss 9.4303e-01 (9.4303e-01)	Acc@1   0.74 (  0.74)	Acc@5   0.00 (  0.00)
 * Acc@1 0.738 Acc@5 0.000
Test: [0/1]	Time  0.295 ( 0.295)	Loss 1.5537e-01 (1.5537e-01)	Acc@1   0.68 (  0.68)	Acc@5   0.00 (  0.00)
 * Acc@1 0.683 Acc@5 0.000
72
TRAINING
Epoch: [72][0/1]	Time  0.920 ( 0.920)	Data  0.247 ( 0.247)	Loss 7.7814e-02 (7.7814e-02)	Acc@1   0.93 (  0.93)	Acc@5   0.00 (  0.00)
[0.9290507829740562]
Test: [0/1]	Time  0.238 ( 0.238)	Loss 9.4307e-01 (9.4307e-01)	Acc@1   0.74 (  0.74)	Acc@5   0.00 (  0.00)
 * Acc@1 0.739 Acc@5 0.000
Test: [0/1]	Time  0.290 ( 0.290)	Loss 1.5541e-01 (1.5541e-01)	Acc@1   0.68 (  0.68)	Acc@5   0.00 (  0.00)
 * Acc@1 0.684 Acc@5 0.000
73
TRAINING
Epoch: [73][0/1]	Time  0.937 ( 0.937)	Data  0.252 ( 0.252)	Loss 7.7766e-02 (7.7766e-02)	Acc@1   0.93 (  0.93)	Acc@5   0.00 (  0.00)
[0.9293142454929283]
Test: [0/1]	Time  0.240 ( 0.240)	Loss 9.4309e-01 (9.4309e-01)	Acc@1   0.74 (  0.74)	Acc@5   0.00 (  0.00)
 * Acc@1 0.740 Acc@5 0.000
Test: [0/1]	Time  0.292 ( 0.292)	Loss 1.5546e-01 (1.5546e-01)	Acc@1   0.68 (  0.68)	Acc@5   0.00 (  0.00)
 * Acc@1 0.685 Acc@5 0.000
74
TRAINING
Epoch: [74][0/1]	Time  0.919 ( 0.919)	Data  0.247 ( 0.247)	Loss 7.7748e-02 (7.7748e-02)	Acc@1   0.93 (  0.93)	Acc@5   0.00 (  0.00)
[0.9295723904828848]
Test: [0/1]	Time  0.237 ( 0.237)	Loss 9.4308e-01 (9.4308e-01)	Acc@1   0.74 (  0.74)	Acc@5   0.00 (  0.00)
 * Acc@1 0.740 Acc@5 0.000
Test: [0/1]	Time  0.318 ( 0.318)	Loss 1.5548e-01 (1.5548e-01)	Acc@1   0.69 (  0.69)	Acc@5   0.00 (  0.00)
 * Acc@1 0.685 Acc@5 0.000
75
TRAINING
Epoch: [75][0/1]	Time  0.993 ( 0.993)	Data  0.278 ( 0.278)	Loss 7.7747e-02 (7.7747e-02)	Acc@1   0.93 (  0.93)	Acc@5   0.00 (  0.00)
[0.9300469532111267]
Test: [0/1]	Time  0.251 ( 0.251)	Loss 9.4305e-01 (9.4305e-01)	Acc@1   0.74 (  0.74)	Acc@5   0.00 (  0.00)
 * Acc@1 0.740 Acc@5 0.000
Test: [0/1]	Time  0.302 ( 0.302)	Loss 1.5545e-01 (1.5545e-01)	Acc@1   0.69 (  0.69)	Acc@5   0.00 (  0.00)
 * Acc@1 0.686 Acc@5 0.000
76
TRAINING
Epoch: [76][0/1]	Time  0.940 ( 0.940)	Data  0.264 ( 0.264)	Loss 7.7746e-02 (7.7746e-02)	Acc@1   0.93 (  0.93)	Acc@5   0.00 (  0.00)
[0.9305278149339885]
Test: [0/1]	Time  0.244 ( 0.244)	Loss 9.4301e-01 (9.4301e-01)	Acc@1   0.74 (  0.74)	Acc@5   0.00 (  0.00)
 * Acc@1 0.740 Acc@5 0.000
Test: [0/1]	Time  0.306 ( 0.306)	Loss 1.5535e-01 (1.5535e-01)	Acc@1   0.69 (  0.69)	Acc@5   0.00 (  0.00)
 * Acc@1 0.687 Acc@5 0.000
77
TRAINING
Epoch: [77][0/1]	Time  0.937 ( 0.937)	Data  0.263 ( 0.263)	Loss 7.7731e-02 (7.7731e-02)	Acc@1   0.93 (  0.93)	Acc@5   0.00 (  0.00)
[0.9309922120362619]
Test: [0/1]	Time  0.242 ( 0.242)	Loss 9.4294e-01 (9.4294e-01)	Acc@1   0.74 (  0.74)	Acc@5   0.00 (  0.00)
 * Acc@1 0.740 Acc@5 0.000
Test: [0/1]	Time  0.302 ( 0.302)	Loss 1.5517e-01 (1.5517e-01)	Acc@1   0.69 (  0.69)	Acc@5   0.00 (  0.00)
 * Acc@1 0.687 Acc@5 0.000
78
TRAINING
Epoch: [78][0/1]	Time  0.934 ( 0.934)	Data  0.261 ( 0.261)	Loss 7.7701e-02 (7.7701e-02)	Acc@1   0.93 (  0.93)	Acc@5   0.00 (  0.00)
[0.93143450962698]
Test: [0/1]	Time  0.247 ( 0.247)	Loss 9.4287e-01 (9.4287e-01)	Acc@1   0.74 (  0.74)	Acc@5   0.00 (  0.00)
 * Acc@1 0.740 Acc@5 0.000
Test: [0/1]	Time  0.295 ( 0.295)	Loss 1.5494e-01 (1.5494e-01)	Acc@1   0.69 (  0.69)	Acc@5   0.00 (  0.00)
 * Acc@1 0.688 Acc@5 0.000
79
TRAINING
Epoch: [79][0/1]	Time  0.940 ( 0.940)	Data  0.259 ( 0.259)	Loss 7.7660e-02 (7.7660e-02)	Acc@1   0.93 (  0.93)	Acc@5   0.00 (  0.00)
[0.9317339076369782]
Test: [0/1]	Time  0.244 ( 0.244)	Loss 9.4278e-01 (9.4278e-01)	Acc@1   0.74 (  0.74)	Acc@5   0.00 (  0.00)
 * Acc@1 0.739 Acc@5 0.000
Test: [0/1]	Time  0.295 ( 0.295)	Loss 1.5469e-01 (1.5469e-01)	Acc@1   0.69 (  0.69)	Acc@5   0.00 (  0.00)
 * Acc@1 0.689 Acc@5 0.000
80
TRAINING
Epoch: [80][0/1]	Time  0.942 ( 0.942)	Data  0.243 ( 0.243)	Loss 7.7620e-02 (7.7620e-02)	Acc@1   0.93 (  0.93)	Acc@5   0.00 (  0.00)
[0.9319565472409154]
Test: [0/1]	Time  0.239 ( 0.239)	Loss 9.4270e-01 (9.4270e-01)	Acc@1   0.74 (  0.74)	Acc@5   0.00 (  0.00)
 * Acc@1 0.739 Acc@5 0.000
Test: [0/1]	Time  0.289 ( 0.289)	Loss 1.5445e-01 (1.5445e-01)	Acc@1   0.69 (  0.69)	Acc@5   0.00 (  0.00)
 * Acc@1 0.689 Acc@5 0.000
81
TRAINING
Epoch: [81][0/1]	Time  0.919 ( 0.919)	Data  0.247 ( 0.247)	Loss 7.7589e-02 (7.7589e-02)	Acc@1   0.93 (  0.93)	Acc@5   0.00 (  0.00)
[0.9321753085073928]
Test: [0/1]	Time  0.241 ( 0.241)	Loss 9.4261e-01 (9.4261e-01)	Acc@1   0.74 (  0.74)	Acc@5   0.00 (  0.00)
 * Acc@1 0.738 Acc@5 0.000
Test: [0/1]	Time  0.293 ( 0.293)	Loss 1.5425e-01 (1.5425e-01)	Acc@1   0.69 (  0.69)	Acc@5   0.00 (  0.00)
 * Acc@1 0.690 Acc@5 0.000
82
TRAINING
Epoch: [82][0/1]	Time  0.918 ( 0.918)	Data  0.245 ( 0.245)	Loss 7.7571e-02 (7.7571e-02)	Acc@1   0.93 (  0.93)	Acc@5   0.00 (  0.00)
[0.9323854681352655]
Test: [0/1]	Time  0.239 ( 0.239)	Loss 9.4252e-01 (9.4252e-01)	Acc@1   0.74 (  0.74)	Acc@5   0.00 (  0.00)
 * Acc@1 0.738 Acc@5 0.000
Test: [0/1]	Time  0.290 ( 0.290)	Loss 1.5408e-01 (1.5408e-01)	Acc@1   0.69 (  0.69)	Acc@5   0.00 (  0.00)
 * Acc@1 0.690 Acc@5 0.000
83
TRAINING
Epoch: [83][0/1]	Time  0.918 ( 0.918)	Data  0.245 ( 0.245)	Loss 7.7562e-02 (7.7562e-02)	Acc@1   0.93 (  0.93)	Acc@5   0.00 (  0.00)
[0.9325833988664465]
Test: [0/1]	Time  0.240 ( 0.240)	Loss 9.4243e-01 (9.4243e-01)	Acc@1   0.74 (  0.74)	Acc@5   0.00 (  0.00)
 * Acc@1 0.738 Acc@5 0.000
Test: [0/1]	Time  0.289 ( 0.289)	Loss 1.5397e-01 (1.5397e-01)	Acc@1   0.69 (  0.69)	Acc@5   0.00 (  0.00)
 * Acc@1 0.691 Acc@5 0.000
84
TRAINING
Epoch: [84][0/1]	Time  0.929 ( 0.929)	Data  0.251 ( 0.251)	Loss 7.7557e-02 (7.7557e-02)	Acc@1   0.93 (  0.93)	Acc@5   0.00 (  0.00)
[0.9327667190860894]
Test: [0/1]	Time  0.240 ( 0.240)	Loss 9.4234e-01 (9.4234e-01)	Acc@1   0.74 (  0.74)	Acc@5   0.00 (  0.00)
 * Acc@1 0.738 Acc@5 0.000
Test: [0/1]	Time  0.290 ( 0.290)	Loss 1.5390e-01 (1.5390e-01)	Acc@1   0.69 (  0.69)	Acc@5   0.00 (  0.00)
 * Acc@1 0.692 Acc@5 0.000
85
TRAINING
Epoch: [85][0/1]	Time  0.923 ( 0.923)	Data  0.250 ( 0.250)	Loss 7.7552e-02 (7.7552e-02)	Acc@1   0.93 (  0.93)	Acc@5   0.00 (  0.00)
[0.932846633281615]
Test: [0/1]	Time  0.240 ( 0.240)	Loss 9.4224e-01 (9.4224e-01)	Acc@1   0.74 (  0.74)	Acc@5   0.00 (  0.00)
 * Acc@1 0.738 Acc@5 0.000
Test: [0/1]	Time  0.289 ( 0.289)	Loss 1.5388e-01 (1.5388e-01)	Acc@1   0.69 (  0.69)	Acc@5   0.00 (  0.00)
 * Acc@1 0.692 Acc@5 0.000
86
TRAINING
Epoch: [86][0/1]	Time  0.920 ( 0.920)	Data  0.248 ( 0.248)	Loss 7.7547e-02 (7.7547e-02)	Acc@1   0.93 (  0.93)	Acc@5   0.00 (  0.00)
[0.9328950410898363]
Test: [0/1]	Time  0.248 ( 0.248)	Loss 9.4216e-01 (9.4216e-01)	Acc@1   0.74 (  0.74)	Acc@5   0.00 (  0.00)
 * Acc@1 0.738 Acc@5 0.000
Test: [0/1]	Time  0.291 ( 0.291)	Loss 1.5389e-01 (1.5389e-01)	Acc@1   0.69 (  0.69)	Acc@5   0.00 (  0.00)
 * Acc@1 0.692 Acc@5 0.000
87
TRAINING
Epoch: [87][0/1]	Time  0.922 ( 0.922)	Data  0.248 ( 0.248)	Loss 7.7542e-02 (7.7542e-02)	Acc@1   0.93 (  0.93)	Acc@5   0.00 (  0.00)
[0.9329571835428805]
Test: [0/1]	Time  0.241 ( 0.241)	Loss 9.4207e-01 (9.4207e-01)	Acc@1   0.74 (  0.74)	Acc@5   0.00 (  0.00)
 * Acc@1 0.738 Acc@5 0.000
Test: [0/1]	Time  0.292 ( 0.292)	Loss 1.5392e-01 (1.5392e-01)	Acc@1   0.69 (  0.69)	Acc@5   0.00 (  0.00)
 * Acc@1 0.693 Acc@5 0.000
88
TRAINING
Epoch: [88][0/1]	Time  0.930 ( 0.930)	Data  0.249 ( 0.249)	Loss 7.7540e-02 (7.7540e-02)	Acc@1   0.93 (  0.93)	Acc@5   0.00 (  0.00)
[0.9330276987009306]
Test: [0/1]	Time  0.267 ( 0.267)	Loss 9.4200e-01 (9.4200e-01)	Acc@1   0.74 (  0.74)	Acc@5   0.00 (  0.00)
 * Acc@1 0.738 Acc@5 0.000
Test: [0/1]	Time  0.316 ( 0.316)	Loss 1.5397e-01 (1.5397e-01)	Acc@1   0.69 (  0.69)	Acc@5   0.00 (  0.00)
 * Acc@1 0.693 Acc@5 0.000
89
TRAINING
Epoch: [89][0/1]	Time  0.951 ( 0.951)	Data  0.275 ( 0.275)	Loss 7.7543e-02 (7.7543e-02)	Acc@1   0.93 (  0.93)	Acc@5   0.00 (  0.00)
[0.9331007620233681]
Test: [0/1]	Time  0.250 ( 0.250)	Loss 9.4193e-01 (9.4193e-01)	Acc@1   0.74 (  0.74)	Acc@5   0.00 (  0.00)
 * Acc@1 0.739 Acc@5 0.000
Test: [0/1]	Time  0.298 ( 0.298)	Loss 1.5401e-01 (1.5401e-01)	Acc@1   0.69 (  0.69)	Acc@5   0.00 (  0.00)
 * Acc@1 0.693 Acc@5 0.000
90
TRAINING
Epoch: [90][0/1]	Time  0.937 ( 0.937)	Data  0.244 ( 0.244)	Loss 7.7547e-02 (7.7547e-02)	Acc@1   0.93 (  0.93)	Acc@5   0.00 (  0.00)
[0.9331712125395124]
Test: [0/1]	Time  0.239 ( 0.239)	Loss 9.4186e-01 (9.4186e-01)	Acc@1   0.74 (  0.74)	Acc@5   0.00 (  0.00)
 * Acc@1 0.739 Acc@5 0.000
Test: [0/1]	Time  0.290 ( 0.290)	Loss 1.5404e-01 (1.5404e-01)	Acc@1   0.69 (  0.69)	Acc@5   0.00 (  0.00)
 * Acc@1 0.693 Acc@5 0.000
91
TRAINING
Epoch: [91][0/1]	Time  0.926 ( 0.926)	Data  0.252 ( 0.252)	Loss 7.7549e-02 (7.7549e-02)	Acc@1   0.93 (  0.93)	Acc@5   0.00 (  0.00)
[0.9332352354132963]
Test: [0/1]	Time  0.242 ( 0.242)	Loss 9.4179e-01 (9.4179e-01)	Acc@1   0.74 (  0.74)	Acc@5   0.00 (  0.00)
 * Acc@1 0.739 Acc@5 0.000
Test: [0/1]	Time  0.291 ( 0.291)	Loss 1.5404e-01 (1.5404e-01)	Acc@1   0.69 (  0.69)	Acc@5   0.00 (  0.00)
 * Acc@1 0.693 Acc@5 0.000
92
TRAINING
Epoch: [92][0/1]	Time  0.955 ( 0.955)	Data  0.281 ( 0.281)	Loss 7.7547e-02 (7.7547e-02)	Acc@1   0.93 (  0.93)	Acc@5   0.00 (  0.00)
[0.933290613889121]
Test: [0/1]	Time  0.253 ( 0.253)	Loss 9.4173e-01 (9.4173e-01)	Acc@1   0.74 (  0.74)	Acc@5   0.00 (  0.00)
 * Acc@1 0.739 Acc@5 0.000
Test: [0/1]	Time  0.307 ( 0.307)	Loss 1.5402e-01 (1.5402e-01)	Acc@1   0.69 (  0.69)	Acc@5   0.00 (  0.00)
 * Acc@1 0.694 Acc@5 0.000
93
TRAINING
Epoch: [93][0/1]	Time  0.924 ( 0.924)	Data  0.251 ( 0.251)	Loss 7.7538e-02 (7.7538e-02)	Acc@1   0.93 (  0.93)	Acc@5   0.00 (  0.00)
[0.9333366888812358]
Test: [0/1]	Time  0.241 ( 0.241)	Loss 9.4167e-01 (9.4167e-01)	Acc@1   0.74 (  0.74)	Acc@5   0.00 (  0.00)
 * Acc@1 0.739 Acc@5 0.000
Test: [0/1]	Time  0.292 ( 0.292)	Loss 1.5397e-01 (1.5397e-01)	Acc@1   0.69 (  0.69)	Acc@5   0.00 (  0.00)
 * Acc@1 0.694 Acc@5 0.000
94
TRAINING
Epoch: [94][0/1]	Time  0.942 ( 0.942)	Data  0.247 ( 0.247)	Loss 7.7523e-02 (7.7523e-02)	Acc@1   0.93 (  0.93)	Acc@5   0.00 (  0.00)
[0.9333741720886082]
Test: [0/1]	Time  0.237 ( 0.237)	Loss 9.4162e-01 (9.4162e-01)	Acc@1   0.74 (  0.74)	Acc@5   0.00 (  0.00)
 * Acc@1 0.739 Acc@5 0.000
Test: [0/1]	Time  0.299 ( 0.299)	Loss 1.5391e-01 (1.5391e-01)	Acc@1   0.69 (  0.69)	Acc@5   0.00 (  0.00)
 * Acc@1 0.694 Acc@5 0.000
95
TRAINING
Epoch: [95][0/1]	Time  0.946 ( 0.946)	Data  0.249 ( 0.249)	Loss 7.7506e-02 (7.7506e-02)	Acc@1   0.93 (  0.93)	Acc@5   0.00 (  0.00)
[0.9334048876883883]
Test: [0/1]	Time  0.240 ( 0.240)	Loss 9.4157e-01 (9.4157e-01)	Acc@1   0.74 (  0.74)	Acc@5   0.00 (  0.00)
 * Acc@1 0.739 Acc@5 0.000
Test: [0/1]	Time  0.291 ( 0.291)	Loss 1.5384e-01 (1.5384e-01)	Acc@1   0.69 (  0.69)	Acc@5   0.00 (  0.00)
 * Acc@1 0.694 Acc@5 0.000
96
TRAINING
Epoch: [96][0/1]	Time  0.939 ( 0.939)	Data  0.264 ( 0.264)	Loss 7.7489e-02 (7.7489e-02)	Acc@1   0.93 (  0.93)	Acc@5   0.00 (  0.00)
[0.9334234876415175]
Test: [0/1]	Time  0.245 ( 0.245)	Loss 9.4153e-01 (9.4153e-01)	Acc@1   0.74 (  0.74)	Acc@5   0.00 (  0.00)
 * Acc@1 0.739 Acc@5 0.000
Test: [0/1]	Time  0.304 ( 0.304)	Loss 1.5377e-01 (1.5377e-01)	Acc@1   0.69 (  0.69)	Acc@5   0.00 (  0.00)
 * Acc@1 0.695 Acc@5 0.000
97
TRAINING
Epoch: [97][0/1]	Time  0.935 ( 0.935)	Data  0.263 ( 0.263)	Loss 7.7474e-02 (7.7474e-02)	Acc@1   0.93 (  0.93)	Acc@5   0.00 (  0.00)
[0.9333481347681449]
Test: [0/1]	Time  0.248 ( 0.248)	Loss 9.4149e-01 (9.4149e-01)	Acc@1   0.74 (  0.74)	Acc@5   0.00 (  0.00)
 * Acc@1 0.738 Acc@5 0.000
Test: [0/1]	Time  0.297 ( 0.297)	Loss 1.5372e-01 (1.5372e-01)	Acc@1   0.69 (  0.69)	Acc@5   0.00 (  0.00)
 * Acc@1 0.695 Acc@5 0.000
98
TRAINING
Epoch: [98][0/1]	Time  0.943 ( 0.943)	Data  0.258 ( 0.258)	Loss 7.7461e-02 (7.7461e-02)	Acc@1   0.93 (  0.93)	Acc@5   0.00 (  0.00)
[0.93327900434955]
Test: [0/1]	Time  0.247 ( 0.247)	Loss 9.4145e-01 (9.4145e-01)	Acc@1   0.74 (  0.74)	Acc@5   0.00 (  0.00)
 * Acc@1 0.738 Acc@5 0.000
Test: [0/1]	Time  0.297 ( 0.297)	Loss 1.5368e-01 (1.5368e-01)	Acc@1   0.70 (  0.70)	Acc@5   0.00 (  0.00)
 * Acc@1 0.695 Acc@5 0.000
99
TRAINING
Epoch: [99][0/1]	Time  0.936 ( 0.936)	Data  0.262 ( 0.262)	Loss 7.7450e-02 (7.7450e-02)	Acc@1   0.93 (  0.93)	Acc@5   0.00 (  0.00)
[0.9332436704620689]
Test: [0/1]	Time  0.244 ( 0.244)	Loss 9.4142e-01 (9.4142e-01)	Acc@1   0.74 (  0.74)	Acc@5   0.00 (  0.00)
 * Acc@1 0.738 Acc@5 0.000
Test: [0/1]	Time  0.298 ( 0.298)	Loss 1.5367e-01 (1.5367e-01)	Acc@1   0.70 (  0.70)	Acc@5   0.00 (  0.00)
 * Acc@1 0.695 Acc@5 0.000
=> using pre-trained model 'st_resnet'
s/ohp/session_1
torch.Size([640, 3, 224, 224])
(640, 22)
attach reg
0
TRAINING
/home/helenr6/Adv_mapper/train_split.py:125: UserWarning: You have chosen to seed training. This will turn on the CUDNN deterministic setting, which can slow down your training considerably! You may see unexpected behavior when restarting from checkpoints.
  warnings.warn('You have chosen to seed training. '
/localscratch/helenr6.6279052.0/env/lib/python3.7/site-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  cpuset_checked))
Epoch: [0][0/1]	Time  5.205 ( 5.205)	Data  1.802 ( 1.802)	Loss 1.6701e+00 (1.6701e+00)	Acc@1   0.02 (  0.02)	Acc@5   0.00 (  0.00)
[0.018326246678643958]
Test: [0/1]	Time  0.440 ( 0.440)	Loss 1.1931e+00 (1.1931e+00)	Acc@1   0.02 (  0.02)	Acc@5   0.00 (  0.00)
 * Acc@1 0.022 Acc@5 0.000
Test: [0/1]	Time  0.565 ( 0.565)	Loss 9.8670e-01 (9.8670e-01)	Acc@1   0.04 (  0.04)	Acc@5   0.00 (  0.00)
 * Acc@1 0.041 Acc@5 0.000
1
TRAINING
Epoch: [1][0/1]	Time  0.967 ( 0.967)	Data  0.260 ( 0.260)	Loss 1.5983e+00 (1.5983e+00)	Acc@1   0.02 (  0.02)	Acc@5   0.00 (  0.00)
[0.022238755310850705]
Test: [0/1]	Time  0.245 ( 0.245)	Loss 1.1833e+00 (1.1833e+00)	Acc@1   0.03 (  0.03)	Acc@5   0.00 (  0.00)
 * Acc@1 0.029 Acc@5 0.000
Test: [0/1]	Time  0.298 ( 0.298)	Loss 9.4121e-01 (9.4121e-01)	Acc@1   0.05 (  0.05)	Acc@5   0.00 (  0.00)
 * Acc@1 0.046 Acc@5 0.000
2
TRAINING
Epoch: [2][0/1]	Time  1.019 ( 1.019)	Data  0.277 ( 0.277)	Loss 1.4887e+00 (1.4887e+00)	Acc@1   0.03 (  0.03)	Acc@5   0.00 (  0.00)
[0.02844144785857456]
Test: [0/1]	Time  0.256 ( 0.256)	Loss 1.1707e+00 (1.1707e+00)	Acc@1   0.03 (  0.03)	Acc@5   0.00 (  0.00)
 * Acc@1 0.029 Acc@5 0.000
Test: [0/1]	Time  0.308 ( 0.308)	Loss 8.9929e-01 (8.9929e-01)	Acc@1   0.05 (  0.05)	Acc@5   0.00 (  0.00)
 * Acc@1 0.053 Acc@5 0.000
3
TRAINING
Epoch: [3][0/1]	Time  0.950 ( 0.950)	Data  0.253 ( 0.253)	Loss 1.3791e+00 (1.3791e+00)	Acc@1   0.04 (  0.04)	Acc@5   0.00 (  0.00)
[0.0352121456357511]
Test: [0/1]	Time  0.244 ( 0.244)	Loss 1.1583e+00 (1.1583e+00)	Acc@1   0.04 (  0.04)	Acc@5   0.00 (  0.00)
 * Acc@1 0.036 Acc@5 0.000
Test: [0/1]	Time  0.297 ( 0.297)	Loss 8.7233e-01 (8.7233e-01)	Acc@1   0.06 (  0.06)	Acc@5   0.00 (  0.00)
 * Acc@1 0.062 Acc@5 0.000
4
TRAINING
Epoch: [4][0/1]	Time  0.950 ( 0.950)	Data  0.243 ( 0.243)	Loss 1.2910e+00 (1.2910e+00)	Acc@1   0.04 (  0.04)	Acc@5   0.00 (  0.00)
[0.044378816175069585]
Test: [0/1]	Time  0.253 ( 0.253)	Loss 1.1472e+00 (1.1472e+00)	Acc@1   0.05 (  0.05)	Acc@5   0.00 (  0.00)
 * Acc@1 0.054 Acc@5 0.000
Test: [0/1]	Time  0.305 ( 0.305)	Loss 8.5795e-01 (8.5795e-01)	Acc@1   0.07 (  0.07)	Acc@5   0.00 (  0.00)
 * Acc@1 0.072 Acc@5 0.000
5
TRAINING
Epoch: [5][0/1]	Time  0.946 ( 0.946)	Data  0.256 ( 0.256)	Loss 1.2227e+00 (1.2227e+00)	Acc@1   0.06 (  0.06)	Acc@5   0.00 (  0.00)
[0.05611735566027932]
Test: [0/1]	Time  0.240 ( 0.240)	Loss 1.1366e+00 (1.1366e+00)	Acc@1   0.09 (  0.09)	Acc@5   0.00 (  0.00)
 * Acc@1 0.089 Acc@5 0.000
Test: [0/1]	Time  0.291 ( 0.291)	Loss 8.4392e-01 (8.4392e-01)	Acc@1   0.08 (  0.08)	Acc@5   0.00 (  0.00)
 * Acc@1 0.083 Acc@5 0.000
6
TRAINING
Epoch: [6][0/1]	Time  0.967 ( 0.967)	Data  0.260 ( 0.260)	Loss 1.1568e+00 (1.1568e+00)	Acc@1   0.07 (  0.07)	Acc@5   0.00 (  0.00)
[0.07060878225507285]
Test: [0/1]	Time  0.246 ( 0.246)	Loss 1.1250e+00 (1.1250e+00)	Acc@1   0.12 (  0.12)	Acc@5   0.00 (  0.00)
 * Acc@1 0.119 Acc@5 0.000
Test: [0/1]	Time  0.304 ( 0.304)	Loss 8.1738e-01 (8.1738e-01)	Acc@1   0.09 (  0.09)	Acc@5   0.00 (  0.00)
 * Acc@1 0.094 Acc@5 0.000
7
TRAINING
Epoch: [7][0/1]	Time  0.958 ( 0.958)	Data  0.258 ( 0.258)	Loss 1.0759e+00 (1.0759e+00)	Acc@1   0.09 (  0.09)	Acc@5   0.00 (  0.00)
[0.0880048855246667]
Test: [0/1]	Time  0.246 ( 0.246)	Loss 1.1119e+00 (1.1119e+00)	Acc@1   0.14 (  0.14)	Acc@5   0.00 (  0.00)
 * Acc@1 0.143 Acc@5 0.000
Test: [0/1]	Time  0.294 ( 0.294)	Loss 7.7311e-01 (7.7311e-01)	Acc@1   0.11 (  0.11)	Acc@5   0.00 (  0.00)
 * Acc@1 0.105 Acc@5 0.000
8
TRAINING
Epoch: [8][0/1]	Time  0.964 ( 0.964)	Data  0.253 ( 0.253)	Loss 9.7405e-01 (9.7405e-01)	Acc@1   0.11 (  0.11)	Acc@5   0.00 (  0.00)
[0.1071421806677111]
Test: [0/1]	Time  0.250 ( 0.250)	Loss 1.0978e+00 (1.0978e+00)	Acc@1   0.18 (  0.18)	Acc@5   0.00 (  0.00)
 * Acc@1 0.182 Acc@5 0.000
Test: [0/1]	Time  0.306 ( 0.306)	Loss 7.1617e-01 (7.1617e-01)	Acc@1   0.12 (  0.12)	Acc@5   0.00 (  0.00)
 * Acc@1 0.117 Acc@5 0.000
9
TRAINING
Epoch: [9][0/1]	Time  0.992 ( 0.992)	Data  0.272 ( 0.272)	Loss 8.5956e-01 (8.5956e-01)	Acc@1   0.13 (  0.13)	Acc@5   0.00 (  0.00)
[0.1286190878861208]
Test: [0/1]	Time  0.291 ( 0.291)	Loss 1.0841e+00 (1.0841e+00)	Acc@1   0.22 (  0.22)	Acc@5   0.00 (  0.00)
 * Acc@1 0.225 Acc@5 0.000
Test: [0/1]	Time  0.330 ( 0.330)	Loss 6.5797e-01 (6.5797e-01)	Acc@1   0.13 (  0.13)	Acc@5   0.00 (  0.00)
 * Acc@1 0.129 Acc@5 0.000
10
TRAINING
Epoch: [10][0/1]	Time  0.962 ( 0.962)	Data  0.259 ( 0.259)	Loss 7.4865e-01 (7.4865e-01)	Acc@1   0.15 (  0.15)	Acc@5   0.00 (  0.00)
[0.15273273702121773]
Test: [0/1]	Time  0.250 ( 0.250)	Loss 1.0720e+00 (1.0720e+00)	Acc@1   0.27 (  0.27)	Acc@5   0.00 (  0.00)
 * Acc@1 0.269 Acc@5 0.000
Test: [0/1]	Time  0.306 ( 0.306)	Loss 6.0902e-01 (6.0902e-01)	Acc@1   0.14 (  0.14)	Acc@5   0.00 (  0.00)
 * Acc@1 0.142 Acc@5 0.000
11
TRAINING
Epoch: [11][0/1]	Time  0.975 ( 0.975)	Data  0.250 ( 0.250)	Loss 6.5512e-01 (6.5512e-01)	Acc@1   0.18 (  0.18)	Acc@5   0.00 (  0.00)
[0.18450323915197892]
Test: [0/1]	Time  0.268 ( 0.268)	Loss 1.0621e+00 (1.0621e+00)	Acc@1   0.31 (  0.31)	Acc@5   0.00 (  0.00)
 * Acc@1 0.314 Acc@5 0.000
Test: [0/1]	Time  0.312 ( 0.312)	Loss 5.7324e-01 (5.7324e-01)	Acc@1   0.16 (  0.16)	Acc@5   0.00 (  0.00)
 * Acc@1 0.162 Acc@5 0.000
12
TRAINING
Epoch: [12][0/1]	Time  1.025 ( 1.025)	Data  0.329 ( 0.329)	Loss 5.8332e-01 (5.8332e-01)	Acc@1   0.21 (  0.21)	Acc@5   0.00 (  0.00)
[0.21487614431449487]
Test: [0/1]	Time  0.250 ( 0.250)	Loss 1.0537e+00 (1.0537e+00)	Acc@1   0.35 (  0.35)	Acc@5   0.00 (  0.00)
 * Acc@1 0.352 Acc@5 0.000
Test: [0/1]	Time  0.305 ( 0.305)	Loss 5.4686e-01 (5.4686e-01)	Acc@1   0.17 (  0.17)	Acc@5   0.00 (  0.00)
 * Acc@1 0.174 Acc@5 0.000
13
TRAINING
Epoch: [13][0/1]	Time  1.010 ( 1.010)	Data  0.298 ( 0.298)	Loss 5.2765e-01 (5.2765e-01)	Acc@1   0.25 (  0.25)	Acc@5   0.00 (  0.00)
[0.24790581431828562]
Test: [0/1]	Time  0.265 ( 0.265)	Loss 1.0459e+00 (1.0459e+00)	Acc@1   0.40 (  0.40)	Acc@5   0.00 (  0.00)
 * Acc@1 0.399 Acc@5 0.000
Test: [0/1]	Time  0.309 ( 0.309)	Loss 5.2203e-01 (5.2203e-01)	Acc@1   0.19 (  0.19)	Acc@5   0.00 (  0.00)
 * Acc@1 0.191 Acc@5 0.000
14
TRAINING
Epoch: [14][0/1]	Time  0.993 ( 0.993)	Data  0.298 ( 0.298)	Loss 4.7777e-01 (4.7777e-01)	Acc@1   0.28 (  0.28)	Acc@5   0.00 (  0.00)
[0.2836108306019799]
Test: [0/1]	Time  0.270 ( 0.270)	Loss 1.0379e+00 (1.0379e+00)	Acc@1   0.45 (  0.45)	Acc@5   0.00 (  0.00)
 * Acc@1 0.449 Acc@5 0.000
Test: [0/1]	Time  0.314 ( 0.314)	Loss 4.9205e-01 (4.9205e-01)	Acc@1   0.21 (  0.21)	Acc@5   0.00 (  0.00)
 * Acc@1 0.214 Acc@5 0.000
15
TRAINING
Epoch: [15][0/1]	Time  0.957 ( 0.957)	Data  0.246 ( 0.246)	Loss 4.2553e-01 (4.2553e-01)	Acc@1   0.32 (  0.32)	Acc@5   0.00 (  0.00)
[0.32016833072755657]
Test: [0/1]	Time  0.237 ( 0.237)	Loss 1.0295e+00 (1.0295e+00)	Acc@1   0.48 (  0.48)	Acc@5   0.00 (  0.00)
 * Acc@1 0.483 Acc@5 0.000
Test: [0/1]	Time  0.295 ( 0.295)	Loss 4.5523e-01 (4.5523e-01)	Acc@1   0.24 (  0.24)	Acc@5   0.00 (  0.00)
 * Acc@1 0.239 Acc@5 0.000
16
TRAINING
Epoch: [16][0/1]	Time  0.947 ( 0.947)	Data  0.243 ( 0.243)	Loss 3.6915e-01 (3.6915e-01)	Acc@1   0.36 (  0.36)	Acc@5   0.00 (  0.00)
[0.3631247795871744]
Test: [0/1]	Time  0.236 ( 0.236)	Loss 1.0215e+00 (1.0215e+00)	Acc@1   0.51 (  0.51)	Acc@5   0.00 (  0.00)
 * Acc@1 0.514 Acc@5 0.000
Test: [0/1]	Time  0.291 ( 0.291)	Loss 4.1502e-01 (4.1502e-01)	Acc@1   0.26 (  0.26)	Acc@5   0.00 (  0.00)
 * Acc@1 0.258 Acc@5 0.000
17
TRAINING
Epoch: [17][0/1]	Time  0.968 ( 0.968)	Data  0.257 ( 0.257)	Loss 3.1299e-01 (3.1299e-01)	Acc@1   0.40 (  0.40)	Acc@5   0.00 (  0.00)
[0.4007653785952284]
Test: [0/1]	Time  0.242 ( 0.242)	Loss 1.0145e+00 (1.0145e+00)	Acc@1   0.53 (  0.53)	Acc@5   0.00 (  0.00)
 * Acc@1 0.533 Acc@5 0.000
Test: [0/1]	Time  0.293 ( 0.293)	Loss 3.7722e-01 (3.7722e-01)	Acc@1   0.28 (  0.28)	Acc@5   0.00 (  0.00)
 * Acc@1 0.280 Acc@5 0.000
18
TRAINING
Epoch: [18][0/1]	Time  1.033 ( 1.033)	Data  0.303 ( 0.303)	Loss 2.6372e-01 (2.6372e-01)	Acc@1   0.45 (  0.45)	Acc@5   0.00 (  0.00)
[0.4457349024834163]
Test: [0/1]	Time  0.253 ( 0.253)	Loss 1.0092e+00 (1.0092e+00)	Acc@1   0.55 (  0.55)	Acc@5   0.00 (  0.00)
 * Acc@1 0.547 Acc@5 0.000
Test: [0/1]	Time  0.305 ( 0.305)	Loss 3.4627e-01 (3.4627e-01)	Acc@1   0.30 (  0.30)	Acc@5   0.00 (  0.00)
 * Acc@1 0.299 Acc@5 0.000
19
TRAINING
Epoch: [19][0/1]	Time  1.000 ( 1.000)	Data  0.297 ( 0.297)	Loss 2.2586e-01 (2.2586e-01)	Acc@1   0.49 (  0.49)	Acc@5   0.00 (  0.00)
[0.4914184888932629]
Test: [0/1]	Time  0.260 ( 0.260)	Loss 1.0054e+00 (1.0054e+00)	Acc@1   0.56 (  0.56)	Acc@5   0.00 (  0.00)
 * Acc@1 0.557 Acc@5 0.000
Test: [0/1]	Time  0.310 ( 0.310)	Loss 3.2297e-01 (3.2297e-01)	Acc@1   0.32 (  0.32)	Acc@5   0.00 (  0.00)
 * Acc@1 0.319 Acc@5 0.000
20
TRAINING
Epoch: [20][0/1]	Time  0.960 ( 0.960)	Data  0.264 ( 0.264)	Loss 1.9944e-01 (1.9944e-01)	Acc@1   0.54 (  0.54)	Acc@5   0.00 (  0.00)
[0.5366564200810521]
Test: [0/1]	Time  0.249 ( 0.249)	Loss 1.0025e+00 (1.0025e+00)	Acc@1   0.57 (  0.57)	Acc@5   0.00 (  0.00)
 * Acc@1 0.567 Acc@5 0.000
Test: [0/1]	Time  0.302 ( 0.302)	Loss 3.0478e-01 (3.0478e-01)	Acc@1   0.34 (  0.34)	Acc@5   0.00 (  0.00)
 * Acc@1 0.344 Acc@5 0.000
21
TRAINING
Epoch: [21][0/1]	Time  0.947 ( 0.947)	Data  0.244 ( 0.244)	Loss 1.8063e-01 (1.8063e-01)	Acc@1   0.58 (  0.58)	Acc@5   0.00 (  0.00)
[0.5828796708895304]
Test: [0/1]	Time  0.237 ( 0.237)	Loss 9.9955e-01 (9.9955e-01)	Acc@1   0.58 (  0.58)	Acc@5   0.00 (  0.00)
 * Acc@1 0.576 Acc@5 0.000
Test: [0/1]	Time  0.285 ( 0.285)	Loss 2.8801e-01 (2.8801e-01)	Acc@1   0.37 (  0.37)	Acc@5   0.00 (  0.00)
 * Acc@1 0.369 Acc@5 0.000
22
TRAINING
Epoch: [22][0/1]	Time  1.021 ( 1.021)	Data  0.310 ( 0.310)	Loss 1.6450e-01 (1.6450e-01)	Acc@1   0.63 (  0.63)	Acc@5   0.00 (  0.00)
[0.6273204335386475]
Test: [0/1]	Time  0.261 ( 0.261)	Loss 9.9619e-01 (9.9619e-01)	Acc@1   0.58 (  0.58)	Acc@5   0.00 (  0.00)
 * Acc@1 0.584 Acc@5 0.000
Test: [0/1]	Time  0.315 ( 0.315)	Loss 2.7028e-01 (2.7028e-01)	Acc@1   0.39 (  0.39)	Acc@5   0.00 (  0.00)
 * Acc@1 0.394 Acc@5 0.000
23
TRAINING
Epoch: [23][0/1]	Time  0.933 ( 0.933)	Data  0.241 ( 0.241)	Loss 1.4783e-01 (1.4783e-01)	Acc@1   0.67 (  0.67)	Acc@5   0.00 (  0.00)
[0.668583257519354]
Test: [0/1]	Time  0.269 ( 0.269)	Loss 9.9235e-01 (9.9235e-01)	Acc@1   0.59 (  0.59)	Acc@5   0.00 (  0.00)
 * Acc@1 0.591 Acc@5 0.000
Test: [0/1]	Time  0.310 ( 0.310)	Loss 2.5168e-01 (2.5168e-01)	Acc@1   0.42 (  0.42)	Acc@5   0.00 (  0.00)
 * Acc@1 0.417 Acc@5 0.000
24
TRAINING
Epoch: [24][0/1]	Time  0.948 ( 0.948)	Data  0.244 ( 0.244)	Loss 1.3045e-01 (1.3045e-01)	Acc@1   0.71 (  0.71)	Acc@5   0.00 (  0.00)
[0.7060901092039734]
Test: [0/1]	Time  0.235 ( 0.235)	Loss 9.8834e-01 (9.8834e-01)	Acc@1   0.60 (  0.60)	Acc@5   0.00 (  0.00)
 * Acc@1 0.595 Acc@5 0.000
Test: [0/1]	Time  0.287 ( 0.287)	Loss 2.3421e-01 (2.3421e-01)	Acc@1   0.44 (  0.44)	Acc@5   0.00 (  0.00)
 * Acc@1 0.440 Acc@5 0.000
25
TRAINING
Epoch: [25][0/1]	Time  0.940 ( 0.940)	Data  0.243 ( 0.243)	Loss 1.1444e-01 (1.1444e-01)	Acc@1   0.74 (  0.74)	Acc@5   0.00 (  0.00)
[0.7393017527934334]
Test: [0/1]	Time  0.239 ( 0.239)	Loss 9.8458e-01 (9.8458e-01)	Acc@1   0.61 (  0.61)	Acc@5   0.00 (  0.00)
 * Acc@1 0.609 Acc@5 0.000
Test: [0/1]	Time  0.287 ( 0.287)	Loss 2.2017e-01 (2.2017e-01)	Acc@1   0.46 (  0.46)	Acc@5   0.00 (  0.00)
 * Acc@1 0.462 Acc@5 0.000
26
TRAINING
Epoch: [26][0/1]	Time  0.934 ( 0.934)	Data  0.251 ( 0.251)	Loss 1.0228e-01 (1.0228e-01)	Acc@1   0.77 (  0.77)	Acc@5   0.00 (  0.00)
[0.7670413647806926]
Test: [0/1]	Time  0.242 ( 0.242)	Loss 9.8129e-01 (9.8129e-01)	Acc@1   0.63 (  0.63)	Acc@5   0.00 (  0.00)
 * Acc@1 0.632 Acc@5 0.000
Test: [0/1]	Time  0.290 ( 0.290)	Loss 2.1053e-01 (2.1053e-01)	Acc@1   0.48 (  0.48)	Acc@5   0.00 (  0.00)
 * Acc@1 0.483 Acc@5 0.000
27
TRAINING
Epoch: [27][0/1]	Time  0.931 ( 0.931)	Data  0.241 ( 0.241)	Loss 9.5078e-02 (9.5078e-02)	Acc@1   0.79 (  0.79)	Acc@5   0.00 (  0.00)
[0.7915796811585367]
Test: [0/1]	Time  0.237 ( 0.237)	Loss 9.7847e-01 (9.7847e-01)	Acc@1   0.65 (  0.65)	Acc@5   0.00 (  0.00)
 * Acc@1 0.650 Acc@5 0.000
Test: [0/1]	Time  0.292 ( 0.292)	Loss 2.0444e-01 (2.0444e-01)	Acc@1   0.50 (  0.50)	Acc@5   0.00 (  0.00)
 * Acc@1 0.504 Acc@5 0.000
28
TRAINING
Epoch: [28][0/1]	Time  0.980 ( 0.980)	Data  0.279 ( 0.279)	Loss 9.1936e-02 (9.1936e-02)	Acc@1   0.81 (  0.81)	Acc@5   0.00 (  0.00)
[0.8144274687241351]
Test: [0/1]	Time  0.311 ( 0.311)	Loss 9.7588e-01 (9.7588e-01)	Acc@1   0.66 (  0.66)	Acc@5   0.00 (  0.00)
 * Acc@1 0.664 Acc@5 0.000
Test: [0/1]	Time  0.319 ( 0.319)	Loss 1.9983e-01 (1.9983e-01)	Acc@1   0.53 (  0.53)	Acc@5   0.00 (  0.00)
 * Acc@1 0.528 Acc@5 0.000
29
TRAINING
Epoch: [29][0/1]	Time  0.981 ( 0.981)	Data  0.269 ( 0.269)	Loss 9.0680e-02 (9.0680e-02)	Acc@1   0.83 (  0.83)	Acc@5   0.00 (  0.00)
[0.8316054757175507]
Test: [0/1]	Time  0.260 ( 0.260)	Loss 9.7328e-01 (9.7328e-01)	Acc@1   0.67 (  0.67)	Acc@5   0.00 (  0.00)
 * Acc@1 0.674 Acc@5 0.000
Test: [0/1]	Time  0.299 ( 0.299)	Loss 1.9469e-01 (1.9469e-01)	Acc@1   0.55 (  0.55)	Acc@5   0.00 (  0.00)
 * Acc@1 0.551 Acc@5 0.000
30
TRAINING
Epoch: [30][0/1]	Time  0.969 ( 0.969)	Data  0.257 ( 0.257)	Loss 8.9172e-02 (8.9172e-02)	Acc@1   0.85 (  0.85)	Acc@5   0.00 (  0.00)
[0.8458360456442879]
Test: [0/1]	Time  0.289 ( 0.289)	Loss 9.7053e-01 (9.7053e-01)	Acc@1   0.68 (  0.68)	Acc@5   0.00 (  0.00)
 * Acc@1 0.681 Acc@5 0.000
Test: [0/1]	Time  0.329 ( 0.329)	Loss 1.8812e-01 (1.8812e-01)	Acc@1   0.58 (  0.58)	Acc@5   0.00 (  0.00)
 * Acc@1 0.577 Acc@5 0.000
31
TRAINING
Epoch: [31][0/1]	Time  0.948 ( 0.948)	Data  0.246 ( 0.246)	Loss 8.6410e-02 (8.6410e-02)	Acc@1   0.86 (  0.86)	Acc@5   0.00 (  0.00)
[0.8573270014636075]
Test: [0/1]	Time  0.243 ( 0.243)	Loss 9.6770e-01 (9.6770e-01)	Acc@1   0.69 (  0.69)	Acc@5   0.00 (  0.00)
 * Acc@1 0.685 Acc@5 0.000
Test: [0/1]	Time  0.290 ( 0.290)	Loss 1.8058e-01 (1.8058e-01)	Acc@1   0.60 (  0.60)	Acc@5   0.00 (  0.00)
 * Acc@1 0.601 Acc@5 0.000
32
TRAINING
Epoch: [32][0/1]	Time  0.986 ( 0.986)	Data  0.293 ( 0.293)	Loss 8.2781e-02 (8.2781e-02)	Acc@1   0.87 (  0.87)	Acc@5   0.00 (  0.00)
[0.8663284936331157]
Test: [0/1]	Time  0.259 ( 0.259)	Loss 9.6494e-01 (9.6494e-01)	Acc@1   0.69 (  0.69)	Acc@5   0.00 (  0.00)
 * Acc@1 0.688 Acc@5 0.000
Test: [0/1]	Time  0.309 ( 0.309)	Loss 1.7337e-01 (1.7337e-01)	Acc@1   0.62 (  0.62)	Acc@5   0.00 (  0.00)
 * Acc@1 0.620 Acc@5 0.000
33
TRAINING
Epoch: [33][0/1]	Time  0.946 ( 0.946)	Data  0.251 ( 0.251)	Loss 7.9494e-02 (7.9494e-02)	Acc@1   0.87 (  0.87)	Acc@5   0.00 (  0.00)
[0.8700164015977794]
Test: [0/1]	Time  0.239 ( 0.239)	Loss 9.6241e-01 (9.6241e-01)	Acc@1   0.69 (  0.69)	Acc@5   0.00 (  0.00)
 * Acc@1 0.690 Acc@5 0.000
Test: [0/1]	Time  0.287 ( 0.287)	Loss 1.6771e-01 (1.6771e-01)	Acc@1   0.64 (  0.64)	Acc@5   0.00 (  0.00)
 * Acc@1 0.638 Acc@5 0.000
34
TRAINING
Epoch: [34][0/1]	Time  0.992 ( 0.992)	Data  0.296 ( 0.296)	Loss 7.7653e-02 (7.7653e-02)	Acc@1   0.87 (  0.87)	Acc@5   0.00 (  0.00)
[0.8739156482258448]
Test: [0/1]	Time  0.269 ( 0.269)	Loss 9.6015e-01 (9.6015e-01)	Acc@1   0.69 (  0.69)	Acc@5   0.00 (  0.00)
 * Acc@1 0.690 Acc@5 0.000
Test: [0/1]	Time  0.313 ( 0.313)	Loss 1.6409e-01 (1.6409e-01)	Acc@1   0.66 (  0.66)	Acc@5   0.00 (  0.00)
 * Acc@1 0.655 Acc@5 0.000
35
TRAINING
Epoch: [35][0/1]	Time  0.993 ( 0.993)	Data  0.301 ( 0.301)	Loss 7.7591e-02 (7.7591e-02)	Acc@1   0.88 (  0.88)	Acc@5   0.00 (  0.00)
[0.8752870676948754]
Test: [0/1]	Time  0.263 ( 0.263)	Loss 9.5812e-01 (9.5812e-01)	Acc@1   0.69 (  0.69)	Acc@5   0.00 (  0.00)
 * Acc@1 0.690 Acc@5 0.000
Test: [0/1]	Time  0.310 ( 0.310)	Loss 1.6216e-01 (1.6216e-01)	Acc@1   0.67 (  0.67)	Acc@5   0.00 (  0.00)
 * Acc@1 0.672 Acc@5 0.000
36
TRAINING
Epoch: [36][0/1]	Time  0.953 ( 0.953)	Data  0.247 ( 0.247)	Loss 7.8780e-02 (7.8780e-02)	Acc@1   0.88 (  0.88)	Acc@5   0.00 (  0.00)
[0.8756608613477955]
Test: [0/1]	Time  0.274 ( 0.274)	Loss 9.5623e-01 (9.5623e-01)	Acc@1   0.69 (  0.69)	Acc@5   0.00 (  0.00)
 * Acc@1 0.690 Acc@5 0.000
Test: [0/1]	Time  0.316 ( 0.316)	Loss 1.6112e-01 (1.6112e-01)	Acc@1   0.69 (  0.69)	Acc@5   0.00 (  0.00)
 * Acc@1 0.687 Acc@5 0.000
37
TRAINING
Epoch: [37][0/1]	Time  0.948 ( 0.948)	Data  0.240 ( 0.240)	Loss 8.0255e-02 (8.0255e-02)	Acc@1   0.88 (  0.88)	Acc@5   0.00 (  0.00)
[0.875457202082769]
Test: [0/1]	Time  0.255 ( 0.255)	Loss 9.5441e-01 (9.5441e-01)	Acc@1   0.69 (  0.69)	Acc@5   0.00 (  0.00)
 * Acc@1 0.690 Acc@5 0.000
Test: [0/1]	Time  0.331 ( 0.331)	Loss 1.6022e-01 (1.6022e-01)	Acc@1   0.70 (  0.70)	Acc@5   0.00 (  0.00)
 * Acc@1 0.695 Acc@5 0.000
38
TRAINING
Epoch: [38][0/1]	Time  0.945 ( 0.945)	Data  0.241 ( 0.241)	Loss 8.1224e-02 (8.1224e-02)	Acc@1   0.87 (  0.87)	Acc@5   0.00 (  0.00)
[0.8749225716295386]
Test: [0/1]	Time  0.234 ( 0.234)	Loss 9.5265e-01 (9.5265e-01)	Acc@1   0.69 (  0.69)	Acc@5   0.00 (  0.00)
 * Acc@1 0.690 Acc@5 0.000
Test: [0/1]	Time  0.287 ( 0.287)	Loss 1.5920e-01 (1.5920e-01)	Acc@1   0.70 (  0.70)	Acc@5   0.00 (  0.00)
 * Acc@1 0.703 Acc@5 0.000
39
TRAINING
Epoch: [39][0/1]	Time  0.945 ( 0.945)	Data  0.256 ( 0.256)	Loss 8.1447e-02 (8.1447e-02)	Acc@1   0.87 (  0.87)	Acc@5   0.00 (  0.00)
[0.8742731220021258]
Test: [0/1]	Time  0.248 ( 0.248)	Loss 9.5102e-01 (9.5102e-01)	Acc@1   0.69 (  0.69)	Acc@5   0.00 (  0.00)
 * Acc@1 0.691 Acc@5 0.000
Test: [0/1]	Time  0.298 ( 0.298)	Loss 1.5824e-01 (1.5824e-01)	Acc@1   0.71 (  0.71)	Acc@5   0.00 (  0.00)
 * Acc@1 0.712 Acc@5 0.000
40
TRAINING
Epoch: [40][0/1]	Time  0.993 ( 0.993)	Data  0.296 ( 0.296)	Loss 8.1232e-02 (8.1232e-02)	Acc@1   0.87 (  0.87)	Acc@5   0.00 (  0.00)
[0.8736960868867295]
Test: [0/1]	Time  0.266 ( 0.266)	Loss 9.4960e-01 (9.4960e-01)	Acc@1   0.69 (  0.69)	Acc@5   0.00 (  0.00)
 * Acc@1 0.691 Acc@5 0.000
Test: [0/1]	Time  0.309 ( 0.309)	Loss 1.5772e-01 (1.5772e-01)	Acc@1   0.72 (  0.72)	Acc@5   0.00 (  0.00)
 * Acc@1 0.720 Acc@5 0.000
41
TRAINING
Epoch: [41][0/1]	Time  0.956 ( 0.956)	Data  0.245 ( 0.245)	Loss 8.1113e-02 (8.1113e-02)	Acc@1   0.87 (  0.87)	Acc@5   0.00 (  0.00)
[0.8733560249612087]
Test: [0/1]	Time  0.242 ( 0.242)	Loss 9.4843e-01 (9.4843e-01)	Acc@1   0.69 (  0.69)	Acc@5   0.00 (  0.00)
 * Acc@1 0.692 Acc@5 0.000
Test: [0/1]	Time  0.289 ( 0.289)	Loss 1.5787e-01 (1.5787e-01)	Acc@1   0.73 (  0.73)	Acc@5   0.00 (  0.00)
 * Acc@1 0.726 Acc@5 0.000
42
TRAINING
Epoch: [42][0/1]	Time  0.946 ( 0.946)	Data  0.255 ( 0.255)	Loss 8.1460e-02 (8.1460e-02)	Acc@1   0.87 (  0.87)	Acc@5   0.00 (  0.00)
[0.8738714915720363]
Test: [0/1]	Time  0.283 ( 0.283)	Loss 9.4749e-01 (9.4749e-01)	Acc@1   0.69 (  0.69)	Acc@5   0.00 (  0.00)
 * Acc@1 0.692 Acc@5 0.000
Test: [0/1]	Time  0.333 ( 0.333)	Loss 1.5857e-01 (1.5857e-01)	Acc@1   0.73 (  0.73)	Acc@5   0.00 (  0.00)
 * Acc@1 0.733 Acc@5 0.000
43
TRAINING
Epoch: [43][0/1]	Time  0.995 ( 0.995)	Data  0.278 ( 0.278)	Loss 8.2268e-02 (8.2268e-02)	Acc@1   0.88 (  0.88)	Acc@5   0.00 (  0.00)
[0.875446435667017]
Test: [0/1]	Time  0.259 ( 0.259)	Loss 9.4673e-01 (9.4673e-01)	Acc@1   0.69 (  0.69)	Acc@5   0.00 (  0.00)
 * Acc@1 0.692 Acc@5 0.000
Test: [0/1]	Time  0.300 ( 0.300)	Loss 1.5944e-01 (1.5944e-01)	Acc@1   0.74 (  0.74)	Acc@5   0.00 (  0.00)
 * Acc@1 0.740 Acc@5 0.000
44
TRAINING
Epoch: [44][0/1]	Time  0.986 ( 0.986)	Data  0.285 ( 0.285)	Loss 8.3207e-02 (8.3207e-02)	Acc@1   0.88 (  0.88)	Acc@5   0.00 (  0.00)
[0.8774882619400485]
Test: [0/1]	Time  0.242 ( 0.242)	Loss 9.4609e-01 (9.4609e-01)	Acc@1   0.69 (  0.69)	Acc@5   0.00 (  0.00)
 * Acc@1 0.691 Acc@5 0.000
Test: [0/1]	Time  0.294 ( 0.294)	Loss 1.6003e-01 (1.6003e-01)	Acc@1   0.75 (  0.75)	Acc@5   0.00 (  0.00)
 * Acc@1 0.746 Acc@5 0.000
45
TRAINING
Epoch: [45][0/1]	Time  1.004 ( 1.004)	Data  0.304 ( 0.304)	Loss 8.3863e-02 (8.3863e-02)	Acc@1   0.88 (  0.88)	Acc@5   0.00 (  0.00)
[0.880029544309179]
Test: [0/1]	Time  0.268 ( 0.268)	Loss 9.4549e-01 (9.4549e-01)	Acc@1   0.69 (  0.69)	Acc@5   0.00 (  0.00)
 * Acc@1 0.689 Acc@5 0.000
Test: [0/1]	Time  0.310 ( 0.310)	Loss 1.6008e-01 (1.6008e-01)	Acc@1   0.75 (  0.75)	Acc@5   0.00 (  0.00)
 * Acc@1 0.750 Acc@5 0.000
46
TRAINING
Epoch: [46][0/1]	Time  0.958 ( 0.958)	Data  0.262 ( 0.262)	Loss 8.3987e-02 (8.3987e-02)	Acc@1   0.88 (  0.88)	Acc@5   0.00 (  0.00)
[0.8828384496485939]
Test: [0/1]	Time  0.244 ( 0.244)	Loss 9.4497e-01 (9.4497e-01)	Acc@1   0.69 (  0.69)	Acc@5   0.00 (  0.00)
 * Acc@1 0.686 Acc@5 0.000
Test: [0/1]	Time  0.303 ( 0.303)	Loss 1.5966e-01 (1.5966e-01)	Acc@1   0.75 (  0.75)	Acc@5   0.00 (  0.00)
 * Acc@1 0.754 Acc@5 0.000
47
TRAINING
Epoch: [47][0/1]	Time  0.953 ( 0.953)	Data  0.266 ( 0.266)	Loss 8.3613e-02 (8.3613e-02)	Acc@1   0.89 (  0.89)	Acc@5   0.00 (  0.00)
[0.8860470663988407]
Test: [0/1]	Time  0.305 ( 0.305)	Loss 9.4456e-01 (9.4456e-01)	Acc@1   0.68 (  0.68)	Acc@5   0.00 (  0.00)
 * Acc@1 0.683 Acc@5 0.000
Test: [0/1]	Time  0.307 ( 0.307)	Loss 1.5901e-01 (1.5901e-01)	Acc@1   0.75 (  0.75)	Acc@5   0.00 (  0.00)
 * Acc@1 0.755 Acc@5 0.000
48
TRAINING
Epoch: [48][0/1]	Time  0.957 ( 0.957)	Data  0.255 ( 0.255)	Loss 8.2993e-02 (8.2993e-02)	Acc@1   0.89 (  0.89)	Acc@5   0.00 (  0.00)
[0.8896058250378776]
Test: [0/1]	Time  0.241 ( 0.241)	Loss 9.4428e-01 (9.4428e-01)	Acc@1   0.68 (  0.68)	Acc@5   0.00 (  0.00)
 * Acc@1 0.680 Acc@5 0.000
Test: [0/1]	Time  0.306 ( 0.306)	Loss 1.5844e-01 (1.5844e-01)	Acc@1   0.75 (  0.75)	Acc@5   0.00 (  0.00)
 * Acc@1 0.755 Acc@5 0.000
49
TRAINING
Epoch: [49][0/1]	Time  0.944 ( 0.944)	Data  0.273 ( 0.273)	Loss 8.2423e-02 (8.2423e-02)	Acc@1   0.89 (  0.89)	Acc@5   0.00 (  0.00)
[0.8933297218004884]
Test: [0/1]	Time  0.245 ( 0.245)	Loss 9.4415e-01 (9.4415e-01)	Acc@1   0.68 (  0.68)	Acc@5   0.00 (  0.00)
 * Acc@1 0.676 Acc@5 0.000
Test: [0/1]	Time  0.297 ( 0.297)	Loss 1.5813e-01 (1.5813e-01)	Acc@1   0.75 (  0.75)	Acc@5   0.00 (  0.00)
 * Acc@1 0.754 Acc@5 0.000
50
TRAINING
Epoch: [50][0/1]	Time  0.954 ( 0.954)	Data  0.241 ( 0.241)	Loss 8.2080e-02 (8.2080e-02)	Acc@1   0.90 (  0.90)	Acc@5   0.00 (  0.00)
[0.8970613746631214]
Test: [0/1]	Time  0.233 ( 0.233)	Loss 9.4418e-01 (9.4418e-01)	Acc@1   0.67 (  0.67)	Acc@5   0.00 (  0.00)
 * Acc@1 0.675 Acc@5 0.000
Test: [0/1]	Time  0.287 ( 0.287)	Loss 1.5810e-01 (1.5810e-01)	Acc@1   0.75 (  0.75)	Acc@5   0.00 (  0.00)
 * Acc@1 0.753 Acc@5 0.000
51
TRAINING
Epoch: [51][0/1]	Time  0.934 ( 0.934)	Data  0.263 ( 0.263)	Loss 8.1955e-02 (8.1955e-02)	Acc@1   0.90 (  0.90)	Acc@5   0.00 (  0.00)
[0.9001383075937737]
Test: [0/1]	Time  0.240 ( 0.240)	Loss 9.4433e-01 (9.4433e-01)	Acc@1   0.68 (  0.68)	Acc@5   0.00 (  0.00)
 * Acc@1 0.676 Acc@5 0.000
Test: [0/1]	Time  0.289 ( 0.289)	Loss 1.5822e-01 (1.5822e-01)	Acc@1   0.75 (  0.75)	Acc@5   0.00 (  0.00)
 * Acc@1 0.754 Acc@5 0.000
52
TRAINING
Epoch: [52][0/1]	Time  0.935 ( 0.935)	Data  0.263 ( 0.263)	Loss 8.1909e-02 (8.1909e-02)	Acc@1   0.90 (  0.90)	Acc@5   0.00 (  0.00)
[0.9032209161539849]
Test: [0/1]	Time  0.244 ( 0.244)	Loss 9.4458e-01 (9.4458e-01)	Acc@1   0.68 (  0.68)	Acc@5   0.00 (  0.00)
 * Acc@1 0.678 Acc@5 0.000
Test: [0/1]	Time  0.293 ( 0.293)	Loss 1.5834e-01 (1.5834e-01)	Acc@1   0.75 (  0.75)	Acc@5   0.00 (  0.00)
 * Acc@1 0.753 Acc@5 0.000
53
TRAINING
Epoch: [53][0/1]	Time  0.933 ( 0.933)	Data  0.263 ( 0.263)	Loss 8.1787e-02 (8.1787e-02)	Acc@1   0.91 (  0.91)	Acc@5   0.00 (  0.00)
[0.9061482546662512]
Test: [0/1]	Time  0.240 ( 0.240)	Loss 9.4490e-01 (9.4490e-01)	Acc@1   0.68 (  0.68)	Acc@5   0.00 (  0.00)
 * Acc@1 0.680 Acc@5 0.000
Test: [0/1]	Time  0.298 ( 0.298)	Loss 1.5837e-01 (1.5837e-01)	Acc@1   0.75 (  0.75)	Acc@5   0.00 (  0.00)
 * Acc@1 0.751 Acc@5 0.000
54
TRAINING
Epoch: [54][0/1]	Time  0.939 ( 0.939)	Data  0.263 ( 0.263)	Loss 8.1517e-02 (8.1517e-02)	Acc@1   0.91 (  0.91)	Acc@5   0.00 (  0.00)
[0.9091563658147817]
Test: [0/1]	Time  0.242 ( 0.242)	Loss 9.4529e-01 (9.4529e-01)	Acc@1   0.68 (  0.68)	Acc@5   0.00 (  0.00)
 * Acc@1 0.682 Acc@5 0.000
Test: [0/1]	Time  0.291 ( 0.291)	Loss 1.5833e-01 (1.5833e-01)	Acc@1   0.75 (  0.75)	Acc@5   0.00 (  0.00)
 * Acc@1 0.749 Acc@5 0.000
55
TRAINING
Epoch: [55][0/1]	Time  0.930 ( 0.930)	Data  0.259 ( 0.259)	Loss 8.1140e-02 (8.1140e-02)	Acc@1   0.91 (  0.91)	Acc@5   0.00 (  0.00)
[0.9123871522554896]
Test: [0/1]	Time  0.238 ( 0.238)	Loss 9.4574e-01 (9.4574e-01)	Acc@1   0.68 (  0.68)	Acc@5   0.00 (  0.00)
 * Acc@1 0.684 Acc@5 0.000
Test: [0/1]	Time  0.291 ( 0.291)	Loss 1.5829e-01 (1.5829e-01)	Acc@1   0.75 (  0.75)	Acc@5   0.00 (  0.00)
 * Acc@1 0.748 Acc@5 0.000
56
TRAINING
Epoch: [56][0/1]	Time  0.939 ( 0.939)	Data  0.267 ( 0.267)	Loss 8.0761e-02 (8.0761e-02)	Acc@1   0.92 (  0.92)	Acc@5   0.00 (  0.00)
[0.9152756420868384]
Test: [0/1]	Time  0.240 ( 0.240)	Loss 9.4625e-01 (9.4625e-01)	Acc@1   0.69 (  0.69)	Acc@5   0.00 (  0.00)
 * Acc@1 0.686 Acc@5 0.000
Test: [0/1]	Time  0.291 ( 0.291)	Loss 1.5830e-01 (1.5830e-01)	Acc@1   0.75 (  0.75)	Acc@5   0.00 (  0.00)
 * Acc@1 0.747 Acc@5 0.000
57
TRAINING
Epoch: [57][0/1]	Time  0.932 ( 0.932)	Data  0.259 ( 0.259)	Loss 8.0477e-02 (8.0477e-02)	Acc@1   0.92 (  0.92)	Acc@5   0.00 (  0.00)
[0.9178995139796147]
Test: [0/1]	Time  0.241 ( 0.241)	Loss 9.4681e-01 (9.4681e-01)	Acc@1   0.69 (  0.69)	Acc@5   0.00 (  0.00)
 * Acc@1 0.688 Acc@5 0.000
Test: [0/1]	Time  0.289 ( 0.289)	Loss 1.5837e-01 (1.5837e-01)	Acc@1   0.75 (  0.75)	Acc@5   0.00 (  0.00)
 * Acc@1 0.746 Acc@5 0.000
58
TRAINING
Epoch: [58][0/1]	Time  0.934 ( 0.934)	Data  0.260 ( 0.260)	Loss 8.0315e-02 (8.0315e-02)	Acc@1   0.92 (  0.92)	Acc@5   0.00 (  0.00)
[0.9202766506254028]
Test: [0/1]	Time  0.240 ( 0.240)	Loss 9.4740e-01 (9.4740e-01)	Acc@1   0.69 (  0.69)	Acc@5   0.00 (  0.00)
 * Acc@1 0.690 Acc@5 0.000
Test: [0/1]	Time  0.291 ( 0.291)	Loss 1.5845e-01 (1.5845e-01)	Acc@1   0.74 (  0.74)	Acc@5   0.00 (  0.00)
 * Acc@1 0.745 Acc@5 0.000
59
TRAINING
Epoch: [59][0/1]	Time  0.937 ( 0.937)	Data  0.264 ( 0.264)	Loss 8.0226e-02 (8.0226e-02)	Acc@1   0.92 (  0.92)	Acc@5   0.00 (  0.00)
[0.9220519036229786]
Test: [0/1]	Time  0.239 ( 0.239)	Loss 9.4800e-01 (9.4800e-01)	Acc@1   0.69 (  0.69)	Acc@5   0.00 (  0.00)
 * Acc@1 0.692 Acc@5 0.000
Test: [0/1]	Time  0.291 ( 0.291)	Loss 1.5846e-01 (1.5846e-01)	Acc@1   0.74 (  0.74)	Acc@5   0.00 (  0.00)
 * Acc@1 0.744 Acc@5 0.000
60
TRAINING
Epoch: [60][0/1]	Time  0.954 ( 0.954)	Data  0.242 ( 0.242)	Loss 8.0128e-02 (8.0128e-02)	Acc@1   0.92 (  0.92)	Acc@5   0.00 (  0.00)
[0.923301423018149]
Test: [0/1]	Time  0.238 ( 0.238)	Loss 9.4858e-01 (9.4858e-01)	Acc@1   0.69 (  0.69)	Acc@5   0.00 (  0.00)
 * Acc@1 0.694 Acc@5 0.000
Test: [0/1]	Time  0.286 ( 0.286)	Loss 1.5834e-01 (1.5834e-01)	Acc@1   0.74 (  0.74)	Acc@5   0.00 (  0.00)
 * Acc@1 0.744 Acc@5 0.000
61
TRAINING
Epoch: [61][0/1]	Time  0.918 ( 0.918)	Data  0.244 ( 0.244)	Loss 7.9955e-02 (7.9955e-02)	Acc@1   0.92 (  0.92)	Acc@5   0.00 (  0.00)
[0.9243697334220685]
Test: [0/1]	Time  0.241 ( 0.241)	Loss 9.4915e-01 (9.4915e-01)	Acc@1   0.70 (  0.70)	Acc@5   0.00 (  0.00)
 * Acc@1 0.696 Acc@5 0.000
Test: [0/1]	Time  0.285 ( 0.285)	Loss 1.5809e-01 (1.5809e-01)	Acc@1   0.74 (  0.74)	Acc@5   0.00 (  0.00)
 * Acc@1 0.743 Acc@5 0.000
62
TRAINING
Epoch: [62][0/1]	Time  0.917 ( 0.917)	Data  0.245 ( 0.245)	Loss 7.9691e-02 (7.9691e-02)	Acc@1   0.93 (  0.93)	Acc@5   0.00 (  0.00)
[0.9257394388059756]
Test: [0/1]	Time  0.268 ( 0.268)	Loss 9.4972e-01 (9.4972e-01)	Acc@1   0.70 (  0.70)	Acc@5   0.00 (  0.00)
 * Acc@1 0.698 Acc@5 0.000
Test: [0/1]	Time  0.313 ( 0.313)	Loss 1.5775e-01 (1.5775e-01)	Acc@1   0.74 (  0.74)	Acc@5   0.00 (  0.00)
 * Acc@1 0.743 Acc@5 0.000
63
TRAINING
Epoch: [63][0/1]	Time  0.928 ( 0.928)	Data  0.257 ( 0.257)	Loss 7.9377e-02 (7.9377e-02)	Acc@1   0.93 (  0.93)	Acc@5   0.00 (  0.00)
[0.9266365887287407]
Test: [0/1]	Time  0.241 ( 0.241)	Loss 9.5026e-01 (9.5026e-01)	Acc@1   0.70 (  0.70)	Acc@5   0.00 (  0.00)
 * Acc@1 0.700 Acc@5 0.000
Test: [0/1]	Time  0.296 ( 0.296)	Loss 1.5739e-01 (1.5739e-01)	Acc@1   0.74 (  0.74)	Acc@5   0.00 (  0.00)
 * Acc@1 0.743 Acc@5 0.000
64
TRAINING
Epoch: [64][0/1]	Time  0.930 ( 0.930)	Data  0.249 ( 0.249)	Loss 7.9074e-02 (7.9074e-02)	Acc@1   0.93 (  0.93)	Acc@5   0.00 (  0.00)
[0.9276028572055615]
Test: [0/1]	Time  0.266 ( 0.266)	Loss 9.5079e-01 (9.5079e-01)	Acc@1   0.70 (  0.70)	Acc@5   0.00 (  0.00)
 * Acc@1 0.701 Acc@5 0.000
Test: [0/1]	Time  0.312 ( 0.312)	Loss 1.5706e-01 (1.5706e-01)	Acc@1   0.74 (  0.74)	Acc@5   0.00 (  0.00)
 * Acc@1 0.744 Acc@5 0.000
65
TRAINING
Epoch: [65][0/1]	Time  0.933 ( 0.933)	Data  0.262 ( 0.262)	Loss 7.8831e-02 (7.8831e-02)	Acc@1   0.93 (  0.93)	Acc@5   0.00 (  0.00)
[0.9284055156112279]
Test: [0/1]	Time  0.245 ( 0.245)	Loss 9.5129e-01 (9.5129e-01)	Acc@1   0.70 (  0.70)	Acc@5   0.00 (  0.00)
 * Acc@1 0.701 Acc@5 0.000
Test: [0/1]	Time  0.291 ( 0.291)	Loss 1.5680e-01 (1.5680e-01)	Acc@1   0.74 (  0.74)	Acc@5   0.00 (  0.00)
 * Acc@1 0.745 Acc@5 0.000
66
TRAINING
Epoch: [66][0/1]	Time  0.927 ( 0.927)	Data  0.254 ( 0.254)	Loss 7.8660e-02 (7.8660e-02)	Acc@1   0.93 (  0.93)	Acc@5   0.00 (  0.00)
[0.9289657541852774]
Test: [0/1]	Time  0.246 ( 0.246)	Loss 9.5175e-01 (9.5175e-01)	Acc@1   0.70 (  0.70)	Acc@5   0.00 (  0.00)
 * Acc@1 0.701 Acc@5 0.000
Test: [0/1]	Time  0.290 ( 0.290)	Loss 1.5658e-01 (1.5658e-01)	Acc@1   0.75 (  0.75)	Acc@5   0.00 (  0.00)
 * Acc@1 0.746 Acc@5 0.000
67
TRAINING
Epoch: [67][0/1]	Time  0.925 ( 0.925)	Data  0.253 ( 0.253)	Loss 7.8542e-02 (7.8542e-02)	Acc@1   0.93 (  0.93)	Acc@5   0.00 (  0.00)
[0.9294566509939637]
Test: [0/1]	Time  0.240 ( 0.240)	Loss 9.5216e-01 (9.5216e-01)	Acc@1   0.70 (  0.70)	Acc@5   0.00 (  0.00)
 * Acc@1 0.702 Acc@5 0.000
Test: [0/1]	Time  0.288 ( 0.288)	Loss 1.5638e-01 (1.5638e-01)	Acc@1   0.75 (  0.75)	Acc@5   0.00 (  0.00)
 * Acc@1 0.748 Acc@5 0.000
68
TRAINING
Epoch: [68][0/1]	Time  0.927 ( 0.927)	Data  0.255 ( 0.255)	Loss 7.8446e-02 (7.8446e-02)	Acc@1   0.93 (  0.93)	Acc@5   0.00 (  0.00)
[0.929584683135458]
Test: [0/1]	Time  0.239 ( 0.239)	Loss 9.5252e-01 (9.5252e-01)	Acc@1   0.70 (  0.70)	Acc@5   0.00 (  0.00)
 * Acc@1 0.702 Acc@5 0.000
Test: [0/1]	Time  0.295 ( 0.295)	Loss 1.5619e-01 (1.5619e-01)	Acc@1   0.75 (  0.75)	Acc@5   0.00 (  0.00)
 * Acc@1 0.749 Acc@5 0.000
69
TRAINING
Epoch: [69][0/1]	Time  0.934 ( 0.934)	Data  0.255 ( 0.255)	Loss 7.8347e-02 (7.8347e-02)	Acc@1   0.93 (  0.93)	Acc@5   0.00 (  0.00)
[0.9298684419687905]
Test: [0/1]	Time  0.237 ( 0.237)	Loss 9.5283e-01 (9.5283e-01)	Acc@1   0.70 (  0.70)	Acc@5   0.00 (  0.00)
 * Acc@1 0.703 Acc@5 0.000
Test: [0/1]	Time  0.294 ( 0.294)	Loss 1.5600e-01 (1.5600e-01)	Acc@1   0.75 (  0.75)	Acc@5   0.00 (  0.00)
 * Acc@1 0.750 Acc@5 0.000
70
TRAINING
Epoch: [70][0/1]	Time  0.930 ( 0.930)	Data  0.241 ( 0.241)	Loss 7.8243e-02 (7.8243e-02)	Acc@1   0.93 (  0.93)	Acc@5   0.00 (  0.00)
[0.9300738819986668]
Test: [0/1]	Time  0.235 ( 0.235)	Loss 9.5309e-01 (9.5309e-01)	Acc@1   0.70 (  0.70)	Acc@5   0.00 (  0.00)
 * Acc@1 0.704 Acc@5 0.000
Test: [0/1]	Time  0.287 ( 0.287)	Loss 1.5582e-01 (1.5582e-01)	Acc@1   0.75 (  0.75)	Acc@5   0.00 (  0.00)
 * Acc@1 0.751 Acc@5 0.000
71
TRAINING
Epoch: [71][0/1]	Time  0.917 ( 0.917)	Data  0.244 ( 0.244)	Loss 7.8150e-02 (7.8150e-02)	Acc@1   0.93 (  0.93)	Acc@5   0.00 (  0.00)
[0.9302170255421547]
Test: [0/1]	Time  0.240 ( 0.240)	Loss 9.5329e-01 (9.5329e-01)	Acc@1   0.70 (  0.70)	Acc@5   0.00 (  0.00)
 * Acc@1 0.704 Acc@5 0.000
Test: [0/1]	Time  0.293 ( 0.293)	Loss 1.5567e-01 (1.5567e-01)	Acc@1   0.75 (  0.75)	Acc@5   0.00 (  0.00)
 * Acc@1 0.752 Acc@5 0.000
72
TRAINING
Epoch: [72][0/1]	Time  0.926 ( 0.926)	Data  0.252 ( 0.252)	Loss 7.8084e-02 (7.8084e-02)	Acc@1   0.93 (  0.93)	Acc@5   0.00 (  0.00)
[0.9303256592972529]
Test: [0/1]	Time  0.238 ( 0.238)	Loss 9.5345e-01 (9.5345e-01)	Acc@1   0.70 (  0.70)	Acc@5   0.00 (  0.00)
 * Acc@1 0.705 Acc@5 0.000
Test: [0/1]	Time  0.284 ( 0.284)	Loss 1.5554e-01 (1.5554e-01)	Acc@1   0.75 (  0.75)	Acc@5   0.00 (  0.00)
 * Acc@1 0.753 Acc@5 0.000
73
TRAINING
Epoch: [73][0/1]	Time  0.923 ( 0.923)	Data  0.249 ( 0.249)	Loss 7.8052e-02 (7.8052e-02)	Acc@1   0.93 (  0.93)	Acc@5   0.00 (  0.00)
[0.9304829505210395]
Test: [0/1]	Time  0.236 ( 0.236)	Loss 9.5358e-01 (9.5358e-01)	Acc@1   0.71 (  0.71)	Acc@5   0.00 (  0.00)
 * Acc@1 0.705 Acc@5 0.000
Test: [0/1]	Time  0.290 ( 0.290)	Loss 1.5544e-01 (1.5544e-01)	Acc@1   0.75 (  0.75)	Acc@5   0.00 (  0.00)
 * Acc@1 0.754 Acc@5 0.000
74
TRAINING
Epoch: [74][0/1]	Time  0.928 ( 0.928)	Data  0.249 ( 0.249)	Loss 7.8046e-02 (7.8046e-02)	Acc@1   0.93 (  0.93)	Acc@5   0.00 (  0.00)
[0.9308084035480823]
Test: [0/1]	Time  0.236 ( 0.236)	Loss 9.5367e-01 (9.5367e-01)	Acc@1   0.71 (  0.71)	Acc@5   0.00 (  0.00)
 * Acc@1 0.706 Acc@5 0.000
Test: [0/1]	Time  0.289 ( 0.289)	Loss 1.5533e-01 (1.5533e-01)	Acc@1   0.75 (  0.75)	Acc@5   0.00 (  0.00)
 * Acc@1 0.755 Acc@5 0.000
75
TRAINING
Epoch: [75][0/1]	Time  0.944 ( 0.944)	Data  0.247 ( 0.247)	Loss 7.8047e-02 (7.8047e-02)	Acc@1   0.93 (  0.93)	Acc@5   0.00 (  0.00)
[0.9311404115962927]
Test: [0/1]	Time  0.239 ( 0.239)	Loss 9.5373e-01 (9.5373e-01)	Acc@1   0.71 (  0.71)	Acc@5   0.00 (  0.00)
 * Acc@1 0.706 Acc@5 0.000
Test: [0/1]	Time  0.293 ( 0.293)	Loss 1.5522e-01 (1.5522e-01)	Acc@1   0.76 (  0.76)	Acc@5   0.00 (  0.00)
 * Acc@1 0.756 Acc@5 0.000
76
TRAINING
Epoch: [76][0/1]	Time  0.925 ( 0.925)	Data  0.237 ( 0.237)	Loss 7.8036e-02 (7.8036e-02)	Acc@1   0.93 (  0.93)	Acc@5   0.00 (  0.00)
[0.931479535545313]
Test: [0/1]	Time  0.238 ( 0.238)	Loss 9.5376e-01 (9.5376e-01)	Acc@1   0.71 (  0.71)	Acc@5   0.00 (  0.00)
 * Acc@1 0.707 Acc@5 0.000
Test: [0/1]	Time  0.286 ( 0.286)	Loss 1.5508e-01 (1.5508e-01)	Acc@1   0.76 (  0.76)	Acc@5   0.00 (  0.00)
 * Acc@1 0.757 Acc@5 0.000
77
TRAINING
Epoch: [77][0/1]	Time  0.961 ( 0.961)	Data  0.251 ( 0.251)	Loss 7.8006e-02 (7.8006e-02)	Acc@1   0.93 (  0.93)	Acc@5   0.00 (  0.00)
[0.9316866172263416]
Test: [0/1]	Time  0.241 ( 0.241)	Loss 9.5377e-01 (9.5377e-01)	Acc@1   0.71 (  0.71)	Acc@5   0.00 (  0.00)
 * Acc@1 0.707 Acc@5 0.000
Test: [0/1]	Time  0.292 ( 0.292)	Loss 1.5493e-01 (1.5493e-01)	Acc@1   0.76 (  0.76)	Acc@5   0.00 (  0.00)
 * Acc@1 0.757 Acc@5 0.000
78
TRAINING
Epoch: [78][0/1]	Time  0.945 ( 0.945)	Data  0.249 ( 0.249)	Loss 7.7960e-02 (7.7960e-02)	Acc@1   0.93 (  0.93)	Acc@5   0.00 (  0.00)
[0.931769107454724]
Test: [0/1]	Time  0.243 ( 0.243)	Loss 9.5376e-01 (9.5376e-01)	Acc@1   0.71 (  0.71)	Acc@5   0.00 (  0.00)
 * Acc@1 0.707 Acc@5 0.000
Test: [0/1]	Time  0.293 ( 0.293)	Loss 1.5478e-01 (1.5478e-01)	Acc@1   0.76 (  0.76)	Acc@5   0.00 (  0.00)
 * Acc@1 0.758 Acc@5 0.000
79
TRAINING
Epoch: [79][0/1]	Time  0.930 ( 0.930)	Data  0.236 ( 0.236)	Loss 7.7910e-02 (7.7910e-02)	Acc@1   0.93 (  0.93)	Acc@5   0.00 (  0.00)
[0.9318560148114252]
Test: [0/1]	Time  0.239 ( 0.239)	Loss 9.5373e-01 (9.5373e-01)	Acc@1   0.71 (  0.71)	Acc@5   0.00 (  0.00)
 * Acc@1 0.707 Acc@5 0.000
Test: [0/1]	Time  0.285 ( 0.285)	Loss 1.5465e-01 (1.5465e-01)	Acc@1   0.76 (  0.76)	Acc@5   0.00 (  0.00)
 * Acc@1 0.759 Acc@5 0.000
80
TRAINING
Epoch: [80][0/1]	Time  0.936 ( 0.936)	Data  0.246 ( 0.246)	Loss 7.7867e-02 (7.7867e-02)	Acc@1   0.93 (  0.93)	Acc@5   0.00 (  0.00)
[0.9319458851348783]
Test: [0/1]	Time  0.235 ( 0.235)	Loss 9.5368e-01 (9.5368e-01)	Acc@1   0.71 (  0.71)	Acc@5   0.00 (  0.00)
 * Acc@1 0.707 Acc@5 0.000
Test: [0/1]	Time  0.288 ( 0.288)	Loss 1.5453e-01 (1.5453e-01)	Acc@1   0.76 (  0.76)	Acc@5   0.00 (  0.00)
 * Acc@1 0.760 Acc@5 0.000
81
TRAINING
Epoch: [81][0/1]	Time  0.953 ( 0.953)	Data  0.245 ( 0.245)	Loss 7.7839e-02 (7.7839e-02)	Acc@1   0.93 (  0.93)	Acc@5   0.00 (  0.00)
[0.9320374060552203]
Test: [0/1]	Time  0.263 ( 0.263)	Loss 9.5360e-01 (9.5360e-01)	Acc@1   0.71 (  0.71)	Acc@5   0.00 (  0.00)
 * Acc@1 0.707 Acc@5 0.000
Test: [0/1]	Time  0.305 ( 0.305)	Loss 1.5443e-01 (1.5443e-01)	Acc@1   0.76 (  0.76)	Acc@5   0.00 (  0.00)
 * Acc@1 0.761 Acc@5 0.000
82
TRAINING
Epoch: [82][0/1]	Time  0.968 ( 0.968)	Data  0.271 ( 0.271)	Loss 7.7824e-02 (7.7824e-02)	Acc@1   0.93 (  0.93)	Acc@5   0.00 (  0.00)
[0.9321298620188062]
Test: [0/1]	Time  0.238 ( 0.238)	Loss 9.5351e-01 (9.5351e-01)	Acc@1   0.71 (  0.71)	Acc@5   0.00 (  0.00)
 * Acc@1 0.707 Acc@5 0.000
Test: [0/1]	Time  0.293 ( 0.293)	Loss 1.5435e-01 (1.5435e-01)	Acc@1   0.76 (  0.76)	Acc@5   0.00 (  0.00)
 * Acc@1 0.761 Acc@5 0.000
83
TRAINING
Epoch: [83][0/1]	Time  0.967 ( 0.967)	Data  0.256 ( 0.256)	Loss 7.7816e-02 (7.7816e-02)	Acc@1   0.93 (  0.93)	Acc@5   0.00 (  0.00)
[0.9322231555900912]
Test: [0/1]	Time  0.243 ( 0.243)	Loss 9.5340e-01 (9.5340e-01)	Acc@1   0.71 (  0.71)	Acc@5   0.00 (  0.00)
 * Acc@1 0.708 Acc@5 0.000
Test: [0/1]	Time  0.296 ( 0.296)	Loss 1.5428e-01 (1.5428e-01)	Acc@1   0.76 (  0.76)	Acc@5   0.00 (  0.00)
 * Acc@1 0.762 Acc@5 0.000
84
TRAINING
Epoch: [84][0/1]	Time  0.949 ( 0.949)	Data  0.243 ( 0.243)	Loss 7.7810e-02 (7.7810e-02)	Acc@1   0.93 (  0.93)	Acc@5   0.00 (  0.00)
[0.9323767886774923]
Test: [0/1]	Time  0.247 ( 0.247)	Loss 9.5326e-01 (9.5326e-01)	Acc@1   0.71 (  0.71)	Acc@5   0.00 (  0.00)
 * Acc@1 0.708 Acc@5 0.000
Test: [0/1]	Time  0.294 ( 0.294)	Loss 1.5421e-01 (1.5421e-01)	Acc@1   0.76 (  0.76)	Acc@5   0.00 (  0.00)
 * Acc@1 0.763 Acc@5 0.000
85
TRAINING
Epoch: [85][0/1]	Time  0.973 ( 0.973)	Data  0.270 ( 0.270)	Loss 7.7803e-02 (7.7803e-02)	Acc@1   0.93 (  0.93)	Acc@5   0.00 (  0.00)
[0.9325810387813027]
Test: [0/1]	Time  0.249 ( 0.249)	Loss 9.5311e-01 (9.5311e-01)	Acc@1   0.71 (  0.71)	Acc@5   0.00 (  0.00)
 * Acc@1 0.708 Acc@5 0.000
Test: [0/1]	Time  0.323 ( 0.323)	Loss 1.5415e-01 (1.5415e-01)	Acc@1   0.76 (  0.76)	Acc@5   0.00 (  0.00)
 * Acc@1 0.764 Acc@5 0.000
86
TRAINING
Epoch: [86][0/1]	Time  0.956 ( 0.956)	Data  0.262 ( 0.262)	Loss 7.7798e-02 (7.7798e-02)	Acc@1   0.93 (  0.93)	Acc@5   0.00 (  0.00)
[0.9327790293488504]
Test: [0/1]	Time  0.245 ( 0.245)	Loss 9.5295e-01 (9.5295e-01)	Acc@1   0.71 (  0.71)	Acc@5   0.00 (  0.00)
 * Acc@1 0.708 Acc@5 0.000
Test: [0/1]	Time  0.294 ( 0.294)	Loss 1.5410e-01 (1.5410e-01)	Acc@1   0.76 (  0.76)	Acc@5   0.00 (  0.00)
 * Acc@1 0.764 Acc@5 0.000
87
TRAINING
Epoch: [87][0/1]	Time  0.958 ( 0.958)	Data  0.262 ( 0.262)	Loss 7.7795e-02 (7.7795e-02)	Acc@1   0.93 (  0.93)	Acc@5   0.00 (  0.00)
[0.9329706957838828]
Test: [0/1]	Time  0.249 ( 0.249)	Loss 9.5279e-01 (9.5279e-01)	Acc@1   0.71 (  0.71)	Acc@5   0.00 (  0.00)
 * Acc@1 0.709 Acc@5 0.000
Test: [0/1]	Time  0.300 ( 0.300)	Loss 1.5406e-01 (1.5406e-01)	Acc@1   0.76 (  0.76)	Acc@5   0.00 (  0.00)
 * Acc@1 0.765 Acc@5 0.000
88
TRAINING
Epoch: [88][0/1]	Time  0.953 ( 0.953)	Data  0.259 ( 0.259)	Loss 7.7798e-02 (7.7798e-02)	Acc@1   0.93 (  0.93)	Acc@5   0.00 (  0.00)
[0.9331561977757478]
Test: [0/1]	Time  0.243 ( 0.243)	Loss 9.5263e-01 (9.5263e-01)	Acc@1   0.71 (  0.71)	Acc@5   0.00 (  0.00)
 * Acc@1 0.709 Acc@5 0.000
Test: [0/1]	Time  0.295 ( 0.295)	Loss 1.5403e-01 (1.5403e-01)	Acc@1   0.77 (  0.77)	Acc@5   0.00 (  0.00)
 * Acc@1 0.765 Acc@5 0.000
89
TRAINING
Epoch: [89][0/1]	Time  0.930 ( 0.930)	Data  0.240 ( 0.240)	Loss 7.7803e-02 (7.7803e-02)	Acc@1   0.93 (  0.93)	Acc@5   0.00 (  0.00)
[0.9333357084543272]
Test: [0/1]	Time  0.258 ( 0.258)	Loss 9.5246e-01 (9.5246e-01)	Acc@1   0.71 (  0.71)	Acc@5   0.00 (  0.00)
 * Acc@1 0.709 Acc@5 0.000
Test: [0/1]	Time  0.306 ( 0.306)	Loss 1.5400e-01 (1.5400e-01)	Acc@1   0.77 (  0.77)	Acc@5   0.00 (  0.00)
 * Acc@1 0.766 Acc@5 0.000
90
TRAINING
Epoch: [90][0/1]	Time  0.963 ( 0.963)	Data  0.251 ( 0.251)	Loss 7.7808e-02 (7.7808e-02)	Acc@1   0.93 (  0.93)	Acc@5   0.00 (  0.00)
[0.9335092033299535]
Test: [0/1]	Time  0.236 ( 0.236)	Loss 9.5230e-01 (9.5230e-01)	Acc@1   0.71 (  0.71)	Acc@5   0.00 (  0.00)
 * Acc@1 0.709 Acc@5 0.000
Test: [0/1]	Time  0.288 ( 0.288)	Loss 1.5397e-01 (1.5397e-01)	Acc@1   0.77 (  0.77)	Acc@5   0.00 (  0.00)
 * Acc@1 0.766 Acc@5 0.000
91
TRAINING
Epoch: [91][0/1]	Time  0.965 ( 0.965)	Data  0.253 ( 0.253)	Loss 7.7808e-02 (7.7808e-02)	Acc@1   0.93 (  0.93)	Acc@5   0.00 (  0.00)
[0.9336762883183958]
Test: [0/1]	Time  0.244 ( 0.244)	Loss 9.5215e-01 (9.5215e-01)	Acc@1   0.71 (  0.71)	Acc@5   0.00 (  0.00)
 * Acc@1 0.709 Acc@5 0.000
Test: [0/1]	Time  0.296 ( 0.296)	Loss 1.5393e-01 (1.5393e-01)	Acc@1   0.77 (  0.77)	Acc@5   0.00 (  0.00)
 * Acc@1 0.767 Acc@5 0.000
92
TRAINING
Epoch: [92][0/1]	Time  0.977 ( 0.977)	Data  0.279 ( 0.279)	Loss 7.7800e-02 (7.7800e-02)	Acc@1   0.93 (  0.93)	Acc@5   0.00 (  0.00)
[0.9338188656768938]
Test: [0/1]	Time  0.248 ( 0.248)	Loss 9.5201e-01 (9.5201e-01)	Acc@1   0.71 (  0.71)	Acc@5   0.00 (  0.00)
 * Acc@1 0.710 Acc@5 0.000
Test: [0/1]	Time  0.298 ( 0.298)	Loss 1.5389e-01 (1.5389e-01)	Acc@1   0.77 (  0.77)	Acc@5   0.00 (  0.00)
 * Acc@1 0.767 Acc@5 0.000
93
TRAINING
Epoch: [93][0/1]	Time  0.942 ( 0.942)	Data  0.245 ( 0.245)	Loss 7.7786e-02 (7.7786e-02)	Acc@1   0.93 (  0.93)	Acc@5   0.00 (  0.00)
[0.9338685493605224]
Test: [0/1]	Time  0.242 ( 0.242)	Loss 9.5188e-01 (9.5188e-01)	Acc@1   0.71 (  0.71)	Acc@5   0.00 (  0.00)
 * Acc@1 0.710 Acc@5 0.000
Test: [0/1]	Time  0.300 ( 0.300)	Loss 1.5385e-01 (1.5385e-01)	Acc@1   0.77 (  0.77)	Acc@5   0.00 (  0.00)
 * Acc@1 0.767 Acc@5 0.000
94
TRAINING
Epoch: [94][0/1]	Time  0.947 ( 0.947)	Data  0.246 ( 0.246)	Loss 7.7767e-02 (7.7767e-02)	Acc@1   0.93 (  0.93)	Acc@5   0.00 (  0.00)
[0.933910196031906]
Test: [0/1]	Time  0.247 ( 0.247)	Loss 9.5175e-01 (9.5175e-01)	Acc@1   0.71 (  0.71)	Acc@5   0.00 (  0.00)
 * Acc@1 0.710 Acc@5 0.000
Test: [0/1]	Time  0.293 ( 0.293)	Loss 1.5381e-01 (1.5381e-01)	Acc@1   0.77 (  0.77)	Acc@5   0.00 (  0.00)
 * Acc@1 0.767 Acc@5 0.000
95
TRAINING
Epoch: [95][0/1]	Time  0.973 ( 0.973)	Data  0.267 ( 0.267)	Loss 7.7747e-02 (7.7747e-02)	Acc@1   0.93 (  0.93)	Acc@5   0.00 (  0.00)
[0.9339454455302358]
Test: [0/1]	Time  0.246 ( 0.246)	Loss 9.5163e-01 (9.5163e-01)	Acc@1   0.71 (  0.71)	Acc@5   0.00 (  0.00)
 * Acc@1 0.710 Acc@5 0.000
Test: [0/1]	Time  0.299 ( 0.299)	Loss 1.5378e-01 (1.5378e-01)	Acc@1   0.77 (  0.77)	Acc@5   0.00 (  0.00)
 * Acc@1 0.768 Acc@5 0.000
96
TRAINING
Epoch: [96][0/1]	Time  0.948 ( 0.948)	Data  0.257 ( 0.257)	Loss 7.7729e-02 (7.7729e-02)	Acc@1   0.93 (  0.93)	Acc@5   0.00 (  0.00)
[0.9339759091311949]
Test: [0/1]	Time  0.249 ( 0.249)	Loss 9.5151e-01 (9.5151e-01)	Acc@1   0.71 (  0.71)	Acc@5   0.00 (  0.00)
 * Acc@1 0.710 Acc@5 0.000
Test: [0/1]	Time  0.297 ( 0.297)	Loss 1.5375e-01 (1.5375e-01)	Acc@1   0.77 (  0.77)	Acc@5   0.00 (  0.00)
 * Acc@1 0.768 Acc@5 0.000
97
TRAINING
Epoch: [97][0/1]	Time  0.944 ( 0.944)	Data  0.258 ( 0.258)	Loss 7.7714e-02 (7.7714e-02)	Acc@1   0.93 (  0.93)	Acc@5   0.00 (  0.00)
[0.9340031279879697]
Test: [0/1]	Time  0.245 ( 0.245)	Loss 9.5140e-01 (9.5140e-01)	Acc@1   0.71 (  0.71)	Acc@5   0.00 (  0.00)
 * Acc@1 0.710 Acc@5 0.000
Test: [0/1]	Time  0.297 ( 0.297)	Loss 1.5373e-01 (1.5373e-01)	Acc@1   0.77 (  0.77)	Acc@5   0.00 (  0.00)
 * Acc@1 0.768 Acc@5 0.000
98
TRAINING
Epoch: [98][0/1]	Time  0.958 ( 0.958)	Data  0.269 ( 0.269)	Loss 7.7701e-02 (7.7701e-02)	Acc@1   0.93 (  0.93)	Acc@5   0.00 (  0.00)
[0.9340200112085897]
Test: [0/1]	Time  0.248 ( 0.248)	Loss 9.5129e-01 (9.5129e-01)	Acc@1   0.71 (  0.71)	Acc@5   0.00 (  0.00)
 * Acc@1 0.710 Acc@5 0.000
Test: [0/1]	Time  0.298 ( 0.298)	Loss 1.5372e-01 (1.5372e-01)	Acc@1   0.77 (  0.77)	Acc@5   0.00 (  0.00)
 * Acc@1 0.768 Acc@5 0.000
99
TRAINING
Epoch: [99][0/1]	Time  0.953 ( 0.953)	Data  0.257 ( 0.257)	Loss 7.7692e-02 (7.7692e-02)	Acc@1   0.93 (  0.93)	Acc@5   0.00 (  0.00)
[0.9340279414376387]
Test: [0/1]	Time  0.240 ( 0.240)	Loss 9.5119e-01 (9.5119e-01)	Acc@1   0.71 (  0.71)	Acc@5   0.00 (  0.00)
 * Acc@1 0.710 Acc@5 0.000
Test: [0/1]	Time  0.293 ( 0.293)	Loss 1.5370e-01 (1.5370e-01)	Acc@1   0.77 (  0.77)	Acc@5   0.00 (  0.00)
 * Acc@1 0.768 Acc@5 0.000
=> using pre-trained model 'st_resnet'
s/ohp/session_1
torch.Size([640, 3, 224, 224])
(640, 22)
attach reg
0
TRAINING
/home/helenr6/Adv_mapper/train_split.py:125: UserWarning: You have chosen to seed training. This will turn on the CUDNN deterministic setting, which can slow down your training considerably! You may see unexpected behavior when restarting from checkpoints.
  warnings.warn('You have chosen to seed training. '
/localscratch/helenr6.6279052.0/env/lib/python3.7/site-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  cpuset_checked))
Epoch: [0][0/1]	Time  5.312 ( 5.312)	Data  1.851 ( 1.851)	Loss 1.6950e+00 (1.6950e+00)	Acc@1   0.01 (  0.01)	Acc@5   0.00 (  0.00)
[0.010892463632573691]
Test: [0/1]	Time  0.475 ( 0.475)	Loss 1.1928e+00 (1.1928e+00)	Acc@1   0.02 (  0.02)	Acc@5   0.00 (  0.00)
 * Acc@1 0.022 Acc@5 0.000
Test: [0/1]	Time  0.584 ( 0.584)	Loss 9.0461e-01 (9.0461e-01)	Acc@1   0.06 (  0.06)	Acc@5   0.00 (  0.00)
 * Acc@1 0.062 Acc@5 0.000
1
TRAINING
Epoch: [1][0/1]	Time  1.019 ( 1.019)	Data  0.311 ( 0.311)	Loss 1.6217e+00 (1.6217e+00)	Acc@1   0.01 (  0.01)	Acc@5   0.00 (  0.00)
[0.014649337683585246]
Test: [0/1]	Time  0.279 ( 0.279)	Loss 1.1827e+00 (1.1827e+00)	Acc@1   0.03 (  0.03)	Acc@5   0.00 (  0.00)
 * Acc@1 0.029 Acc@5 0.000
Test: [0/1]	Time  0.327 ( 0.327)	Loss 8.6101e-01 (8.6101e-01)	Acc@1   0.07 (  0.07)	Acc@5   0.00 (  0.00)
 * Acc@1 0.069 Acc@5 0.000
2
TRAINING
Epoch: [2][0/1]	Time  0.978 ( 0.978)	Data  0.280 ( 0.280)	Loss 1.5096e+00 (1.5096e+00)	Acc@1   0.02 (  0.02)	Acc@5   0.00 (  0.00)
[0.02112046371306916]
Test: [0/1]	Time  0.269 ( 0.269)	Loss 1.1699e+00 (1.1699e+00)	Acc@1   0.03 (  0.03)	Acc@5   0.00 (  0.00)
 * Acc@1 0.028 Acc@5 0.000
Test: [0/1]	Time  0.310 ( 0.310)	Loss 8.2395e-01 (8.2395e-01)	Acc@1   0.08 (  0.08)	Acc@5   0.00 (  0.00)
 * Acc@1 0.078 Acc@5 0.000
3
TRAINING
Epoch: [3][0/1]	Time  0.958 ( 0.958)	Data  0.245 ( 0.245)	Loss 1.3973e+00 (1.3973e+00)	Acc@1   0.03 (  0.03)	Acc@5   0.00 (  0.00)
[0.02839592734388481]
Test: [0/1]	Time  0.242 ( 0.242)	Loss 1.1575e+00 (1.1575e+00)	Acc@1   0.04 (  0.04)	Acc@5   0.00 (  0.00)
 * Acc@1 0.036 Acc@5 0.000
Test: [0/1]	Time  0.290 ( 0.290)	Loss 8.0508e-01 (8.0508e-01)	Acc@1   0.08 (  0.08)	Acc@5   0.00 (  0.00)
 * Acc@1 0.084 Acc@5 0.000
4
TRAINING
Epoch: [4][0/1]	Time  0.947 ( 0.947)	Data  0.258 ( 0.258)	Loss 1.3068e+00 (1.3068e+00)	Acc@1   0.04 (  0.04)	Acc@5   0.00 (  0.00)
[0.037354386717651025]
Test: [0/1]	Time  0.247 ( 0.247)	Loss 1.1465e+00 (1.1465e+00)	Acc@1   0.05 (  0.05)	Acc@5   0.00 (  0.00)
 * Acc@1 0.048 Acc@5 0.000
Test: [0/1]	Time  0.318 ( 0.318)	Loss 8.0070e-01 (8.0070e-01)	Acc@1   0.09 (  0.09)	Acc@5   0.00 (  0.00)
 * Acc@1 0.090 Acc@5 0.000
5
TRAINING
Epoch: [5][0/1]	Time  0.974 ( 0.974)	Data  0.272 ( 0.272)	Loss 1.2370e+00 (1.2370e+00)	Acc@1   0.05 (  0.05)	Acc@5   0.00 (  0.00)
[0.04852842341596897]
Test: [0/1]	Time  0.260 ( 0.260)	Loss 1.1360e+00 (1.1360e+00)	Acc@1   0.07 (  0.07)	Acc@5   0.00 (  0.00)
 * Acc@1 0.075 Acc@5 0.000
Test: [0/1]	Time  0.306 ( 0.306)	Loss 7.9634e-01 (7.9634e-01)	Acc@1   0.10 (  0.10)	Acc@5   0.00 (  0.00)
 * Acc@1 0.095 Acc@5 0.000
6
TRAINING
Epoch: [6][0/1]	Time  0.962 ( 0.962)	Data  0.256 ( 0.256)	Loss 1.1706e+00 (1.1706e+00)	Acc@1   0.06 (  0.06)	Acc@5   0.00 (  0.00)
[0.06333552581467441]
Test: [0/1]	Time  0.248 ( 0.248)	Loss 1.1246e+00 (1.1246e+00)	Acc@1   0.11 (  0.11)	Acc@5   0.00 (  0.00)
 * Acc@1 0.110 Acc@5 0.000
Test: [0/1]	Time  0.330 ( 0.330)	Loss 7.7676e-01 (7.7676e-01)	Acc@1   0.10 (  0.10)	Acc@5   0.00 (  0.00)
 * Acc@1 0.104 Acc@5 0.000
7
TRAINING
Epoch: [7][0/1]	Time  0.953 ( 0.953)	Data  0.248 ( 0.248)	Loss 1.0898e+00 (1.0898e+00)	Acc@1   0.08 (  0.08)	Acc@5   0.00 (  0.00)
[0.0791555461485816]
Test: [0/1]	Time  0.241 ( 0.241)	Loss 1.1116e+00 (1.1116e+00)	Acc@1   0.14 (  0.14)	Acc@5   0.00 (  0.00)
 * Acc@1 0.144 Acc@5 0.000
Test: [0/1]	Time  0.336 ( 0.336)	Loss 7.3537e-01 (7.3537e-01)	Acc@1   0.11 (  0.11)	Acc@5   0.00 (  0.00)
 * Acc@1 0.113 Acc@5 0.000
8
TRAINING
Epoch: [8][0/1]	Time  0.963 ( 0.963)	Data  0.253 ( 0.253)	Loss 9.8771e-01 (9.8771e-01)	Acc@1   0.10 (  0.10)	Acc@5   0.00 (  0.00)
[0.09729018769942996]
Test: [0/1]	Time  0.241 ( 0.241)	Loss 1.0974e+00 (1.0974e+00)	Acc@1   0.19 (  0.19)	Acc@5   0.00 (  0.00)
 * Acc@1 0.186 Acc@5 0.000
Test: [0/1]	Time  0.295 ( 0.295)	Loss 6.7728e-01 (6.7728e-01)	Acc@1   0.12 (  0.12)	Acc@5   0.00 (  0.00)
 * Acc@1 0.122 Acc@5 0.000
9
TRAINING
Epoch: [9][0/1]	Time  0.956 ( 0.956)	Data  0.251 ( 0.251)	Loss 8.7230e-01 (8.7230e-01)	Acc@1   0.12 (  0.12)	Acc@5   0.00 (  0.00)
[0.11702887738960088]
Test: [0/1]	Time  0.242 ( 0.242)	Loss 1.0837e+00 (1.0837e+00)	Acc@1   0.23 (  0.23)	Acc@5   0.00 (  0.00)
 * Acc@1 0.229 Acc@5 0.000
Test: [0/1]	Time  0.299 ( 0.299)	Loss 6.1548e-01 (6.1548e-01)	Acc@1   0.13 (  0.13)	Acc@5   0.00 (  0.00)
 * Acc@1 0.131 Acc@5 0.000
10
TRAINING
Epoch: [10][0/1]	Time  0.978 ( 0.978)	Data  0.280 ( 0.280)	Loss 7.5962e-01 (7.5962e-01)	Acc@1   0.14 (  0.14)	Acc@5   0.00 (  0.00)
[0.14075962435747702]
Test: [0/1]	Time  0.260 ( 0.260)	Loss 1.0716e+00 (1.0716e+00)	Acc@1   0.27 (  0.27)	Acc@5   0.00 (  0.00)
 * Acc@1 0.273 Acc@5 0.000
Test: [0/1]	Time  0.309 ( 0.309)	Loss 5.6257e-01 (5.6257e-01)	Acc@1   0.15 (  0.15)	Acc@5   0.00 (  0.00)
 * Acc@1 0.150 Acc@5 0.000
11
TRAINING
Epoch: [11][0/1]	Time  0.960 ( 0.960)	Data  0.260 ( 0.260)	Loss 6.6394e-01 (6.6394e-01)	Acc@1   0.17 (  0.17)	Acc@5   0.00 (  0.00)
[0.16929137478424233]
Test: [0/1]	Time  0.269 ( 0.269)	Loss 1.0616e+00 (1.0616e+00)	Acc@1   0.32 (  0.32)	Acc@5   0.00 (  0.00)
 * Acc@1 0.319 Acc@5 0.000
Test: [0/1]	Time  0.317 ( 0.317)	Loss 5.2436e-01 (5.2436e-01)	Acc@1   0.17 (  0.17)	Acc@5   0.00 (  0.00)
 * Acc@1 0.166 Acc@5 0.000
12
TRAINING
Epoch: [12][0/1]	Time  1.026 ( 1.026)	Data  0.335 ( 0.335)	Loss 5.9038e-01 (5.9038e-01)	Acc@1   0.20 (  0.20)	Acc@5   0.00 (  0.00)
[0.19862756847653174]
Test: [0/1]	Time  0.265 ( 0.265)	Loss 1.0532e+00 (1.0532e+00)	Acc@1   0.36 (  0.36)	Acc@5   0.00 (  0.00)
 * Acc@1 0.365 Acc@5 0.000
Test: [0/1]	Time  0.313 ( 0.313)	Loss 4.9805e-01 (4.9805e-01)	Acc@1   0.18 (  0.18)	Acc@5   0.00 (  0.00)
 * Acc@1 0.176 Acc@5 0.000
13
TRAINING
Epoch: [13][0/1]	Time  1.029 ( 1.029)	Data  0.323 ( 0.323)	Loss 5.3386e-01 (5.3386e-01)	Acc@1   0.23 (  0.23)	Acc@5   0.00 (  0.00)
[0.2325885192584711]
Test: [0/1]	Time  0.256 ( 0.256)	Loss 1.0451e+00 (1.0451e+00)	Acc@1   0.40 (  0.40)	Acc@5   0.00 (  0.00)
 * Acc@1 0.405 Acc@5 0.000
Test: [0/1]	Time  0.319 ( 0.319)	Loss 4.7559e-01 (4.7559e-01)	Acc@1   0.19 (  0.19)	Acc@5   0.00 (  0.00)
 * Acc@1 0.188 Acc@5 0.000
14
TRAINING
Epoch: [14][0/1]	Time  1.025 ( 1.025)	Data  0.328 ( 0.328)	Loss 4.8408e-01 (4.8408e-01)	Acc@1   0.27 (  0.27)	Acc@5   0.00 (  0.00)
[0.27215029966829085]
Test: [0/1]	Time  0.262 ( 0.262)	Loss 1.0364e+00 (1.0364e+00)	Acc@1   0.44 (  0.44)	Acc@5   0.00 (  0.00)
 * Acc@1 0.442 Acc@5 0.000
Test: [0/1]	Time  0.310 ( 0.310)	Loss 4.4949e-01 (4.4949e-01)	Acc@1   0.21 (  0.21)	Acc@5   0.00 (  0.00)
 * Acc@1 0.210 Acc@5 0.000
15
TRAINING
Epoch: [15][0/1]	Time  0.943 ( 0.943)	Data  0.246 ( 0.246)	Loss 4.3238e-01 (4.3238e-01)	Acc@1   0.31 (  0.31)	Acc@5   0.00 (  0.00)
[0.3137681354051385]
Test: [0/1]	Time  0.243 ( 0.243)	Loss 1.0268e+00 (1.0268e+00)	Acc@1   0.48 (  0.48)	Acc@5   0.00 (  0.00)
 * Acc@1 0.478 Acc@5 0.000
Test: [0/1]	Time  0.297 ( 0.297)	Loss 4.1710e-01 (4.1710e-01)	Acc@1   0.23 (  0.23)	Acc@5   0.00 (  0.00)
 * Acc@1 0.232 Acc@5 0.000
16
TRAINING
Epoch: [16][0/1]	Time  0.954 ( 0.954)	Data  0.249 ( 0.249)	Loss 3.7630e-01 (3.7630e-01)	Acc@1   0.36 (  0.36)	Acc@5   0.00 (  0.00)
[0.35715049731248616]
Test: [0/1]	Time  0.241 ( 0.241)	Loss 1.0169e+00 (1.0169e+00)	Acc@1   0.50 (  0.50)	Acc@5   0.00 (  0.00)
 * Acc@1 0.504 Acc@5 0.000
Test: [0/1]	Time  0.292 ( 0.292)	Loss 3.8135e-01 (3.8135e-01)	Acc@1   0.26 (  0.26)	Acc@5   0.00 (  0.00)
 * Acc@1 0.256 Acc@5 0.000
17
TRAINING
Epoch: [17][0/1]	Time  0.943 ( 0.943)	Data  0.245 ( 0.245)	Loss 3.1972e-01 (3.1972e-01)	Acc@1   0.40 (  0.40)	Acc@5   0.00 (  0.00)
[0.40195461624431494]
Test: [0/1]	Time  0.260 ( 0.260)	Loss 1.0079e+00 (1.0079e+00)	Acc@1   0.52 (  0.52)	Acc@5   0.00 (  0.00)
 * Acc@1 0.523 Acc@5 0.000
Test: [0/1]	Time  0.332 ( 0.332)	Loss 3.4802e-01 (3.4802e-01)	Acc@1   0.29 (  0.29)	Acc@5   0.00 (  0.00)
 * Acc@1 0.290 Acc@5 0.000
18
TRAINING
Epoch: [18][0/1]	Time  0.954 ( 0.954)	Data  0.257 ( 0.257)	Loss 2.6930e-01 (2.6930e-01)	Acc@1   0.44 (  0.44)	Acc@5   0.00 (  0.00)
[0.44491688662071593]
Test: [0/1]	Time  0.275 ( 0.275)	Loss 1.0003e+00 (1.0003e+00)	Acc@1   0.54 (  0.54)	Acc@5   0.00 (  0.00)
 * Acc@1 0.541 Acc@5 0.000
Test: [0/1]	Time  0.316 ( 0.316)	Loss 3.2170e-01 (3.2170e-01)	Acc@1   0.32 (  0.32)	Acc@5   0.00 (  0.00)
 * Acc@1 0.322 Acc@5 0.000
19
TRAINING
Epoch: [19][0/1]	Time  0.965 ( 0.965)	Data  0.280 ( 0.280)	Loss 2.3001e-01 (2.3001e-01)	Acc@1   0.49 (  0.49)	Acc@5   0.00 (  0.00)
[0.4910910922864489]
Test: [0/1]	Time  0.263 ( 0.263)	Loss 9.9440e-01 (9.9440e-01)	Acc@1   0.55 (  0.55)	Acc@5   0.00 (  0.00)
 * Acc@1 0.553 Acc@5 0.000
Test: [0/1]	Time  0.311 ( 0.311)	Loss 3.0322e-01 (3.0322e-01)	Acc@1   0.35 (  0.35)	Acc@5   0.00 (  0.00)
 * Acc@1 0.347 Acc@5 0.000
20
TRAINING
Epoch: [20][0/1]	Time  0.939 ( 0.939)	Data  0.245 ( 0.245)	Loss 2.0244e-01 (2.0244e-01)	Acc@1   0.54 (  0.54)	Acc@5   0.00 (  0.00)
[0.5378115224596423]
Test: [0/1]	Time  0.240 ( 0.240)	Loss 9.8976e-01 (9.8976e-01)	Acc@1   0.56 (  0.56)	Acc@5   0.00 (  0.00)
 * Acc@1 0.562 Acc@5 0.000
Test: [0/1]	Time  0.291 ( 0.291)	Loss 2.8973e-01 (2.8973e-01)	Acc@1   0.37 (  0.37)	Acc@5   0.00 (  0.00)
 * Acc@1 0.372 Acc@5 0.000
21
TRAINING
Epoch: [21][0/1]	Time  1.007 ( 1.007)	Data  0.311 ( 0.311)	Loss 1.8312e-01 (1.8312e-01)	Acc@1   0.58 (  0.58)	Acc@5   0.00 (  0.00)
[0.5839356645266421]
Test: [0/1]	Time  0.272 ( 0.272)	Loss 9.8572e-01 (9.8572e-01)	Acc@1   0.57 (  0.57)	Acc@5   0.00 (  0.00)
 * Acc@1 0.570 Acc@5 0.000
Test: [0/1]	Time  0.325 ( 0.325)	Loss 2.7692e-01 (2.7692e-01)	Acc@1   0.40 (  0.40)	Acc@5   0.00 (  0.00)
 * Acc@1 0.398 Acc@5 0.000
22
TRAINING
Epoch: [22][0/1]	Time  0.934 ( 0.934)	Data  0.249 ( 0.249)	Loss 1.6709e-01 (1.6709e-01)	Acc@1   0.63 (  0.63)	Acc@5   0.00 (  0.00)
[0.628514947558034]
Test: [0/1]	Time  0.271 ( 0.271)	Loss 9.8178e-01 (9.8178e-01)	Acc@1   0.58 (  0.58)	Acc@5   0.00 (  0.00)
 * Acc@1 0.577 Acc@5 0.000
Test: [0/1]	Time  0.318 ( 0.318)	Loss 2.6181e-01 (2.6181e-01)	Acc@1   0.42 (  0.42)	Acc@5   0.00 (  0.00)
 * Acc@1 0.423 Acc@5 0.000
23
TRAINING
Epoch: [23][0/1]	Time  0.954 ( 0.954)	Data  0.249 ( 0.249)	Loss 1.5077e-01 (1.5077e-01)	Acc@1   0.67 (  0.67)	Acc@5   0.00 (  0.00)
[0.6698732261746146]
Test: [0/1]	Time  0.244 ( 0.244)	Loss 9.7783e-01 (9.7783e-01)	Acc@1   0.58 (  0.58)	Acc@5   0.00 (  0.00)
 * Acc@1 0.583 Acc@5 0.000
Test: [0/1]	Time  0.304 ( 0.304)	Loss 2.4422e-01 (2.4422e-01)	Acc@1   0.44 (  0.44)	Acc@5   0.00 (  0.00)
 * Acc@1 0.442 Acc@5 0.000
24
TRAINING
Epoch: [24][0/1]	Time  0.978 ( 0.978)	Data  0.291 ( 0.291)	Loss 1.3354e-01 (1.3354e-01)	Acc@1   0.71 (  0.71)	Acc@5   0.00 (  0.00)
[0.7086552297999058]
Test: [0/1]	Time  0.283 ( 0.283)	Loss 9.7408e-01 (9.7408e-01)	Acc@1   0.59 (  0.59)	Acc@5   0.00 (  0.00)
 * Acc@1 0.587 Acc@5 0.000
Test: [0/1]	Time  0.319 ( 0.319)	Loss 2.2639e-01 (2.2639e-01)	Acc@1   0.46 (  0.46)	Acc@5   0.00 (  0.00)
 * Acc@1 0.462 Acc@5 0.000
25
TRAINING
Epoch: [25][0/1]	Time  0.946 ( 0.946)	Data  0.247 ( 0.247)	Loss 1.1727e-01 (1.1727e-01)	Acc@1   0.74 (  0.74)	Acc@5   0.00 (  0.00)
[0.7398566178000687]
Test: [0/1]	Time  0.239 ( 0.239)	Loss 9.7086e-01 (9.7086e-01)	Acc@1   0.58 (  0.58)	Acc@5   0.00 (  0.00)
 * Acc@1 0.583 Acc@5 0.000
Test: [0/1]	Time  0.304 ( 0.304)	Loss 2.1124e-01 (2.1124e-01)	Acc@1   0.48 (  0.48)	Acc@5   0.00 (  0.00)
 * Acc@1 0.482 Acc@5 0.000
26
TRAINING
Epoch: [26][0/1]	Time  0.944 ( 0.944)	Data  0.246 ( 0.246)	Loss 1.0450e-01 (1.0450e-01)	Acc@1   0.77 (  0.77)	Acc@5   0.00 (  0.00)
[0.7660863569305867]
Test: [0/1]	Time  0.241 ( 0.241)	Loss 9.6828e-01 (9.6828e-01)	Acc@1   0.58 (  0.58)	Acc@5   0.00 (  0.00)
 * Acc@1 0.580 Acc@5 0.000
Test: [0/1]	Time  0.293 ( 0.293)	Loss 2.0048e-01 (2.0048e-01)	Acc@1   0.50 (  0.50)	Acc@5   0.00 (  0.00)
 * Acc@1 0.503 Acc@5 0.000
27
TRAINING
Epoch: [27][0/1]	Time  0.983 ( 0.983)	Data  0.282 ( 0.282)	Loss 9.6631e-02 (9.6631e-02)	Acc@1   0.79 (  0.79)	Acc@5   0.00 (  0.00)
[0.7890516681888751]
Test: [0/1]	Time  0.269 ( 0.269)	Loss 9.6624e-01 (9.6624e-01)	Acc@1   0.58 (  0.58)	Acc@5   0.00 (  0.00)
 * Acc@1 0.582 Acc@5 0.000
Test: [0/1]	Time  0.318 ( 0.318)	Loss 1.9380e-01 (1.9380e-01)	Acc@1   0.52 (  0.52)	Acc@5   0.00 (  0.00)
 * Acc@1 0.524 Acc@5 0.000
28
TRAINING
Epoch: [28][0/1]	Time  0.993 ( 0.993)	Data  0.284 ( 0.284)	Loss 9.3111e-02 (9.3111e-02)	Acc@1   0.81 (  0.81)	Acc@5   0.00 (  0.00)
[0.8099843763138257]
Test: [0/1]	Time  0.256 ( 0.256)	Loss 9.6444e-01 (9.6444e-01)	Acc@1   0.59 (  0.59)	Acc@5   0.00 (  0.00)
 * Acc@1 0.592 Acc@5 0.000
Test: [0/1]	Time  0.308 ( 0.308)	Loss 1.8930e-01 (1.8930e-01)	Acc@1   0.54 (  0.54)	Acc@5   0.00 (  0.00)
 * Acc@1 0.545 Acc@5 0.000
29
TRAINING
Epoch: [29][0/1]	Time  0.954 ( 0.954)	Data  0.250 ( 0.250)	Loss 9.1903e-02 (9.1903e-02)	Acc@1   0.83 (  0.83)	Acc@5   0.00 (  0.00)
[0.827798724329914]
Test: [0/1]	Time  0.242 ( 0.242)	Loss 9.6252e-01 (9.6252e-01)	Acc@1   0.60 (  0.60)	Acc@5   0.00 (  0.00)
 * Acc@1 0.601 Acc@5 0.000
Test: [0/1]	Time  0.291 ( 0.291)	Loss 1.8480e-01 (1.8480e-01)	Acc@1   0.57 (  0.57)	Acc@5   0.00 (  0.00)
 * Acc@1 0.566 Acc@5 0.000
30
TRAINING
Epoch: [30][0/1]	Time  0.985 ( 0.985)	Data  0.293 ( 0.293)	Loss 9.0769e-02 (9.0769e-02)	Acc@1   0.84 (  0.84)	Acc@5   0.00 (  0.00)
[0.8427157029979733]
Test: [0/1]	Time  0.261 ( 0.261)	Loss 9.6032e-01 (9.6032e-01)	Acc@1   0.61 (  0.61)	Acc@5   0.00 (  0.00)
 * Acc@1 0.608 Acc@5 0.000
Test: [0/1]	Time  0.314 ( 0.314)	Loss 1.7910e-01 (1.7910e-01)	Acc@1   0.59 (  0.59)	Acc@5   0.00 (  0.00)
 * Acc@1 0.586 Acc@5 0.000
31
TRAINING
Epoch: [31][0/1]	Time  0.964 ( 0.964)	Data  0.265 ( 0.265)	Loss 8.8445e-02 (8.8445e-02)	Acc@1   0.85 (  0.85)	Acc@5   0.00 (  0.00)
[0.8533904800427194]
Test: [0/1]	Time  0.259 ( 0.259)	Loss 9.5789e-01 (9.5789e-01)	Acc@1   0.61 (  0.61)	Acc@5   0.00 (  0.00)
 * Acc@1 0.613 Acc@5 0.000
Test: [0/1]	Time  0.311 ( 0.311)	Loss 1.7238e-01 (1.7238e-01)	Acc@1   0.61 (  0.61)	Acc@5   0.00 (  0.00)
 * Acc@1 0.605 Acc@5 0.000
32
TRAINING
Epoch: [32][0/1]	Time  0.938 ( 0.938)	Data  0.244 ( 0.244)	Loss 8.5065e-02 (8.5065e-02)	Acc@1   0.86 (  0.86)	Acc@5   0.00 (  0.00)
[0.8621894034209223]
Test: [0/1]	Time  0.241 ( 0.241)	Loss 9.5539e-01 (9.5539e-01)	Acc@1   0.62 (  0.62)	Acc@5   0.00 (  0.00)
 * Acc@1 0.622 Acc@5 0.000
Test: [0/1]	Time  0.302 ( 0.302)	Loss 1.6583e-01 (1.6583e-01)	Acc@1   0.62 (  0.62)	Acc@5   0.00 (  0.00)
 * Acc@1 0.623 Acc@5 0.000
33
TRAINING
Epoch: [33][0/1]	Time  0.977 ( 0.977)	Data  0.275 ( 0.275)	Loss 8.1728e-02 (8.1728e-02)	Acc@1   0.87 (  0.87)	Acc@5   0.00 (  0.00)
[0.8662382149138173]
Test: [0/1]	Time  0.257 ( 0.257)	Loss 9.5306e-01 (9.5306e-01)	Acc@1   0.63 (  0.63)	Acc@5   0.00 (  0.00)
 * Acc@1 0.627 Acc@5 0.000
Test: [0/1]	Time  0.334 ( 0.334)	Loss 1.6074e-01 (1.6074e-01)	Acc@1   0.64 (  0.64)	Acc@5   0.00 (  0.00)
 * Acc@1 0.639 Acc@5 0.000
34
TRAINING
Epoch: [34][0/1]	Time  0.953 ( 0.953)	Data  0.256 ( 0.256)	Loss 7.9619e-02 (7.9619e-02)	Acc@1   0.87 (  0.87)	Acc@5   0.00 (  0.00)
[0.8692177565010102]
Test: [0/1]	Time  0.243 ( 0.243)	Loss 9.5102e-01 (9.5102e-01)	Acc@1   0.63 (  0.63)	Acc@5   0.00 (  0.00)
 * Acc@1 0.630 Acc@5 0.000
Test: [0/1]	Time  0.292 ( 0.292)	Loss 1.5771e-01 (1.5771e-01)	Acc@1   0.66 (  0.66)	Acc@5   0.00 (  0.00)
 * Acc@1 0.659 Acc@5 0.000
35
TRAINING
Epoch: [35][0/1]	Time  0.956 ( 0.956)	Data  0.248 ( 0.248)	Loss 7.9258e-02 (7.9258e-02)	Acc@1   0.87 (  0.87)	Acc@5   0.00 (  0.00)
[0.8715336216814207]
Test: [0/1]	Time  0.249 ( 0.249)	Loss 9.4927e-01 (9.4927e-01)	Acc@1   0.63 (  0.63)	Acc@5   0.00 (  0.00)
 * Acc@1 0.633 Acc@5 0.000
Test: [0/1]	Time  0.301 ( 0.301)	Loss 1.5641e-01 (1.5641e-01)	Acc@1   0.67 (  0.67)	Acc@5   0.00 (  0.00)
 * Acc@1 0.673 Acc@5 0.000
36
TRAINING
Epoch: [36][0/1]	Time  1.012 ( 1.012)	Data  0.268 ( 0.268)	Loss 8.0284e-02 (8.0284e-02)	Acc@1   0.87 (  0.87)	Acc@5   0.00 (  0.00)
[0.8738152439437161]
Test: [0/1]	Time  0.252 ( 0.252)	Loss 9.4774e-01 (9.4774e-01)	Acc@1   0.64 (  0.64)	Acc@5   0.00 (  0.00)
 * Acc@1 0.636 Acc@5 0.000
Test: [0/1]	Time  0.297 ( 0.297)	Loss 1.5592e-01 (1.5592e-01)	Acc@1   0.68 (  0.68)	Acc@5   0.00 (  0.00)
 * Acc@1 0.685 Acc@5 0.000
37
TRAINING
Epoch: [37][0/1]	Time  0.951 ( 0.951)	Data  0.253 ( 0.253)	Loss 8.1789e-02 (8.1789e-02)	Acc@1   0.87 (  0.87)	Acc@5   0.00 (  0.00)
[0.8742098452124893]
Test: [0/1]	Time  0.251 ( 0.251)	Loss 9.4635e-01 (9.4635e-01)	Acc@1   0.64 (  0.64)	Acc@5   0.00 (  0.00)
 * Acc@1 0.639 Acc@5 0.000
Test: [0/1]	Time  0.304 ( 0.304)	Loss 1.5534e-01 (1.5534e-01)	Acc@1   0.70 (  0.70)	Acc@5   0.00 (  0.00)
 * Acc@1 0.695 Acc@5 0.000
38
TRAINING
Epoch: [38][0/1]	Time  0.948 ( 0.948)	Data  0.248 ( 0.248)	Loss 8.2899e-02 (8.2899e-02)	Acc@1   0.87 (  0.87)	Acc@5   0.00 (  0.00)
[0.8730974999587929]
Test: [0/1]	Time  0.242 ( 0.242)	Loss 9.4505e-01 (9.4505e-01)	Acc@1   0.64 (  0.64)	Acc@5   0.00 (  0.00)
 * Acc@1 0.643 Acc@5 0.000
Test: [0/1]	Time  0.293 ( 0.293)	Loss 1.5425e-01 (1.5425e-01)	Acc@1   0.71 (  0.71)	Acc@5   0.00 (  0.00)
 * Acc@1 0.706 Acc@5 0.000
39
TRAINING
Epoch: [39][0/1]	Time  0.937 ( 0.937)	Data  0.250 ( 0.250)	Loss 8.3235e-02 (8.3235e-02)	Acc@1   0.87 (  0.87)	Acc@5   0.00 (  0.00)
[0.8716456788371513]
Test: [0/1]	Time  0.244 ( 0.244)	Loss 9.4386e-01 (9.4386e-01)	Acc@1   0.65 (  0.65)	Acc@5   0.00 (  0.00)
 * Acc@1 0.647 Acc@5 0.000
Test: [0/1]	Time  0.294 ( 0.294)	Loss 1.5281e-01 (1.5281e-01)	Acc@1   0.72 (  0.72)	Acc@5   0.00 (  0.00)
 * Acc@1 0.718 Acc@5 0.000
40
TRAINING
Epoch: [40][0/1]	Time  0.951 ( 0.951)	Data  0.254 ( 0.254)	Loss 8.2995e-02 (8.2995e-02)	Acc@1   0.87 (  0.87)	Acc@5   0.00 (  0.00)
[0.8698873284794105]
Test: [0/1]	Time  0.249 ( 0.249)	Loss 9.4283e-01 (9.4283e-01)	Acc@1   0.65 (  0.65)	Acc@5   0.00 (  0.00)
 * Acc@1 0.650 Acc@5 0.000
Test: [0/1]	Time  0.295 ( 0.295)	Loss 1.5154e-01 (1.5154e-01)	Acc@1   0.73 (  0.73)	Acc@5   0.00 (  0.00)
 * Acc@1 0.732 Acc@5 0.000
41
TRAINING
Epoch: [41][0/1]	Time  0.980 ( 0.980)	Data  0.288 ( 0.288)	Loss 8.2693e-02 (8.2693e-02)	Acc@1   0.87 (  0.87)	Acc@5   0.00 (  0.00)
[0.8690120024529191]
Test: [0/1]	Time  0.261 ( 0.261)	Loss 9.4199e-01 (9.4199e-01)	Acc@1   0.65 (  0.65)	Acc@5   0.00 (  0.00)
 * Acc@1 0.654 Acc@5 0.000
Test: [0/1]	Time  0.316 ( 0.316)	Loss 1.5089e-01 (1.5089e-01)	Acc@1   0.74 (  0.74)	Acc@5   0.00 (  0.00)
 * Acc@1 0.740 Acc@5 0.000
42
TRAINING
Epoch: [42][0/1]	Time  0.958 ( 0.958)	Data  0.243 ( 0.243)	Loss 8.2776e-02 (8.2776e-02)	Acc@1   0.87 (  0.87)	Acc@5   0.00 (  0.00)
[0.8695100145945187]
Test: [0/1]	Time  0.266 ( 0.266)	Loss 9.4131e-01 (9.4131e-01)	Acc@1   0.66 (  0.66)	Acc@5   0.00 (  0.00)
 * Acc@1 0.657 Acc@5 0.000
Test: [0/1]	Time  0.315 ( 0.315)	Loss 1.5095e-01 (1.5095e-01)	Acc@1   0.74 (  0.74)	Acc@5   0.00 (  0.00)
 * Acc@1 0.743 Acc@5 0.000
43
TRAINING
Epoch: [43][0/1]	Time  0.959 ( 0.959)	Data  0.257 ( 0.257)	Loss 8.3351e-02 (8.3351e-02)	Acc@1   0.87 (  0.87)	Acc@5   0.00 (  0.00)
[0.8714574631325973]
Test: [0/1]	Time  0.260 ( 0.260)	Loss 9.4072e-01 (9.4072e-01)	Acc@1   0.66 (  0.66)	Acc@5   0.00 (  0.00)
 * Acc@1 0.660 Acc@5 0.000
Test: [0/1]	Time  0.305 ( 0.305)	Loss 1.5148e-01 (1.5148e-01)	Acc@1   0.75 (  0.75)	Acc@5   0.00 (  0.00)
 * Acc@1 0.749 Acc@5 0.000
44
TRAINING
Epoch: [44][0/1]	Time  0.949 ( 0.949)	Data  0.247 ( 0.247)	Loss 8.4168e-02 (8.4168e-02)	Acc@1   0.87 (  0.87)	Acc@5   0.00 (  0.00)
[0.8735153969185436]
Test: [0/1]	Time  0.242 ( 0.242)	Loss 9.4015e-01 (9.4015e-01)	Acc@1   0.66 (  0.66)	Acc@5   0.00 (  0.00)
 * Acc@1 0.662 Acc@5 0.000
Test: [0/1]	Time  0.290 ( 0.290)	Loss 1.5205e-01 (1.5205e-01)	Acc@1   0.75 (  0.75)	Acc@5   0.00 (  0.00)
 * Acc@1 0.754 Acc@5 0.000
45
TRAINING
Epoch: [45][0/1]	Time  1.003 ( 1.003)	Data  0.308 ( 0.308)	Loss 8.4822e-02 (8.4822e-02)	Acc@1   0.88 (  0.88)	Acc@5   0.00 (  0.00)
[0.8759434728663242]
Test: [0/1]	Time  0.258 ( 0.258)	Loss 9.3953e-01 (9.3953e-01)	Acc@1   0.66 (  0.66)	Acc@5   0.00 (  0.00)
 * Acc@1 0.663 Acc@5 0.000
Test: [0/1]	Time  0.310 ( 0.310)	Loss 1.5236e-01 (1.5236e-01)	Acc@1   0.76 (  0.76)	Acc@5   0.00 (  0.00)
 * Acc@1 0.757 Acc@5 0.000
46
TRAINING
Epoch: [46][0/1]	Time  0.999 ( 0.999)	Data  0.296 ( 0.296)	Loss 8.5005e-02 (8.5005e-02)	Acc@1   0.88 (  0.88)	Acc@5   0.00 (  0.00)
[0.8789194268358703]
Test: [0/1]	Time  0.265 ( 0.265)	Loss 9.3889e-01 (9.3889e-01)	Acc@1   0.66 (  0.66)	Acc@5   0.00 (  0.00)
 * Acc@1 0.663 Acc@5 0.000
Test: [0/1]	Time  0.313 ( 0.313)	Loss 1.5235e-01 (1.5235e-01)	Acc@1   0.76 (  0.76)	Acc@5   0.00 (  0.00)
 * Acc@1 0.757 Acc@5 0.000
47
TRAINING
Epoch: [47][0/1]	Time  0.947 ( 0.947)	Data  0.251 ( 0.251)	Loss 8.4672e-02 (8.4672e-02)	Acc@1   0.88 (  0.88)	Acc@5   0.00 (  0.00)
[0.88231986632925]
Test: [0/1]	Time  0.244 ( 0.244)	Loss 9.3827e-01 (9.3827e-01)	Acc@1   0.66 (  0.66)	Acc@5   0.00 (  0.00)
 * Acc@1 0.662 Acc@5 0.000
Test: [0/1]	Time  0.291 ( 0.291)	Loss 1.5221e-01 (1.5221e-01)	Acc@1   0.76 (  0.76)	Acc@5   0.00 (  0.00)
 * Acc@1 0.757 Acc@5 0.000
48
TRAINING
Epoch: [48][0/1]	Time  0.933 ( 0.933)	Data  0.258 ( 0.258)	Loss 8.4023e-02 (8.4023e-02)	Acc@1   0.89 (  0.89)	Acc@5   0.00 (  0.00)
[0.8860014512469989]
Test: [0/1]	Time  0.244 ( 0.244)	Loss 9.3772e-01 (9.3772e-01)	Acc@1   0.66 (  0.66)	Acc@5   0.00 (  0.00)
 * Acc@1 0.661 Acc@5 0.000
Test: [0/1]	Time  0.293 ( 0.293)	Loss 1.5217e-01 (1.5217e-01)	Acc@1   0.76 (  0.76)	Acc@5   0.00 (  0.00)
 * Acc@1 0.757 Acc@5 0.000
49
TRAINING
Epoch: [49][0/1]	Time  0.927 ( 0.927)	Data  0.256 ( 0.256)	Loss 8.3356e-02 (8.3356e-02)	Acc@1   0.89 (  0.89)	Acc@5   0.00 (  0.00)
[0.8900556682467212]
Test: [0/1]	Time  0.245 ( 0.245)	Loss 9.3730e-01 (9.3730e-01)	Acc@1   0.66 (  0.66)	Acc@5   0.00 (  0.00)
 * Acc@1 0.659 Acc@5 0.000
Test: [0/1]	Time  0.297 ( 0.297)	Loss 1.5243e-01 (1.5243e-01)	Acc@1   0.76 (  0.76)	Acc@5   0.00 (  0.00)
 * Acc@1 0.757 Acc@5 0.000
50
TRAINING
Epoch: [50][0/1]	Time  0.959 ( 0.959)	Data  0.247 ( 0.247)	Loss 8.2891e-02 (8.2891e-02)	Acc@1   0.89 (  0.89)	Acc@5   0.00 (  0.00)
[0.8939180238209149]
Test: [0/1]	Time  0.292 ( 0.292)	Loss 9.3704e-01 (9.3704e-01)	Acc@1   0.66 (  0.66)	Acc@5   0.00 (  0.00)
 * Acc@1 0.660 Acc@5 0.000
Test: [0/1]	Time  0.340 ( 0.340)	Loss 1.5296e-01 (1.5296e-01)	Acc@1   0.76 (  0.76)	Acc@5   0.00 (  0.00)
 * Acc@1 0.756 Acc@5 0.000
51
TRAINING
Epoch: [51][0/1]	Time  0.966 ( 0.966)	Data  0.293 ( 0.293)	Loss 8.2674e-02 (8.2674e-02)	Acc@1   0.90 (  0.90)	Acc@5   0.00 (  0.00)
[0.8975290653885039]
Test: [0/1]	Time  0.257 ( 0.257)	Loss 9.3692e-01 (9.3692e-01)	Acc@1   0.66 (  0.66)	Acc@5   0.00 (  0.00)
 * Acc@1 0.664 Acc@5 0.000
Test: [0/1]	Time  0.310 ( 0.310)	Loss 1.5360e-01 (1.5360e-01)	Acc@1   0.76 (  0.76)	Acc@5   0.00 (  0.00)
 * Acc@1 0.755 Acc@5 0.000
52
TRAINING
Epoch: [52][0/1]	Time  1.013 ( 1.013)	Data  0.299 ( 0.299)	Loss 8.2598e-02 (8.2598e-02)	Acc@1   0.90 (  0.90)	Acc@5   0.00 (  0.00)
[0.9008898642225236]
Test: [0/1]	Time  0.262 ( 0.262)	Loss 9.3693e-01 (9.3693e-01)	Acc@1   0.67 (  0.67)	Acc@5   0.00 (  0.00)
 * Acc@1 0.668 Acc@5 0.000
Test: [0/1]	Time  0.312 ( 0.312)	Loss 1.5413e-01 (1.5413e-01)	Acc@1   0.75 (  0.75)	Acc@5   0.00 (  0.00)
 * Acc@1 0.755 Acc@5 0.000
53
TRAINING
Epoch: [53][0/1]	Time  0.943 ( 0.943)	Data  0.271 ( 0.271)	Loss 8.2500e-02 (8.2500e-02)	Acc@1   0.90 (  0.90)	Acc@5   0.00 (  0.00)
[0.9040505730625088]
Test: [0/1]	Time  0.248 ( 0.248)	Loss 9.3705e-01 (9.3705e-01)	Acc@1   0.67 (  0.67)	Acc@5   0.00 (  0.00)
 * Acc@1 0.671 Acc@5 0.000
Test: [0/1]	Time  0.297 ( 0.297)	Loss 1.5442e-01 (1.5442e-01)	Acc@1   0.75 (  0.75)	Acc@5   0.00 (  0.00)
 * Acc@1 0.754 Acc@5 0.000
54
TRAINING
Epoch: [54][0/1]	Time  0.943 ( 0.943)	Data  0.270 ( 0.270)	Loss 8.2273e-02 (8.2273e-02)	Acc@1   0.91 (  0.91)	Acc@5   0.00 (  0.00)
[0.9070695476472347]
Test: [0/1]	Time  0.244 ( 0.244)	Loss 9.3726e-01 (9.3726e-01)	Acc@1   0.67 (  0.67)	Acc@5   0.00 (  0.00)
 * Acc@1 0.675 Acc@5 0.000
Test: [0/1]	Time  0.298 ( 0.298)	Loss 1.5446e-01 (1.5446e-01)	Acc@1   0.75 (  0.75)	Acc@5   0.00 (  0.00)
 * Acc@1 0.754 Acc@5 0.000
55
TRAINING
Epoch: [55][0/1]	Time  0.943 ( 0.943)	Data  0.271 ( 0.271)	Loss 8.1919e-02 (8.1919e-02)	Acc@1   0.91 (  0.91)	Acc@5   0.00 (  0.00)
[0.90967907993836]
Test: [0/1]	Time  0.249 ( 0.249)	Loss 9.3756e-01 (9.3756e-01)	Acc@1   0.68 (  0.68)	Acc@5   0.00 (  0.00)
 * Acc@1 0.678 Acc@5 0.000
Test: [0/1]	Time  0.298 ( 0.298)	Loss 1.5433e-01 (1.5433e-01)	Acc@1   0.75 (  0.75)	Acc@5   0.00 (  0.00)
 * Acc@1 0.753 Acc@5 0.000
56
TRAINING
Epoch: [56][0/1]	Time  0.944 ( 0.944)	Data  0.269 ( 0.269)	Loss 8.1526e-02 (8.1526e-02)	Acc@1   0.91 (  0.91)	Acc@5   0.00 (  0.00)
[0.9117886010128928]
Test: [0/1]	Time  0.248 ( 0.248)	Loss 9.3794e-01 (9.3794e-01)	Acc@1   0.68 (  0.68)	Acc@5   0.00 (  0.00)
 * Acc@1 0.682 Acc@5 0.000
Test: [0/1]	Time  0.303 ( 0.303)	Loss 1.5416e-01 (1.5416e-01)	Acc@1   0.75 (  0.75)	Acc@5   0.00 (  0.00)
 * Acc@1 0.753 Acc@5 0.000
57
TRAINING
Epoch: [57][0/1]	Time  0.947 ( 0.947)	Data  0.275 ( 0.275)	Loss 8.1198e-02 (8.1198e-02)	Acc@1   0.91 (  0.91)	Acc@5   0.00 (  0.00)
[0.9137534151163331]
Test: [0/1]	Time  0.244 ( 0.244)	Loss 9.3839e-01 (9.3839e-01)	Acc@1   0.69 (  0.69)	Acc@5   0.00 (  0.00)
 * Acc@1 0.685 Acc@5 0.000
Test: [0/1]	Time  0.298 ( 0.298)	Loss 1.5405e-01 (1.5405e-01)	Acc@1   0.75 (  0.75)	Acc@5   0.00 (  0.00)
 * Acc@1 0.753 Acc@5 0.000
58
TRAINING
Epoch: [58][0/1]	Time  0.944 ( 0.944)	Data  0.271 ( 0.271)	Loss 8.0991e-02 (8.0991e-02)	Acc@1   0.92 (  0.92)	Acc@5   0.00 (  0.00)
[0.9155419478714983]
Test: [0/1]	Time  0.245 ( 0.245)	Loss 9.3888e-01 (9.3888e-01)	Acc@1   0.69 (  0.69)	Acc@5   0.00 (  0.00)
 * Acc@1 0.689 Acc@5 0.000
Test: [0/1]	Time  0.294 ( 0.294)	Loss 1.5401e-01 (1.5401e-01)	Acc@1   0.75 (  0.75)	Acc@5   0.00 (  0.00)
 * Acc@1 0.754 Acc@5 0.000
59
TRAINING
Epoch: [59][0/1]	Time  0.949 ( 0.949)	Data  0.276 ( 0.276)	Loss 8.0883e-02 (8.0883e-02)	Acc@1   0.92 (  0.92)	Acc@5   0.00 (  0.00)
[0.9171529898836721]
Test: [0/1]	Time  0.246 ( 0.246)	Loss 9.3937e-01 (9.3937e-01)	Acc@1   0.69 (  0.69)	Acc@5   0.00 (  0.00)
 * Acc@1 0.692 Acc@5 0.000
Test: [0/1]	Time  0.297 ( 0.297)	Loss 1.5398e-01 (1.5398e-01)	Acc@1   0.75 (  0.75)	Acc@5   0.00 (  0.00)
 * Acc@1 0.754 Acc@5 0.000
60
TRAINING
Epoch: [60][0/1]	Time  0.947 ( 0.947)	Data  0.250 ( 0.250)	Loss 8.0799e-02 (8.0799e-02)	Acc@1   0.92 (  0.92)	Acc@5   0.00 (  0.00)
[0.919336370917889]
Test: [0/1]	Time  0.241 ( 0.241)	Loss 9.3985e-01 (9.3985e-01)	Acc@1   0.70 (  0.70)	Acc@5   0.00 (  0.00)
 * Acc@1 0.695 Acc@5 0.000
Test: [0/1]	Time  0.297 ( 0.297)	Loss 1.5392e-01 (1.5392e-01)	Acc@1   0.75 (  0.75)	Acc@5   0.00 (  0.00)
 * Acc@1 0.754 Acc@5 0.000
61
TRAINING
Epoch: [61][0/1]	Time  0.929 ( 0.929)	Data  0.257 ( 0.257)	Loss 8.0664e-02 (8.0664e-02)	Acc@1   0.92 (  0.92)	Acc@5   0.00 (  0.00)
[0.9212176375751708]
Test: [0/1]	Time  0.244 ( 0.244)	Loss 9.4030e-01 (9.4030e-01)	Acc@1   0.70 (  0.70)	Acc@5   0.00 (  0.00)
 * Acc@1 0.698 Acc@5 0.000
Test: [0/1]	Time  0.293 ( 0.293)	Loss 1.5379e-01 (1.5379e-01)	Acc@1   0.76 (  0.76)	Acc@5   0.00 (  0.00)
 * Acc@1 0.755 Acc@5 0.000
62
TRAINING
Epoch: [62][0/1]	Time  0.929 ( 0.929)	Data  0.257 ( 0.257)	Loss 8.0443e-02 (8.0443e-02)	Acc@1   0.92 (  0.92)	Acc@5   0.00 (  0.00)
[0.923237747629265]
Test: [0/1]	Time  0.257 ( 0.257)	Loss 9.4074e-01 (9.4074e-01)	Acc@1   0.70 (  0.70)	Acc@5   0.00 (  0.00)
 * Acc@1 0.701 Acc@5 0.000
Test: [0/1]	Time  0.299 ( 0.299)	Loss 1.5363e-01 (1.5363e-01)	Acc@1   0.76 (  0.76)	Acc@5   0.00 (  0.00)
 * Acc@1 0.756 Acc@5 0.000
63
TRAINING
Epoch: [63][0/1]	Time  0.929 ( 0.929)	Data  0.254 ( 0.254)	Loss 8.0156e-02 (8.0156e-02)	Acc@1   0.92 (  0.92)	Acc@5   0.00 (  0.00)
[0.924775140599282]
Test: [0/1]	Time  0.259 ( 0.259)	Loss 9.4116e-01 (9.4116e-01)	Acc@1   0.70 (  0.70)	Acc@5   0.00 (  0.00)
 * Acc@1 0.704 Acc@5 0.000
Test: [0/1]	Time  0.301 ( 0.301)	Loss 1.5346e-01 (1.5346e-01)	Acc@1   0.76 (  0.76)	Acc@5   0.00 (  0.00)
 * Acc@1 0.757 Acc@5 0.000
64
TRAINING
Epoch: [64][0/1]	Time  0.931 ( 0.931)	Data  0.257 ( 0.257)	Loss 7.9859e-02 (7.9859e-02)	Acc@1   0.93 (  0.93)	Acc@5   0.00 (  0.00)
[0.9257196150499847]
Test: [0/1]	Time  0.241 ( 0.241)	Loss 9.4156e-01 (9.4156e-01)	Acc@1   0.71 (  0.71)	Acc@5   0.00 (  0.00)
 * Acc@1 0.706 Acc@5 0.000
Test: [0/1]	Time  0.294 ( 0.294)	Loss 1.5333e-01 (1.5333e-01)	Acc@1   0.76 (  0.76)	Acc@5   0.00 (  0.00)
 * Acc@1 0.758 Acc@5 0.000
65
TRAINING
Epoch: [65][0/1]	Time  0.981 ( 0.981)	Data  0.268 ( 0.268)	Loss 7.9608e-02 (7.9608e-02)	Acc@1   0.93 (  0.93)	Acc@5   0.00 (  0.00)
[0.92641657022366]
Test: [0/1]	Time  0.252 ( 0.252)	Loss 9.4194e-01 (9.4194e-01)	Acc@1   0.71 (  0.71)	Acc@5   0.00 (  0.00)
 * Acc@1 0.708 Acc@5 0.000
Test: [0/1]	Time  0.303 ( 0.303)	Loss 1.5325e-01 (1.5325e-01)	Acc@1   0.76 (  0.76)	Acc@5   0.00 (  0.00)
 * Acc@1 0.759 Acc@5 0.000
66
TRAINING
Epoch: [66][0/1]	Time  0.968 ( 0.968)	Data  0.280 ( 0.280)	Loss 7.9430e-02 (7.9430e-02)	Acc@1   0.93 (  0.93)	Acc@5   0.00 (  0.00)
[0.9268850357068084]
Test: [0/1]	Time  0.258 ( 0.258)	Loss 9.4232e-01 (9.4232e-01)	Acc@1   0.71 (  0.71)	Acc@5   0.00 (  0.00)
 * Acc@1 0.710 Acc@5 0.000
Test: [0/1]	Time  0.307 ( 0.307)	Loss 1.5319e-01 (1.5319e-01)	Acc@1   0.76 (  0.76)	Acc@5   0.00 (  0.00)
 * Acc@1 0.760 Acc@5 0.000
67
TRAINING
Epoch: [67][0/1]	Time  0.965 ( 0.965)	Data  0.254 ( 0.254)	Loss 7.9319e-02 (7.9319e-02)	Acc@1   0.93 (  0.93)	Acc@5   0.00 (  0.00)
[0.926926365304095]
Test: [0/1]	Time  0.243 ( 0.243)	Loss 9.4266e-01 (9.4266e-01)	Acc@1   0.71 (  0.71)	Acc@5   0.00 (  0.00)
 * Acc@1 0.711 Acc@5 0.000
Test: [0/1]	Time  0.293 ( 0.293)	Loss 1.5310e-01 (1.5310e-01)	Acc@1   0.76 (  0.76)	Acc@5   0.00 (  0.00)
 * Acc@1 0.761 Acc@5 0.000
68
TRAINING
Epoch: [68][0/1]	Time  0.984 ( 0.984)	Data  0.283 ( 0.283)	Loss 7.9243e-02 (7.9243e-02)	Acc@1   0.93 (  0.93)	Acc@5   0.00 (  0.00)
[0.9268740696761801]
Test: [0/1]	Time  0.263 ( 0.263)	Loss 9.4298e-01 (9.4298e-01)	Acc@1   0.71 (  0.71)	Acc@5   0.00 (  0.00)
 * Acc@1 0.712 Acc@5 0.000
Test: [0/1]	Time  0.311 ( 0.311)	Loss 1.5294e-01 (1.5294e-01)	Acc@1   0.76 (  0.76)	Acc@5   0.00 (  0.00)
 * Acc@1 0.762 Acc@5 0.000
69
TRAINING
Epoch: [69][0/1]	Time  0.982 ( 0.982)	Data  0.279 ( 0.279)	Loss 7.9174e-02 (7.9174e-02)	Acc@1   0.93 (  0.93)	Acc@5   0.00 (  0.00)
[0.9268308669680383]
Test: [0/1]	Time  0.256 ( 0.256)	Loss 9.4327e-01 (9.4327e-01)	Acc@1   0.71 (  0.71)	Acc@5   0.00 (  0.00)
 * Acc@1 0.712 Acc@5 0.000
Test: [0/1]	Time  0.308 ( 0.308)	Loss 1.5270e-01 (1.5270e-01)	Acc@1   0.76 (  0.76)	Acc@5   0.00 (  0.00)
 * Acc@1 0.763 Acc@5 0.000
70
TRAINING
Epoch: [70][0/1]	Time  0.991 ( 0.991)	Data  0.280 ( 0.280)	Loss 7.9099e-02 (7.9099e-02)	Acc@1   0.93 (  0.93)	Acc@5   0.00 (  0.00)
[0.9269588133373625]
Test: [0/1]	Time  0.289 ( 0.289)	Loss 9.4352e-01 (9.4352e-01)	Acc@1   0.71 (  0.71)	Acc@5   0.00 (  0.00)
 * Acc@1 0.713 Acc@5 0.000
Test: [0/1]	Time  0.331 ( 0.331)	Loss 1.5241e-01 (1.5241e-01)	Acc@1   0.76 (  0.76)	Acc@5   0.00 (  0.00)
 * Acc@1 0.763 Acc@5 0.000
71
TRAINING
Epoch: [71][0/1]	Time  0.951 ( 0.951)	Data  0.253 ( 0.253)	Loss 7.9027e-02 (7.9027e-02)	Acc@1   0.93 (  0.93)	Acc@5   0.00 (  0.00)
[0.9272427188372556]
Test: [0/1]	Time  0.242 ( 0.242)	Loss 9.4373e-01 (9.4373e-01)	Acc@1   0.71 (  0.71)	Acc@5   0.00 (  0.00)
 * Acc@1 0.714 Acc@5 0.000
Test: [0/1]	Time  0.294 ( 0.294)	Loss 1.5211e-01 (1.5211e-01)	Acc@1   0.76 (  0.76)	Acc@5   0.00 (  0.00)
 * Acc@1 0.764 Acc@5 0.000
72
TRAINING
Epoch: [72][0/1]	Time  1.001 ( 1.001)	Data  0.291 ( 0.291)	Loss 7.8973e-02 (7.8973e-02)	Acc@1   0.93 (  0.93)	Acc@5   0.00 (  0.00)
[0.9275394295352215]
Test: [0/1]	Time  0.283 ( 0.283)	Loss 9.4391e-01 (9.4391e-01)	Acc@1   0.71 (  0.71)	Acc@5   0.00 (  0.00)
 * Acc@1 0.714 Acc@5 0.000
Test: [0/1]	Time  0.327 ( 0.327)	Loss 1.5181e-01 (1.5181e-01)	Acc@1   0.76 (  0.76)	Acc@5   0.00 (  0.00)
 * Acc@1 0.765 Acc@5 0.000
73
TRAINING
Epoch: [73][0/1]	Time  0.947 ( 0.947)	Data  0.257 ( 0.257)	Loss 7.8949e-02 (7.8949e-02)	Acc@1   0.93 (  0.93)	Acc@5   0.00 (  0.00)
[0.9278425281285119]
Test: [0/1]	Time  0.353 ( 0.353)	Loss 9.4404e-01 (9.4404e-01)	Acc@1   0.71 (  0.71)	Acc@5   0.00 (  0.00)
 * Acc@1 0.715 Acc@5 0.000
Test: [0/1]	Time  0.326 ( 0.326)	Loss 1.5155e-01 (1.5155e-01)	Acc@1   0.77 (  0.77)	Acc@5   0.00 (  0.00)
 * Acc@1 0.766 Acc@5 0.000
74
TRAINING
Epoch: [74][0/1]	Time  1.022 ( 1.022)	Data  0.330 ( 0.330)	Loss 7.8953e-02 (7.8953e-02)	Acc@1   0.93 (  0.93)	Acc@5   0.00 (  0.00)
[0.9281442163478012]
Test: [0/1]	Time  0.270 ( 0.270)	Loss 9.4414e-01 (9.4414e-01)	Acc@1   0.71 (  0.71)	Acc@5   0.00 (  0.00)
 * Acc@1 0.715 Acc@5 0.000
Test: [0/1]	Time  0.321 ( 0.321)	Loss 1.5133e-01 (1.5133e-01)	Acc@1   0.77 (  0.77)	Acc@5   0.00 (  0.00)
 * Acc@1 0.766 Acc@5 0.000
75
TRAINING
Epoch: [75][0/1]	Time  1.023 ( 1.023)	Data  0.323 ( 0.323)	Loss 7.8971e-02 (7.8971e-02)	Acc@1   0.93 (  0.93)	Acc@5   0.00 (  0.00)
[0.9284372159201062]
Test: [0/1]	Time  0.279 ( 0.279)	Loss 9.4421e-01 (9.4421e-01)	Acc@1   0.72 (  0.72)	Acc@5   0.00 (  0.00)
 * Acc@1 0.715 Acc@5 0.000
Test: [0/1]	Time  0.329 ( 0.329)	Loss 1.5114e-01 (1.5114e-01)	Acc@1   0.77 (  0.77)	Acc@5   0.00 (  0.00)
 * Acc@1 0.767 Acc@5 0.000
76
TRAINING
Epoch: [76][0/1]	Time  0.978 ( 0.978)	Data  0.270 ( 0.270)	Loss 7.8982e-02 (7.8982e-02)	Acc@1   0.93 (  0.93)	Acc@5   0.00 (  0.00)
[0.9287158797179095]
Test: [0/1]	Time  0.247 ( 0.247)	Loss 9.4423e-01 (9.4423e-01)	Acc@1   0.72 (  0.72)	Acc@5   0.00 (  0.00)
 * Acc@1 0.715 Acc@5 0.000
Test: [0/1]	Time  0.296 ( 0.296)	Loss 1.5098e-01 (1.5098e-01)	Acc@1   0.77 (  0.77)	Acc@5   0.00 (  0.00)
 * Acc@1 0.768 Acc@5 0.000
77
TRAINING
Epoch: [77][0/1]	Time  0.960 ( 0.960)	Data  0.266 ( 0.266)	Loss 7.8975e-02 (7.8975e-02)	Acc@1   0.93 (  0.93)	Acc@5   0.00 (  0.00)
[0.9289766513891284]
Test: [0/1]	Time  0.253 ( 0.253)	Loss 9.4422e-01 (9.4422e-01)	Acc@1   0.71 (  0.71)	Acc@5   0.00 (  0.00)
 * Acc@1 0.715 Acc@5 0.000
Test: [0/1]	Time  0.302 ( 0.302)	Loss 1.5084e-01 (1.5084e-01)	Acc@1   0.77 (  0.77)	Acc@5   0.00 (  0.00)
 * Acc@1 0.768 Acc@5 0.000
78
TRAINING
Epoch: [78][0/1]	Time  0.956 ( 0.956)	Data  0.259 ( 0.259)	Loss 7.8947e-02 (7.8947e-02)	Acc@1   0.93 (  0.93)	Acc@5   0.00 (  0.00)
[0.9292181187117541]
Test: [0/1]	Time  0.244 ( 0.244)	Loss 9.4419e-01 (9.4419e-01)	Acc@1   0.71 (  0.71)	Acc@5   0.00 (  0.00)
 * Acc@1 0.715 Acc@5 0.000
Test: [0/1]	Time  0.293 ( 0.293)	Loss 1.5074e-01 (1.5074e-01)	Acc@1   0.77 (  0.77)	Acc@5   0.00 (  0.00)
 * Acc@1 0.769 Acc@5 0.000
79
TRAINING
Epoch: [79][0/1]	Time  0.958 ( 0.958)	Data  0.254 ( 0.254)	Loss 7.8906e-02 (7.8906e-02)	Acc@1   0.93 (  0.93)	Acc@5   0.00 (  0.00)
[0.9294408371206055]
Test: [0/1]	Time  0.245 ( 0.245)	Loss 9.4414e-01 (9.4414e-01)	Acc@1   0.71 (  0.71)	Acc@5   0.00 (  0.00)
 * Acc@1 0.714 Acc@5 0.000
Test: [0/1]	Time  0.296 ( 0.296)	Loss 1.5066e-01 (1.5066e-01)	Acc@1   0.77 (  0.77)	Acc@5   0.00 (  0.00)
 * Acc@1 0.769 Acc@5 0.000
80
TRAINING
Epoch: [80][0/1]	Time  0.972 ( 0.972)	Data  0.262 ( 0.262)	Loss 7.8866e-02 (7.8866e-02)	Acc@1   0.93 (  0.93)	Acc@5   0.00 (  0.00)
[0.9296469687193212]
Test: [0/1]	Time  0.250 ( 0.250)	Loss 9.4407e-01 (9.4407e-01)	Acc@1   0.71 (  0.71)	Acc@5   0.00 (  0.00)
 * Acc@1 0.714 Acc@5 0.000
Test: [0/1]	Time  0.299 ( 0.299)	Loss 1.5060e-01 (1.5060e-01)	Acc@1   0.77 (  0.77)	Acc@5   0.00 (  0.00)
 * Acc@1 0.770 Acc@5 0.000
81
TRAINING
Epoch: [81][0/1]	Time  0.966 ( 0.966)	Data  0.265 ( 0.265)	Loss 7.8836e-02 (7.8836e-02)	Acc@1   0.93 (  0.93)	Acc@5   0.00 (  0.00)
[0.9298397086193475]
Test: [0/1]	Time  0.250 ( 0.250)	Loss 9.4399e-01 (9.4399e-01)	Acc@1   0.71 (  0.71)	Acc@5   0.00 (  0.00)
 * Acc@1 0.713 Acc@5 0.000
Test: [0/1]	Time  0.296 ( 0.296)	Loss 1.5056e-01 (1.5056e-01)	Acc@1   0.77 (  0.77)	Acc@5   0.00 (  0.00)
 * Acc@1 0.770 Acc@5 0.000
82
TRAINING
Epoch: [82][0/1]	Time  1.023 ( 1.023)	Data  0.267 ( 0.267)	Loss 7.8819e-02 (7.8819e-02)	Acc@1   0.93 (  0.93)	Acc@5   0.00 (  0.00)
[0.9299748505524734]
Test: [0/1]	Time  0.262 ( 0.262)	Loss 9.4389e-01 (9.4389e-01)	Acc@1   0.71 (  0.71)	Acc@5   0.00 (  0.00)
 * Acc@1 0.713 Acc@5 0.000
Test: [0/1]	Time  0.314 ( 0.314)	Loss 1.5052e-01 (1.5052e-01)	Acc@1   0.77 (  0.77)	Acc@5   0.00 (  0.00)
 * Acc@1 0.771 Acc@5 0.000
83
TRAINING
Epoch: [83][0/1]	Time  0.965 ( 0.965)	Data  0.259 ( 0.259)	Loss 7.8811e-02 (7.8811e-02)	Acc@1   0.93 (  0.93)	Acc@5   0.00 (  0.00)
[0.9299514905170354]
Test: [0/1]	Time  0.272 ( 0.272)	Loss 9.4378e-01 (9.4378e-01)	Acc@1   0.71 (  0.71)	Acc@5   0.00 (  0.00)
 * Acc@1 0.713 Acc@5 0.000
Test: [0/1]	Time  0.319 ( 0.319)	Loss 1.5046e-01 (1.5046e-01)	Acc@1   0.77 (  0.77)	Acc@5   0.00 (  0.00)
 * Acc@1 0.771 Acc@5 0.000
84
TRAINING
Epoch: [84][0/1]	Time  0.958 ( 0.958)	Data  0.249 ( 0.249)	Loss 7.8807e-02 (7.8807e-02)	Acc@1   0.93 (  0.93)	Acc@5   0.00 (  0.00)
[0.9299834949246619]
Test: [0/1]	Time  0.243 ( 0.243)	Loss 9.4366e-01 (9.4366e-01)	Acc@1   0.71 (  0.71)	Acc@5   0.00 (  0.00)
 * Acc@1 0.713 Acc@5 0.000
Test: [0/1]	Time  0.291 ( 0.291)	Loss 1.5038e-01 (1.5038e-01)	Acc@1   0.77 (  0.77)	Acc@5   0.00 (  0.00)
 * Acc@1 0.771 Acc@5 0.000
85
TRAINING
Epoch: [85][0/1]	Time  0.953 ( 0.953)	Data  0.259 ( 0.259)	Loss 7.8803e-02 (7.8803e-02)	Acc@1   0.93 (  0.93)	Acc@5   0.00 (  0.00)
[0.9300737110748589]
Test: [0/1]	Time  0.245 ( 0.245)	Loss 9.4354e-01 (9.4354e-01)	Acc@1   0.71 (  0.71)	Acc@5   0.00 (  0.00)
 * Acc@1 0.713 Acc@5 0.000
Test: [0/1]	Time  0.301 ( 0.301)	Loss 1.5028e-01 (1.5028e-01)	Acc@1   0.77 (  0.77)	Acc@5   0.00 (  0.00)
 * Acc@1 0.771 Acc@5 0.000
86
TRAINING
Epoch: [86][0/1]	Time  1.001 ( 1.001)	Data  0.298 ( 0.298)	Loss 7.8798e-02 (7.8798e-02)	Acc@1   0.93 (  0.93)	Acc@5   0.00 (  0.00)
[0.9302168008129336]
Test: [0/1]	Time  0.265 ( 0.265)	Loss 9.4340e-01 (9.4340e-01)	Acc@1   0.71 (  0.71)	Acc@5   0.00 (  0.00)
 * Acc@1 0.713 Acc@5 0.000
Test: [0/1]	Time  0.312 ( 0.312)	Loss 1.5016e-01 (1.5016e-01)	Acc@1   0.77 (  0.77)	Acc@5   0.00 (  0.00)
 * Acc@1 0.772 Acc@5 0.000
87
TRAINING
Epoch: [87][0/1]	Time  0.995 ( 0.995)	Data  0.306 ( 0.306)	Loss 7.8796e-02 (7.8796e-02)	Acc@1   0.93 (  0.93)	Acc@5   0.00 (  0.00)
[0.9304008017142821]
Test: [0/1]	Time  0.269 ( 0.269)	Loss 9.4326e-01 (9.4326e-01)	Acc@1   0.71 (  0.71)	Acc@5   0.00 (  0.00)
 * Acc@1 0.713 Acc@5 0.000
Test: [0/1]	Time  0.327 ( 0.327)	Loss 1.5004e-01 (1.5004e-01)	Acc@1   0.77 (  0.77)	Acc@5   0.00 (  0.00)
 * Acc@1 0.772 Acc@5 0.000
88
TRAINING
Epoch: [88][0/1]	Time  0.958 ( 0.958)	Data  0.247 ( 0.247)	Loss 7.8797e-02 (7.8797e-02)	Acc@1   0.93 (  0.93)	Acc@5   0.00 (  0.00)
[0.9306097763556713]
Test: [0/1]	Time  0.243 ( 0.243)	Loss 9.4312e-01 (9.4312e-01)	Acc@1   0.71 (  0.71)	Acc@5   0.00 (  0.00)
 * Acc@1 0.713 Acc@5 0.000
Test: [0/1]	Time  0.312 ( 0.312)	Loss 1.4993e-01 (1.4993e-01)	Acc@1   0.77 (  0.77)	Acc@5   0.00 (  0.00)
 * Acc@1 0.772 Acc@5 0.000
89
TRAINING
Epoch: [89][0/1]	Time  0.958 ( 0.958)	Data  0.251 ( 0.251)	Loss 7.8803e-02 (7.8803e-02)	Acc@1   0.93 (  0.93)	Acc@5   0.00 (  0.00)
[0.9307214165265189]
Test: [0/1]	Time  0.241 ( 0.241)	Loss 9.4298e-01 (9.4298e-01)	Acc@1   0.71 (  0.71)	Acc@5   0.00 (  0.00)
 * Acc@1 0.713 Acc@5 0.000
Test: [0/1]	Time  0.295 ( 0.295)	Loss 1.4983e-01 (1.4983e-01)	Acc@1   0.77 (  0.77)	Acc@5   0.00 (  0.00)
 * Acc@1 0.772 Acc@5 0.000
90
TRAINING
Epoch: [90][0/1]	Time  0.971 ( 0.971)	Data  0.270 ( 0.270)	Loss 7.8810e-02 (7.8810e-02)	Acc@1   0.93 (  0.93)	Acc@5   0.00 (  0.00)
[0.9308006148325296]
Test: [0/1]	Time  0.250 ( 0.250)	Loss 9.4284e-01 (9.4284e-01)	Acc@1   0.71 (  0.71)	Acc@5   0.00 (  0.00)
 * Acc@1 0.713 Acc@5 0.000
Test: [0/1]	Time  0.300 ( 0.300)	Loss 1.4975e-01 (1.4975e-01)	Acc@1   0.77 (  0.77)	Acc@5   0.00 (  0.00)
 * Acc@1 0.772 Acc@5 0.000
91
TRAINING
Epoch: [91][0/1]	Time  1.039 ( 1.039)	Data  0.337 ( 0.337)	Loss 7.8814e-02 (7.8814e-02)	Acc@1   0.93 (  0.93)	Acc@5   0.00 (  0.00)
[0.930864734254051]
Test: [0/1]	Time  0.275 ( 0.275)	Loss 9.4269e-01 (9.4269e-01)	Acc@1   0.71 (  0.71)	Acc@5   0.00 (  0.00)
 * Acc@1 0.713 Acc@5 0.000
Test: [0/1]	Time  0.328 ( 0.328)	Loss 1.4969e-01 (1.4969e-01)	Acc@1   0.77 (  0.77)	Acc@5   0.00 (  0.00)
 * Acc@1 0.772 Acc@5 0.000
92
TRAINING
Epoch: [92][0/1]	Time  0.979 ( 0.979)	Data  0.282 ( 0.282)	Loss 7.8811e-02 (7.8811e-02)	Acc@1   0.93 (  0.93)	Acc@5   0.00 (  0.00)
[0.9308005831184023]
Test: [0/1]	Time  0.261 ( 0.261)	Loss 9.4255e-01 (9.4255e-01)	Acc@1   0.71 (  0.71)	Acc@5   0.00 (  0.00)
 * Acc@1 0.712 Acc@5 0.000
Test: [0/1]	Time  0.314 ( 0.314)	Loss 1.4965e-01 (1.4965e-01)	Acc@1   0.77 (  0.77)	Acc@5   0.00 (  0.00)
 * Acc@1 0.772 Acc@5 0.000
93
TRAINING
Epoch: [93][0/1]	Time  0.988 ( 0.988)	Data  0.302 ( 0.302)	Loss 7.8801e-02 (7.8801e-02)	Acc@1   0.93 (  0.93)	Acc@5   0.00 (  0.00)
[0.9307331954940552]
Test: [0/1]	Time  0.275 ( 0.275)	Loss 9.4241e-01 (9.4241e-01)	Acc@1   0.71 (  0.71)	Acc@5   0.00 (  0.00)
 * Acc@1 0.712 Acc@5 0.000
Test: [0/1]	Time  0.318 ( 0.318)	Loss 1.4962e-01 (1.4962e-01)	Acc@1   0.77 (  0.77)	Acc@5   0.00 (  0.00)
 * Acc@1 0.773 Acc@5 0.000
94
TRAINING
Epoch: [94][0/1]	Time  1.032 ( 1.032)	Data  0.320 ( 0.320)	Loss 7.8785e-02 (7.8785e-02)	Acc@1   0.93 (  0.93)	Acc@5   0.00 (  0.00)
[0.9306667023065438]
Test: [0/1]	Time  0.274 ( 0.274)	Loss 9.4228e-01 (9.4228e-01)	Acc@1   0.71 (  0.71)	Acc@5   0.00 (  0.00)
 * Acc@1 0.712 Acc@5 0.000
Test: [0/1]	Time  0.327 ( 0.327)	Loss 1.4961e-01 (1.4961e-01)	Acc@1   0.77 (  0.77)	Acc@5   0.00 (  0.00)
 * Acc@1 0.773 Acc@5 0.000
95
TRAINING
Epoch: [95][0/1]	Time  1.001 ( 1.001)	Data  0.293 ( 0.293)	Loss 7.8765e-02 (7.8765e-02)	Acc@1   0.93 (  0.93)	Acc@5   0.00 (  0.00)
[0.9306046327915982]
Test: [0/1]	Time  0.266 ( 0.266)	Loss 9.4215e-01 (9.4215e-01)	Acc@1   0.71 (  0.71)	Acc@5   0.00 (  0.00)
 * Acc@1 0.712 Acc@5 0.000
Test: [0/1]	Time  0.321 ( 0.321)	Loss 1.4961e-01 (1.4961e-01)	Acc@1   0.77 (  0.77)	Acc@5   0.00 (  0.00)
 * Acc@1 0.773 Acc@5 0.000
96
TRAINING
Epoch: [96][0/1]	Time  1.008 ( 1.008)	Data  0.312 ( 0.312)	Loss 7.8746e-02 (7.8746e-02)	Acc@1   0.93 (  0.93)	Acc@5   0.00 (  0.00)
[0.9305498934987892]
Test: [0/1]	Time  0.270 ( 0.270)	Loss 9.4203e-01 (9.4203e-01)	Acc@1   0.71 (  0.71)	Acc@5   0.00 (  0.00)
 * Acc@1 0.712 Acc@5 0.000
Test: [0/1]	Time  0.320 ( 0.320)	Loss 1.4961e-01 (1.4961e-01)	Acc@1   0.77 (  0.77)	Acc@5   0.00 (  0.00)
 * Acc@1 0.773 Acc@5 0.000
97
TRAINING
Epoch: [97][0/1]	Time  0.942 ( 0.942)	Data  0.251 ( 0.251)	Loss 7.8729e-02 (7.8729e-02)	Acc@1   0.93 (  0.93)	Acc@5   0.00 (  0.00)
[0.9305047841036218]
Test: [0/1]	Time  0.265 ( 0.265)	Loss 9.4191e-01 (9.4191e-01)	Acc@1   0.71 (  0.71)	Acc@5   0.00 (  0.00)
 * Acc@1 0.712 Acc@5 0.000
Test: [0/1]	Time  0.316 ( 0.316)	Loss 1.4961e-01 (1.4961e-01)	Acc@1   0.77 (  0.77)	Acc@5   0.00 (  0.00)
 * Acc@1 0.773 Acc@5 0.000
98
TRAINING
Epoch: [98][0/1]	Time  0.963 ( 0.963)	Data  0.251 ( 0.251)	Loss 7.8714e-02 (7.8714e-02)	Acc@1   0.93 (  0.93)	Acc@5   0.00 (  0.00)
[0.9304710279002917]
Test: [0/1]	Time  0.242 ( 0.242)	Loss 9.4179e-01 (9.4179e-01)	Acc@1   0.71 (  0.71)	Acc@5   0.00 (  0.00)
 * Acc@1 0.712 Acc@5 0.000
Test: [0/1]	Time  0.292 ( 0.292)	Loss 1.4960e-01 (1.4960e-01)	Acc@1   0.77 (  0.77)	Acc@5   0.00 (  0.00)
 * Acc@1 0.773 Acc@5 0.000
99
TRAINING
Epoch: [99][0/1]	Time  0.980 ( 0.980)	Data  0.273 ( 0.273)	Loss 7.8703e-02 (7.8703e-02)	Acc@1   0.93 (  0.93)	Acc@5   0.00 (  0.00)
[0.9304498043566858]
Test: [0/1]	Time  0.253 ( 0.253)	Loss 9.4168e-01 (9.4168e-01)	Acc@1   0.71 (  0.71)	Acc@5   0.00 (  0.00)
 * Acc@1 0.712 Acc@5 0.000
Test: [0/1]	Time  0.303 ( 0.303)	Loss 1.4959e-01 (1.4959e-01)	Acc@1   0.77 (  0.77)	Acc@5   0.00 (  0.00)
 * Acc@1 0.773 Acc@5 0.000
=> using pre-trained model 'st_resnet'
s/ohp/session_1
torch.Size([640, 3, 224, 224])
(640, 22)
attach reg
0
TRAINING
/home/helenr6/Adv_mapper/train_split.py:125: UserWarning: You have chosen to seed training. This will turn on the CUDNN deterministic setting, which can slow down your training considerably! You may see unexpected behavior when restarting from checkpoints.
  warnings.warn('You have chosen to seed training. '
/localscratch/helenr6.6279052.0/env/lib/python3.7/site-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  cpuset_checked))
Epoch: [0][0/1]	Time  5.324 ( 5.324)	Data  1.913 ( 1.913)	Loss 1.6794e+00 (1.6794e+00)	Acc@1  -0.00 ( -0.00)	Acc@5   0.00 (  0.00)
[-0.0024878916396324363]
Test: [0/1]	Time  0.446 ( 0.446)	Loss 1.1925e+00 (1.1925e+00)	Acc@1   0.02 (  0.02)	Acc@5   0.00 (  0.00)
 * Acc@1 0.023 Acc@5 0.000
Test: [0/1]	Time  0.567 ( 0.567)	Loss 9.7082e-01 (9.7082e-01)	Acc@1   0.04 (  0.04)	Acc@5   0.00 (  0.00)
 * Acc@1 0.037 Acc@5 0.000
1
TRAINING
Epoch: [1][0/1]	Time  0.989 ( 0.989)	Data  0.275 ( 0.275)	Loss 1.6074e+00 (1.6074e+00)	Acc@1   0.00 (  0.00)	Acc@5   0.00 (  0.00)
[0.002433837348317349]
Test: [0/1]	Time  0.260 ( 0.260)	Loss 1.1820e+00 (1.1820e+00)	Acc@1   0.03 (  0.03)	Acc@5   0.00 (  0.00)
 * Acc@1 0.028 Acc@5 0.000
Test: [0/1]	Time  0.307 ( 0.307)	Loss 9.2298e-01 (9.2298e-01)	Acc@1   0.04 (  0.04)	Acc@5   0.00 (  0.00)
 * Acc@1 0.044 Acc@5 0.000
2
TRAINING
Epoch: [2][0/1]	Time  0.957 ( 0.957)	Data  0.244 ( 0.244)	Loss 1.4977e+00 (1.4977e+00)	Acc@1   0.01 (  0.01)	Acc@5   0.00 (  0.00)
[0.009256579161325912]
Test: [0/1]	Time  0.266 ( 0.266)	Loss 1.1687e+00 (1.1687e+00)	Acc@1   0.03 (  0.03)	Acc@5   0.00 (  0.00)
 * Acc@1 0.030 Acc@5 0.000
Test: [0/1]	Time  0.312 ( 0.312)	Loss 8.7832e-01 (8.7832e-01)	Acc@1   0.05 (  0.05)	Acc@5   0.00 (  0.00)
 * Acc@1 0.052 Acc@5 0.000
3
TRAINING
Epoch: [3][0/1]	Time  0.947 ( 0.947)	Data  0.246 ( 0.246)	Loss 1.3885e+00 (1.3885e+00)	Acc@1   0.02 (  0.02)	Acc@5   0.00 (  0.00)
[0.01617640769457949]
Test: [0/1]	Time  0.252 ( 0.252)	Loss 1.1557e+00 (1.1557e+00)	Acc@1   0.04 (  0.04)	Acc@5   0.00 (  0.00)
 * Acc@1 0.039 Acc@5 0.000
Test: [0/1]	Time  0.299 ( 0.299)	Loss 8.4834e-01 (8.4834e-01)	Acc@1   0.06 (  0.06)	Acc@5   0.00 (  0.00)
 * Acc@1 0.061 Acc@5 0.000
4
TRAINING
Epoch: [4][0/1]	Time  0.972 ( 0.972)	Data  0.252 ( 0.252)	Loss 1.3011e+00 (1.3011e+00)	Acc@1   0.03 (  0.03)	Acc@5   0.00 (  0.00)
[0.02752316560909495]
Test: [0/1]	Time  0.255 ( 0.255)	Loss 1.1441e+00 (1.1441e+00)	Acc@1   0.05 (  0.05)	Acc@5   0.00 (  0.00)
 * Acc@1 0.052 Acc@5 0.000
Test: [0/1]	Time  0.309 ( 0.309)	Loss 8.3092e-01 (8.3092e-01)	Acc@1   0.07 (  0.07)	Acc@5   0.00 (  0.00)
 * Acc@1 0.073 Acc@5 0.000
5
TRAINING
Epoch: [5][0/1]	Time  1.022 ( 1.022)	Data  0.312 ( 0.312)	Loss 1.2331e+00 (1.2331e+00)	Acc@1   0.04 (  0.04)	Acc@5   0.00 (  0.00)
[0.04154226037892071]
Test: [0/1]	Time  0.282 ( 0.282)	Loss 1.1331e+00 (1.1331e+00)	Acc@1   0.08 (  0.08)	Acc@5   0.00 (  0.00)
 * Acc@1 0.082 Acc@5 0.000
Test: [0/1]	Time  0.326 ( 0.326)	Loss 8.1421e-01 (8.1421e-01)	Acc@1   0.08 (  0.08)	Acc@5   0.00 (  0.00)
 * Acc@1 0.083 Acc@5 0.000
6
TRAINING
Epoch: [6][0/1]	Time  0.986 ( 0.986)	Data  0.293 ( 0.293)	Loss 1.1668e+00 (1.1668e+00)	Acc@1   0.06 (  0.06)	Acc@5   0.00 (  0.00)
[0.055311543343266885]
Test: [0/1]	Time  0.262 ( 0.262)	Loss 1.1214e+00 (1.1214e+00)	Acc@1   0.12 (  0.12)	Acc@5   0.00 (  0.00)
 * Acc@1 0.119 Acc@5 0.000
Test: [0/1]	Time  0.310 ( 0.310)	Loss 7.8598e-01 (7.8598e-01)	Acc@1   0.09 (  0.09)	Acc@5   0.00 (  0.00)
 * Acc@1 0.088 Acc@5 0.000
7
TRAINING
Epoch: [7][0/1]	Time  0.993 ( 0.993)	Data  0.290 ( 0.290)	Loss 1.0845e+00 (1.0845e+00)	Acc@1   0.07 (  0.07)	Acc@5   0.00 (  0.00)
[0.07111509529744339]
Test: [0/1]	Time  0.261 ( 0.261)	Loss 1.1085e+00 (1.1085e+00)	Acc@1   0.14 (  0.14)	Acc@5   0.00 (  0.00)
 * Acc@1 0.142 Acc@5 0.000
Test: [0/1]	Time  0.312 ( 0.312)	Loss 7.4144e-01 (7.4144e-01)	Acc@1   0.09 (  0.09)	Acc@5   0.00 (  0.00)
 * Acc@1 0.093 Acc@5 0.000
8
TRAINING
Epoch: [8][0/1]	Time  1.016 ( 1.016)	Data  0.308 ( 0.308)	Loss 9.8059e-01 (9.8059e-01)	Acc@1   0.09 (  0.09)	Acc@5   0.00 (  0.00)
[0.09250060615127204]
Test: [0/1]	Time  0.268 ( 0.268)	Loss 1.0950e+00 (1.0950e+00)	Acc@1   0.17 (  0.17)	Acc@5   0.00 (  0.00)
 * Acc@1 0.168 Acc@5 0.000
Test: [0/1]	Time  0.324 ( 0.324)	Loss 6.8588e-01 (6.8588e-01)	Acc@1   0.10 (  0.10)	Acc@5   0.00 (  0.00)
 * Acc@1 0.098 Acc@5 0.000
9
TRAINING
Epoch: [9][0/1]	Time  0.970 ( 0.970)	Data  0.251 ( 0.251)	Loss 8.6416e-01 (8.6416e-01)	Acc@1   0.12 (  0.12)	Acc@5   0.00 (  0.00)
[0.1171245693158621]
Test: [0/1]	Time  0.241 ( 0.241)	Loss 1.0823e+00 (1.0823e+00)	Acc@1   0.21 (  0.21)	Acc@5   0.00 (  0.00)
 * Acc@1 0.207 Acc@5 0.000
Test: [0/1]	Time  0.301 ( 0.301)	Loss 6.3048e-01 (6.3048e-01)	Acc@1   0.11 (  0.11)	Acc@5   0.00 (  0.00)
 * Acc@1 0.113 Acc@5 0.000
10
TRAINING
Epoch: [10][0/1]	Time  0.987 ( 0.987)	Data  0.294 ( 0.294)	Loss 7.5187e-01 (7.5187e-01)	Acc@1   0.14 (  0.14)	Acc@5   0.00 (  0.00)
[0.1446960171923352]
Test: [0/1]	Time  0.266 ( 0.266)	Loss 1.0716e+00 (1.0716e+00)	Acc@1   0.25 (  0.25)	Acc@5   0.00 (  0.00)
 * Acc@1 0.249 Acc@5 0.000
Test: [0/1]	Time  0.321 ( 0.321)	Loss 5.8523e-01 (5.8523e-01)	Acc@1   0.14 (  0.14)	Acc@5   0.00 (  0.00)
 * Acc@1 0.141 Acc@5 0.000
11
TRAINING
Epoch: [11][0/1]	Time  0.989 ( 0.989)	Data  0.272 ( 0.272)	Loss 6.5764e-01 (6.5764e-01)	Acc@1   0.18 (  0.18)	Acc@5   0.00 (  0.00)
[0.17605981420189615]
Test: [0/1]	Time  0.254 ( 0.254)	Loss 1.0631e+00 (1.0631e+00)	Acc@1   0.29 (  0.29)	Acc@5   0.00 (  0.00)
 * Acc@1 0.291 Acc@5 0.000
Test: [0/1]	Time  0.309 ( 0.309)	Loss 5.5328e-01 (5.5328e-01)	Acc@1   0.16 (  0.16)	Acc@5   0.00 (  0.00)
 * Acc@1 0.164 Acc@5 0.000
12
TRAINING
Epoch: [12][0/1]	Time  1.023 ( 1.023)	Data  0.304 ( 0.304)	Loss 5.8552e-01 (5.8552e-01)	Acc@1   0.21 (  0.21)	Acc@5   0.00 (  0.00)
[0.21114054253738657]
Test: [0/1]	Time  0.251 ( 0.251)	Loss 1.0559e+00 (1.0559e+00)	Acc@1   0.33 (  0.33)	Acc@5   0.00 (  0.00)
 * Acc@1 0.335 Acc@5 0.000
Test: [0/1]	Time  0.305 ( 0.305)	Loss 5.3023e-01 (5.3023e-01)	Acc@1   0.18 (  0.18)	Acc@5   0.00 (  0.00)
 * Acc@1 0.178 Acc@5 0.000
13
TRAINING
Epoch: [13][0/1]	Time  1.005 ( 1.005)	Data  0.302 ( 0.302)	Loss 5.2951e-01 (5.2951e-01)	Acc@1   0.25 (  0.25)	Acc@5   0.00 (  0.00)
[0.24901318668801758]
Test: [0/1]	Time  0.242 ( 0.242)	Loss 1.0486e+00 (1.0486e+00)	Acc@1   0.38 (  0.38)	Acc@5   0.00 (  0.00)
 * Acc@1 0.377 Acc@5 0.000
Test: [0/1]	Time  0.294 ( 0.294)	Loss 5.0788e-01 (5.0788e-01)	Acc@1   0.19 (  0.19)	Acc@5   0.00 (  0.00)
 * Acc@1 0.187 Acc@5 0.000
14
TRAINING
Epoch: [14][0/1]	Time  1.006 ( 1.006)	Data  0.303 ( 0.303)	Loss 4.7904e-01 (4.7904e-01)	Acc@1   0.28 (  0.28)	Acc@5   0.00 (  0.00)
[0.28422945957628487]
Test: [0/1]	Time  0.244 ( 0.244)	Loss 1.0405e+00 (1.0405e+00)	Acc@1   0.42 (  0.42)	Acc@5   0.00 (  0.00)
 * Acc@1 0.425 Acc@5 0.000
Test: [0/1]	Time  0.297 ( 0.297)	Loss 4.7958e-01 (4.7958e-01)	Acc@1   0.20 (  0.20)	Acc@5   0.00 (  0.00)
 * Acc@1 0.204 Acc@5 0.000
15
TRAINING
Epoch: [15][0/1]	Time  0.965 ( 0.965)	Data  0.259 ( 0.259)	Loss 4.2602e-01 (4.2602e-01)	Acc@1   0.33 (  0.33)	Acc@5   0.00 (  0.00)
[0.32770912885077136]
Test: [0/1]	Time  0.248 ( 0.248)	Loss 1.0314e+00 (1.0314e+00)	Acc@1   0.46 (  0.46)	Acc@5   0.00 (  0.00)
 * Acc@1 0.459 Acc@5 0.000
Test: [0/1]	Time  0.302 ( 0.302)	Loss 4.4386e-01 (4.4386e-01)	Acc@1   0.23 (  0.23)	Acc@5   0.00 (  0.00)
 * Acc@1 0.227 Acc@5 0.000
16
TRAINING
Epoch: [16][0/1]	Time  0.973 ( 0.973)	Data  0.267 ( 0.267)	Loss 3.6903e-01 (3.6903e-01)	Acc@1   0.37 (  0.37)	Acc@5   0.00 (  0.00)
[0.37290584293993756]
Test: [0/1]	Time  0.251 ( 0.251)	Loss 1.0221e+00 (1.0221e+00)	Acc@1   0.47 (  0.47)	Acc@5   0.00 (  0.00)
 * Acc@1 0.473 Acc@5 0.000
Test: [0/1]	Time  0.302 ( 0.302)	Loss 4.0452e-01 (4.0452e-01)	Acc@1   0.25 (  0.25)	Acc@5   0.00 (  0.00)
 * Acc@1 0.250 Acc@5 0.000
17
TRAINING
Epoch: [17][0/1]	Time  0.937 ( 0.937)	Data  0.244 ( 0.244)	Loss 3.1272e-01 (3.1272e-01)	Acc@1   0.42 (  0.42)	Acc@5   0.00 (  0.00)
[0.41934754833696697]
Test: [0/1]	Time  0.241 ( 0.241)	Loss 1.0136e+00 (1.0136e+00)	Acc@1   0.49 (  0.49)	Acc@5   0.00 (  0.00)
 * Acc@1 0.486 Acc@5 0.000
Test: [0/1]	Time  0.308 ( 0.308)	Loss 3.6754e-01 (3.6754e-01)	Acc@1   0.27 (  0.27)	Acc@5   0.00 (  0.00)
 * Acc@1 0.272 Acc@5 0.000
18
TRAINING
Epoch: [18][0/1]	Time  1.005 ( 1.005)	Data  0.286 ( 0.286)	Loss 2.6381e-01 (2.6381e-01)	Acc@1   0.46 (  0.46)	Acc@5   0.00 (  0.00)
[0.46460618287759053]
Test: [0/1]	Time  0.260 ( 0.260)	Loss 1.0067e+00 (1.0067e+00)	Acc@1   0.50 (  0.50)	Acc@5   0.00 (  0.00)
 * Acc@1 0.499 Acc@5 0.000
Test: [0/1]	Time  0.312 ( 0.312)	Loss 3.3736e-01 (3.3736e-01)	Acc@1   0.29 (  0.29)	Acc@5   0.00 (  0.00)
 * Acc@1 0.295 Acc@5 0.000
19
TRAINING
Epoch: [19][0/1]	Time  0.972 ( 0.972)	Data  0.267 ( 0.267)	Loss 2.2658e-01 (2.2658e-01)	Acc@1   0.51 (  0.51)	Acc@5   0.00 (  0.00)
[0.5118602540537592]
Test: [0/1]	Time  0.247 ( 0.247)	Loss 1.0015e+00 (1.0015e+00)	Acc@1   0.51 (  0.51)	Acc@5   0.00 (  0.00)
 * Acc@1 0.511 Acc@5 0.000
Test: [0/1]	Time  0.300 ( 0.300)	Loss 3.1470e-01 (3.1470e-01)	Acc@1   0.32 (  0.32)	Acc@5   0.00 (  0.00)
 * Acc@1 0.318 Acc@5 0.000
20
TRAINING
Epoch: [20][0/1]	Time  0.990 ( 0.990)	Data  0.274 ( 0.274)	Loss 2.0068e-01 (2.0068e-01)	Acc@1   0.56 (  0.56)	Acc@5   0.00 (  0.00)
[0.555375924881726]
Test: [0/1]	Time  0.251 ( 0.251)	Loss 9.9742e-01 (9.9742e-01)	Acc@1   0.52 (  0.52)	Acc@5   0.00 (  0.00)
 * Acc@1 0.521 Acc@5 0.000
Test: [0/1]	Time  0.305 ( 0.305)	Loss 2.9699e-01 (2.9699e-01)	Acc@1   0.34 (  0.34)	Acc@5   0.00 (  0.00)
 * Acc@1 0.342 Acc@5 0.000
21
TRAINING
Epoch: [21][0/1]	Time  0.975 ( 0.975)	Data  0.264 ( 0.264)	Loss 1.8197e-01 (1.8197e-01)	Acc@1   0.60 (  0.60)	Acc@5   0.00 (  0.00)
[0.5979240307293718]
Test: [0/1]	Time  0.251 ( 0.251)	Loss 9.9391e-01 (9.9391e-01)	Acc@1   0.53 (  0.53)	Acc@5   0.00 (  0.00)
 * Acc@1 0.533 Acc@5 0.000
Test: [0/1]	Time  0.302 ( 0.302)	Loss 2.8064e-01 (2.8064e-01)	Acc@1   0.37 (  0.37)	Acc@5   0.00 (  0.00)
 * Acc@1 0.366 Acc@5 0.000
22
TRAINING
Epoch: [22][0/1]	Time  0.998 ( 0.998)	Data  0.284 ( 0.284)	Loss 1.6549e-01 (1.6549e-01)	Acc@1   0.64 (  0.64)	Acc@5   0.00 (  0.00)
[0.6389225987341568]
Test: [0/1]	Time  0.262 ( 0.262)	Loss 9.9048e-01 (9.9048e-01)	Acc@1   0.55 (  0.55)	Acc@5   0.00 (  0.00)
 * Acc@1 0.552 Acc@5 0.000
Test: [0/1]	Time  0.320 ( 0.320)	Loss 2.6346e-01 (2.6346e-01)	Acc@1   0.39 (  0.39)	Acc@5   0.00 (  0.00)
 * Acc@1 0.391 Acc@5 0.000
23
TRAINING
Epoch: [23][0/1]	Time  0.996 ( 0.996)	Data  0.291 ( 0.291)	Loss 1.4822e-01 (1.4822e-01)	Acc@1   0.68 (  0.68)	Acc@5   0.00 (  0.00)
[0.6775165127343632]
Test: [0/1]	Time  0.271 ( 0.271)	Loss 9.8704e-01 (9.8704e-01)	Acc@1   0.56 (  0.56)	Acc@5   0.00 (  0.00)
 * Acc@1 0.565 Acc@5 0.000
Test: [0/1]	Time  0.318 ( 0.318)	Loss 2.4569e-01 (2.4569e-01)	Acc@1   0.42 (  0.42)	Acc@5   0.00 (  0.00)
 * Acc@1 0.416 Acc@5 0.000
24
TRAINING
Epoch: [24][0/1]	Time  0.988 ( 0.988)	Data  0.278 ( 0.278)	Loss 1.3030e-01 (1.3030e-01)	Acc@1   0.71 (  0.71)	Acc@5   0.00 (  0.00)
[0.7128906881694852]
Test: [0/1]	Time  0.258 ( 0.258)	Loss 9.8381e-01 (9.8381e-01)	Acc@1   0.57 (  0.57)	Acc@5   0.00 (  0.00)
 * Acc@1 0.574 Acc@5 0.000
Test: [0/1]	Time  0.309 ( 0.309)	Loss 2.2934e-01 (2.2934e-01)	Acc@1   0.44 (  0.44)	Acc@5   0.00 (  0.00)
 * Acc@1 0.441 Acc@5 0.000
25
TRAINING
Epoch: [25][0/1]	Time  0.972 ( 0.972)	Data  0.250 ( 0.250)	Loss 1.1402e-01 (1.1402e-01)	Acc@1   0.75 (  0.75)	Acc@5   0.00 (  0.00)
[0.7458095125455761]
Test: [0/1]	Time  0.274 ( 0.274)	Loss 9.8101e-01 (9.8101e-01)	Acc@1   0.58 (  0.58)	Acc@5   0.00 (  0.00)
 * Acc@1 0.582 Acc@5 0.000
Test: [0/1]	Time  0.326 ( 0.326)	Loss 2.1651e-01 (2.1651e-01)	Acc@1   0.47 (  0.47)	Acc@5   0.00 (  0.00)
 * Acc@1 0.465 Acc@5 0.000
26
TRAINING
Epoch: [26][0/1]	Time  0.954 ( 0.954)	Data  0.246 ( 0.246)	Loss 1.0190e-01 (1.0190e-01)	Acc@1   0.77 (  0.77)	Acc@5   0.00 (  0.00)
[0.7746046354832672]
Test: [0/1]	Time  0.264 ( 0.264)	Loss 9.7870e-01 (9.7870e-01)	Acc@1   0.59 (  0.59)	Acc@5   0.00 (  0.00)
 * Acc@1 0.588 Acc@5 0.000
Test: [0/1]	Time  0.313 ( 0.313)	Loss 2.0791e-01 (2.0791e-01)	Acc@1   0.49 (  0.49)	Acc@5   0.00 (  0.00)
 * Acc@1 0.489 Acc@5 0.000
27
TRAINING
Epoch: [27][0/1]	Time  1.017 ( 1.017)	Data  0.315 ( 0.315)	Loss 9.4891e-02 (9.4891e-02)	Acc@1   0.80 (  0.80)	Acc@5   0.00 (  0.00)
[0.7987172266734867]
Test: [0/1]	Time  0.269 ( 0.269)	Loss 9.7669e-01 (9.7669e-01)	Acc@1   0.59 (  0.59)	Acc@5   0.00 (  0.00)
 * Acc@1 0.593 Acc@5 0.000
Test: [0/1]	Time  0.332 ( 0.332)	Loss 2.0244e-01 (2.0244e-01)	Acc@1   0.51 (  0.51)	Acc@5   0.00 (  0.00)
 * Acc@1 0.512 Acc@5 0.000
28
TRAINING
Epoch: [28][0/1]	Time  1.000 ( 1.000)	Data  0.286 ( 0.286)	Loss 9.1902e-02 (9.1902e-02)	Acc@1   0.82 (  0.82)	Acc@5   0.00 (  0.00)
[0.8185299654884297]
Test: [0/1]	Time  0.258 ( 0.258)	Loss 9.7464e-01 (9.7464e-01)	Acc@1   0.60 (  0.60)	Acc@5   0.00 (  0.00)
 * Acc@1 0.599 Acc@5 0.000
Test: [0/1]	Time  0.306 ( 0.306)	Loss 1.9795e-01 (1.9795e-01)	Acc@1   0.53 (  0.53)	Acc@5   0.00 (  0.00)
 * Acc@1 0.534 Acc@5 0.000
29
TRAINING
Epoch: [29][0/1]	Time  1.000 ( 1.000)	Data  0.283 ( 0.283)	Loss 9.0632e-02 (9.0632e-02)	Acc@1   0.83 (  0.83)	Acc@5   0.00 (  0.00)
[0.8343947257315549]
Test: [0/1]	Time  0.270 ( 0.270)	Loss 9.7229e-01 (9.7229e-01)	Acc@1   0.61 (  0.61)	Acc@5   0.00 (  0.00)
 * Acc@1 0.609 Acc@5 0.000
Test: [0/1]	Time  0.318 ( 0.318)	Loss 1.9256e-01 (1.9256e-01)	Acc@1   0.55 (  0.55)	Acc@5   0.00 (  0.00)
 * Acc@1 0.554 Acc@5 0.000
30
TRAINING
Epoch: [30][0/1]	Time  0.996 ( 0.996)	Data  0.275 ( 0.275)	Loss 8.8968e-02 (8.8968e-02)	Acc@1   0.85 (  0.85)	Acc@5   0.00 (  0.00)
[0.8468680560035]
Test: [0/1]	Time  0.254 ( 0.254)	Loss 9.6955e-01 (9.6955e-01)	Acc@1   0.62 (  0.62)	Acc@5   0.00 (  0.00)
 * Acc@1 0.623 Acc@5 0.000
Test: [0/1]	Time  0.307 ( 0.307)	Loss 1.8556e-01 (1.8556e-01)	Acc@1   0.57 (  0.57)	Acc@5   0.00 (  0.00)
 * Acc@1 0.573 Acc@5 0.000
31
TRAINING
Epoch: [31][0/1]	Time  0.979 ( 0.979)	Data  0.283 ( 0.283)	Loss 8.6035e-02 (8.6035e-02)	Acc@1   0.86 (  0.86)	Acc@5   0.00 (  0.00)
[0.8578955866993666]
Test: [0/1]	Time  0.263 ( 0.263)	Loss 9.6654e-01 (9.6654e-01)	Acc@1   0.63 (  0.63)	Acc@5   0.00 (  0.00)
 * Acc@1 0.633 Acc@5 0.000
Test: [0/1]	Time  0.315 ( 0.315)	Loss 1.7763e-01 (1.7763e-01)	Acc@1   0.59 (  0.59)	Acc@5   0.00 (  0.00)
 * Acc@1 0.592 Acc@5 0.000
32
TRAINING
Epoch: [32][0/1]	Time  0.954 ( 0.954)	Data  0.246 ( 0.246)	Loss 8.2358e-02 (8.2358e-02)	Acc@1   0.87 (  0.87)	Acc@5   0.00 (  0.00)
[0.8668892523129714]
Test: [0/1]	Time  0.259 ( 0.259)	Loss 9.6352e-01 (9.6352e-01)	Acc@1   0.64 (  0.64)	Acc@5   0.00 (  0.00)
 * Acc@1 0.642 Acc@5 0.000
Test: [0/1]	Time  0.308 ( 0.308)	Loss 1.7018e-01 (1.7018e-01)	Acc@1   0.61 (  0.61)	Acc@5   0.00 (  0.00)
 * Acc@1 0.611 Acc@5 0.000
33
TRAINING
Epoch: [33][0/1]	Time  0.991 ( 0.991)	Data  0.272 ( 0.272)	Loss 7.9198e-02 (7.9198e-02)	Acc@1   0.87 (  0.87)	Acc@5   0.00 (  0.00)
[0.8720916486185937]
Test: [0/1]	Time  0.252 ( 0.252)	Loss 9.6072e-01 (9.6072e-01)	Acc@1   0.65 (  0.65)	Acc@5   0.00 (  0.00)
 * Acc@1 0.649 Acc@5 0.000
Test: [0/1]	Time  0.305 ( 0.305)	Loss 1.6440e-01 (1.6440e-01)	Acc@1   0.63 (  0.63)	Acc@5   0.00 (  0.00)
 * Acc@1 0.628 Acc@5 0.000
34
TRAINING
Epoch: [34][0/1]	Time  0.968 ( 0.968)	Data  0.271 ( 0.271)	Loss 7.7603e-02 (7.7603e-02)	Acc@1   0.88 (  0.88)	Acc@5   0.00 (  0.00)
[0.8765334628350874]
Test: [0/1]	Time  0.256 ( 0.256)	Loss 9.5822e-01 (9.5822e-01)	Acc@1   0.65 (  0.65)	Acc@5   0.00 (  0.00)
 * Acc@1 0.654 Acc@5 0.000
Test: [0/1]	Time  0.310 ( 0.310)	Loss 1.6072e-01 (1.6072e-01)	Acc@1   0.64 (  0.64)	Acc@5   0.00 (  0.00)
 * Acc@1 0.645 Acc@5 0.000
35
TRAINING
Epoch: [35][0/1]	Time  0.959 ( 0.959)	Data  0.247 ( 0.247)	Loss 7.7782e-02 (7.7782e-02)	Acc@1   0.88 (  0.88)	Acc@5   0.00 (  0.00)
[0.878486947704292]
Test: [0/1]	Time  0.247 ( 0.247)	Loss 9.5602e-01 (9.5602e-01)	Acc@1   0.65 (  0.65)	Acc@5   0.00 (  0.00)
 * Acc@1 0.655 Acc@5 0.000
Test: [0/1]	Time  0.315 ( 0.315)	Loss 1.5871e-01 (1.5871e-01)	Acc@1   0.66 (  0.66)	Acc@5   0.00 (  0.00)
 * Acc@1 0.660 Acc@5 0.000
36
TRAINING
Epoch: [36][0/1]	Time  0.961 ( 0.961)	Data  0.258 ( 0.258)	Loss 7.9092e-02 (7.9092e-02)	Acc@1   0.88 (  0.88)	Acc@5   0.00 (  0.00)
[0.8787392832844965]
Test: [0/1]	Time  0.258 ( 0.258)	Loss 9.5404e-01 (9.5404e-01)	Acc@1   0.65 (  0.65)	Acc@5   0.00 (  0.00)
 * Acc@1 0.654 Acc@5 0.000
Test: [0/1]	Time  0.308 ( 0.308)	Loss 1.5753e-01 (1.5753e-01)	Acc@1   0.67 (  0.67)	Acc@5   0.00 (  0.00)
 * Acc@1 0.674 Acc@5 0.000
37
TRAINING
Epoch: [37][0/1]	Time  0.964 ( 0.964)	Data  0.257 ( 0.257)	Loss 8.0538e-02 (8.0538e-02)	Acc@1   0.88 (  0.88)	Acc@5   0.00 (  0.00)
[0.8779370454901484]
Test: [0/1]	Time  0.248 ( 0.248)	Loss 9.5220e-01 (9.5220e-01)	Acc@1   0.65 (  0.65)	Acc@5   0.00 (  0.00)
 * Acc@1 0.654 Acc@5 0.000
Test: [0/1]	Time  0.297 ( 0.297)	Loss 1.5648e-01 (1.5648e-01)	Acc@1   0.69 (  0.69)	Acc@5   0.00 (  0.00)
 * Acc@1 0.686 Acc@5 0.000
38
TRAINING
Epoch: [38][0/1]	Time  0.949 ( 0.949)	Data  0.251 ( 0.251)	Loss 8.1378e-02 (8.1378e-02)	Acc@1   0.88 (  0.88)	Acc@5   0.00 (  0.00)
[0.8775016783633617]
Test: [0/1]	Time  0.247 ( 0.247)	Loss 9.5049e-01 (9.5049e-01)	Acc@1   0.65 (  0.65)	Acc@5   0.00 (  0.00)
 * Acc@1 0.654 Acc@5 0.000
Test: [0/1]	Time  0.297 ( 0.297)	Loss 1.5536e-01 (1.5536e-01)	Acc@1   0.70 (  0.70)	Acc@5   0.00 (  0.00)
 * Acc@1 0.695 Acc@5 0.000
39
TRAINING
Epoch: [39][0/1]	Time  0.970 ( 0.970)	Data  0.251 ( 0.251)	Loss 8.1468e-02 (8.1468e-02)	Acc@1   0.88 (  0.88)	Acc@5   0.00 (  0.00)
[0.8769395385291492]
Test: [0/1]	Time  0.256 ( 0.256)	Loss 9.4896e-01 (9.4896e-01)	Acc@1   0.65 (  0.65)	Acc@5   0.00 (  0.00)
 * Acc@1 0.654 Acc@5 0.000
Test: [0/1]	Time  0.305 ( 0.305)	Loss 1.5437e-01 (1.5437e-01)	Acc@1   0.71 (  0.71)	Acc@5   0.00 (  0.00)
 * Acc@1 0.706 Acc@5 0.000
40
TRAINING
Epoch: [40][0/1]	Time  0.987 ( 0.987)	Data  0.286 ( 0.286)	Loss 8.1197e-02 (8.1197e-02)	Acc@1   0.88 (  0.88)	Acc@5   0.00 (  0.00)
[0.8764180886460835]
Test: [0/1]	Time  0.268 ( 0.268)	Loss 9.4764e-01 (9.4764e-01)	Acc@1   0.65 (  0.65)	Acc@5   0.00 (  0.00)
 * Acc@1 0.654 Acc@5 0.000
Test: [0/1]	Time  0.321 ( 0.321)	Loss 1.5390e-01 (1.5390e-01)	Acc@1   0.71 (  0.71)	Acc@5   0.00 (  0.00)
 * Acc@1 0.712 Acc@5 0.000
41
TRAINING
Epoch: [41][0/1]	Time  0.966 ( 0.966)	Data  0.271 ( 0.271)	Loss 8.1121e-02 (8.1121e-02)	Acc@1   0.88 (  0.88)	Acc@5   0.00 (  0.00)
[0.8761528852564882]
Test: [0/1]	Time  0.251 ( 0.251)	Loss 9.4653e-01 (9.4653e-01)	Acc@1   0.65 (  0.65)	Acc@5   0.00 (  0.00)
 * Acc@1 0.653 Acc@5 0.000
Test: [0/1]	Time  0.306 ( 0.306)	Loss 1.5409e-01 (1.5409e-01)	Acc@1   0.72 (  0.72)	Acc@5   0.00 (  0.00)
 * Acc@1 0.716 Acc@5 0.000
42
TRAINING
Epoch: [42][0/1]	Time  0.951 ( 0.951)	Data  0.255 ( 0.255)	Loss 8.1571e-02 (8.1571e-02)	Acc@1   0.88 (  0.88)	Acc@5   0.00 (  0.00)
[0.8761594254581901]
Test: [0/1]	Time  0.266 ( 0.266)	Loss 9.4558e-01 (9.4558e-01)	Acc@1   0.66 (  0.66)	Acc@5   0.00 (  0.00)
 * Acc@1 0.657 Acc@5 0.000
Test: [0/1]	Time  0.315 ( 0.315)	Loss 1.5479e-01 (1.5479e-01)	Acc@1   0.72 (  0.72)	Acc@5   0.00 (  0.00)
 * Acc@1 0.720 Acc@5 0.000
43
TRAINING
Epoch: [43][0/1]	Time  0.940 ( 0.940)	Data  0.248 ( 0.248)	Loss 8.2474e-02 (8.2474e-02)	Acc@1   0.88 (  0.88)	Acc@5   0.00 (  0.00)
[0.8760118259997252]
Test: [0/1]	Time  0.285 ( 0.285)	Loss 9.4471e-01 (9.4471e-01)	Acc@1   0.66 (  0.66)	Acc@5   0.00 (  0.00)
 * Acc@1 0.661 Acc@5 0.000
Test: [0/1]	Time  0.290 ( 0.290)	Loss 1.5558e-01 (1.5558e-01)	Acc@1   0.72 (  0.72)	Acc@5   0.00 (  0.00)
 * Acc@1 0.724 Acc@5 0.000
44
TRAINING
Epoch: [44][0/1]	Time  0.989 ( 0.989)	Data  0.276 ( 0.276)	Loss 8.3451e-02 (8.3451e-02)	Acc@1   0.88 (  0.88)	Acc@5   0.00 (  0.00)
[0.8765723158779346]
Test: [0/1]	Time  0.255 ( 0.255)	Loss 9.4385e-01 (9.4385e-01)	Acc@1   0.66 (  0.66)	Acc@5   0.00 (  0.00)
 * Acc@1 0.663 Acc@5 0.000
Test: [0/1]	Time  0.308 ( 0.308)	Loss 1.5606e-01 (1.5606e-01)	Acc@1   0.73 (  0.73)	Acc@5   0.00 (  0.00)
 * Acc@1 0.727 Acc@5 0.000
45
TRAINING
Epoch: [45][0/1]	Time  0.970 ( 0.970)	Data  0.269 ( 0.269)	Loss 8.4084e-02 (8.4084e-02)	Acc@1   0.88 (  0.88)	Acc@5   0.00 (  0.00)
[0.8780224956803784]
Test: [0/1]	Time  0.248 ( 0.248)	Loss 9.4294e-01 (9.4294e-01)	Acc@1   0.66 (  0.66)	Acc@5   0.00 (  0.00)
 * Acc@1 0.663 Acc@5 0.000
Test: [0/1]	Time  0.296 ( 0.296)	Loss 1.5605e-01 (1.5605e-01)	Acc@1   0.73 (  0.73)	Acc@5   0.00 (  0.00)
 * Acc@1 0.729 Acc@5 0.000
46
TRAINING
Epoch: [46][0/1]	Time  0.949 ( 0.949)	Data  0.248 ( 0.248)	Loss 8.4156e-02 (8.4156e-02)	Acc@1   0.88 (  0.88)	Acc@5   0.00 (  0.00)
[0.8810386367245322]
Test: [0/1]	Time  0.260 ( 0.260)	Loss 9.4204e-01 (9.4204e-01)	Acc@1   0.66 (  0.66)	Acc@5   0.00 (  0.00)
 * Acc@1 0.663 Acc@5 0.000
Test: [0/1]	Time  0.309 ( 0.309)	Loss 1.5563e-01 (1.5563e-01)	Acc@1   0.73 (  0.73)	Acc@5   0.00 (  0.00)
 * Acc@1 0.730 Acc@5 0.000
47
TRAINING
Epoch: [47][0/1]	Time  0.971 ( 0.971)	Data  0.275 ( 0.275)	Loss 8.3747e-02 (8.3747e-02)	Acc@1   0.88 (  0.88)	Acc@5   0.00 (  0.00)
[0.8843491629486613]
Test: [0/1]	Time  0.246 ( 0.246)	Loss 9.4119e-01 (9.4119e-01)	Acc@1   0.66 (  0.66)	Acc@5   0.00 (  0.00)
 * Acc@1 0.662 Acc@5 0.000
Test: [0/1]	Time  0.297 ( 0.297)	Loss 1.5509e-01 (1.5509e-01)	Acc@1   0.73 (  0.73)	Acc@5   0.00 (  0.00)
 * Acc@1 0.730 Acc@5 0.000
48
TRAINING
Epoch: [48][0/1]	Time  0.939 ( 0.939)	Data  0.255 ( 0.255)	Loss 8.3134e-02 (8.3134e-02)	Acc@1   0.89 (  0.89)	Acc@5   0.00 (  0.00)
[0.8878182073247394]
Test: [0/1]	Time  0.250 ( 0.250)	Loss 9.4044e-01 (9.4044e-01)	Acc@1   0.66 (  0.66)	Acc@5   0.00 (  0.00)
 * Acc@1 0.660 Acc@5 0.000
Test: [0/1]	Time  0.301 ( 0.301)	Loss 1.5471e-01 (1.5471e-01)	Acc@1   0.73 (  0.73)	Acc@5   0.00 (  0.00)
 * Acc@1 0.732 Acc@5 0.000
49
TRAINING
Epoch: [49][0/1]	Time  0.972 ( 0.972)	Data  0.278 ( 0.278)	Loss 8.2609e-02 (8.2609e-02)	Acc@1   0.89 (  0.89)	Acc@5   0.00 (  0.00)
[0.8913149142132493]
Test: [0/1]	Time  0.257 ( 0.257)	Loss 9.3983e-01 (9.3983e-01)	Acc@1   0.66 (  0.66)	Acc@5   0.00 (  0.00)
 * Acc@1 0.659 Acc@5 0.000
Test: [0/1]	Time  0.305 ( 0.305)	Loss 1.5463e-01 (1.5463e-01)	Acc@1   0.73 (  0.73)	Acc@5   0.00 (  0.00)
 * Acc@1 0.734 Acc@5 0.000
50
TRAINING
Epoch: [50][0/1]	Time  0.939 ( 0.939)	Data  0.248 ( 0.248)	Loss 8.2317e-02 (8.2317e-02)	Acc@1   0.89 (  0.89)	Acc@5   0.00 (  0.00)
[0.8947458854215102]
Test: [0/1]	Time  0.272 ( 0.272)	Loss 9.3938e-01 (9.3938e-01)	Acc@1   0.66 (  0.66)	Acc@5   0.00 (  0.00)
 * Acc@1 0.657 Acc@5 0.000
Test: [0/1]	Time  0.330 ( 0.330)	Loss 1.5480e-01 (1.5480e-01)	Acc@1   0.73 (  0.73)	Acc@5   0.00 (  0.00)
 * Acc@1 0.735 Acc@5 0.000
51
TRAINING
Epoch: [51][0/1]	Time  0.949 ( 0.949)	Data  0.246 ( 0.246)	Loss 8.2215e-02 (8.2215e-02)	Acc@1   0.90 (  0.90)	Acc@5   0.00 (  0.00)
[0.8981829616046956]
Test: [0/1]	Time  0.260 ( 0.260)	Loss 9.3908e-01 (9.3908e-01)	Acc@1   0.66 (  0.66)	Acc@5   0.00 (  0.00)
 * Acc@1 0.655 Acc@5 0.000
Test: [0/1]	Time  0.317 ( 0.317)	Loss 1.5506e-01 (1.5506e-01)	Acc@1   0.74 (  0.74)	Acc@5   0.00 (  0.00)
 * Acc@1 0.736 Acc@5 0.000
52
TRAINING
Epoch: [52][0/1]	Time  0.964 ( 0.964)	Data  0.244 ( 0.244)	Loss 8.2149e-02 (8.2149e-02)	Acc@1   0.90 (  0.90)	Acc@5   0.00 (  0.00)
[0.9020019701588637]
Test: [0/1]	Time  0.249 ( 0.249)	Loss 9.3890e-01 (9.3890e-01)	Acc@1   0.65 (  0.65)	Acc@5   0.00 (  0.00)
 * Acc@1 0.654 Acc@5 0.000
Test: [0/1]	Time  0.299 ( 0.299)	Loss 1.5526e-01 (1.5526e-01)	Acc@1   0.73 (  0.73)	Acc@5   0.00 (  0.00)
 * Acc@1 0.734 Acc@5 0.000
53
TRAINING
Epoch: [53][0/1]	Time  0.943 ( 0.943)	Data  0.261 ( 0.261)	Loss 8.1972e-02 (8.1972e-02)	Acc@1   0.91 (  0.91)	Acc@5   0.00 (  0.00)
[0.9055861786648338]
Test: [0/1]	Time  0.242 ( 0.242)	Loss 9.3882e-01 (9.3882e-01)	Acc@1   0.65 (  0.65)	Acc@5   0.00 (  0.00)
 * Acc@1 0.655 Acc@5 0.000
Test: [0/1]	Time  0.305 ( 0.305)	Loss 1.5533e-01 (1.5533e-01)	Acc@1   0.73 (  0.73)	Acc@5   0.00 (  0.00)
 * Acc@1 0.731 Acc@5 0.000
54
TRAINING
Epoch: [54][0/1]	Time  0.949 ( 0.949)	Data  0.267 ( 0.267)	Loss 8.1640e-02 (8.1640e-02)	Acc@1   0.91 (  0.91)	Acc@5   0.00 (  0.00)
[0.908293646053209]
Test: [0/1]	Time  0.247 ( 0.247)	Loss 9.3885e-01 (9.3885e-01)	Acc@1   0.65 (  0.65)	Acc@5   0.00 (  0.00)
 * Acc@1 0.655 Acc@5 0.000
Test: [0/1]	Time  0.301 ( 0.301)	Loss 1.5530e-01 (1.5530e-01)	Acc@1   0.73 (  0.73)	Acc@5   0.00 (  0.00)
 * Acc@1 0.729 Acc@5 0.000
55
TRAINING
Epoch: [55][0/1]	Time  0.939 ( 0.939)	Data  0.258 ( 0.258)	Loss 8.1217e-02 (8.1217e-02)	Acc@1   0.91 (  0.91)	Acc@5   0.00 (  0.00)
[0.9107635661803358]
Test: [0/1]	Time  0.246 ( 0.246)	Loss 9.3897e-01 (9.3897e-01)	Acc@1   0.65 (  0.65)	Acc@5   0.00 (  0.00)
 * Acc@1 0.655 Acc@5 0.000
Test: [0/1]	Time  0.298 ( 0.298)	Loss 1.5527e-01 (1.5527e-01)	Acc@1   0.73 (  0.73)	Acc@5   0.00 (  0.00)
 * Acc@1 0.728 Acc@5 0.000
56
TRAINING
Epoch: [56][0/1]	Time  0.942 ( 0.942)	Data  0.261 ( 0.261)	Loss 8.0821e-02 (8.0821e-02)	Acc@1   0.91 (  0.91)	Acc@5   0.00 (  0.00)
[0.9134491958634673]
Test: [0/1]	Time  0.246 ( 0.246)	Loss 9.3918e-01 (9.3918e-01)	Acc@1   0.65 (  0.65)	Acc@5   0.00 (  0.00)
 * Acc@1 0.655 Acc@5 0.000
Test: [0/1]	Time  0.297 ( 0.297)	Loss 1.5528e-01 (1.5528e-01)	Acc@1   0.73 (  0.73)	Acc@5   0.00 (  0.00)
 * Acc@1 0.727 Acc@5 0.000
57
TRAINING
Epoch: [57][0/1]	Time  0.943 ( 0.943)	Data  0.259 ( 0.259)	Loss 8.0541e-02 (8.0541e-02)	Acc@1   0.92 (  0.92)	Acc@5   0.00 (  0.00)
[0.9160824889974564]
Test: [0/1]	Time  0.244 ( 0.244)	Loss 9.3945e-01 (9.3945e-01)	Acc@1   0.65 (  0.65)	Acc@5   0.00 (  0.00)
 * Acc@1 0.655 Acc@5 0.000
Test: [0/1]	Time  0.299 ( 0.299)	Loss 1.5536e-01 (1.5536e-01)	Acc@1   0.73 (  0.73)	Acc@5   0.00 (  0.00)
 * Acc@1 0.727 Acc@5 0.000
58
TRAINING
Epoch: [58][0/1]	Time  0.942 ( 0.942)	Data  0.257 ( 0.257)	Loss 8.0388e-02 (8.0388e-02)	Acc@1   0.92 (  0.92)	Acc@5   0.00 (  0.00)
[0.9185698560693238]
Test: [0/1]	Time  0.246 ( 0.246)	Loss 9.3976e-01 (9.3976e-01)	Acc@1   0.66 (  0.66)	Acc@5   0.00 (  0.00)
 * Acc@1 0.655 Acc@5 0.000
Test: [0/1]	Time  0.302 ( 0.302)	Loss 1.5544e-01 (1.5544e-01)	Acc@1   0.73 (  0.73)	Acc@5   0.00 (  0.00)
 * Acc@1 0.727 Acc@5 0.000
59
TRAINING
Epoch: [59][0/1]	Time  0.946 ( 0.946)	Data  0.262 ( 0.262)	Loss 8.0298e-02 (8.0298e-02)	Acc@1   0.92 (  0.92)	Acc@5   0.00 (  0.00)
[0.9208244415679863]
Test: [0/1]	Time  0.244 ( 0.244)	Loss 9.4007e-01 (9.4007e-01)	Acc@1   0.66 (  0.66)	Acc@5   0.00 (  0.00)
 * Acc@1 0.656 Acc@5 0.000
Test: [0/1]	Time  0.297 ( 0.297)	Loss 1.5546e-01 (1.5546e-01)	Acc@1   0.73 (  0.73)	Acc@5   0.00 (  0.00)
 * Acc@1 0.727 Acc@5 0.000
60
TRAINING
Epoch: [60][0/1]	Time  0.968 ( 0.968)	Data  0.249 ( 0.249)	Loss 8.0182e-02 (8.0182e-02)	Acc@1   0.92 (  0.92)	Acc@5   0.00 (  0.00)
[0.9231766721529816]
Test: [0/1]	Time  0.241 ( 0.241)	Loss 9.4038e-01 (9.4038e-01)	Acc@1   0.66 (  0.66)	Acc@5   0.00 (  0.00)
 * Acc@1 0.657 Acc@5 0.000
Test: [0/1]	Time  0.294 ( 0.294)	Loss 1.5538e-01 (1.5538e-01)	Acc@1   0.73 (  0.73)	Acc@5   0.00 (  0.00)
 * Acc@1 0.727 Acc@5 0.000
61
TRAINING
Epoch: [61][0/1]	Time  0.941 ( 0.941)	Data  0.258 ( 0.258)	Loss 7.9982e-02 (7.9982e-02)	Acc@1   0.92 (  0.92)	Acc@5   0.00 (  0.00)
[0.9246673763634601]
Test: [0/1]	Time  0.240 ( 0.240)	Loss 9.4068e-01 (9.4068e-01)	Acc@1   0.66 (  0.66)	Acc@5   0.00 (  0.00)
 * Acc@1 0.657 Acc@5 0.000
Test: [0/1]	Time  0.295 ( 0.295)	Loss 1.5519e-01 (1.5519e-01)	Acc@1   0.73 (  0.73)	Acc@5   0.00 (  0.00)
 * Acc@1 0.727 Acc@5 0.000
62
TRAINING
Epoch: [62][0/1]	Time  0.943 ( 0.943)	Data  0.257 ( 0.257)	Loss 7.9695e-02 (7.9695e-02)	Acc@1   0.93 (  0.93)	Acc@5   0.00 (  0.00)
[0.9258813308688651]
Test: [0/1]	Time  0.251 ( 0.251)	Loss 9.4098e-01 (9.4098e-01)	Acc@1   0.66 (  0.66)	Acc@5   0.00 (  0.00)
 * Acc@1 0.658 Acc@5 0.000
Test: [0/1]	Time  0.304 ( 0.304)	Loss 1.5495e-01 (1.5495e-01)	Acc@1   0.73 (  0.73)	Acc@5   0.00 (  0.00)
 * Acc@1 0.728 Acc@5 0.000
63
TRAINING
Epoch: [63][0/1]	Time  0.938 ( 0.938)	Data  0.253 ( 0.253)	Loss 7.9369e-02 (7.9369e-02)	Acc@1   0.93 (  0.93)	Acc@5   0.00 (  0.00)
[0.9269384214421318]
Test: [0/1]	Time  0.239 ( 0.239)	Loss 9.4129e-01 (9.4129e-01)	Acc@1   0.66 (  0.66)	Acc@5   0.00 (  0.00)
 * Acc@1 0.659 Acc@5 0.000
Test: [0/1]	Time  0.293 ( 0.293)	Loss 1.5471e-01 (1.5471e-01)	Acc@1   0.73 (  0.73)	Acc@5   0.00 (  0.00)
 * Acc@1 0.728 Acc@5 0.000
64
TRAINING
Epoch: [64][0/1]	Time  0.933 ( 0.933)	Data  0.253 ( 0.253)	Loss 7.9068e-02 (7.9068e-02)	Acc@1   0.93 (  0.93)	Acc@5   0.00 (  0.00)
[0.9277560188092346]
Test: [0/1]	Time  0.241 ( 0.241)	Loss 9.4160e-01 (9.4160e-01)	Acc@1   0.66 (  0.66)	Acc@5   0.00 (  0.00)
 * Acc@1 0.659 Acc@5 0.000
Test: [0/1]	Time  0.297 ( 0.297)	Loss 1.5451e-01 (1.5451e-01)	Acc@1   0.73 (  0.73)	Acc@5   0.00 (  0.00)
 * Acc@1 0.729 Acc@5 0.000
65
TRAINING
Epoch: [65][0/1]	Time  0.929 ( 0.929)	Data  0.250 ( 0.250)	Loss 7.8833e-02 (7.8833e-02)	Acc@1   0.93 (  0.93)	Acc@5   0.00 (  0.00)
[0.928333113389296]
Test: [0/1]	Time  0.283 ( 0.283)	Loss 9.4191e-01 (9.4191e-01)	Acc@1   0.66 (  0.66)	Acc@5   0.00 (  0.00)
 * Acc@1 0.660 Acc@5 0.000
Test: [0/1]	Time  0.292 ( 0.292)	Loss 1.5435e-01 (1.5435e-01)	Acc@1   0.73 (  0.73)	Acc@5   0.00 (  0.00)
 * Acc@1 0.729 Acc@5 0.000
66
TRAINING
Epoch: [66][0/1]	Time  0.933 ( 0.933)	Data  0.254 ( 0.254)	Loss 7.8667e-02 (7.8667e-02)	Acc@1   0.93 (  0.93)	Acc@5   0.00 (  0.00)
[0.9288620420851924]
Test: [0/1]	Time  0.245 ( 0.245)	Loss 9.4223e-01 (9.4223e-01)	Acc@1   0.66 (  0.66)	Acc@5   0.00 (  0.00)
 * Acc@1 0.661 Acc@5 0.000
Test: [0/1]	Time  0.293 ( 0.293)	Loss 1.5420e-01 (1.5420e-01)	Acc@1   0.73 (  0.73)	Acc@5   0.00 (  0.00)
 * Acc@1 0.730 Acc@5 0.000
67
TRAINING
Epoch: [67][0/1]	Time  0.935 ( 0.935)	Data  0.253 ( 0.253)	Loss 7.8546e-02 (7.8546e-02)	Acc@1   0.93 (  0.93)	Acc@5   0.00 (  0.00)
[0.9293518245835951]
Test: [0/1]	Time  0.239 ( 0.239)	Loss 9.4255e-01 (9.4255e-01)	Acc@1   0.66 (  0.66)	Acc@5   0.00 (  0.00)
 * Acc@1 0.662 Acc@5 0.000
Test: [0/1]	Time  0.294 ( 0.294)	Loss 1.5404e-01 (1.5404e-01)	Acc@1   0.73 (  0.73)	Acc@5   0.00 (  0.00)
 * Acc@1 0.731 Acc@5 0.000
68
TRAINING
Epoch: [68][0/1]	Time  0.934 ( 0.934)	Data  0.254 ( 0.254)	Loss 7.8436e-02 (7.8436e-02)	Acc@1   0.93 (  0.93)	Acc@5   0.00 (  0.00)
[0.9298100376272636]
Test: [0/1]	Time  0.242 ( 0.242)	Loss 9.4287e-01 (9.4287e-01)	Acc@1   0.66 (  0.66)	Acc@5   0.00 (  0.00)
 * Acc@1 0.663 Acc@5 0.000
Test: [0/1]	Time  0.291 ( 0.291)	Loss 1.5386e-01 (1.5386e-01)	Acc@1   0.73 (  0.73)	Acc@5   0.00 (  0.00)
 * Acc@1 0.733 Acc@5 0.000
69
TRAINING
Epoch: [69][0/1]	Time  0.933 ( 0.933)	Data  0.253 ( 0.253)	Loss 7.8319e-02 (7.8319e-02)	Acc@1   0.93 (  0.93)	Acc@5   0.00 (  0.00)
[0.930162288792374]
Test: [0/1]	Time  0.239 ( 0.239)	Loss 9.4317e-01 (9.4317e-01)	Acc@1   0.66 (  0.66)	Acc@5   0.00 (  0.00)
 * Acc@1 0.664 Acc@5 0.000
Test: [0/1]	Time  0.297 ( 0.297)	Loss 1.5365e-01 (1.5365e-01)	Acc@1   0.73 (  0.73)	Acc@5   0.00 (  0.00)
 * Acc@1 0.734 Acc@5 0.000
70
TRAINING
Epoch: [70][0/1]	Time  0.961 ( 0.961)	Data  0.250 ( 0.250)	Loss 7.8201e-02 (7.8201e-02)	Acc@1   0.93 (  0.93)	Acc@5   0.00 (  0.00)
[0.9303905598795661]
Test: [0/1]	Time  0.239 ( 0.239)	Loss 9.4346e-01 (9.4346e-01)	Acc@1   0.67 (  0.67)	Acc@5   0.00 (  0.00)
 * Acc@1 0.666 Acc@5 0.000
Test: [0/1]	Time  0.290 ( 0.290)	Loss 1.5343e-01 (1.5343e-01)	Acc@1   0.74 (  0.74)	Acc@5   0.00 (  0.00)
 * Acc@1 0.736 Acc@5 0.000
71
TRAINING
Epoch: [71][0/1]	Time  0.961 ( 0.961)	Data  0.252 ( 0.252)	Loss 7.8099e-02 (7.8099e-02)	Acc@1   0.93 (  0.93)	Acc@5   0.00 (  0.00)
[0.9306128821306058]
Test: [0/1]	Time  0.246 ( 0.246)	Loss 9.4372e-01 (9.4372e-01)	Acc@1   0.67 (  0.67)	Acc@5   0.00 (  0.00)
 * Acc@1 0.667 Acc@5 0.000
Test: [0/1]	Time  0.306 ( 0.306)	Loss 1.5324e-01 (1.5324e-01)	Acc@1   0.74 (  0.74)	Acc@5   0.00 (  0.00)
 * Acc@1 0.737 Acc@5 0.000
72
TRAINING
Epoch: [72][0/1]	Time  0.951 ( 0.951)	Data  0.245 ( 0.245)	Loss 7.8030e-02 (7.8030e-02)	Acc@1   0.93 (  0.93)	Acc@5   0.00 (  0.00)
[0.9308296446932511]
Test: [0/1]	Time  0.242 ( 0.242)	Loss 9.4395e-01 (9.4395e-01)	Acc@1   0.67 (  0.67)	Acc@5   0.00 (  0.00)
 * Acc@1 0.668 Acc@5 0.000
Test: [0/1]	Time  0.309 ( 0.309)	Loss 1.5308e-01 (1.5308e-01)	Acc@1   0.74 (  0.74)	Acc@5   0.00 (  0.00)
 * Acc@1 0.739 Acc@5 0.000
73
TRAINING
Epoch: [73][0/1]	Time  0.967 ( 0.967)	Data  0.246 ( 0.246)	Loss 7.7998e-02 (7.7998e-02)	Acc@1   0.93 (  0.93)	Acc@5   0.00 (  0.00)
[0.9310407295868774]
Test: [0/1]	Time  0.241 ( 0.241)	Loss 9.4416e-01 (9.4416e-01)	Acc@1   0.67 (  0.67)	Acc@5   0.00 (  0.00)
 * Acc@1 0.669 Acc@5 0.000
Test: [0/1]	Time  0.294 ( 0.294)	Loss 1.5294e-01 (1.5294e-01)	Acc@1   0.74 (  0.74)	Acc@5   0.00 (  0.00)
 * Acc@1 0.740 Acc@5 0.000
74
TRAINING
Epoch: [74][0/1]	Time  0.968 ( 0.968)	Data  0.260 ( 0.260)	Loss 7.7989e-02 (7.7989e-02)	Acc@1   0.93 (  0.93)	Acc@5   0.00 (  0.00)
[0.93123374097541]
Test: [0/1]	Time  0.244 ( 0.244)	Loss 9.4434e-01 (9.4434e-01)	Acc@1   0.67 (  0.67)	Acc@5   0.00 (  0.00)
 * Acc@1 0.669 Acc@5 0.000
Test: [0/1]	Time  0.298 ( 0.298)	Loss 1.5281e-01 (1.5281e-01)	Acc@1   0.74 (  0.74)	Acc@5   0.00 (  0.00)
 * Acc@1 0.742 Acc@5 0.000
75
TRAINING
Epoch: [75][0/1]	Time  0.951 ( 0.951)	Data  0.243 ( 0.243)	Loss 7.7982e-02 (7.7982e-02)	Acc@1   0.93 (  0.93)	Acc@5   0.00 (  0.00)
[0.93136547874982]
Test: [0/1]	Time  0.239 ( 0.239)	Loss 9.4449e-01 (9.4449e-01)	Acc@1   0.67 (  0.67)	Acc@5   0.00 (  0.00)
 * Acc@1 0.670 Acc@5 0.000
Test: [0/1]	Time  0.292 ( 0.292)	Loss 1.5268e-01 (1.5268e-01)	Acc@1   0.74 (  0.74)	Acc@5   0.00 (  0.00)
 * Acc@1 0.743 Acc@5 0.000
76
TRAINING
Epoch: [76][0/1]	Time  0.960 ( 0.960)	Data  0.243 ( 0.243)	Loss 7.7961e-02 (7.7961e-02)	Acc@1   0.93 (  0.93)	Acc@5   0.00 (  0.00)
[0.9314852425887132]
Test: [0/1]	Time  0.248 ( 0.248)	Loss 9.4460e-01 (9.4460e-01)	Acc@1   0.67 (  0.67)	Acc@5   0.00 (  0.00)
 * Acc@1 0.670 Acc@5 0.000
Test: [0/1]	Time  0.293 ( 0.293)	Loss 1.5255e-01 (1.5255e-01)	Acc@1   0.74 (  0.74)	Acc@5   0.00 (  0.00)
 * Acc@1 0.743 Acc@5 0.000
77
TRAINING
Epoch: [77][0/1]	Time  0.947 ( 0.947)	Data  0.242 ( 0.242)	Loss 7.7921e-02 (7.7921e-02)	Acc@1   0.93 (  0.93)	Acc@5   0.00 (  0.00)
[0.9315956633880438]
Test: [0/1]	Time  0.239 ( 0.239)	Loss 9.4469e-01 (9.4469e-01)	Acc@1   0.67 (  0.67)	Acc@5   0.00 (  0.00)
 * Acc@1 0.670 Acc@5 0.000
Test: [0/1]	Time  0.293 ( 0.293)	Loss 1.5242e-01 (1.5242e-01)	Acc@1   0.74 (  0.74)	Acc@5   0.00 (  0.00)
 * Acc@1 0.744 Acc@5 0.000
78
TRAINING
Epoch: [78][0/1]	Time  0.954 ( 0.954)	Data  0.248 ( 0.248)	Loss 7.7869e-02 (7.7869e-02)	Acc@1   0.93 (  0.93)	Acc@5   0.00 (  0.00)
[0.9317012833407925]
Test: [0/1]	Time  0.241 ( 0.241)	Loss 9.4476e-01 (9.4476e-01)	Acc@1   0.67 (  0.67)	Acc@5   0.00 (  0.00)
 * Acc@1 0.669 Acc@5 0.000
Test: [0/1]	Time  0.292 ( 0.292)	Loss 1.5230e-01 (1.5230e-01)	Acc@1   0.74 (  0.74)	Acc@5   0.00 (  0.00)
 * Acc@1 0.745 Acc@5 0.000
79
TRAINING
Epoch: [79][0/1]	Time  0.948 ( 0.948)	Data  0.247 ( 0.247)	Loss 7.7816e-02 (7.7816e-02)	Acc@1   0.93 (  0.93)	Acc@5   0.00 (  0.00)
[0.931807950713466]
Test: [0/1]	Time  0.244 ( 0.244)	Loss 9.4481e-01 (9.4481e-01)	Acc@1   0.67 (  0.67)	Acc@5   0.00 (  0.00)
 * Acc@1 0.669 Acc@5 0.000
Test: [0/1]	Time  0.297 ( 0.297)	Loss 1.5220e-01 (1.5220e-01)	Acc@1   0.75 (  0.75)	Acc@5   0.00 (  0.00)
 * Acc@1 0.746 Acc@5 0.000
80
TRAINING
Epoch: [80][0/1]	Time  0.982 ( 0.982)	Data  0.284 ( 0.284)	Loss 7.7775e-02 (7.7775e-02)	Acc@1   0.93 (  0.93)	Acc@5   0.00 (  0.00)
[0.9319220872849008]
Test: [0/1]	Time  0.258 ( 0.258)	Loss 9.4485e-01 (9.4485e-01)	Acc@1   0.67 (  0.67)	Acc@5   0.00 (  0.00)
 * Acc@1 0.668 Acc@5 0.000
Test: [0/1]	Time  0.334 ( 0.334)	Loss 1.5211e-01 (1.5211e-01)	Acc@1   0.75 (  0.75)	Acc@5   0.00 (  0.00)
 * Acc@1 0.746 Acc@5 0.000
81
TRAINING
Epoch: [81][0/1]	Time  0.962 ( 0.962)	Data  0.251 ( 0.251)	Loss 7.7748e-02 (7.7748e-02)	Acc@1   0.93 (  0.93)	Acc@5   0.00 (  0.00)
[0.9320497275671593]
Test: [0/1]	Time  0.240 ( 0.240)	Loss 9.4487e-01 (9.4487e-01)	Acc@1   0.67 (  0.67)	Acc@5   0.00 (  0.00)
 * Acc@1 0.669 Acc@5 0.000
Test: [0/1]	Time  0.294 ( 0.294)	Loss 1.5205e-01 (1.5205e-01)	Acc@1   0.75 (  0.75)	Acc@5   0.00 (  0.00)
 * Acc@1 0.747 Acc@5 0.000
82
TRAINING
Epoch: [82][0/1]	Time  0.963 ( 0.963)	Data  0.265 ( 0.265)	Loss 7.7734e-02 (7.7734e-02)	Acc@1   0.93 (  0.93)	Acc@5   0.00 (  0.00)
[0.9320145128799678]
Test: [0/1]	Time  0.268 ( 0.268)	Loss 9.4488e-01 (9.4488e-01)	Acc@1   0.67 (  0.67)	Acc@5   0.00 (  0.00)
 * Acc@1 0.669 Acc@5 0.000
Test: [0/1]	Time  0.311 ( 0.311)	Loss 1.5198e-01 (1.5198e-01)	Acc@1   0.75 (  0.75)	Acc@5   0.00 (  0.00)
 * Acc@1 0.747 Acc@5 0.000
83
TRAINING
Epoch: [83][0/1]	Time  0.985 ( 0.985)	Data  0.270 ( 0.270)	Loss 7.7724e-02 (7.7724e-02)	Acc@1   0.93 (  0.93)	Acc@5   0.00 (  0.00)
[0.9320190992671816]
Test: [0/1]	Time  0.253 ( 0.253)	Loss 9.4487e-01 (9.4487e-01)	Acc@1   0.67 (  0.67)	Acc@5   0.00 (  0.00)
 * Acc@1 0.669 Acc@5 0.000
Test: [0/1]	Time  0.304 ( 0.304)	Loss 1.5192e-01 (1.5192e-01)	Acc@1   0.75 (  0.75)	Acc@5   0.00 (  0.00)
 * Acc@1 0.748 Acc@5 0.000
84
TRAINING
Epoch: [84][0/1]	Time  0.957 ( 0.957)	Data  0.248 ( 0.248)	Loss 7.7716e-02 (7.7716e-02)	Acc@1   0.93 (  0.93)	Acc@5   0.00 (  0.00)
[0.9320742886544575]
Test: [0/1]	Time  0.247 ( 0.247)	Loss 9.4485e-01 (9.4485e-01)	Acc@1   0.67 (  0.67)	Acc@5   0.00 (  0.00)
 * Acc@1 0.670 Acc@5 0.000
Test: [0/1]	Time  0.298 ( 0.298)	Loss 1.5185e-01 (1.5185e-01)	Acc@1   0.75 (  0.75)	Acc@5   0.00 (  0.00)
 * Acc@1 0.748 Acc@5 0.000
85
TRAINING
Epoch: [85][0/1]	Time  1.001 ( 1.001)	Data  0.276 ( 0.276)	Loss 7.7707e-02 (7.7707e-02)	Acc@1   0.93 (  0.93)	Acc@5   0.00 (  0.00)
[0.9321953645631703]
Test: [0/1]	Time  0.263 ( 0.263)	Loss 9.4482e-01 (9.4482e-01)	Acc@1   0.67 (  0.67)	Acc@5   0.00 (  0.00)
 * Acc@1 0.670 Acc@5 0.000
Test: [0/1]	Time  0.323 ( 0.323)	Loss 1.5179e-01 (1.5179e-01)	Acc@1   0.75 (  0.75)	Acc@5   0.00 (  0.00)
 * Acc@1 0.748 Acc@5 0.000
86
TRAINING
Epoch: [86][0/1]	Time  0.958 ( 0.958)	Data  0.248 ( 0.248)	Loss 7.7700e-02 (7.7700e-02)	Acc@1   0.93 (  0.93)	Acc@5   0.00 (  0.00)
[0.9323950531277183]
Test: [0/1]	Time  0.268 ( 0.268)	Loss 9.4477e-01 (9.4477e-01)	Acc@1   0.67 (  0.67)	Acc@5   0.00 (  0.00)
 * Acc@1 0.670 Acc@5 0.000
Test: [0/1]	Time  0.313 ( 0.313)	Loss 1.5174e-01 (1.5174e-01)	Acc@1   0.75 (  0.75)	Acc@5   0.00 (  0.00)
 * Acc@1 0.748 Acc@5 0.000
87
TRAINING
Epoch: [87][0/1]	Time  0.965 ( 0.965)	Data  0.260 ( 0.260)	Loss 7.7698e-02 (7.7698e-02)	Acc@1   0.93 (  0.93)	Acc@5   0.00 (  0.00)
[0.9325910480000807]
Test: [0/1]	Time  0.259 ( 0.259)	Loss 9.4472e-01 (9.4472e-01)	Acc@1   0.67 (  0.67)	Acc@5   0.00 (  0.00)
 * Acc@1 0.670 Acc@5 0.000
Test: [0/1]	Time  0.316 ( 0.316)	Loss 1.5169e-01 (1.5169e-01)	Acc@1   0.75 (  0.75)	Acc@5   0.00 (  0.00)
 * Acc@1 0.748 Acc@5 0.000
88
TRAINING
Epoch: [88][0/1]	Time  0.947 ( 0.947)	Data  0.244 ( 0.244)	Loss 7.7700e-02 (7.7700e-02)	Acc@1   0.93 (  0.93)	Acc@5   0.00 (  0.00)
[0.9327765033345385]
Test: [0/1]	Time  0.307 ( 0.307)	Loss 9.4466e-01 (9.4466e-01)	Acc@1   0.67 (  0.67)	Acc@5   0.00 (  0.00)
 * Acc@1 0.671 Acc@5 0.000
Test: [0/1]	Time  0.293 ( 0.293)	Loss 1.5166e-01 (1.5166e-01)	Acc@1   0.75 (  0.75)	Acc@5   0.00 (  0.00)
 * Acc@1 0.748 Acc@5 0.000
89
TRAINING
Epoch: [89][0/1]	Time  0.950 ( 0.950)	Data  0.255 ( 0.255)	Loss 7.7706e-02 (7.7706e-02)	Acc@1   0.93 (  0.93)	Acc@5   0.00 (  0.00)
[0.932945365364295]
Test: [0/1]	Time  0.244 ( 0.244)	Loss 9.4459e-01 (9.4459e-01)	Acc@1   0.67 (  0.67)	Acc@5   0.00 (  0.00)
 * Acc@1 0.671 Acc@5 0.000
Test: [0/1]	Time  0.294 ( 0.294)	Loss 1.5163e-01 (1.5163e-01)	Acc@1   0.75 (  0.75)	Acc@5   0.00 (  0.00)
 * Acc@1 0.748 Acc@5 0.000
90
TRAINING
Epoch: [90][0/1]	Time  0.997 ( 0.997)	Data  0.295 ( 0.295)	Loss 7.7709e-02 (7.7709e-02)	Acc@1   0.93 (  0.93)	Acc@5   0.00 (  0.00)
[0.9330307630672134]
Test: [0/1]	Time  0.266 ( 0.266)	Loss 9.4452e-01 (9.4452e-01)	Acc@1   0.67 (  0.67)	Acc@5   0.00 (  0.00)
 * Acc@1 0.671 Acc@5 0.000
Test: [0/1]	Time  0.317 ( 0.317)	Loss 1.5161e-01 (1.5161e-01)	Acc@1   0.75 (  0.75)	Acc@5   0.00 (  0.00)
 * Acc@1 0.748 Acc@5 0.000
91
TRAINING
Epoch: [91][0/1]	Time  0.949 ( 0.949)	Data  0.262 ( 0.262)	Loss 7.7706e-02 (7.7706e-02)	Acc@1   0.93 (  0.93)	Acc@5   0.00 (  0.00)
[0.9330727409289135]
Test: [0/1]	Time  0.278 ( 0.278)	Loss 9.4444e-01 (9.4444e-01)	Acc@1   0.67 (  0.67)	Acc@5   0.00 (  0.00)
 * Acc@1 0.671 Acc@5 0.000
Test: [0/1]	Time  0.298 ( 0.298)	Loss 1.5159e-01 (1.5159e-01)	Acc@1   0.75 (  0.75)	Acc@5   0.00 (  0.00)
 * Acc@1 0.748 Acc@5 0.000
92
TRAINING
Epoch: [92][0/1]	Time  0.974 ( 0.974)	Data  0.259 ( 0.259)	Loss 7.7695e-02 (7.7695e-02)	Acc@1   0.93 (  0.93)	Acc@5   0.00 (  0.00)
[0.933100032255108]
Test: [0/1]	Time  0.253 ( 0.253)	Loss 9.4436e-01 (9.4436e-01)	Acc@1   0.67 (  0.67)	Acc@5   0.00 (  0.00)
 * Acc@1 0.672 Acc@5 0.000
Test: [0/1]	Time  0.302 ( 0.302)	Loss 1.5157e-01 (1.5157e-01)	Acc@1   0.75 (  0.75)	Acc@5   0.00 (  0.00)
 * Acc@1 0.748 Acc@5 0.000
93
TRAINING
Epoch: [93][0/1]	Time  0.945 ( 0.945)	Data  0.263 ( 0.263)	Loss 7.7677e-02 (7.7677e-02)	Acc@1   0.93 (  0.93)	Acc@5   0.00 (  0.00)
[0.9331143987416082]
Test: [0/1]	Time  0.249 ( 0.249)	Loss 9.4428e-01 (9.4428e-01)	Acc@1   0.67 (  0.67)	Acc@5   0.00 (  0.00)
 * Acc@1 0.672 Acc@5 0.000
Test: [0/1]	Time  0.300 ( 0.300)	Loss 1.5156e-01 (1.5156e-01)	Acc@1   0.75 (  0.75)	Acc@5   0.00 (  0.00)
 * Acc@1 0.748 Acc@5 0.000
94
TRAINING
Epoch: [94][0/1]	Time  0.939 ( 0.939)	Data  0.258 ( 0.258)	Loss 7.7657e-02 (7.7657e-02)	Acc@1   0.93 (  0.93)	Acc@5   0.00 (  0.00)
[0.9331179490000648]
Test: [0/1]	Time  0.245 ( 0.245)	Loss 9.4419e-01 (9.4419e-01)	Acc@1   0.67 (  0.67)	Acc@5   0.00 (  0.00)
 * Acc@1 0.672 Acc@5 0.000
Test: [0/1]	Time  0.324 ( 0.324)	Loss 1.5156e-01 (1.5156e-01)	Acc@1   0.75 (  0.75)	Acc@5   0.00 (  0.00)
 * Acc@1 0.748 Acc@5 0.000
95
TRAINING
Epoch: [95][0/1]	Time  0.954 ( 0.954)	Data  0.272 ( 0.272)	Loss 7.7636e-02 (7.7636e-02)	Acc@1   0.93 (  0.93)	Acc@5   0.00 (  0.00)
[0.9331130037651807]
Test: [0/1]	Time  0.248 ( 0.248)	Loss 9.4411e-01 (9.4411e-01)	Acc@1   0.67 (  0.67)	Acc@5   0.00 (  0.00)
 * Acc@1 0.672 Acc@5 0.000
Test: [0/1]	Time  0.303 ( 0.303)	Loss 1.5155e-01 (1.5155e-01)	Acc@1   0.75 (  0.75)	Acc@5   0.00 (  0.00)
 * Acc@1 0.748 Acc@5 0.000
96
TRAINING
Epoch: [96][0/1]	Time  0.943 ( 0.943)	Data  0.264 ( 0.264)	Loss 7.7619e-02 (7.7619e-02)	Acc@1   0.93 (  0.93)	Acc@5   0.00 (  0.00)
[0.9331019523054548]
Test: [0/1]	Time  0.245 ( 0.245)	Loss 9.4403e-01 (9.4403e-01)	Acc@1   0.67 (  0.67)	Acc@5   0.00 (  0.00)
 * Acc@1 0.673 Acc@5 0.000
Test: [0/1]	Time  0.298 ( 0.298)	Loss 1.5156e-01 (1.5156e-01)	Acc@1   0.75 (  0.75)	Acc@5   0.00 (  0.00)
 * Acc@1 0.748 Acc@5 0.000
97
TRAINING
Epoch: [97][0/1]	Time  0.950 ( 0.950)	Data  0.271 ( 0.271)	Loss 7.7604e-02 (7.7604e-02)	Acc@1   0.93 (  0.93)	Acc@5   0.00 (  0.00)
[0.9330871128012228]
Test: [0/1]	Time  0.246 ( 0.246)	Loss 9.4395e-01 (9.4395e-01)	Acc@1   0.67 (  0.67)	Acc@5   0.00 (  0.00)
 * Acc@1 0.673 Acc@5 0.000
Test: [0/1]	Time  0.296 ( 0.296)	Loss 1.5156e-01 (1.5156e-01)	Acc@1   0.75 (  0.75)	Acc@5   0.00 (  0.00)
 * Acc@1 0.748 Acc@5 0.000
98
TRAINING
Epoch: [98][0/1]	Time  0.954 ( 0.954)	Data  0.275 ( 0.275)	Loss 7.7591e-02 (7.7591e-02)	Acc@1   0.93 (  0.93)	Acc@5   0.00 (  0.00)
[0.9330706107957574]
Test: [0/1]	Time  0.245 ( 0.245)	Loss 9.4387e-01 (9.4387e-01)	Acc@1   0.67 (  0.67)	Acc@5   0.00 (  0.00)
 * Acc@1 0.673 Acc@5 0.000
Test: [0/1]	Time  0.298 ( 0.298)	Loss 1.5156e-01 (1.5156e-01)	Acc@1   0.75 (  0.75)	Acc@5   0.00 (  0.00)
 * Acc@1 0.748 Acc@5 0.000
99
TRAINING
Epoch: [99][0/1]	Time  0.946 ( 0.946)	Data  0.266 ( 0.266)	Loss 7.7581e-02 (7.7581e-02)	Acc@1   0.93 (  0.93)	Acc@5   0.00 (  0.00)
[0.9330964002645342]
Test: [0/1]	Time  0.245 ( 0.245)	Loss 9.4379e-01 (9.4379e-01)	Acc@1   0.67 (  0.67)	Acc@5   0.00 (  0.00)
 * Acc@1 0.673 Acc@5 0.000
Test: [0/1]	Time  0.300 ( 0.300)	Loss 1.5156e-01 (1.5156e-01)	Acc@1   0.75 (  0.75)	Acc@5   0.00 (  0.00)
 * Acc@1 0.748 Acc@5 0.000
=> using pre-trained model 'st_resnet'
s/ohp/session_1
torch.Size([640, 3, 224, 224])
(640, 22)
attach reg
0
TRAINING
/home/helenr6/Adv_mapper/train_split.py:125: UserWarning: You have chosen to seed training. This will turn on the CUDNN deterministic setting, which can slow down your training considerably! You may see unexpected behavior when restarting from checkpoints.
  warnings.warn('You have chosen to seed training. '
/localscratch/helenr6.6279052.0/env/lib/python3.7/site-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  cpuset_checked))
Epoch: [0][0/1]	Time  5.139 ( 5.139)	Data  1.730 ( 1.730)	Loss 1.7371e+00 (1.7371e+00)	Acc@1   0.02 (  0.02)	Acc@5   0.00 (  0.00)
[0.01888743744917288]
Test: [0/1]	Time  0.437 ( 0.437)	Loss 1.1063e+00 (1.1063e+00)	Acc@1   0.02 (  0.02)	Acc@5   0.00 (  0.00)
 * Acc@1 0.016 Acc@5 0.000
Test: [0/1]	Time  0.556 ( 0.556)	Loss 9.3437e-01 (9.3437e-01)	Acc@1  -0.01 ( -0.01)	Acc@5   0.00 (  0.00)
 * Acc@1 -0.005 Acc@5 0.000
1
TRAINING
Epoch: [1][0/1]	Time  0.941 ( 0.941)	Data  0.243 ( 0.243)	Loss 1.6560e+00 (1.6560e+00)	Acc@1   0.02 (  0.02)	Acc@5   0.00 (  0.00)
[0.02013838439193972]
Test: [0/1]	Time  0.245 ( 0.245)	Loss 1.0973e+00 (1.0973e+00)	Acc@1   0.01 (  0.01)	Acc@5   0.00 (  0.00)
 * Acc@1 0.013 Acc@5 0.000
Test: [0/1]	Time  0.300 ( 0.300)	Loss 8.7643e-01 (8.7643e-01)	Acc@1  -0.00 ( -0.00)	Acc@5   0.00 (  0.00)
 * Acc@1 -0.000 Acc@5 0.000
2
TRAINING
Epoch: [2][0/1]	Time  0.941 ( 0.941)	Data  0.254 ( 0.254)	Loss 1.5329e+00 (1.5329e+00)	Acc@1   0.02 (  0.02)	Acc@5   0.00 (  0.00)
[0.022705277971935188]
Test: [0/1]	Time  0.242 ( 0.242)	Loss 1.0887e+00 (1.0887e+00)	Acc@1   0.02 (  0.02)	Acc@5   0.00 (  0.00)
 * Acc@1 0.023 Acc@5 0.000
Test: [0/1]	Time  0.294 ( 0.294)	Loss 8.2579e-01 (8.2579e-01)	Acc@1   0.01 (  0.01)	Acc@5   0.00 (  0.00)
 * Acc@1 0.008 Acc@5 0.000
3
TRAINING
Epoch: [3][0/1]	Time  0.954 ( 0.954)	Data  0.247 ( 0.247)	Loss 1.4118e+00 (1.4118e+00)	Acc@1   0.03 (  0.03)	Acc@5   0.00 (  0.00)
[0.030897346953097714]
Test: [0/1]	Time  0.238 ( 0.238)	Loss 1.0819e+00 (1.0819e+00)	Acc@1   0.04 (  0.04)	Acc@5   0.00 (  0.00)
 * Acc@1 0.035 Acc@5 0.000
Test: [0/1]	Time  0.292 ( 0.292)	Loss 7.9674e-01 (7.9674e-01)	Acc@1   0.02 (  0.02)	Acc@5   0.00 (  0.00)
 * Acc@1 0.018 Acc@5 0.000
4
TRAINING
Epoch: [4][0/1]	Time  0.930 ( 0.930)	Data  0.240 ( 0.240)	Loss 1.3176e+00 (1.3176e+00)	Acc@1   0.04 (  0.04)	Acc@5   0.00 (  0.00)
[0.044080370071958204]
Test: [0/1]	Time  0.238 ( 0.238)	Loss 1.0763e+00 (1.0763e+00)	Acc@1   0.05 (  0.05)	Acc@5   0.00 (  0.00)
 * Acc@1 0.049 Acc@5 0.000
Test: [0/1]	Time  0.296 ( 0.296)	Loss 7.8621e-01 (7.8621e-01)	Acc@1   0.03 (  0.03)	Acc@5   0.00 (  0.00)
 * Acc@1 0.032 Acc@5 0.000
5
TRAINING
Epoch: [5][0/1]	Time  0.978 ( 0.978)	Data  0.251 ( 0.251)	Loss 1.2487e+00 (1.2487e+00)	Acc@1   0.06 (  0.06)	Acc@5   0.00 (  0.00)
[0.061486138662123394]
Test: [0/1]	Time  0.245 ( 0.245)	Loss 1.0697e+00 (1.0697e+00)	Acc@1   0.06 (  0.06)	Acc@5   0.00 (  0.00)
 * Acc@1 0.063 Acc@5 0.000
Test: [0/1]	Time  0.288 ( 0.288)	Loss 7.7875e-01 (7.7875e-01)	Acc@1   0.05 (  0.05)	Acc@5   0.00 (  0.00)
 * Acc@1 0.049 Acc@5 0.000
6
TRAINING
Epoch: [6][0/1]	Time  0.951 ( 0.951)	Data  0.249 ( 0.249)	Loss 1.1851e+00 (1.1851e+00)	Acc@1   0.08 (  0.08)	Acc@5   0.00 (  0.00)
[0.07741806721892736]
Test: [0/1]	Time  0.241 ( 0.241)	Loss 1.0603e+00 (1.0603e+00)	Acc@1   0.08 (  0.08)	Acc@5   0.00 (  0.00)
 * Acc@1 0.078 Acc@5 0.000
Test: [0/1]	Time  0.291 ( 0.291)	Loss 7.5808e-01 (7.5808e-01)	Acc@1   0.07 (  0.07)	Acc@5   0.00 (  0.00)
 * Acc@1 0.072 Acc@5 0.000
7
TRAINING
Epoch: [7][0/1]	Time  0.930 ( 0.930)	Data  0.236 ( 0.236)	Loss 1.1062e+00 (1.1062e+00)	Acc@1   0.10 (  0.10)	Acc@5   0.00 (  0.00)
[0.10377694753013315]
Test: [0/1]	Time  0.239 ( 0.239)	Loss 1.0476e+00 (1.0476e+00)	Acc@1   0.13 (  0.13)	Acc@5   0.00 (  0.00)
 * Acc@1 0.130 Acc@5 0.000
Test: [0/1]	Time  0.291 ( 0.291)	Loss 7.1730e-01 (7.1730e-01)	Acc@1   0.09 (  0.09)	Acc@5   0.00 (  0.00)
 * Acc@1 0.089 Acc@5 0.000
8
TRAINING
Epoch: [8][0/1]	Time  0.942 ( 0.942)	Data  0.250 ( 0.250)	Loss 1.0040e+00 (1.0040e+00)	Acc@1   0.13 (  0.13)	Acc@5   0.00 (  0.00)
[0.1327953307785939]
Test: [0/1]	Time  0.251 ( 0.251)	Loss 1.0331e+00 (1.0331e+00)	Acc@1   0.17 (  0.17)	Acc@5   0.00 (  0.00)
 * Acc@1 0.172 Acc@5 0.000
Test: [0/1]	Time  0.303 ( 0.303)	Loss 6.6219e-01 (6.6219e-01)	Acc@1   0.11 (  0.11)	Acc@5   0.00 (  0.00)
 * Acc@1 0.110 Acc@5 0.000
9
TRAINING
Epoch: [9][0/1]	Time  0.958 ( 0.958)	Data  0.250 ( 0.250)	Loss 8.8713e-01 (8.8713e-01)	Acc@1   0.15 (  0.15)	Acc@5   0.00 (  0.00)
[0.15400532801204456]
Test: [0/1]	Time  0.234 ( 0.234)	Loss 1.0192e+00 (1.0192e+00)	Acc@1   0.19 (  0.19)	Acc@5   0.00 (  0.00)
 * Acc@1 0.188 Acc@5 0.000
Test: [0/1]	Time  0.295 ( 0.295)	Loss 6.0644e-01 (6.0644e-01)	Acc@1   0.12 (  0.12)	Acc@5   0.00 (  0.00)
 * Acc@1 0.123 Acc@5 0.000
10
TRAINING
Epoch: [10][0/1]	Time  0.953 ( 0.953)	Data  0.244 ( 0.244)	Loss 7.7339e-01 (7.7339e-01)	Acc@1   0.18 (  0.18)	Acc@5   0.00 (  0.00)
[0.17811343932535478]
Test: [0/1]	Time  0.242 ( 0.242)	Loss 1.0080e+00 (1.0080e+00)	Acc@1   0.20 (  0.20)	Acc@5   0.00 (  0.00)
 * Acc@1 0.203 Acc@5 0.000
Test: [0/1]	Time  0.289 ( 0.289)	Loss 5.6272e-01 (5.6272e-01)	Acc@1   0.13 (  0.13)	Acc@5   0.00 (  0.00)
 * Acc@1 0.134 Acc@5 0.000
11
TRAINING
Epoch: [11][0/1]	Time  0.934 ( 0.934)	Data  0.240 ( 0.240)	Loss 6.7832e-01 (6.7832e-01)	Acc@1   0.20 (  0.20)	Acc@5   0.00 (  0.00)
[0.1986188461242872]
Test: [0/1]	Time  0.240 ( 0.240)	Loss 1.0003e+00 (1.0003e+00)	Acc@1   0.24 (  0.24)	Acc@5   0.00 (  0.00)
 * Acc@1 0.237 Acc@5 0.000
Test: [0/1]	Time  0.289 ( 0.289)	Loss 5.3542e-01 (5.3542e-01)	Acc@1   0.14 (  0.14)	Acc@5   0.00 (  0.00)
 * Acc@1 0.145 Acc@5 0.000
12
TRAINING
Epoch: [12][0/1]	Time  1.007 ( 1.007)	Data  0.310 ( 0.310)	Loss 6.0698e-01 (6.0698e-01)	Acc@1   0.22 (  0.22)	Acc@5   0.00 (  0.00)
[0.21995693137617023]
Test: [0/1]	Time  0.267 ( 0.267)	Loss 9.9519e-01 (9.9519e-01)	Acc@1   0.28 (  0.28)	Acc@5   0.00 (  0.00)
 * Acc@1 0.276 Acc@5 0.000
Test: [0/1]	Time  0.315 ( 0.315)	Loss 5.1930e-01 (5.1930e-01)	Acc@1   0.16 (  0.16)	Acc@5   0.00 (  0.00)
 * Acc@1 0.159 Acc@5 0.000
13
TRAINING
Epoch: [13][0/1]	Time  1.028 ( 1.028)	Data  0.324 ( 0.324)	Loss 5.5307e-01 (5.5307e-01)	Acc@1   0.25 (  0.25)	Acc@5   0.00 (  0.00)
[0.2502647321364295]
Test: [0/1]	Time  0.256 ( 0.256)	Loss 9.9083e-01 (9.9083e-01)	Acc@1   0.29 (  0.29)	Acc@5   0.00 (  0.00)
 * Acc@1 0.289 Acc@5 0.000
Test: [0/1]	Time  0.310 ( 0.310)	Loss 5.0390e-01 (5.0390e-01)	Acc@1   0.18 (  0.18)	Acc@5   0.00 (  0.00)
 * Acc@1 0.176 Acc@5 0.000
14
TRAINING
Epoch: [14][0/1]	Time  0.997 ( 0.997)	Data  0.295 ( 0.295)	Loss 5.0471e-01 (5.0471e-01)	Acc@1   0.28 (  0.28)	Acc@5   0.00 (  0.00)
[0.2833942512743155]
Test: [0/1]	Time  0.254 ( 0.254)	Loss 9.8555e-01 (9.8555e-01)	Acc@1   0.33 (  0.33)	Acc@5   0.00 (  0.00)
 * Acc@1 0.326 Acc@5 0.000
Test: [0/1]	Time  0.310 ( 0.310)	Loss 4.8022e-01 (4.8022e-01)	Acc@1   0.19 (  0.19)	Acc@5   0.00 (  0.00)
 * Acc@1 0.193 Acc@5 0.000
15
TRAINING
Epoch: [15][0/1]	Time  0.934 ( 0.934)	Data  0.240 ( 0.240)	Loss 4.5228e-01 (4.5228e-01)	Acc@1   0.33 (  0.33)	Acc@5   0.00 (  0.00)
[0.326947983830548]
Test: [0/1]	Time  0.252 ( 0.252)	Loss 9.7863e-01 (9.7863e-01)	Acc@1   0.38 (  0.38)	Acc@5   0.00 (  0.00)
 * Acc@1 0.377 Acc@5 0.000
Test: [0/1]	Time  0.309 ( 0.309)	Loss 4.4561e-01 (4.4561e-01)	Acc@1   0.21 (  0.21)	Acc@5   0.00 (  0.00)
 * Acc@1 0.210 Acc@5 0.000
16
TRAINING
Epoch: [16][0/1]	Time  0.953 ( 0.953)	Data  0.239 ( 0.239)	Loss 3.9347e-01 (3.9347e-01)	Acc@1   0.36 (  0.36)	Acc@5   0.00 (  0.00)
[0.36272077176402123]
Test: [0/1]	Time  0.246 ( 0.246)	Loss 9.7054e-01 (9.7054e-01)	Acc@1   0.45 (  0.45)	Acc@5   0.00 (  0.00)
 * Acc@1 0.452 Acc@5 0.000
Test: [0/1]	Time  0.291 ( 0.291)	Loss 4.0441e-01 (4.0441e-01)	Acc@1   0.23 (  0.23)	Acc@5   0.00 (  0.00)
 * Acc@1 0.228 Acc@5 0.000
17
TRAINING
Epoch: [17][0/1]	Time  0.978 ( 0.978)	Data  0.279 ( 0.279)	Loss 3.3319e-01 (3.3319e-01)	Acc@1   0.40 (  0.40)	Acc@5   0.00 (  0.00)
[0.4028207721744481]
Test: [0/1]	Time  0.269 ( 0.269)	Loss 9.6238e-01 (9.6238e-01)	Acc@1   0.52 (  0.52)	Acc@5   0.00 (  0.00)
 * Acc@1 0.521 Acc@5 0.000
Test: [0/1]	Time  0.320 ( 0.320)	Loss 3.6436e-01 (3.6436e-01)	Acc@1   0.25 (  0.25)	Acc@5   0.00 (  0.00)
 * Acc@1 0.247 Acc@5 0.000
18
TRAINING
Epoch: [18][0/1]	Time  0.971 ( 0.971)	Data  0.277 ( 0.277)	Loss 2.7936e-01 (2.7936e-01)	Acc@1   0.45 (  0.45)	Acc@5   0.00 (  0.00)
[0.4482990318446042]
Test: [0/1]	Time  0.264 ( 0.264)	Loss 9.5519e-01 (9.5519e-01)	Acc@1   0.56 (  0.56)	Acc@5   0.00 (  0.00)
 * Acc@1 0.557 Acc@5 0.000
Test: [0/1]	Time  0.331 ( 0.331)	Loss 3.3181e-01 (3.3181e-01)	Acc@1   0.27 (  0.27)	Acc@5   0.00 (  0.00)
 * Acc@1 0.266 Acc@5 0.000
19
TRAINING
Epoch: [19][0/1]	Time  0.934 ( 0.934)	Data  0.245 ( 0.245)	Loss 2.3774e-01 (2.3774e-01)	Acc@1   0.49 (  0.49)	Acc@5   0.00 (  0.00)
[0.49466520703536]
Test: [0/1]	Time  0.245 ( 0.245)	Loss 9.4949e-01 (9.4949e-01)	Acc@1   0.57 (  0.57)	Acc@5   0.00 (  0.00)
 * Acc@1 0.571 Acc@5 0.000
Test: [0/1]	Time  0.349 ( 0.349)	Loss 3.0862e-01 (3.0862e-01)	Acc@1   0.28 (  0.28)	Acc@5   0.00 (  0.00)
 * Acc@1 0.285 Acc@5 0.000
20
TRAINING
Epoch: [20][0/1]	Time  0.982 ( 0.982)	Data  0.286 ( 0.286)	Loss 2.0897e-01 (2.0897e-01)	Acc@1   0.54 (  0.54)	Acc@5   0.00 (  0.00)
[0.5423559817229872]
Test: [0/1]	Time  0.259 ( 0.259)	Loss 9.4520e-01 (9.4520e-01)	Acc@1   0.58 (  0.58)	Acc@5   0.00 (  0.00)
 * Acc@1 0.583 Acc@5 0.000
Test: [0/1]	Time  0.315 ( 0.315)	Loss 2.9219e-01 (2.9219e-01)	Acc@1   0.30 (  0.30)	Acc@5   0.00 (  0.00)
 * Acc@1 0.300 Acc@5 0.000
21
TRAINING
Epoch: [21][0/1]	Time  1.049 ( 1.049)	Data  0.353 ( 0.353)	Loss 1.8910e-01 (1.8910e-01)	Acc@1   0.59 (  0.59)	Acc@5   0.00 (  0.00)
[0.5899072685482492]
Test: [0/1]	Time  0.270 ( 0.270)	Loss 9.4189e-01 (9.4189e-01)	Acc@1   0.59 (  0.59)	Acc@5   0.00 (  0.00)
 * Acc@1 0.593 Acc@5 0.000
Test: [0/1]	Time  0.322 ( 0.322)	Loss 2.7797e-01 (2.7797e-01)	Acc@1   0.31 (  0.31)	Acc@5   0.00 (  0.00)
 * Acc@1 0.314 Acc@5 0.000
22
TRAINING
Epoch: [22][0/1]	Time  0.943 ( 0.943)	Data  0.239 ( 0.239)	Loss 1.7254e-01 (1.7254e-01)	Acc@1   0.64 (  0.64)	Acc@5   0.00 (  0.00)
[0.6361787561912821]
Test: [0/1]	Time  0.253 ( 0.253)	Loss 9.3925e-01 (9.3925e-01)	Acc@1   0.60 (  0.60)	Acc@5   0.00 (  0.00)
 * Acc@1 0.600 Acc@5 0.000
Test: [0/1]	Time  0.301 ( 0.301)	Loss 2.6264e-01 (2.6264e-01)	Acc@1   0.33 (  0.33)	Acc@5   0.00 (  0.00)
 * Acc@1 0.326 Acc@5 0.000
23
TRAINING
Epoch: [23][0/1]	Time  0.966 ( 0.966)	Data  0.273 ( 0.273)	Loss 1.5542e-01 (1.5542e-01)	Acc@1   0.68 (  0.68)	Acc@5   0.00 (  0.00)
[0.6791148158322405]
Test: [0/1]	Time  0.257 ( 0.257)	Loss 9.3724e-01 (9.3724e-01)	Acc@1   0.60 (  0.60)	Acc@5   0.00 (  0.00)
 * Acc@1 0.604 Acc@5 0.000
Test: [0/1]	Time  0.303 ( 0.303)	Loss 2.4577e-01 (2.4577e-01)	Acc@1   0.34 (  0.34)	Acc@5   0.00 (  0.00)
 * Acc@1 0.339 Acc@5 0.000
24
TRAINING
Epoch: [24][0/1]	Time  0.954 ( 0.954)	Data  0.242 ( 0.242)	Loss 1.3721e-01 (1.3721e-01)	Acc@1   0.72 (  0.72)	Acc@5   0.00 (  0.00)
[0.7185699138864468]
Test: [0/1]	Time  0.253 ( 0.253)	Loss 9.3609e-01 (9.3609e-01)	Acc@1   0.61 (  0.61)	Acc@5   0.00 (  0.00)
 * Acc@1 0.608 Acc@5 0.000
Test: [0/1]	Time  0.377 ( 0.377)	Loss 2.2944e-01 (2.2944e-01)	Acc@1   0.36 (  0.36)	Acc@5   0.00 (  0.00)
 * Acc@1 0.356 Acc@5 0.000
25
TRAINING
Epoch: [25][0/1]	Time  0.955 ( 0.955)	Data  0.258 ( 0.258)	Loss 1.2010e-01 (1.2010e-01)	Acc@1   0.75 (  0.75)	Acc@5   0.00 (  0.00)
[0.7532710099065325]
Test: [0/1]	Time  0.241 ( 0.241)	Loss 9.3597e-01 (9.3597e-01)	Acc@1   0.62 (  0.62)	Acc@5   0.00 (  0.00)
 * Acc@1 0.618 Acc@5 0.000
Test: [0/1]	Time  0.293 ( 0.293)	Loss 2.1633e-01 (2.1633e-01)	Acc@1   0.37 (  0.37)	Acc@5   0.00 (  0.00)
 * Acc@1 0.374 Acc@5 0.000
26
TRAINING
Epoch: [26][0/1]	Time  0.987 ( 0.987)	Data  0.285 ( 0.285)	Loss 1.0694e-01 (1.0694e-01)	Acc@1   0.78 (  0.78)	Acc@5   0.00 (  0.00)
[0.7825621610419802]
Test: [0/1]	Time  0.263 ( 0.263)	Loss 9.3682e-01 (9.3682e-01)	Acc@1   0.62 (  0.62)	Acc@5   0.00 (  0.00)
 * Acc@1 0.623 Acc@5 0.000
Test: [0/1]	Time  0.318 ( 0.318)	Loss 2.0773e-01 (2.0773e-01)	Acc@1   0.39 (  0.39)	Acc@5   0.00 (  0.00)
 * Acc@1 0.394 Acc@5 0.000
27
TRAINING
Epoch: [27][0/1]	Time  0.963 ( 0.963)	Data  0.274 ( 0.274)	Loss 9.9163e-02 (9.9163e-02)	Acc@1   0.81 (  0.81)	Acc@5   0.00 (  0.00)
[0.8064425903805057]
Test: [0/1]	Time  0.250 ( 0.250)	Loss 9.3828e-01 (9.3828e-01)	Acc@1   0.63 (  0.63)	Acc@5   0.00 (  0.00)
 * Acc@1 0.626 Acc@5 0.000
Test: [0/1]	Time  0.309 ( 0.309)	Loss 2.0281e-01 (2.0281e-01)	Acc@1   0.42 (  0.42)	Acc@5   0.00 (  0.00)
 * Acc@1 0.416 Acc@5 0.000
28
TRAINING
Epoch: [28][0/1]	Time  1.003 ( 1.003)	Data  0.304 ( 0.304)	Loss 9.5963e-02 (9.5963e-02)	Acc@1   0.82 (  0.82)	Acc@5   0.00 (  0.00)
[0.8247633614554379]
Test: [0/1]	Time  0.273 ( 0.273)	Loss 9.3978e-01 (9.3978e-01)	Acc@1   0.63 (  0.63)	Acc@5   0.00 (  0.00)
 * Acc@1 0.628 Acc@5 0.000
Test: [0/1]	Time  0.330 ( 0.330)	Loss 1.9916e-01 (1.9916e-01)	Acc@1   0.44 (  0.44)	Acc@5   0.00 (  0.00)
 * Acc@1 0.439 Acc@5 0.000
29
TRAINING
Epoch: [29][0/1]	Time  0.983 ( 0.983)	Data  0.287 ( 0.287)	Loss 9.4949e-02 (9.4949e-02)	Acc@1   0.84 (  0.84)	Acc@5   0.00 (  0.00)
[0.8383143718671707]
Test: [0/1]	Time  0.259 ( 0.259)	Loss 9.4082e-01 (9.4082e-01)	Acc@1   0.63 (  0.63)	Acc@5   0.00 (  0.00)
 * Acc@1 0.629 Acc@5 0.000
Test: [0/1]	Time  0.314 ( 0.314)	Loss 1.9435e-01 (1.9435e-01)	Acc@1   0.46 (  0.46)	Acc@5   0.00 (  0.00)
 * Acc@1 0.463 Acc@5 0.000
30
TRAINING
Epoch: [30][0/1]	Time  0.962 ( 0.962)	Data  0.244 ( 0.244)	Loss 9.3627e-02 (9.3627e-02)	Acc@1   0.85 (  0.85)	Acc@5   0.00 (  0.00)
[0.849452712122887]
Test: [0/1]	Time  0.235 ( 0.235)	Loss 9.4117e-01 (9.4117e-01)	Acc@1   0.63 (  0.63)	Acc@5   0.00 (  0.00)
 * Acc@1 0.631 Acc@5 0.000
Test: [0/1]	Time  0.294 ( 0.294)	Loss 1.8721e-01 (1.8721e-01)	Acc@1   0.49 (  0.49)	Acc@5   0.00 (  0.00)
 * Acc@1 0.488 Acc@5 0.000
31
TRAINING
Epoch: [31][0/1]	Time  0.958 ( 0.958)	Data  0.245 ( 0.245)	Loss 9.0708e-02 (9.0708e-02)	Acc@1   0.86 (  0.86)	Acc@5   0.00 (  0.00)
[0.8607754637431322]
Test: [0/1]	Time  0.236 ( 0.236)	Loss 9.4091e-01 (9.4091e-01)	Acc@1   0.63 (  0.63)	Acc@5   0.00 (  0.00)
 * Acc@1 0.633 Acc@5 0.000
Test: [0/1]	Time  0.291 ( 0.291)	Loss 1.7828e-01 (1.7828e-01)	Acc@1   0.51 (  0.51)	Acc@5   0.00 (  0.00)
 * Acc@1 0.513 Acc@5 0.000
32
TRAINING
Epoch: [32][0/1]	Time  0.973 ( 0.973)	Data  0.279 ( 0.279)	Loss 8.6511e-02 (8.6511e-02)	Acc@1   0.87 (  0.87)	Acc@5   0.00 (  0.00)
[0.8687913781744204]
Test: [0/1]	Time  0.264 ( 0.264)	Loss 9.4035e-01 (9.4035e-01)	Acc@1   0.64 (  0.64)	Acc@5   0.00 (  0.00)
 * Acc@1 0.636 Acc@5 0.000
Test: [0/1]	Time  0.319 ( 0.319)	Loss 1.6919e-01 (1.6919e-01)	Acc@1   0.54 (  0.54)	Acc@5   0.00 (  0.00)
 * Acc@1 0.537 Acc@5 0.000
33
TRAINING
Epoch: [33][0/1]	Time  0.978 ( 0.978)	Data  0.284 ( 0.284)	Loss 8.2399e-02 (8.2399e-02)	Acc@1   0.87 (  0.87)	Acc@5   0.00 (  0.00)
[0.8742408614703874]
Test: [0/1]	Time  0.266 ( 0.266)	Loss 9.3985e-01 (9.3985e-01)	Acc@1   0.64 (  0.64)	Acc@5   0.00 (  0.00)
 * Acc@1 0.639 Acc@5 0.000
Test: [0/1]	Time  0.311 ( 0.311)	Loss 1.6162e-01 (1.6162e-01)	Acc@1   0.56 (  0.56)	Acc@5   0.00 (  0.00)
 * Acc@1 0.561 Acc@5 0.000
34
TRAINING
Epoch: [34][0/1]	Time  0.940 ( 0.940)	Data  0.251 ( 0.251)	Loss 7.9742e-02 (7.9742e-02)	Acc@1   0.88 (  0.88)	Acc@5   0.00 (  0.00)
[0.8767029967039224]
Test: [0/1]	Time  0.246 ( 0.246)	Loss 9.3966e-01 (9.3966e-01)	Acc@1   0.64 (  0.64)	Acc@5   0.00 (  0.00)
 * Acc@1 0.639 Acc@5 0.000
Test: [0/1]	Time  0.290 ( 0.290)	Loss 1.5639e-01 (1.5639e-01)	Acc@1   0.58 (  0.58)	Acc@5   0.00 (  0.00)
 * Acc@1 0.583 Acc@5 0.000
35
TRAINING
Epoch: [35][0/1]	Time  0.990 ( 0.990)	Data  0.277 ( 0.277)	Loss 7.9091e-02 (7.9091e-02)	Acc@1   0.88 (  0.88)	Acc@5   0.00 (  0.00)
[0.8777746733594073]
Test: [0/1]	Time  0.278 ( 0.278)	Loss 9.3990e-01 (9.3990e-01)	Acc@1   0.64 (  0.64)	Acc@5   0.00 (  0.00)
 * Acc@1 0.637 Acc@5 0.000
Test: [0/1]	Time  0.327 ( 0.327)	Loss 1.5326e-01 (1.5326e-01)	Acc@1   0.60 (  0.60)	Acc@5   0.00 (  0.00)
 * Acc@1 0.603 Acc@5 0.000
36
TRAINING
Epoch: [36][0/1]	Time  0.963 ( 0.963)	Data  0.265 ( 0.265)	Loss 7.9983e-02 (7.9983e-02)	Acc@1   0.88 (  0.88)	Acc@5   0.00 (  0.00)
[0.8771791867856953]
Test: [0/1]	Time  0.246 ( 0.246)	Loss 9.4054e-01 (9.4054e-01)	Acc@1   0.64 (  0.64)	Acc@5   0.00 (  0.00)
 * Acc@1 0.636 Acc@5 0.000
Test: [0/1]	Time  0.302 ( 0.302)	Loss 1.5129e-01 (1.5129e-01)	Acc@1   0.62 (  0.62)	Acc@5   0.00 (  0.00)
 * Acc@1 0.620 Acc@5 0.000
37
TRAINING
Epoch: [37][0/1]	Time  1.018 ( 1.018)	Data  0.302 ( 0.302)	Loss 8.1367e-02 (8.1367e-02)	Acc@1   0.88 (  0.88)	Acc@5   0.00 (  0.00)
[0.876119848005013]
Test: [0/1]	Time  0.271 ( 0.271)	Loss 9.4150e-01 (9.4150e-01)	Acc@1   0.63 (  0.63)	Acc@5   0.00 (  0.00)
 * Acc@1 0.634 Acc@5 0.000
Test: [0/1]	Time  0.323 ( 0.323)	Loss 1.4956e-01 (1.4956e-01)	Acc@1   0.64 (  0.64)	Acc@5   0.00 (  0.00)
 * Acc@1 0.635 Acc@5 0.000
38
TRAINING
Epoch: [38][0/1]	Time  0.951 ( 0.951)	Data  0.259 ( 0.259)	Loss 8.2283e-02 (8.2283e-02)	Acc@1   0.87 (  0.87)	Acc@5   0.00 (  0.00)
[0.8746834650799848]
Test: [0/1]	Time  0.241 ( 0.241)	Loss 9.4272e-01 (9.4272e-01)	Acc@1   0.63 (  0.63)	Acc@5   0.00 (  0.00)
 * Acc@1 0.633 Acc@5 0.000
Test: [0/1]	Time  0.296 ( 0.296)	Loss 1.4767e-01 (1.4767e-01)	Acc@1   0.65 (  0.65)	Acc@5   0.00 (  0.00)
 * Acc@1 0.646 Acc@5 0.000
39
TRAINING
Epoch: [39][0/1]	Time  0.947 ( 0.947)	Data  0.258 ( 0.258)	Loss 8.2359e-02 (8.2359e-02)	Acc@1   0.87 (  0.87)	Acc@5   0.00 (  0.00)
[0.8731982075444467]
Test: [0/1]	Time  0.245 ( 0.245)	Loss 9.4412e-01 (9.4412e-01)	Acc@1   0.63 (  0.63)	Acc@5   0.00 (  0.00)
 * Acc@1 0.632 Acc@5 0.000
Test: [0/1]	Time  0.298 ( 0.298)	Loss 1.4579e-01 (1.4579e-01)	Acc@1   0.65 (  0.65)	Acc@5   0.00 (  0.00)
 * Acc@1 0.653 Acc@5 0.000
40
TRAINING
Epoch: [40][0/1]	Time  0.956 ( 0.956)	Data  0.270 ( 0.270)	Loss 8.1870e-02 (8.1870e-02)	Acc@1   0.87 (  0.87)	Acc@5   0.00 (  0.00)
[0.8725510023143552]
Test: [0/1]	Time  0.254 ( 0.254)	Loss 9.4567e-01 (9.4567e-01)	Acc@1   0.63 (  0.63)	Acc@5   0.00 (  0.00)
 * Acc@1 0.631 Acc@5 0.000
Test: [0/1]	Time  0.304 ( 0.304)	Loss 1.4439e-01 (1.4439e-01)	Acc@1   0.66 (  0.66)	Acc@5   0.00 (  0.00)
 * Acc@1 0.662 Acc@5 0.000
41
TRAINING
Epoch: [41][0/1]	Time  0.988 ( 0.988)	Data  0.290 ( 0.290)	Loss 8.1412e-02 (8.1412e-02)	Acc@1   0.87 (  0.87)	Acc@5   0.00 (  0.00)
[0.8723356506817754]
Test: [0/1]	Time  0.259 ( 0.259)	Loss 9.4726e-01 (9.4726e-01)	Acc@1   0.63 (  0.63)	Acc@5   0.00 (  0.00)
 * Acc@1 0.631 Acc@5 0.000
Test: [0/1]	Time  0.306 ( 0.306)	Loss 1.4381e-01 (1.4381e-01)	Acc@1   0.67 (  0.67)	Acc@5   0.00 (  0.00)
 * Acc@1 0.669 Acc@5 0.000
42
TRAINING
Epoch: [42][0/1]	Time  0.943 ( 0.943)	Data  0.246 ( 0.246)	Loss 8.1461e-02 (8.1461e-02)	Acc@1   0.87 (  0.87)	Acc@5   0.00 (  0.00)
[0.8723737675438584]
Test: [0/1]	Time  0.243 ( 0.243)	Loss 9.4876e-01 (9.4876e-01)	Acc@1   0.63 (  0.63)	Acc@5   0.00 (  0.00)
 * Acc@1 0.631 Acc@5 0.000
Test: [0/1]	Time  0.287 ( 0.287)	Loss 1.4400e-01 (1.4400e-01)	Acc@1   0.68 (  0.68)	Acc@5   0.00 (  0.00)
 * Acc@1 0.675 Acc@5 0.000
43
TRAINING
Epoch: [43][0/1]	Time  0.986 ( 0.986)	Data  0.285 ( 0.285)	Loss 8.2091e-02 (8.2091e-02)	Acc@1   0.87 (  0.87)	Acc@5   0.00 (  0.00)
[0.8727769029716085]
Test: [0/1]	Time  0.259 ( 0.259)	Loss 9.4999e-01 (9.4999e-01)	Acc@1   0.63 (  0.63)	Acc@5   0.00 (  0.00)
 * Acc@1 0.631 Acc@5 0.000
Test: [0/1]	Time  0.331 ( 0.331)	Loss 1.4452e-01 (1.4452e-01)	Acc@1   0.68 (  0.68)	Acc@5   0.00 (  0.00)
 * Acc@1 0.682 Acc@5 0.000
44
TRAINING
Epoch: [44][0/1]	Time  0.967 ( 0.967)	Data  0.271 ( 0.271)	Loss 8.2979e-02 (8.2979e-02)	Acc@1   0.87 (  0.87)	Acc@5   0.00 (  0.00)
[0.8737905815970592]
Test: [0/1]	Time  0.259 ( 0.259)	Loss 9.5086e-01 (9.5086e-01)	Acc@1   0.63 (  0.63)	Acc@5   0.00 (  0.00)
 * Acc@1 0.632 Acc@5 0.000
Test: [0/1]	Time  0.311 ( 0.311)	Loss 1.4485e-01 (1.4485e-01)	Acc@1   0.69 (  0.69)	Acc@5   0.00 (  0.00)
 * Acc@1 0.685 Acc@5 0.000
45
TRAINING
Epoch: [45][0/1]	Time  0.958 ( 0.958)	Data  0.247 ( 0.247)	Loss 8.3656e-02 (8.3656e-02)	Acc@1   0.88 (  0.88)	Acc@5   0.00 (  0.00)
[0.8753657076661638]
Test: [0/1]	Time  0.242 ( 0.242)	Loss 9.5130e-01 (9.5130e-01)	Acc@1   0.63 (  0.63)	Acc@5   0.00 (  0.00)
 * Acc@1 0.632 Acc@5 0.000
Test: [0/1]	Time  0.286 ( 0.286)	Loss 1.4465e-01 (1.4465e-01)	Acc@1   0.69 (  0.69)	Acc@5   0.00 (  0.00)
 * Acc@1 0.686 Acc@5 0.000
46
TRAINING
Epoch: [46][0/1]	Time  1.004 ( 1.004)	Data  0.314 ( 0.314)	Loss 8.3801e-02 (8.3801e-02)	Acc@1   0.88 (  0.88)	Acc@5   0.00 (  0.00)
[0.877387261967926]
Test: [0/1]	Time  0.268 ( 0.268)	Loss 9.5134e-01 (9.5134e-01)	Acc@1   0.63 (  0.63)	Acc@5   0.00 (  0.00)
 * Acc@1 0.632 Acc@5 0.000
Test: [0/1]	Time  0.333 ( 0.333)	Loss 1.4390e-01 (1.4390e-01)	Acc@1   0.69 (  0.69)	Acc@5   0.00 (  0.00)
 * Acc@1 0.690 Acc@5 0.000
47
TRAINING
Epoch: [47][0/1]	Time  1.057 ( 1.057)	Data  0.343 ( 0.343)	Loss 8.3396e-02 (8.3396e-02)	Acc@1   0.88 (  0.88)	Acc@5   0.00 (  0.00)
[0.8798669456972619]
Test: [0/1]	Time  0.278 ( 0.278)	Loss 9.5111e-01 (9.5111e-01)	Acc@1   0.63 (  0.63)	Acc@5   0.00 (  0.00)
 * Acc@1 0.633 Acc@5 0.000
Test: [0/1]	Time  0.330 ( 0.330)	Loss 1.4289e-01 (1.4289e-01)	Acc@1   0.69 (  0.69)	Acc@5   0.00 (  0.00)
 * Acc@1 0.695 Acc@5 0.000
48
TRAINING
Epoch: [48][0/1]	Time  0.950 ( 0.950)	Data  0.252 ( 0.252)	Loss 8.2696e-02 (8.2696e-02)	Acc@1   0.88 (  0.88)	Acc@5   0.00 (  0.00)
[0.8837568383042307]
Test: [0/1]	Time  0.247 ( 0.247)	Loss 9.5073e-01 (9.5073e-01)	Acc@1   0.63 (  0.63)	Acc@5   0.00 (  0.00)
 * Acc@1 0.634 Acc@5 0.000
Test: [0/1]	Time  0.299 ( 0.299)	Loss 1.4198e-01 (1.4198e-01)	Acc@1   0.70 (  0.70)	Acc@5   0.00 (  0.00)
 * Acc@1 0.695 Acc@5 0.000
49
TRAINING
Epoch: [49][0/1]	Time  1.018 ( 1.018)	Data  0.308 ( 0.308)	Loss 8.2038e-02 (8.2038e-02)	Acc@1   0.89 (  0.89)	Acc@5   0.00 (  0.00)
[0.8881675747385573]
Test: [0/1]	Time  0.267 ( 0.267)	Loss 9.5032e-01 (9.5032e-01)	Acc@1   0.64 (  0.64)	Acc@5   0.00 (  0.00)
 * Acc@1 0.636 Acc@5 0.000
Test: [0/1]	Time  0.318 ( 0.318)	Loss 1.4144e-01 (1.4144e-01)	Acc@1   0.70 (  0.70)	Acc@5   0.00 (  0.00)
 * Acc@1 0.696 Acc@5 0.000
50
TRAINING
Epoch: [50][0/1]	Time  0.961 ( 0.961)	Data  0.264 ( 0.264)	Loss 8.1651e-02 (8.1651e-02)	Acc@1   0.89 (  0.89)	Acc@5   0.00 (  0.00)
[0.8931014227844933]
Test: [0/1]	Time  0.278 ( 0.278)	Loss 9.4996e-01 (9.4996e-01)	Acc@1   0.64 (  0.64)	Acc@5   0.00 (  0.00)
 * Acc@1 0.639 Acc@5 0.000
Test: [0/1]	Time  0.328 ( 0.328)	Loss 1.4128e-01 (1.4128e-01)	Acc@1   0.70 (  0.70)	Acc@5   0.00 (  0.00)
 * Acc@1 0.695 Acc@5 0.000
51
TRAINING
Epoch: [51][0/1]	Time  0.933 ( 0.933)	Data  0.261 ( 0.261)	Loss 8.1555e-02 (8.1555e-02)	Acc@1   0.90 (  0.90)	Acc@5   0.00 (  0.00)
[0.8974307200125398]
Test: [0/1]	Time  0.240 ( 0.240)	Loss 9.4970e-01 (9.4970e-01)	Acc@1   0.64 (  0.64)	Acc@5   0.00 (  0.00)
 * Acc@1 0.643 Acc@5 0.000
Test: [0/1]	Time  0.292 ( 0.292)	Loss 1.4137e-01 (1.4137e-01)	Acc@1   0.70 (  0.70)	Acc@5   0.00 (  0.00)
 * Acc@1 0.695 Acc@5 0.000
52
TRAINING
Epoch: [52][0/1]	Time  0.942 ( 0.942)	Data  0.268 ( 0.268)	Loss 8.1603e-02 (8.1603e-02)	Acc@1   0.90 (  0.90)	Acc@5   0.00 (  0.00)
[0.9004273715050454]
Test: [0/1]	Time  0.249 ( 0.249)	Loss 9.4955e-01 (9.4955e-01)	Acc@1   0.65 (  0.65)	Acc@5   0.00 (  0.00)
 * Acc@1 0.647 Acc@5 0.000
Test: [0/1]	Time  0.299 ( 0.299)	Loss 1.4153e-01 (1.4153e-01)	Acc@1   0.70 (  0.70)	Acc@5   0.00 (  0.00)
 * Acc@1 0.696 Acc@5 0.000
53
TRAINING
Epoch: [53][0/1]	Time  0.949 ( 0.949)	Data  0.244 ( 0.244)	Loss 8.1605e-02 (8.1605e-02)	Acc@1   0.90 (  0.90)	Acc@5   0.00 (  0.00)
[0.9035323905002834]
Test: [0/1]	Time  0.282 ( 0.282)	Loss 9.4949e-01 (9.4949e-01)	Acc@1   0.65 (  0.65)	Acc@5   0.00 (  0.00)
 * Acc@1 0.651 Acc@5 0.000
Test: [0/1]	Time  0.318 ( 0.318)	Loss 1.4161e-01 (1.4161e-01)	Acc@1   0.70 (  0.70)	Acc@5   0.00 (  0.00)
 * Acc@1 0.697 Acc@5 0.000
54
TRAINING
Epoch: [54][0/1]	Time  0.967 ( 0.967)	Data  0.250 ( 0.250)	Loss 8.1447e-02 (8.1447e-02)	Acc@1   0.91 (  0.91)	Acc@5   0.00 (  0.00)
[0.9068018611743125]
Test: [0/1]	Time  0.236 ( 0.236)	Loss 9.4951e-01 (9.4951e-01)	Acc@1   0.66 (  0.66)	Acc@5   0.00 (  0.00)
 * Acc@1 0.655 Acc@5 0.000
Test: [0/1]	Time  0.292 ( 0.292)	Loss 1.4161e-01 (1.4161e-01)	Acc@1   0.70 (  0.70)	Acc@5   0.00 (  0.00)
 * Acc@1 0.698 Acc@5 0.000
55
TRAINING
Epoch: [55][0/1]	Time  0.959 ( 0.959)	Data  0.252 ( 0.252)	Loss 8.1144e-02 (8.1144e-02)	Acc@1   0.91 (  0.91)	Acc@5   0.00 (  0.00)
[0.9102724267722488]
Test: [0/1]	Time  0.268 ( 0.268)	Loss 9.4959e-01 (9.4959e-01)	Acc@1   0.66 (  0.66)	Acc@5   0.00 (  0.00)
 * Acc@1 0.660 Acc@5 0.000
Test: [0/1]	Time  0.318 ( 0.318)	Loss 1.4160e-01 (1.4160e-01)	Acc@1   0.70 (  0.70)	Acc@5   0.00 (  0.00)
 * Acc@1 0.699 Acc@5 0.000
56
TRAINING
Epoch: [56][0/1]	Time  0.984 ( 0.984)	Data  0.275 ( 0.275)	Loss 8.0805e-02 (8.0805e-02)	Acc@1   0.91 (  0.91)	Acc@5   0.00 (  0.00)
[0.9138564826132851]
Test: [0/1]	Time  0.249 ( 0.249)	Loss 9.4971e-01 (9.4971e-01)	Acc@1   0.66 (  0.66)	Acc@5   0.00 (  0.00)
 * Acc@1 0.664 Acc@5 0.000
Test: [0/1]	Time  0.301 ( 0.301)	Loss 1.4166e-01 (1.4166e-01)	Acc@1   0.70 (  0.70)	Acc@5   0.00 (  0.00)
 * Acc@1 0.700 Acc@5 0.000
57
TRAINING
Epoch: [57][0/1]	Time  1.032 ( 1.032)	Data  0.323 ( 0.323)	Loss 8.0547e-02 (8.0547e-02)	Acc@1   0.92 (  0.92)	Acc@5   0.00 (  0.00)
[0.9172089237650305]
Test: [0/1]	Time  0.270 ( 0.270)	Loss 9.4983e-01 (9.4983e-01)	Acc@1   0.67 (  0.67)	Acc@5   0.00 (  0.00)
 * Acc@1 0.668 Acc@5 0.000
Test: [0/1]	Time  0.328 ( 0.328)	Loss 1.4182e-01 (1.4182e-01)	Acc@1   0.70 (  0.70)	Acc@5   0.00 (  0.00)
 * Acc@1 0.701 Acc@5 0.000
58
TRAINING
Epoch: [58][0/1]	Time  0.997 ( 0.997)	Data  0.300 ( 0.300)	Loss 8.0422e-02 (8.0422e-02)	Acc@1   0.92 (  0.92)	Acc@5   0.00 (  0.00)
[0.9195868832898455]
Test: [0/1]	Time  0.264 ( 0.264)	Loss 9.4990e-01 (9.4990e-01)	Acc@1   0.67 (  0.67)	Acc@5   0.00 (  0.00)
 * Acc@1 0.672 Acc@5 0.000
Test: [0/1]	Time  0.328 ( 0.328)	Loss 1.4203e-01 (1.4203e-01)	Acc@1   0.70 (  0.70)	Acc@5   0.00 (  0.00)
 * Acc@1 0.701 Acc@5 0.000
59
TRAINING
Epoch: [59][0/1]	Time  0.945 ( 0.945)	Data  0.252 ( 0.252)	Loss 8.0397e-02 (8.0397e-02)	Acc@1   0.92 (  0.92)	Acc@5   0.00 (  0.00)
[0.9217552301245542]
Test: [0/1]	Time  0.307 ( 0.307)	Loss 9.4987e-01 (9.4987e-01)	Acc@1   0.68 (  0.68)	Acc@5   0.00 (  0.00)
 * Acc@1 0.676 Acc@5 0.000
Test: [0/1]	Time  0.349 ( 0.349)	Loss 1.4218e-01 (1.4218e-01)	Acc@1   0.70 (  0.70)	Acc@5   0.00 (  0.00)
 * Acc@1 0.701 Acc@5 0.000
60
TRAINING
Epoch: [60][0/1]	Time  0.975 ( 0.975)	Data  0.270 ( 0.270)	Loss 8.0384e-02 (8.0384e-02)	Acc@1   0.92 (  0.92)	Acc@5   0.00 (  0.00)
[0.9242541445746895]
Test: [0/1]	Time  0.248 ( 0.248)	Loss 9.4973e-01 (9.4973e-01)	Acc@1   0.68 (  0.68)	Acc@5   0.00 (  0.00)
 * Acc@1 0.680 Acc@5 0.000
Test: [0/1]	Time  0.299 ( 0.299)	Loss 1.4219e-01 (1.4219e-01)	Acc@1   0.70 (  0.70)	Acc@5   0.00 (  0.00)
 * Acc@1 0.702 Acc@5 0.000
61
TRAINING
Epoch: [61][0/1]	Time  0.964 ( 0.964)	Data  0.277 ( 0.277)	Loss 8.0302e-02 (8.0302e-02)	Acc@1   0.93 (  0.93)	Acc@5   0.00 (  0.00)
[0.9262815093270182]
Test: [0/1]	Time  0.256 ( 0.256)	Loss 9.4947e-01 (9.4947e-01)	Acc@1   0.68 (  0.68)	Acc@5   0.00 (  0.00)
 * Acc@1 0.683 Acc@5 0.000
Test: [0/1]	Time  0.321 ( 0.321)	Loss 1.4203e-01 (1.4203e-01)	Acc@1   0.70 (  0.70)	Acc@5   0.00 (  0.00)
 * Acc@1 0.702 Acc@5 0.000
62
TRAINING
Epoch: [62][0/1]	Time  0.984 ( 0.984)	Data  0.289 ( 0.289)	Loss 8.0120e-02 (8.0120e-02)	Acc@1   0.93 (  0.93)	Acc@5   0.00 (  0.00)
[0.9273910542331256]
Test: [0/1]	Time  0.260 ( 0.260)	Loss 9.4912e-01 (9.4912e-01)	Acc@1   0.69 (  0.69)	Acc@5   0.00 (  0.00)
 * Acc@1 0.685 Acc@5 0.000
Test: [0/1]	Time  0.311 ( 0.311)	Loss 1.4175e-01 (1.4175e-01)	Acc@1   0.70 (  0.70)	Acc@5   0.00 (  0.00)
 * Acc@1 0.702 Acc@5 0.000
63
TRAINING
Epoch: [63][0/1]	Time  0.943 ( 0.943)	Data  0.247 ( 0.247)	Loss 7.9872e-02 (7.9872e-02)	Acc@1   0.93 (  0.93)	Acc@5   0.00 (  0.00)
[0.9282138044330427]
Test: [0/1]	Time  0.264 ( 0.264)	Loss 9.4871e-01 (9.4871e-01)	Acc@1   0.69 (  0.69)	Acc@5   0.00 (  0.00)
 * Acc@1 0.688 Acc@5 0.000
Test: [0/1]	Time  0.307 ( 0.307)	Loss 1.4140e-01 (1.4140e-01)	Acc@1   0.70 (  0.70)	Acc@5   0.00 (  0.00)
 * Acc@1 0.702 Acc@5 0.000
64
TRAINING
Epoch: [64][0/1]	Time  1.014 ( 1.014)	Data  0.293 ( 0.293)	Loss 7.9621e-02 (7.9621e-02)	Acc@1   0.93 (  0.93)	Acc@5   0.00 (  0.00)
[0.9289375045482782]
Test: [0/1]	Time  0.262 ( 0.262)	Loss 9.4826e-01 (9.4826e-01)	Acc@1   0.69 (  0.69)	Acc@5   0.00 (  0.00)
 * Acc@1 0.690 Acc@5 0.000
Test: [0/1]	Time  0.315 ( 0.315)	Loss 1.4109e-01 (1.4109e-01)	Acc@1   0.70 (  0.70)	Acc@5   0.00 (  0.00)
 * Acc@1 0.703 Acc@5 0.000
65
TRAINING
Epoch: [65][0/1]	Time  0.940 ( 0.940)	Data  0.251 ( 0.251)	Loss 7.9427e-02 (7.9427e-02)	Acc@1   0.93 (  0.93)	Acc@5   0.00 (  0.00)
[0.9300487987594657]
Test: [0/1]	Time  0.238 ( 0.238)	Loss 9.4782e-01 (9.4782e-01)	Acc@1   0.69 (  0.69)	Acc@5   0.00 (  0.00)
 * Acc@1 0.692 Acc@5 0.000
Test: [0/1]	Time  0.295 ( 0.295)	Loss 1.4083e-01 (1.4083e-01)	Acc@1   0.70 (  0.70)	Acc@5   0.00 (  0.00)
 * Acc@1 0.703 Acc@5 0.000
66
TRAINING
Epoch: [66][0/1]	Time  1.063 ( 1.063)	Data  0.355 ( 0.355)	Loss 7.9312e-02 (7.9312e-02)	Acc@1   0.93 (  0.93)	Acc@5   0.00 (  0.00)
[0.9313799276974728]
Test: [0/1]	Time  0.303 ( 0.303)	Loss 9.4741e-01 (9.4741e-01)	Acc@1   0.69 (  0.69)	Acc@5   0.00 (  0.00)
 * Acc@1 0.694 Acc@5 0.000
Test: [0/1]	Time  0.345 ( 0.345)	Loss 1.4064e-01 (1.4064e-01)	Acc@1   0.70 (  0.70)	Acc@5   0.00 (  0.00)
 * Acc@1 0.703 Acc@5 0.000
67
TRAINING
Epoch: [67][0/1]	Time  1.001 ( 1.001)	Data  0.292 ( 0.292)	Loss 7.9259e-02 (7.9259e-02)	Acc@1   0.93 (  0.93)	Acc@5   0.00 (  0.00)
[0.9322036585453404]
Test: [0/1]	Time  0.276 ( 0.276)	Loss 9.4704e-01 (9.4704e-01)	Acc@1   0.70 (  0.70)	Acc@5   0.00 (  0.00)
 * Acc@1 0.695 Acc@5 0.000
Test: [0/1]	Time  0.328 ( 0.328)	Loss 1.4049e-01 (1.4049e-01)	Acc@1   0.70 (  0.70)	Acc@5   0.00 (  0.00)
 * Acc@1 0.703 Acc@5 0.000
68
TRAINING
Epoch: [68][0/1]	Time  0.967 ( 0.967)	Data  0.257 ( 0.257)	Loss 7.9229e-02 (7.9229e-02)	Acc@1   0.93 (  0.93)	Acc@5   0.00 (  0.00)
[0.9327462813316053]
Test: [0/1]	Time  0.306 ( 0.306)	Loss 9.4672e-01 (9.4672e-01)	Acc@1   0.70 (  0.70)	Acc@5   0.00 (  0.00)
 * Acc@1 0.696 Acc@5 0.000
Test: [0/1]	Time  0.335 ( 0.335)	Loss 1.4035e-01 (1.4035e-01)	Acc@1   0.70 (  0.70)	Acc@5   0.00 (  0.00)
 * Acc@1 0.704 Acc@5 0.000
69
TRAINING
Epoch: [69][0/1]	Time  1.016 ( 1.016)	Data  0.306 ( 0.306)	Loss 7.9190e-02 (7.9190e-02)	Acc@1   0.93 (  0.93)	Acc@5   0.00 (  0.00)
[0.9330044632087072]
Test: [0/1]	Time  0.263 ( 0.263)	Loss 9.4645e-01 (9.4645e-01)	Acc@1   0.70 (  0.70)	Acc@5   0.00 (  0.00)
 * Acc@1 0.697 Acc@5 0.000
Test: [0/1]	Time  0.317 ( 0.317)	Loss 1.4022e-01 (1.4022e-01)	Acc@1   0.70 (  0.70)	Acc@5   0.00 (  0.00)
 * Acc@1 0.704 Acc@5 0.000
70
TRAINING
Epoch: [70][0/1]	Time  0.999 ( 0.999)	Data  0.287 ( 0.287)	Loss 7.9134e-02 (7.9134e-02)	Acc@1   0.93 (  0.93)	Acc@5   0.00 (  0.00)
[0.9331880864632294]
Test: [0/1]	Time  0.280 ( 0.280)	Loss 9.4623e-01 (9.4623e-01)	Acc@1   0.70 (  0.70)	Acc@5   0.00 (  0.00)
 * Acc@1 0.697 Acc@5 0.000
Test: [0/1]	Time  0.336 ( 0.336)	Loss 1.4011e-01 (1.4011e-01)	Acc@1   0.70 (  0.70)	Acc@5   0.00 (  0.00)
 * Acc@1 0.704 Acc@5 0.000
71
TRAINING
Epoch: [71][0/1]	Time  0.968 ( 0.968)	Data  0.244 ( 0.244)	Loss 7.9072e-02 (7.9072e-02)	Acc@1   0.93 (  0.93)	Acc@5   0.00 (  0.00)
[0.9333440908170278]
Test: [0/1]	Time  0.261 ( 0.261)	Loss 9.4603e-01 (9.4603e-01)	Acc@1   0.70 (  0.70)	Acc@5   0.00 (  0.00)
 * Acc@1 0.698 Acc@5 0.000
Test: [0/1]	Time  0.321 ( 0.321)	Loss 1.4002e-01 (1.4002e-01)	Acc@1   0.71 (  0.71)	Acc@5   0.00 (  0.00)
 * Acc@1 0.705 Acc@5 0.000
72
TRAINING
Epoch: [72][0/1]	Time  0.973 ( 0.973)	Data  0.266 ( 0.266)	Loss 7.9026e-02 (7.9026e-02)	Acc@1   0.93 (  0.93)	Acc@5   0.00 (  0.00)
[0.9334773935716644]
Test: [0/1]	Time  0.262 ( 0.262)	Loss 9.4584e-01 (9.4584e-01)	Acc@1   0.70 (  0.70)	Acc@5   0.00 (  0.00)
 * Acc@1 0.699 Acc@5 0.000
Test: [0/1]	Time  0.307 ( 0.307)	Loss 1.3997e-01 (1.3997e-01)	Acc@1   0.71 (  0.71)	Acc@5   0.00 (  0.00)
 * Acc@1 0.706 Acc@5 0.000
73
TRAINING
Epoch: [73][0/1]	Time  0.946 ( 0.946)	Data  0.241 ( 0.241)	Loss 7.9011e-02 (7.9011e-02)	Acc@1   0.93 (  0.93)	Acc@5   0.00 (  0.00)
[0.9335910901636226]
Test: [0/1]	Time  0.241 ( 0.241)	Loss 9.4566e-01 (9.4566e-01)	Acc@1   0.70 (  0.70)	Acc@5   0.00 (  0.00)
 * Acc@1 0.699 Acc@5 0.000
Test: [0/1]	Time  0.293 ( 0.293)	Loss 1.3995e-01 (1.3995e-01)	Acc@1   0.71 (  0.71)	Acc@5   0.00 (  0.00)
 * Acc@1 0.706 Acc@5 0.000
74
TRAINING
Epoch: [74][0/1]	Time  1.001 ( 1.001)	Data  0.292 ( 0.292)	Loss 7.9024e-02 (7.9024e-02)	Acc@1   0.93 (  0.93)	Acc@5   0.00 (  0.00)
[0.9336871217223579]
Test: [0/1]	Time  0.262 ( 0.262)	Loss 9.4546e-01 (9.4546e-01)	Acc@1   0.70 (  0.70)	Acc@5   0.00 (  0.00)
 * Acc@1 0.700 Acc@5 0.000
Test: [0/1]	Time  0.306 ( 0.306)	Loss 1.3993e-01 (1.3993e-01)	Acc@1   0.71 (  0.71)	Acc@5   0.00 (  0.00)
 * Acc@1 0.706 Acc@5 0.000
75
TRAINING
Epoch: [75][0/1]	Time  0.928 ( 0.928)	Data  0.256 ( 0.256)	Loss 7.9049e-02 (7.9049e-02)	Acc@1   0.93 (  0.93)	Acc@5   0.00 (  0.00)
[0.9337669812634877]
Test: [0/1]	Time  0.238 ( 0.238)	Loss 9.4524e-01 (9.4524e-01)	Acc@1   0.70 (  0.70)	Acc@5   0.00 (  0.00)
 * Acc@1 0.700 Acc@5 0.000
Test: [0/1]	Time  0.286 ( 0.286)	Loss 1.3988e-01 (1.3988e-01)	Acc@1   0.71 (  0.71)	Acc@5   0.00 (  0.00)
 * Acc@1 0.706 Acc@5 0.000
76
TRAINING
Epoch: [76][0/1]	Time  0.954 ( 0.954)	Data  0.243 ( 0.243)	Loss 7.9065e-02 (7.9065e-02)	Acc@1   0.93 (  0.93)	Acc@5   0.00 (  0.00)
[0.9338323202132384]
Test: [0/1]	Time  0.240 ( 0.240)	Loss 9.4499e-01 (9.4499e-01)	Acc@1   0.70 (  0.70)	Acc@5   0.00 (  0.00)
 * Acc@1 0.701 Acc@5 0.000
Test: [0/1]	Time  0.287 ( 0.287)	Loss 1.3981e-01 (1.3981e-01)	Acc@1   0.71 (  0.71)	Acc@5   0.00 (  0.00)
 * Acc@1 0.706 Acc@5 0.000
77
TRAINING
Epoch: [77][0/1]	Time  1.058 ( 1.058)	Data  0.337 ( 0.337)	Loss 7.9062e-02 (7.9062e-02)	Acc@1   0.93 (  0.93)	Acc@5   0.00 (  0.00)
[0.9338853766563343]
Test: [0/1]	Time  0.256 ( 0.256)	Loss 9.4472e-01 (9.4472e-01)	Acc@1   0.70 (  0.70)	Acc@5   0.00 (  0.00)
 * Acc@1 0.701 Acc@5 0.000
Test: [0/1]	Time  0.316 ( 0.316)	Loss 1.3971e-01 (1.3971e-01)	Acc@1   0.71 (  0.71)	Acc@5   0.00 (  0.00)
 * Acc@1 0.707 Acc@5 0.000
78
TRAINING
Epoch: [78][0/1]	Time  0.980 ( 0.980)	Data  0.285 ( 0.285)	Loss 7.9038e-02 (7.9038e-02)	Acc@1   0.93 (  0.93)	Acc@5   0.00 (  0.00)
[0.9339291905097387]
Test: [0/1]	Time  0.247 ( 0.247)	Loss 9.4444e-01 (9.4444e-01)	Acc@1   0.70 (  0.70)	Acc@5   0.00 (  0.00)
 * Acc@1 0.702 Acc@5 0.000
Test: [0/1]	Time  0.294 ( 0.294)	Loss 1.3960e-01 (1.3960e-01)	Acc@1   0.71 (  0.71)	Acc@5   0.00 (  0.00)
 * Acc@1 0.707 Acc@5 0.000
79
TRAINING
Epoch: [79][0/1]	Time  0.982 ( 0.982)	Data  0.272 ( 0.272)	Loss 7.9007e-02 (7.9007e-02)	Acc@1   0.93 (  0.93)	Acc@5   0.00 (  0.00)
[0.9339675965070426]
Test: [0/1]	Time  0.251 ( 0.251)	Loss 9.4417e-01 (9.4417e-01)	Acc@1   0.70 (  0.70)	Acc@5   0.00 (  0.00)
 * Acc@1 0.702 Acc@5 0.000
Test: [0/1]	Time  0.308 ( 0.308)	Loss 1.3949e-01 (1.3949e-01)	Acc@1   0.71 (  0.71)	Acc@5   0.00 (  0.00)
 * Acc@1 0.707 Acc@5 0.000
80
TRAINING
Epoch: [80][0/1]	Time  0.995 ( 0.995)	Data  0.283 ( 0.283)	Loss 7.8979e-02 (7.8979e-02)	Acc@1   0.93 (  0.93)	Acc@5   0.00 (  0.00)
[0.9340050054272251]
Test: [0/1]	Time  0.251 ( 0.251)	Loss 9.4391e-01 (9.4391e-01)	Acc@1   0.70 (  0.70)	Acc@5   0.00 (  0.00)
 * Acc@1 0.703 Acc@5 0.000
Test: [0/1]	Time  0.305 ( 0.305)	Loss 1.3940e-01 (1.3940e-01)	Acc@1   0.71 (  0.71)	Acc@5   0.00 (  0.00)
 * Acc@1 0.708 Acc@5 0.000
81
TRAINING
Epoch: [81][0/1]	Time  0.973 ( 0.973)	Data  0.262 ( 0.262)	Loss 7.8964e-02 (7.8964e-02)	Acc@1   0.93 (  0.93)	Acc@5   0.00 (  0.00)
[0.9340460092471461]
Test: [0/1]	Time  0.270 ( 0.270)	Loss 9.4367e-01 (9.4367e-01)	Acc@1   0.70 (  0.70)	Acc@5   0.00 (  0.00)
 * Acc@1 0.703 Acc@5 0.000
Test: [0/1]	Time  0.318 ( 0.318)	Loss 1.3933e-01 (1.3933e-01)	Acc@1   0.71 (  0.71)	Acc@5   0.00 (  0.00)
 * Acc@1 0.708 Acc@5 0.000
82
TRAINING
Epoch: [82][0/1]	Time  0.974 ( 0.974)	Data  0.267 ( 0.267)	Loss 7.8961e-02 (7.8961e-02)	Acc@1   0.93 (  0.93)	Acc@5   0.00 (  0.00)
[0.9340940684100936]
Test: [0/1]	Time  0.258 ( 0.258)	Loss 9.4347e-01 (9.4347e-01)	Acc@1   0.70 (  0.70)	Acc@5   0.00 (  0.00)
 * Acc@1 0.704 Acc@5 0.000
Test: [0/1]	Time  0.304 ( 0.304)	Loss 1.3928e-01 (1.3928e-01)	Acc@1   0.71 (  0.71)	Acc@5   0.00 (  0.00)
 * Acc@1 0.709 Acc@5 0.000
83
TRAINING
Epoch: [83][0/1]	Time  1.019 ( 1.019)	Data  0.318 ( 0.318)	Loss 7.8964e-02 (7.8964e-02)	Acc@1   0.93 (  0.93)	Acc@5   0.00 (  0.00)
[0.934071975374555]
Test: [0/1]	Time  0.270 ( 0.270)	Loss 9.4331e-01 (9.4331e-01)	Acc@1   0.70 (  0.70)	Acc@5   0.00 (  0.00)
 * Acc@1 0.704 Acc@5 0.000
Test: [0/1]	Time  0.315 ( 0.315)	Loss 1.3924e-01 (1.3924e-01)	Acc@1   0.71 (  0.71)	Acc@5   0.00 (  0.00)
 * Acc@1 0.709 Acc@5 0.000
84
TRAINING
Epoch: [84][0/1]	Time  0.954 ( 0.954)	Data  0.257 ( 0.257)	Loss 7.8967e-02 (7.8967e-02)	Acc@1   0.93 (  0.93)	Acc@5   0.00 (  0.00)
[0.9340354772962933]
Test: [0/1]	Time  0.245 ( 0.245)	Loss 9.4319e-01 (9.4319e-01)	Acc@1   0.70 (  0.70)	Acc@5   0.00 (  0.00)
 * Acc@1 0.704 Acc@5 0.000
Test: [0/1]	Time  0.297 ( 0.297)	Loss 1.3921e-01 (1.3921e-01)	Acc@1   0.71 (  0.71)	Acc@5   0.00 (  0.00)
 * Acc@1 0.710 Acc@5 0.000
85
TRAINING
Epoch: [85][0/1]	Time  0.970 ( 0.970)	Data  0.283 ( 0.283)	Loss 7.8964e-02 (7.8964e-02)	Acc@1   0.93 (  0.93)	Acc@5   0.00 (  0.00)
[0.9339887730438741]
Test: [0/1]	Time  0.282 ( 0.282)	Loss 9.4310e-01 (9.4310e-01)	Acc@1   0.70 (  0.70)	Acc@5   0.00 (  0.00)
 * Acc@1 0.705 Acc@5 0.000
Test: [0/1]	Time  0.329 ( 0.329)	Loss 1.3919e-01 (1.3919e-01)	Acc@1   0.71 (  0.71)	Acc@5   0.00 (  0.00)
 * Acc@1 0.710 Acc@5 0.000
86
TRAINING
Epoch: [86][0/1]	Time  0.962 ( 0.962)	Data  0.250 ( 0.250)	Loss 7.8957e-02 (7.8957e-02)	Acc@1   0.93 (  0.93)	Acc@5   0.00 (  0.00)
[0.9339371978079873]
Test: [0/1]	Time  0.241 ( 0.241)	Loss 9.4303e-01 (9.4303e-01)	Acc@1   0.70 (  0.70)	Acc@5   0.00 (  0.00)
 * Acc@1 0.705 Acc@5 0.000
Test: [0/1]	Time  0.294 ( 0.294)	Loss 1.3918e-01 (1.3918e-01)	Acc@1   0.71 (  0.71)	Acc@5   0.00 (  0.00)
 * Acc@1 0.710 Acc@5 0.000
87
TRAINING
Epoch: [87][0/1]	Time  0.997 ( 0.997)	Data  0.286 ( 0.286)	Loss 7.8949e-02 (7.8949e-02)	Acc@1   0.93 (  0.93)	Acc@5   0.00 (  0.00)
[0.9338866560122252]
Test: [0/1]	Time  0.250 ( 0.250)	Loss 9.4298e-01 (9.4298e-01)	Acc@1   0.70 (  0.70)	Acc@5   0.00 (  0.00)
 * Acc@1 0.705 Acc@5 0.000
Test: [0/1]	Time  0.309 ( 0.309)	Loss 1.3918e-01 (1.3918e-01)	Acc@1   0.71 (  0.71)	Acc@5   0.00 (  0.00)
 * Acc@1 0.711 Acc@5 0.000
88
TRAINING
Epoch: [88][0/1]	Time  0.992 ( 0.992)	Data  0.281 ( 0.281)	Loss 7.8943e-02 (7.8943e-02)	Acc@1   0.93 (  0.93)	Acc@5   0.00 (  0.00)
[0.9338431125301109]
Test: [0/1]	Time  0.265 ( 0.265)	Loss 9.4294e-01 (9.4294e-01)	Acc@1   0.70 (  0.70)	Acc@5   0.00 (  0.00)
 * Acc@1 0.705 Acc@5 0.000
Test: [0/1]	Time  0.309 ( 0.309)	Loss 1.3919e-01 (1.3919e-01)	Acc@1   0.71 (  0.71)	Acc@5   0.00 (  0.00)
 * Acc@1 0.711 Acc@5 0.000
89
TRAINING
Epoch: [89][0/1]	Time  0.966 ( 0.966)	Data  0.254 ( 0.254)	Loss 7.8941e-02 (7.8941e-02)	Acc@1   0.93 (  0.93)	Acc@5   0.00 (  0.00)
[0.9338120447680196]
Test: [0/1]	Time  0.289 ( 0.289)	Loss 9.4290e-01 (9.4290e-01)	Acc@1   0.70 (  0.70)	Acc@5   0.00 (  0.00)
 * Acc@1 0.705 Acc@5 0.000
Test: [0/1]	Time  0.325 ( 0.325)	Loss 1.3919e-01 (1.3919e-01)	Acc@1   0.71 (  0.71)	Acc@5   0.00 (  0.00)
 * Acc@1 0.712 Acc@5 0.000
90
TRAINING
Epoch: [90][0/1]	Time  0.995 ( 0.995)	Data  0.283 ( 0.283)	Loss 7.8939e-02 (7.8939e-02)	Acc@1   0.93 (  0.93)	Acc@5   0.00 (  0.00)
[0.9337978211193236]
Test: [0/1]	Time  0.282 ( 0.282)	Loss 9.4285e-01 (9.4285e-01)	Acc@1   0.70 (  0.70)	Acc@5   0.00 (  0.00)
 * Acc@1 0.705 Acc@5 0.000
Test: [0/1]	Time  0.331 ( 0.331)	Loss 1.3919e-01 (1.3919e-01)	Acc@1   0.71 (  0.71)	Acc@5   0.00 (  0.00)
 * Acc@1 0.712 Acc@5 0.000
91
TRAINING
Epoch: [91][0/1]	Time  1.005 ( 1.005)	Data  0.315 ( 0.315)	Loss 7.8933e-02 (7.8933e-02)	Acc@1   0.93 (  0.93)	Acc@5   0.00 (  0.00)
[0.9338030907606438]
Test: [0/1]	Time  0.268 ( 0.268)	Loss 9.4280e-01 (9.4280e-01)	Acc@1   0.70 (  0.70)	Acc@5   0.00 (  0.00)
 * Acc@1 0.705 Acc@5 0.000
Test: [0/1]	Time  0.349 ( 0.349)	Loss 1.3917e-01 (1.3917e-01)	Acc@1   0.71 (  0.71)	Acc@5   0.00 (  0.00)
 * Acc@1 0.713 Acc@5 0.000
92
TRAINING
Epoch: [92][0/1]	Time  0.947 ( 0.947)	Data  0.244 ( 0.244)	Loss 7.8921e-02 (7.8921e-02)	Acc@1   0.93 (  0.93)	Acc@5   0.00 (  0.00)
[0.9338283520837518]
Test: [0/1]	Time  0.279 ( 0.279)	Loss 9.4273e-01 (9.4273e-01)	Acc@1   0.70 (  0.70)	Acc@5   0.00 (  0.00)
 * Acc@1 0.705 Acc@5 0.000
Test: [0/1]	Time  0.312 ( 0.312)	Loss 1.3914e-01 (1.3914e-01)	Acc@1   0.71 (  0.71)	Acc@5   0.00 (  0.00)
 * Acc@1 0.713 Acc@5 0.000
93
TRAINING
Epoch: [93][0/1]	Time  0.956 ( 0.956)	Data  0.243 ( 0.243)	Loss 7.8902e-02 (7.8902e-02)	Acc@1   0.93 (  0.93)	Acc@5   0.00 (  0.00)
[0.9338718567863047]
Test: [0/1]	Time  0.239 ( 0.239)	Loss 9.4265e-01 (9.4265e-01)	Acc@1   0.70 (  0.70)	Acc@5   0.00 (  0.00)
 * Acc@1 0.705 Acc@5 0.000
Test: [0/1]	Time  0.295 ( 0.295)	Loss 1.3911e-01 (1.3911e-01)	Acc@1   0.71 (  0.71)	Acc@5   0.00 (  0.00)
 * Acc@1 0.713 Acc@5 0.000
94
TRAINING
Epoch: [94][0/1]	Time  0.957 ( 0.957)	Data  0.255 ( 0.255)	Loss 7.8878e-02 (7.8878e-02)	Acc@1   0.93 (  0.93)	Acc@5   0.00 (  0.00)
[0.9339299112999213]
Test: [0/1]	Time  0.243 ( 0.243)	Loss 9.4257e-01 (9.4257e-01)	Acc@1   0.70 (  0.70)	Acc@5   0.00 (  0.00)
 * Acc@1 0.705 Acc@5 0.000
Test: [0/1]	Time  0.296 ( 0.296)	Loss 1.3907e-01 (1.3907e-01)	Acc@1   0.71 (  0.71)	Acc@5   0.00 (  0.00)
 * Acc@1 0.714 Acc@5 0.000
95
TRAINING
Epoch: [95][0/1]	Time  0.985 ( 0.985)	Data  0.288 ( 0.288)	Loss 7.8852e-02 (7.8852e-02)	Acc@1   0.93 (  0.93)	Acc@5   0.00 (  0.00)
[0.9339975109256528]
Test: [0/1]	Time  0.258 ( 0.258)	Loss 9.4249e-01 (9.4249e-01)	Acc@1   0.70 (  0.70)	Acc@5   0.00 (  0.00)
 * Acc@1 0.705 Acc@5 0.000
Test: [0/1]	Time  0.306 ( 0.306)	Loss 1.3903e-01 (1.3903e-01)	Acc@1   0.71 (  0.71)	Acc@5   0.00 (  0.00)
 * Acc@1 0.714 Acc@5 0.000
96
TRAINING
Epoch: [96][0/1]	Time  0.992 ( 0.992)	Data  0.300 ( 0.300)	Loss 7.8828e-02 (7.8828e-02)	Acc@1   0.93 (  0.93)	Acc@5   0.00 (  0.00)
[0.9340691473808058]
Test: [0/1]	Time  0.265 ( 0.265)	Loss 9.4241e-01 (9.4241e-01)	Acc@1   0.70 (  0.70)	Acc@5   0.00 (  0.00)
 * Acc@1 0.705 Acc@5 0.000
Test: [0/1]	Time  0.318 ( 0.318)	Loss 1.3900e-01 (1.3900e-01)	Acc@1   0.71 (  0.71)	Acc@5   0.00 (  0.00)
 * Acc@1 0.714 Acc@5 0.000
97
TRAINING
Epoch: [97][0/1]	Time  0.961 ( 0.961)	Data  0.249 ( 0.249)	Loss 7.8806e-02 (7.8806e-02)	Acc@1   0.93 (  0.93)	Acc@5   0.00 (  0.00)
[0.9341396042231764]
Test: [0/1]	Time  0.243 ( 0.243)	Loss 9.4234e-01 (9.4234e-01)	Acc@1   0.70 (  0.70)	Acc@5   0.00 (  0.00)
 * Acc@1 0.705 Acc@5 0.000
Test: [0/1]	Time  0.294 ( 0.294)	Loss 1.3898e-01 (1.3898e-01)	Acc@1   0.71 (  0.71)	Acc@5   0.00 (  0.00)
 * Acc@1 0.715 Acc@5 0.000
98
TRAINING
Epoch: [98][0/1]	Time  1.000 ( 1.000)	Data  0.303 ( 0.303)	Loss 7.8786e-02 (7.8786e-02)	Acc@1   0.93 (  0.93)	Acc@5   0.00 (  0.00)
[0.934204594101925]
Test: [0/1]	Time  0.267 ( 0.267)	Loss 9.4228e-01 (9.4228e-01)	Acc@1   0.70 (  0.70)	Acc@5   0.00 (  0.00)
 * Acc@1 0.705 Acc@5 0.000
Test: [0/1]	Time  0.353 ( 0.353)	Loss 1.3896e-01 (1.3896e-01)	Acc@1   0.71 (  0.71)	Acc@5   0.00 (  0.00)
 * Acc@1 0.715 Acc@5 0.000
99
TRAINING
Epoch: [99][0/1]	Time  0.947 ( 0.947)	Data  0.252 ( 0.252)	Loss 7.8768e-02 (7.8768e-02)	Acc@1   0.93 (  0.93)	Acc@5   0.00 (  0.00)
[0.9342611644331343]
Test: [0/1]	Time  0.244 ( 0.244)	Loss 9.4224e-01 (9.4224e-01)	Acc@1   0.71 (  0.71)	Acc@5   0.00 (  0.00)
 * Acc@1 0.705 Acc@5 0.000
Test: [0/1]	Time  0.296 ( 0.296)	Loss 1.3895e-01 (1.3895e-01)	Acc@1   0.72 (  0.72)	Acc@5   0.00 (  0.00)
 * Acc@1 0.715 Acc@5 0.000
=> using pre-trained model 'st_resnet'
s/ohp/session_1
torch.Size([640, 3, 224, 224])
(640, 22)
attach reg
0
TRAINING
/home/helenr6/Adv_mapper/train_split.py:125: UserWarning: You have chosen to seed training. This will turn on the CUDNN deterministic setting, which can slow down your training considerably! You may see unexpected behavior when restarting from checkpoints.
  warnings.warn('You have chosen to seed training. '
/localscratch/helenr6.6279052.0/env/lib/python3.7/site-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  cpuset_checked))
Epoch: [0][0/1]	Time  5.248 ( 5.248)	Data  1.831 ( 1.831)	Loss 1.7383e+00 (1.7383e+00)	Acc@1   0.04 (  0.04)	Acc@5   0.00 (  0.00)
[0.035299940335806176]
Test: [0/1]	Time  0.436 ( 0.436)	Loss 1.1068e+00 (1.1068e+00)	Acc@1   0.02 (  0.02)	Acc@5   0.00 (  0.00)
 * Acc@1 0.015 Acc@5 0.000
Test: [0/1]	Time  0.561 ( 0.561)	Loss 9.2695e-01 (9.2695e-01)	Acc@1   0.07 (  0.07)	Acc@5   0.00 (  0.00)
 * Acc@1 0.070 Acc@5 0.000
1
TRAINING
Epoch: [1][0/1]	Time  0.939 ( 0.939)	Data  0.244 ( 0.244)	Loss 1.6570e+00 (1.6570e+00)	Acc@1   0.04 (  0.04)	Acc@5   0.00 (  0.00)
[0.03786883934935891]
Test: [0/1]	Time  0.237 ( 0.237)	Loss 1.0982e+00 (1.0982e+00)	Acc@1   0.01 (  0.01)	Acc@5   0.00 (  0.00)
 * Acc@1 0.013 Acc@5 0.000
Test: [0/1]	Time  0.329 ( 0.329)	Loss 8.6937e-01 (8.6937e-01)	Acc@1   0.07 (  0.07)	Acc@5   0.00 (  0.00)
 * Acc@1 0.074 Acc@5 0.000
2
TRAINING
Epoch: [2][0/1]	Time  1.039 ( 1.039)	Data  0.295 ( 0.295)	Loss 1.5334e+00 (1.5334e+00)	Acc@1   0.04 (  0.04)	Acc@5   0.00 (  0.00)
[0.04296120103005595]
Test: [0/1]	Time  0.263 ( 0.263)	Loss 1.0901e+00 (1.0901e+00)	Acc@1   0.02 (  0.02)	Acc@5   0.00 (  0.00)
 * Acc@1 0.023 Acc@5 0.000
Test: [0/1]	Time  0.312 ( 0.312)	Loss 8.2012e-01 (8.2012e-01)	Acc@1   0.08 (  0.08)	Acc@5   0.00 (  0.00)
 * Acc@1 0.080 Acc@5 0.000
3
TRAINING
Epoch: [3][0/1]	Time  1.027 ( 1.027)	Data  0.317 ( 0.317)	Loss 1.4110e+00 (1.4110e+00)	Acc@1   0.05 (  0.05)	Acc@5   0.00 (  0.00)
[0.050711067098191426]
Test: [0/1]	Time  0.288 ( 0.288)	Loss 1.0838e+00 (1.0838e+00)	Acc@1   0.04 (  0.04)	Acc@5   0.00 (  0.00)
 * Acc@1 0.035 Acc@5 0.000
Test: [0/1]	Time  0.330 ( 0.330)	Loss 7.9366e-01 (7.9366e-01)	Acc@1   0.09 (  0.09)	Acc@5   0.00 (  0.00)
 * Acc@1 0.088 Acc@5 0.000
4
TRAINING
Epoch: [4][0/1]	Time  0.995 ( 0.995)	Data  0.257 ( 0.257)	Loss 1.3151e+00 (1.3151e+00)	Acc@1   0.06 (  0.06)	Acc@5   0.00 (  0.00)
[0.05924095291941491]
Test: [0/1]	Time  0.250 ( 0.250)	Loss 1.0787e+00 (1.0787e+00)	Acc@1   0.05 (  0.05)	Acc@5   0.00 (  0.00)
 * Acc@1 0.050 Acc@5 0.000
Test: [0/1]	Time  0.329 ( 0.329)	Loss 7.8671e-01 (7.8671e-01)	Acc@1   0.10 (  0.10)	Acc@5   0.00 (  0.00)
 * Acc@1 0.096 Acc@5 0.000
5
TRAINING
Epoch: [5][0/1]	Time  0.954 ( 0.954)	Data  0.257 ( 0.257)	Loss 1.2445e+00 (1.2445e+00)	Acc@1   0.07 (  0.07)	Acc@5   0.00 (  0.00)
[0.06969649731914646]
Test: [0/1]	Time  0.241 ( 0.241)	Loss 1.0727e+00 (1.0727e+00)	Acc@1   0.06 (  0.06)	Acc@5   0.00 (  0.00)
 * Acc@1 0.065 Acc@5 0.000
Test: [0/1]	Time  0.300 ( 0.300)	Loss 7.8335e-01 (7.8335e-01)	Acc@1   0.11 (  0.11)	Acc@5   0.00 (  0.00)
 * Acc@1 0.106 Acc@5 0.000
6
TRAINING
Epoch: [6][0/1]	Time  0.954 ( 0.954)	Data  0.262 ( 0.262)	Loss 1.1801e+00 (1.1801e+00)	Acc@1   0.10 (  0.10)	Acc@5   0.00 (  0.00)
[0.09559998350492727]
Test: [0/1]	Time  0.250 ( 0.250)	Loss 1.0641e+00 (1.0641e+00)	Acc@1   0.08 (  0.08)	Acc@5   0.00 (  0.00)
 * Acc@1 0.081 Acc@5 0.000
Test: [0/1]	Time  0.302 ( 0.302)	Loss 7.6651e-01 (7.6651e-01)	Acc@1   0.11 (  0.11)	Acc@5   0.00 (  0.00)
 * Acc@1 0.115 Acc@5 0.000
7
TRAINING
Epoch: [7][0/1]	Time  1.038 ( 1.038)	Data  0.329 ( 0.329)	Loss 1.1010e+00 (1.1010e+00)	Acc@1   0.12 (  0.12)	Acc@5   0.00 (  0.00)
[0.11665377422152884]
Test: [0/1]	Time  0.277 ( 0.277)	Loss 1.0525e+00 (1.0525e+00)	Acc@1   0.13 (  0.13)	Acc@5   0.00 (  0.00)
 * Acc@1 0.125 Acc@5 0.000
Test: [0/1]	Time  0.342 ( 0.342)	Loss 7.2859e-01 (7.2859e-01)	Acc@1   0.12 (  0.12)	Acc@5   0.00 (  0.00)
 * Acc@1 0.118 Acc@5 0.000
8
TRAINING
Epoch: [8][0/1]	Time  0.985 ( 0.985)	Data  0.291 ( 0.291)	Loss 9.9917e-01 (9.9917e-01)	Acc@1   0.14 (  0.14)	Acc@5   0.00 (  0.00)
[0.13736579872188692]
Test: [0/1]	Time  0.279 ( 0.279)	Loss 1.0393e+00 (1.0393e+00)	Acc@1   0.18 (  0.18)	Acc@5   0.00 (  0.00)
 * Acc@1 0.178 Acc@5 0.000
Test: [0/1]	Time  0.337 ( 0.337)	Loss 6.7495e-01 (6.7495e-01)	Acc@1   0.13 (  0.13)	Acc@5   0.00 (  0.00)
 * Acc@1 0.126 Acc@5 0.000
9
TRAINING
Epoch: [9][0/1]	Time  0.953 ( 0.953)	Data  0.255 ( 0.255)	Loss 8.8270e-01 (8.8270e-01)	Acc@1   0.16 (  0.16)	Acc@5   0.00 (  0.00)
[0.1607644008712963]
Test: [0/1]	Time  0.244 ( 0.244)	Loss 1.0267e+00 (1.0267e+00)	Acc@1   0.19 (  0.19)	Acc@5   0.00 (  0.00)
 * Acc@1 0.192 Acc@5 0.000
Test: [0/1]	Time  0.299 ( 0.299)	Loss 6.1935e-01 (6.1935e-01)	Acc@1   0.14 (  0.14)	Acc@5   0.00 (  0.00)
 * Acc@1 0.136 Acc@5 0.000
10
TRAINING
Epoch: [10][0/1]	Time  1.020 ( 1.020)	Data  0.314 ( 0.314)	Loss 7.6897e-01 (7.6897e-01)	Acc@1   0.19 (  0.19)	Acc@5   0.00 (  0.00)
[0.1860178488350052]
Test: [0/1]	Time  0.269 ( 0.269)	Loss 1.0169e+00 (1.0169e+00)	Acc@1   0.21 (  0.21)	Acc@5   0.00 (  0.00)
 * Acc@1 0.205 Acc@5 0.000
Test: [0/1]	Time  0.326 ( 0.326)	Loss 5.7497e-01 (5.7497e-01)	Acc@1   0.15 (  0.15)	Acc@5   0.00 (  0.00)
 * Acc@1 0.147 Acc@5 0.000
11
TRAINING
Epoch: [11][0/1]	Time  1.036 ( 1.036)	Data  0.327 ( 0.327)	Loss 6.7357e-01 (6.7357e-01)	Acc@1   0.21 (  0.21)	Acc@5   0.00 (  0.00)
[0.21116494532765773]
Test: [0/1]	Time  0.279 ( 0.279)	Loss 1.0104e+00 (1.0104e+00)	Acc@1   0.22 (  0.22)	Acc@5   0.00 (  0.00)
 * Acc@1 0.219 Acc@5 0.000
Test: [0/1]	Time  0.330 ( 0.330)	Loss 5.4697e-01 (5.4697e-01)	Acc@1   0.17 (  0.17)	Acc@5   0.00 (  0.00)
 * Acc@1 0.170 Acc@5 0.000
12
TRAINING
Epoch: [12][0/1]	Time  1.034 ( 1.034)	Data  0.342 ( 0.342)	Loss 6.0194e-01 (6.0194e-01)	Acc@1   0.23 (  0.23)	Acc@5   0.00 (  0.00)
[0.23291385955482682]
Test: [0/1]	Time  0.258 ( 0.258)	Loss 1.0063e+00 (1.0063e+00)	Acc@1   0.25 (  0.25)	Acc@5   0.00 (  0.00)
 * Acc@1 0.245 Acc@5 0.000
Test: [0/1]	Time  0.313 ( 0.313)	Loss 5.3079e-01 (5.3079e-01)	Acc@1   0.19 (  0.19)	Acc@5   0.00 (  0.00)
 * Acc@1 0.195 Acc@5 0.000
13
TRAINING
Epoch: [13][0/1]	Time  0.994 ( 0.994)	Data  0.294 ( 0.294)	Loss 5.4825e-01 (5.4825e-01)	Acc@1   0.26 (  0.26)	Acc@5   0.00 (  0.00)
[0.25575609949979505]
Test: [0/1]	Time  0.240 ( 0.240)	Loss 1.0026e+00 (1.0026e+00)	Acc@1   0.26 (  0.26)	Acc@5   0.00 (  0.00)
 * Acc@1 0.261 Acc@5 0.000
Test: [0/1]	Time  0.295 ( 0.295)	Loss 5.1611e-01 (5.1611e-01)	Acc@1   0.21 (  0.21)	Acc@5   0.00 (  0.00)
 * Acc@1 0.211 Acc@5 0.000
14
TRAINING
Epoch: [14][0/1]	Time  1.058 ( 1.058)	Data  0.353 ( 0.353)	Loss 5.0082e-01 (5.0082e-01)	Acc@1   0.28 (  0.28)	Acc@5   0.00 (  0.00)
[0.282219162777569]
Test: [0/1]	Time  0.265 ( 0.265)	Loss 9.9760e-01 (9.9760e-01)	Acc@1   0.28 (  0.28)	Acc@5   0.00 (  0.00)
 * Acc@1 0.285 Acc@5 0.000
Test: [0/1]	Time  0.323 ( 0.323)	Loss 4.9366e-01 (4.9366e-01)	Acc@1   0.22 (  0.22)	Acc@5   0.00 (  0.00)
 * Acc@1 0.224 Acc@5 0.000
15
TRAINING
Epoch: [15][0/1]	Time  1.028 ( 1.028)	Data  0.315 ( 0.315)	Loss 4.4982e-01 (4.4982e-01)	Acc@1   0.33 (  0.33)	Acc@5   0.00 (  0.00)
[0.3250800560290765]
Test: [0/1]	Time  0.272 ( 0.272)	Loss 9.9041e-01 (9.9041e-01)	Acc@1   0.36 (  0.36)	Acc@5   0.00 (  0.00)
 * Acc@1 0.357 Acc@5 0.000
Test: [0/1]	Time  0.321 ( 0.321)	Loss 4.6034e-01 (4.6034e-01)	Acc@1   0.23 (  0.23)	Acc@5   0.00 (  0.00)
 * Acc@1 0.235 Acc@5 0.000
16
TRAINING
Epoch: [16][0/1]	Time  0.982 ( 0.982)	Data  0.285 ( 0.285)	Loss 3.9245e-01 (3.9245e-01)	Acc@1   0.36 (  0.36)	Acc@5   0.00 (  0.00)
[0.3597699621606941]
Test: [0/1]	Time  0.264 ( 0.264)	Loss 9.8149e-01 (9.8149e-01)	Acc@1   0.42 (  0.42)	Acc@5   0.00 (  0.00)
 * Acc@1 0.423 Acc@5 0.000
Test: [0/1]	Time  0.312 ( 0.312)	Loss 4.1995e-01 (4.1995e-01)	Acc@1   0.25 (  0.25)	Acc@5   0.00 (  0.00)
 * Acc@1 0.249 Acc@5 0.000
17
TRAINING
Epoch: [17][0/1]	Time  0.995 ( 0.995)	Data  0.279 ( 0.279)	Loss 3.3315e-01 (3.3315e-01)	Acc@1   0.40 (  0.40)	Acc@5   0.00 (  0.00)
[0.39611196585082775]
Test: [0/1]	Time  0.278 ( 0.278)	Loss 9.7200e-01 (9.7200e-01)	Acc@1   0.46 (  0.46)	Acc@5   0.00 (  0.00)
 * Acc@1 0.460 Acc@5 0.000
Test: [0/1]	Time  0.325 ( 0.325)	Loss 3.8001e-01 (3.8001e-01)	Acc@1   0.27 (  0.27)	Acc@5   0.00 (  0.00)
 * Acc@1 0.268 Acc@5 0.000
18
TRAINING
Epoch: [18][0/1]	Time  0.978 ( 0.978)	Data  0.269 ( 0.269)	Loss 2.7966e-01 (2.7966e-01)	Acc@1   0.43 (  0.43)	Acc@5   0.00 (  0.00)
[0.43350311331196156]
Test: [0/1]	Time  0.300 ( 0.300)	Loss 9.6314e-01 (9.6314e-01)	Acc@1   0.48 (  0.48)	Acc@5   0.00 (  0.00)
 * Acc@1 0.483 Acc@5 0.000
Test: [0/1]	Time  0.336 ( 0.336)	Loss 3.4700e-01 (3.4700e-01)	Acc@1   0.29 (  0.29)	Acc@5   0.00 (  0.00)
 * Acc@1 0.286 Acc@5 0.000
19
TRAINING
Epoch: [19][0/1]	Time  0.997 ( 0.997)	Data  0.311 ( 0.311)	Loss 2.3789e-01 (2.3789e-01)	Acc@1   0.48 (  0.48)	Acc@5   0.00 (  0.00)
[0.4775247080559275]
Test: [0/1]	Time  0.268 ( 0.268)	Loss 9.5569e-01 (9.5569e-01)	Acc@1   0.51 (  0.51)	Acc@5   0.00 (  0.00)
 * Acc@1 0.505 Acc@5 0.000
Test: [0/1]	Time  0.318 ( 0.318)	Loss 3.2309e-01 (3.2309e-01)	Acc@1   0.30 (  0.30)	Acc@5   0.00 (  0.00)
 * Acc@1 0.299 Acc@5 0.000
20
TRAINING
Epoch: [20][0/1]	Time  0.990 ( 0.990)	Data  0.284 ( 0.284)	Loss 2.0887e-01 (2.0887e-01)	Acc@1   0.52 (  0.52)	Acc@5   0.00 (  0.00)
[0.5233478911582632]
Test: [0/1]	Time  0.259 ( 0.259)	Loss 9.4975e-01 (9.4975e-01)	Acc@1   0.53 (  0.53)	Acc@5   0.00 (  0.00)
 * Acc@1 0.525 Acc@5 0.000
Test: [0/1]	Time  0.315 ( 0.315)	Loss 3.0594e-01 (3.0594e-01)	Acc@1   0.31 (  0.31)	Acc@5   0.00 (  0.00)
 * Acc@1 0.312 Acc@5 0.000
21
TRAINING
Epoch: [21][0/1]	Time  1.029 ( 1.029)	Data  0.303 ( 0.303)	Loss 1.8896e-01 (1.8896e-01)	Acc@1   0.57 (  0.57)	Acc@5   0.00 (  0.00)
[0.5669116126825688]
Test: [0/1]	Time  0.270 ( 0.270)	Loss 9.4508e-01 (9.4508e-01)	Acc@1   0.55 (  0.55)	Acc@5   0.00 (  0.00)
 * Acc@1 0.550 Acc@5 0.000
Test: [0/1]	Time  0.317 ( 0.317)	Loss 2.9111e-01 (2.9111e-01)	Acc@1   0.32 (  0.32)	Acc@5   0.00 (  0.00)
 * Acc@1 0.324 Acc@5 0.000
22
TRAINING
Epoch: [22][0/1]	Time  0.949 ( 0.949)	Data  0.259 ( 0.259)	Loss 1.7268e-01 (1.7268e-01)	Acc@1   0.61 (  0.61)	Acc@5   0.00 (  0.00)
[0.6086093624586462]
Test: [0/1]	Time  0.252 ( 0.252)	Loss 9.4144e-01 (9.4144e-01)	Acc@1   0.59 (  0.59)	Acc@5   0.00 (  0.00)
 * Acc@1 0.588 Acc@5 0.000
Test: [0/1]	Time  0.300 ( 0.300)	Loss 2.7517e-01 (2.7517e-01)	Acc@1   0.34 (  0.34)	Acc@5   0.00 (  0.00)
 * Acc@1 0.339 Acc@5 0.000
23
TRAINING
Epoch: [23][0/1]	Time  0.970 ( 0.970)	Data  0.250 ( 0.250)	Loss 1.5599e-01 (1.5599e-01)	Acc@1   0.66 (  0.66)	Acc@5   0.00 (  0.00)
[0.6560746652348646]
Test: [0/1]	Time  0.249 ( 0.249)	Loss 9.3877e-01 (9.3877e-01)	Acc@1   0.62 (  0.62)	Acc@5   0.00 (  0.00)
 * Acc@1 0.622 Acc@5 0.000
Test: [0/1]	Time  0.304 ( 0.304)	Loss 2.5755e-01 (2.5755e-01)	Acc@1   0.36 (  0.36)	Acc@5   0.00 (  0.00)
 * Acc@1 0.358 Acc@5 0.000
24
TRAINING
Epoch: [24][0/1]	Time  0.998 ( 0.998)	Data  0.292 ( 0.292)	Loss 1.3806e-01 (1.3806e-01)	Acc@1   0.70 (  0.70)	Acc@5   0.00 (  0.00)
[0.6995952630213181]
Test: [0/1]	Time  0.269 ( 0.269)	Loss 9.3723e-01 (9.3723e-01)	Acc@1   0.65 (  0.65)	Acc@5   0.00 (  0.00)
 * Acc@1 0.647 Acc@5 0.000
Test: [0/1]	Time  0.325 ( 0.325)	Loss 2.4031e-01 (2.4031e-01)	Acc@1   0.38 (  0.38)	Acc@5   0.00 (  0.00)
 * Acc@1 0.380 Acc@5 0.000
25
TRAINING
Epoch: [25][0/1]	Time  1.000 ( 1.000)	Data  0.272 ( 0.272)	Loss 1.2090e-01 (1.2090e-01)	Acc@1   0.74 (  0.74)	Acc@5   0.00 (  0.00)
[0.7372410366963499]
Test: [0/1]	Time  0.277 ( 0.277)	Loss 9.3693e-01 (9.3693e-01)	Acc@1   0.66 (  0.66)	Acc@5   0.00 (  0.00)
 * Acc@1 0.662 Acc@5 0.000
Test: [0/1]	Time  0.322 ( 0.322)	Loss 2.2626e-01 (2.2626e-01)	Acc@1   0.40 (  0.40)	Acc@5   0.00 (  0.00)
 * Acc@1 0.399 Acc@5 0.000
26
TRAINING
Epoch: [26][0/1]	Time  1.011 ( 1.011)	Data  0.309 ( 0.309)	Loss 1.0734e-01 (1.0734e-01)	Acc@1   0.77 (  0.77)	Acc@5   0.00 (  0.00)
[0.7714827529863182]
Test: [0/1]	Time  0.276 ( 0.276)	Loss 9.3772e-01 (9.3772e-01)	Acc@1   0.67 (  0.67)	Acc@5   0.00 (  0.00)
 * Acc@1 0.674 Acc@5 0.000
Test: [0/1]	Time  0.324 ( 0.324)	Loss 2.1695e-01 (2.1695e-01)	Acc@1   0.42 (  0.42)	Acc@5   0.00 (  0.00)
 * Acc@1 0.419 Acc@5 0.000
27
TRAINING
Epoch: [27][0/1]	Time  0.960 ( 0.960)	Data  0.265 ( 0.265)	Loss 9.9009e-02 (9.9009e-02)	Acc@1   0.80 (  0.80)	Acc@5   0.00 (  0.00)
[0.796729447635903]
Test: [0/1]	Time  0.246 ( 0.246)	Loss 9.3916e-01 (9.3916e-01)	Acc@1   0.68 (  0.68)	Acc@5   0.00 (  0.00)
 * Acc@1 0.682 Acc@5 0.000
Test: [0/1]	Time  0.305 ( 0.305)	Loss 2.1171e-01 (2.1171e-01)	Acc@1   0.44 (  0.44)	Acc@5   0.00 (  0.00)
 * Acc@1 0.439 Acc@5 0.000
28
TRAINING
Epoch: [28][0/1]	Time  0.991 ( 0.991)	Data  0.274 ( 0.274)	Loss 9.5347e-02 (9.5347e-02)	Acc@1   0.82 (  0.82)	Acc@5   0.00 (  0.00)
[0.817255124614989]
Test: [0/1]	Time  0.255 ( 0.255)	Loss 9.4064e-01 (9.4064e-01)	Acc@1   0.69 (  0.69)	Acc@5   0.00 (  0.00)
 * Acc@1 0.688 Acc@5 0.000
Test: [0/1]	Time  0.317 ( 0.317)	Loss 2.0819e-01 (2.0819e-01)	Acc@1   0.46 (  0.46)	Acc@5   0.00 (  0.00)
 * Acc@1 0.461 Acc@5 0.000
29
TRAINING
Epoch: [29][0/1]	Time  0.970 ( 0.970)	Data  0.258 ( 0.258)	Loss 9.4132e-02 (9.4132e-02)	Acc@1   0.83 (  0.83)	Acc@5   0.00 (  0.00)
[0.832937385821716]
Test: [0/1]	Time  0.243 ( 0.243)	Loss 9.4159e-01 (9.4159e-01)	Acc@1   0.69 (  0.69)	Acc@5   0.00 (  0.00)
 * Acc@1 0.691 Acc@5 0.000
Test: [0/1]	Time  0.329 ( 0.329)	Loss 2.0379e-01 (2.0379e-01)	Acc@1   0.48 (  0.48)	Acc@5   0.00 (  0.00)
 * Acc@1 0.482 Acc@5 0.000
30
TRAINING
Epoch: [30][0/1]	Time  0.993 ( 0.993)	Data  0.303 ( 0.303)	Loss 9.2870e-02 (9.2870e-02)	Acc@1   0.84 (  0.84)	Acc@5   0.00 (  0.00)
[0.8443351686893117]
Test: [0/1]	Time  0.257 ( 0.257)	Loss 9.4174e-01 (9.4174e-01)	Acc@1   0.69 (  0.69)	Acc@5   0.00 (  0.00)
 * Acc@1 0.694 Acc@5 0.000
Test: [0/1]	Time  0.318 ( 0.318)	Loss 1.9711e-01 (1.9711e-01)	Acc@1   0.51 (  0.51)	Acc@5   0.00 (  0.00)
 * Acc@1 0.506 Acc@5 0.000
31
TRAINING
Epoch: [31][0/1]	Time  1.008 ( 1.008)	Data  0.302 ( 0.302)	Loss 9.0124e-02 (9.0124e-02)	Acc@1   0.85 (  0.85)	Acc@5   0.00 (  0.00)
[0.8536972388744584]
Test: [0/1]	Time  0.257 ( 0.257)	Loss 9.4116e-01 (9.4116e-01)	Acc@1   0.70 (  0.70)	Acc@5   0.00 (  0.00)
 * Acc@1 0.696 Acc@5 0.000
Test: [0/1]	Time  0.327 ( 0.327)	Loss 1.8843e-01 (1.8843e-01)	Acc@1   0.53 (  0.53)	Acc@5   0.00 (  0.00)
 * Acc@1 0.531 Acc@5 0.000
32
TRAINING
Epoch: [32][0/1]	Time  0.967 ( 0.967)	Data  0.253 ( 0.253)	Loss 8.6029e-02 (8.6029e-02)	Acc@1   0.86 (  0.86)	Acc@5   0.00 (  0.00)
[0.8616125786705597]
Test: [0/1]	Time  0.299 ( 0.299)	Loss 9.4016e-01 (9.4016e-01)	Acc@1   0.69 (  0.69)	Acc@5   0.00 (  0.00)
 * Acc@1 0.695 Acc@5 0.000
Test: [0/1]	Time  0.324 ( 0.324)	Loss 1.7934e-01 (1.7934e-01)	Acc@1   0.56 (  0.56)	Acc@5   0.00 (  0.00)
 * Acc@1 0.557 Acc@5 0.000
33
TRAINING
Epoch: [33][0/1]	Time  0.945 ( 0.945)	Data  0.248 ( 0.248)	Loss 8.1843e-02 (8.1843e-02)	Acc@1   0.87 (  0.87)	Acc@5   0.00 (  0.00)
[0.868992532756593]
Test: [0/1]	Time  0.297 ( 0.297)	Loss 9.3915e-01 (9.3915e-01)	Acc@1   0.69 (  0.69)	Acc@5   0.00 (  0.00)
 * Acc@1 0.689 Acc@5 0.000
Test: [0/1]	Time  0.341 ( 0.341)	Loss 1.7159e-01 (1.7159e-01)	Acc@1   0.58 (  0.58)	Acc@5   0.00 (  0.00)
 * Acc@1 0.581 Acc@5 0.000
34
TRAINING
Epoch: [34][0/1]	Time  0.953 ( 0.953)	Data  0.245 ( 0.245)	Loss 7.8956e-02 (7.8956e-02)	Acc@1   0.87 (  0.87)	Acc@5   0.00 (  0.00)
[0.8732316253973584]
Test: [0/1]	Time  0.244 ( 0.244)	Loss 9.3847e-01 (9.3847e-01)	Acc@1   0.68 (  0.68)	Acc@5   0.00 (  0.00)
 * Acc@1 0.684 Acc@5 0.000
Test: [0/1]	Time  0.294 ( 0.294)	Loss 1.6620e-01 (1.6620e-01)	Acc@1   0.60 (  0.60)	Acc@5   0.00 (  0.00)
 * Acc@1 0.601 Acc@5 0.000
35
TRAINING
Epoch: [35][0/1]	Time  1.011 ( 1.011)	Data  0.306 ( 0.306)	Loss 7.8036e-02 (7.8036e-02)	Acc@1   0.88 (  0.88)	Acc@5   0.00 (  0.00)
[0.8754198593700784]
Test: [0/1]	Time  0.278 ( 0.278)	Loss 9.3828e-01 (9.3828e-01)	Acc@1   0.68 (  0.68)	Acc@5   0.00 (  0.00)
 * Acc@1 0.679 Acc@5 0.000
Test: [0/1]	Time  0.332 ( 0.332)	Loss 1.6306e-01 (1.6306e-01)	Acc@1   0.61 (  0.61)	Acc@5   0.00 (  0.00)
 * Acc@1 0.615 Acc@5 0.000
36
TRAINING
Epoch: [36][0/1]	Time  0.982 ( 0.982)	Data  0.287 ( 0.287)	Loss 7.8748e-02 (7.8748e-02)	Acc@1   0.88 (  0.88)	Acc@5   0.00 (  0.00)
[0.876311849971475]
Test: [0/1]	Time  0.273 ( 0.273)	Loss 9.3861e-01 (9.3861e-01)	Acc@1   0.68 (  0.68)	Acc@5   0.00 (  0.00)
 * Acc@1 0.675 Acc@5 0.000
Test: [0/1]	Time  0.318 ( 0.318)	Loss 1.6133e-01 (1.6133e-01)	Acc@1   0.63 (  0.63)	Acc@5   0.00 (  0.00)
 * Acc@1 0.626 Acc@5 0.000
37
TRAINING
Epoch: [37][0/1]	Time  0.960 ( 0.960)	Data  0.254 ( 0.254)	Loss 8.0102e-02 (8.0102e-02)	Acc@1   0.88 (  0.88)	Acc@5   0.00 (  0.00)
[0.8762923896454258]
Test: [0/1]	Time  0.283 ( 0.283)	Loss 9.3939e-01 (9.3939e-01)	Acc@1   0.67 (  0.67)	Acc@5   0.00 (  0.00)
 * Acc@1 0.672 Acc@5 0.000
Test: [0/1]	Time  0.326 ( 0.326)	Loss 1.6003e-01 (1.6003e-01)	Acc@1   0.63 (  0.63)	Acc@5   0.00 (  0.00)
 * Acc@1 0.634 Acc@5 0.000
38
TRAINING
Epoch: [38][0/1]	Time  1.001 ( 1.001)	Data  0.307 ( 0.307)	Loss 8.1104e-02 (8.1104e-02)	Acc@1   0.88 (  0.88)	Acc@5   0.00 (  0.00)
[0.8757276447808799]
Test: [0/1]	Time  0.288 ( 0.288)	Loss 9.4053e-01 (9.4053e-01)	Acc@1   0.67 (  0.67)	Acc@5   0.00 (  0.00)
 * Acc@1 0.670 Acc@5 0.000
Test: [0/1]	Time  0.335 ( 0.335)	Loss 1.5865e-01 (1.5865e-01)	Acc@1   0.64 (  0.64)	Acc@5   0.00 (  0.00)
 * Acc@1 0.644 Acc@5 0.000
39
TRAINING
Epoch: [39][0/1]	Time  0.962 ( 0.962)	Data  0.249 ( 0.249)	Loss 8.1288e-02 (8.1288e-02)	Acc@1   0.87 (  0.87)	Acc@5   0.00 (  0.00)
[0.8749512789154819]
Test: [0/1]	Time  0.295 ( 0.295)	Loss 9.4195e-01 (9.4195e-01)	Acc@1   0.67 (  0.67)	Acc@5   0.00 (  0.00)
 * Acc@1 0.669 Acc@5 0.000
Test: [0/1]	Time  0.336 ( 0.336)	Loss 1.5727e-01 (1.5727e-01)	Acc@1   0.65 (  0.65)	Acc@5   0.00 (  0.00)
 * Acc@1 0.654 Acc@5 0.000
40
TRAINING
Epoch: [40][0/1]	Time  0.989 ( 0.989)	Data  0.287 ( 0.287)	Loss 8.0833e-02 (8.0833e-02)	Acc@1   0.87 (  0.87)	Acc@5   0.00 (  0.00)
[0.8742514687118623]
Test: [0/1]	Time  0.244 ( 0.244)	Loss 9.4356e-01 (9.4356e-01)	Acc@1   0.67 (  0.67)	Acc@5   0.00 (  0.00)
 * Acc@1 0.668 Acc@5 0.000
Test: [0/1]	Time  0.294 ( 0.294)	Loss 1.5633e-01 (1.5633e-01)	Acc@1   0.66 (  0.66)	Acc@5   0.00 (  0.00)
 * Acc@1 0.663 Acc@5 0.000
41
TRAINING
Epoch: [41][0/1]	Time  1.046 ( 1.046)	Data  0.328 ( 0.328)	Loss 8.0302e-02 (8.0302e-02)	Acc@1   0.87 (  0.87)	Acc@5   0.00 (  0.00)
[0.873861411708472]
Test: [0/1]	Time  0.279 ( 0.279)	Loss 9.4524e-01 (9.4524e-01)	Acc@1   0.67 (  0.67)	Acc@5   0.00 (  0.00)
 * Acc@1 0.668 Acc@5 0.000
Test: [0/1]	Time  0.328 ( 0.328)	Loss 1.5619e-01 (1.5619e-01)	Acc@1   0.67 (  0.67)	Acc@5   0.00 (  0.00)
 * Acc@1 0.671 Acc@5 0.000
42
TRAINING
Epoch: [42][0/1]	Time  0.974 ( 0.974)	Data  0.277 ( 0.277)	Loss 8.0202e-02 (8.0202e-02)	Acc@1   0.87 (  0.87)	Acc@5   0.00 (  0.00)
[0.8739597123462676]
Test: [0/1]	Time  0.254 ( 0.254)	Loss 9.4682e-01 (9.4682e-01)	Acc@1   0.67 (  0.67)	Acc@5   0.00 (  0.00)
 * Acc@1 0.669 Acc@5 0.000
Test: [0/1]	Time  0.301 ( 0.301)	Loss 1.5685e-01 (1.5685e-01)	Acc@1   0.67 (  0.67)	Acc@5   0.00 (  0.00)
 * Acc@1 0.673 Acc@5 0.000
43
TRAINING
Epoch: [43][0/1]	Time  0.985 ( 0.985)	Data  0.282 ( 0.282)	Loss 8.0680e-02 (8.0680e-02)	Acc@1   0.88 (  0.88)	Acc@5   0.00 (  0.00)
[0.8750425991264281]
Test: [0/1]	Time  0.259 ( 0.259)	Loss 9.4813e-01 (9.4813e-01)	Acc@1   0.67 (  0.67)	Acc@5   0.00 (  0.00)
 * Acc@1 0.670 Acc@5 0.000
Test: [0/1]	Time  0.309 ( 0.309)	Loss 1.5790e-01 (1.5790e-01)	Acc@1   0.68 (  0.68)	Acc@5   0.00 (  0.00)
 * Acc@1 0.678 Acc@5 0.000
44
TRAINING
Epoch: [44][0/1]	Time  0.939 ( 0.939)	Data  0.242 ( 0.242)	Loss 8.1477e-02 (8.1477e-02)	Acc@1   0.88 (  0.88)	Acc@5   0.00 (  0.00)
[0.8754755919927509]
Test: [0/1]	Time  0.257 ( 0.257)	Loss 9.4902e-01 (9.4902e-01)	Acc@1   0.67 (  0.67)	Acc@5   0.00 (  0.00)
 * Acc@1 0.671 Acc@5 0.000
Test: [0/1]	Time  0.293 ( 0.293)	Loss 1.5879e-01 (1.5879e-01)	Acc@1   0.68 (  0.68)	Acc@5   0.00 (  0.00)
 * Acc@1 0.682 Acc@5 0.000
45
TRAINING
Epoch: [45][0/1]	Time  1.027 ( 1.027)	Data  0.314 ( 0.314)	Loss 8.2144e-02 (8.2144e-02)	Acc@1   0.88 (  0.88)	Acc@5   0.00 (  0.00)
[0.8764805351055531]
Test: [0/1]	Time  0.268 ( 0.268)	Loss 9.4941e-01 (9.4941e-01)	Acc@1   0.67 (  0.67)	Acc@5   0.00 (  0.00)
 * Acc@1 0.673 Acc@5 0.000
Test: [0/1]	Time  0.314 ( 0.314)	Loss 1.5911e-01 (1.5911e-01)	Acc@1   0.68 (  0.68)	Acc@5   0.00 (  0.00)
 * Acc@1 0.685 Acc@5 0.000
46
TRAINING
Epoch: [46][0/1]	Time  0.992 ( 0.992)	Data  0.298 ( 0.298)	Loss 8.2330e-02 (8.2330e-02)	Acc@1   0.88 (  0.88)	Acc@5   0.00 (  0.00)
[0.8785535740472983]
Test: [0/1]	Time  0.269 ( 0.269)	Loss 9.4936e-01 (9.4936e-01)	Acc@1   0.68 (  0.68)	Acc@5   0.00 (  0.00)
 * Acc@1 0.675 Acc@5 0.000
Test: [0/1]	Time  0.313 ( 0.313)	Loss 1.5878e-01 (1.5878e-01)	Acc@1   0.69 (  0.69)	Acc@5   0.00 (  0.00)
 * Acc@1 0.687 Acc@5 0.000
47
TRAINING
Epoch: [47][0/1]	Time  0.962 ( 0.962)	Data  0.265 ( 0.265)	Loss 8.1964e-02 (8.1964e-02)	Acc@1   0.88 (  0.88)	Acc@5   0.00 (  0.00)
[0.8815989670057436]
Test: [0/1]	Time  0.261 ( 0.261)	Loss 9.4899e-01 (9.4899e-01)	Acc@1   0.68 (  0.68)	Acc@5   0.00 (  0.00)
 * Acc@1 0.678 Acc@5 0.000
Test: [0/1]	Time  0.327 ( 0.327)	Loss 1.5804e-01 (1.5804e-01)	Acc@1   0.69 (  0.69)	Acc@5   0.00 (  0.00)
 * Acc@1 0.688 Acc@5 0.000
48
TRAINING
Epoch: [48][0/1]	Time  0.950 ( 0.950)	Data  0.247 ( 0.247)	Loss 8.1258e-02 (8.1258e-02)	Acc@1   0.89 (  0.89)	Acc@5   0.00 (  0.00)
[0.8853593789888919]
Test: [0/1]	Time  0.238 ( 0.238)	Loss 9.4844e-01 (9.4844e-01)	Acc@1   0.68 (  0.68)	Acc@5   0.00 (  0.00)
 * Acc@1 0.680 Acc@5 0.000
Test: [0/1]	Time  0.290 ( 0.290)	Loss 1.5729e-01 (1.5729e-01)	Acc@1   0.69 (  0.69)	Acc@5   0.00 (  0.00)
 * Acc@1 0.689 Acc@5 0.000
49
TRAINING
Epoch: [49][0/1]	Time  0.991 ( 0.991)	Data  0.292 ( 0.292)	Loss 8.0543e-02 (8.0543e-02)	Acc@1   0.89 (  0.89)	Acc@5   0.00 (  0.00)
[0.8894850967497201]
Test: [0/1]	Time  0.266 ( 0.266)	Loss 9.4784e-01 (9.4784e-01)	Acc@1   0.68 (  0.68)	Acc@5   0.00 (  0.00)
 * Acc@1 0.683 Acc@5 0.000
Test: [0/1]	Time  0.310 ( 0.310)	Loss 1.5682e-01 (1.5682e-01)	Acc@1   0.69 (  0.69)	Acc@5   0.00 (  0.00)
 * Acc@1 0.689 Acc@5 0.000
50
TRAINING
Epoch: [50][0/1]	Time  1.003 ( 1.003)	Data  0.291 ( 0.291)	Loss 8.0071e-02 (8.0071e-02)	Acc@1   0.89 (  0.89)	Acc@5   0.00 (  0.00)
[0.8936269061742432]
Test: [0/1]	Time  0.264 ( 0.264)	Loss 9.4730e-01 (9.4730e-01)	Acc@1   0.69 (  0.69)	Acc@5   0.00 (  0.00)
 * Acc@1 0.686 Acc@5 0.000
Test: [0/1]	Time  0.346 ( 0.346)	Loss 1.5674e-01 (1.5674e-01)	Acc@1   0.69 (  0.69)	Acc@5   0.00 (  0.00)
 * Acc@1 0.690 Acc@5 0.000
51
TRAINING
Epoch: [51][0/1]	Time  0.972 ( 0.972)	Data  0.277 ( 0.277)	Loss 7.9906e-02 (7.9906e-02)	Acc@1   0.90 (  0.90)	Acc@5   0.00 (  0.00)
[0.8979153077055023]
Test: [0/1]	Time  0.261 ( 0.261)	Loss 9.4690e-01 (9.4690e-01)	Acc@1   0.69 (  0.69)	Acc@5   0.00 (  0.00)
 * Acc@1 0.690 Acc@5 0.000
Test: [0/1]	Time  0.363 ( 0.363)	Loss 1.5695e-01 (1.5695e-01)	Acc@1   0.69 (  0.69)	Acc@5   0.00 (  0.00)
 * Acc@1 0.691 Acc@5 0.000
52
TRAINING
Epoch: [52][0/1]	Time  0.934 ( 0.934)	Data  0.248 ( 0.248)	Loss 7.9927e-02 (7.9927e-02)	Acc@1   0.90 (  0.90)	Acc@5   0.00 (  0.00)
[0.9011207336843301]
Test: [0/1]	Time  0.250 ( 0.250)	Loss 9.4664e-01 (9.4664e-01)	Acc@1   0.69 (  0.69)	Acc@5   0.00 (  0.00)
 * Acc@1 0.693 Acc@5 0.000
Test: [0/1]	Time  0.327 ( 0.327)	Loss 1.5725e-01 (1.5725e-01)	Acc@1   0.69 (  0.69)	Acc@5   0.00 (  0.00)
 * Acc@1 0.690 Acc@5 0.000
53
TRAINING
Epoch: [53][0/1]	Time  0.937 ( 0.937)	Data  0.265 ( 0.265)	Loss 7.9948e-02 (7.9948e-02)	Acc@1   0.90 (  0.90)	Acc@5   0.00 (  0.00)
[0.9039923964865577]
Test: [0/1]	Time  0.244 ( 0.244)	Loss 9.4653e-01 (9.4653e-01)	Acc@1   0.70 (  0.70)	Acc@5   0.00 (  0.00)
 * Acc@1 0.696 Acc@5 0.000
Test: [0/1]	Time  0.302 ( 0.302)	Loss 1.5750e-01 (1.5750e-01)	Acc@1   0.69 (  0.69)	Acc@5   0.00 (  0.00)
 * Acc@1 0.689 Acc@5 0.000
54
TRAINING
Epoch: [54][0/1]	Time  0.937 ( 0.937)	Data  0.261 ( 0.261)	Loss 7.9832e-02 (7.9832e-02)	Acc@1   0.91 (  0.91)	Acc@5   0.00 (  0.00)
[0.9068051873328089]
Test: [0/1]	Time  0.249 ( 0.249)	Loss 9.4655e-01 (9.4655e-01)	Acc@1   0.70 (  0.70)	Acc@5   0.00 (  0.00)
 * Acc@1 0.699 Acc@5 0.000
Test: [0/1]	Time  0.301 ( 0.301)	Loss 1.5766e-01 (1.5766e-01)	Acc@1   0.69 (  0.69)	Acc@5   0.00 (  0.00)
 * Acc@1 0.687 Acc@5 0.000
55
TRAINING
Epoch: [55][0/1]	Time  0.973 ( 0.973)	Data  0.274 ( 0.274)	Loss 7.9569e-02 (7.9569e-02)	Acc@1   0.91 (  0.91)	Acc@5   0.00 (  0.00)
[0.9095758625733071]
Test: [0/1]	Time  0.256 ( 0.256)	Loss 9.4667e-01 (9.4667e-01)	Acc@1   0.70 (  0.70)	Acc@5   0.00 (  0.00)
 * Acc@1 0.702 Acc@5 0.000
Test: [0/1]	Time  0.303 ( 0.303)	Loss 1.5780e-01 (1.5780e-01)	Acc@1   0.68 (  0.68)	Acc@5   0.00 (  0.00)
 * Acc@1 0.685 Acc@5 0.000
56
TRAINING
Epoch: [56][0/1]	Time  0.940 ( 0.940)	Data  0.264 ( 0.264)	Loss 7.9248e-02 (7.9248e-02)	Acc@1   0.91 (  0.91)	Acc@5   0.00 (  0.00)
[0.9123711387522533]
Test: [0/1]	Time  0.252 ( 0.252)	Loss 9.4686e-01 (9.4686e-01)	Acc@1   0.70 (  0.70)	Acc@5   0.00 (  0.00)
 * Acc@1 0.705 Acc@5 0.000
Test: [0/1]	Time  0.304 ( 0.304)	Loss 1.5799e-01 (1.5799e-01)	Acc@1   0.68 (  0.68)	Acc@5   0.00 (  0.00)
 * Acc@1 0.683 Acc@5 0.000
57
TRAINING
Epoch: [57][0/1]	Time  0.937 ( 0.937)	Data  0.265 ( 0.265)	Loss 7.8986e-02 (7.8986e-02)	Acc@1   0.92 (  0.92)	Acc@5   0.00 (  0.00)
[0.9153118348320983]
Test: [0/1]	Time  0.240 ( 0.240)	Loss 9.4708e-01 (9.4708e-01)	Acc@1   0.71 (  0.71)	Acc@5   0.00 (  0.00)
 * Acc@1 0.707 Acc@5 0.000
Test: [0/1]	Time  0.299 ( 0.299)	Loss 1.5827e-01 (1.5827e-01)	Acc@1   0.68 (  0.68)	Acc@5   0.00 (  0.00)
 * Acc@1 0.682 Acc@5 0.000
58
TRAINING
Epoch: [58][0/1]	Time  0.936 ( 0.936)	Data  0.263 ( 0.263)	Loss 7.8852e-02 (7.8852e-02)	Acc@1   0.92 (  0.92)	Acc@5   0.00 (  0.00)
[0.9181027986987087]
Test: [0/1]	Time  0.247 ( 0.247)	Loss 9.4726e-01 (9.4726e-01)	Acc@1   0.71 (  0.71)	Acc@5   0.00 (  0.00)
 * Acc@1 0.709 Acc@5 0.000
Test: [0/1]	Time  0.302 ( 0.302)	Loss 1.5859e-01 (1.5859e-01)	Acc@1   0.68 (  0.68)	Acc@5   0.00 (  0.00)
 * Acc@1 0.681 Acc@5 0.000
59
TRAINING
Epoch: [59][0/1]	Time  0.938 ( 0.938)	Data  0.264 ( 0.264)	Loss 7.8831e-02 (7.8831e-02)	Acc@1   0.92 (  0.92)	Acc@5   0.00 (  0.00)
[0.9207007653873914]
Test: [0/1]	Time  0.248 ( 0.248)	Loss 9.4735e-01 (9.4735e-01)	Acc@1   0.71 (  0.71)	Acc@5   0.00 (  0.00)
 * Acc@1 0.711 Acc@5 0.000
Test: [0/1]	Time  0.300 ( 0.300)	Loss 1.5885e-01 (1.5885e-01)	Acc@1   0.68 (  0.68)	Acc@5   0.00 (  0.00)
 * Acc@1 0.681 Acc@5 0.000
60
TRAINING
Epoch: [60][0/1]	Time  0.949 ( 0.949)	Data  0.260 ( 0.260)	Loss 7.8844e-02 (7.8844e-02)	Acc@1   0.92 (  0.92)	Acc@5   0.00 (  0.00)
[0.923066870191866]
Test: [0/1]	Time  0.251 ( 0.251)	Loss 9.4733e-01 (9.4733e-01)	Acc@1   0.71 (  0.71)	Acc@5   0.00 (  0.00)
 * Acc@1 0.713 Acc@5 0.000
Test: [0/1]	Time  0.306 ( 0.306)	Loss 1.5895e-01 (1.5895e-01)	Acc@1   0.68 (  0.68)	Acc@5   0.00 (  0.00)
 * Acc@1 0.681 Acc@5 0.000
61
TRAINING
Epoch: [61][0/1]	Time  0.932 ( 0.932)	Data  0.257 ( 0.257)	Loss 7.8806e-02 (7.8806e-02)	Acc@1   0.92 (  0.92)	Acc@5   0.00 (  0.00)
[0.9247056170409499]
Test: [0/1]	Time  0.245 ( 0.245)	Loss 9.4717e-01 (9.4717e-01)	Acc@1   0.71 (  0.71)	Acc@5   0.00 (  0.00)
 * Acc@1 0.714 Acc@5 0.000
Test: [0/1]	Time  0.300 ( 0.300)	Loss 1.5885e-01 (1.5885e-01)	Acc@1   0.68 (  0.68)	Acc@5   0.00 (  0.00)
 * Acc@1 0.681 Acc@5 0.000
62
TRAINING
Epoch: [62][0/1]	Time  0.959 ( 0.959)	Data  0.287 ( 0.287)	Loss 7.8673e-02 (7.8673e-02)	Acc@1   0.93 (  0.93)	Acc@5   0.00 (  0.00)
[0.9262265557539453]
Test: [0/1]	Time  0.244 ( 0.244)	Loss 9.4691e-01 (9.4691e-01)	Acc@1   0.72 (  0.72)	Acc@5   0.00 (  0.00)
 * Acc@1 0.715 Acc@5 0.000
Test: [0/1]	Time  0.292 ( 0.292)	Loss 1.5858e-01 (1.5858e-01)	Acc@1   0.68 (  0.68)	Acc@5   0.00 (  0.00)
 * Acc@1 0.682 Acc@5 0.000
63
TRAINING
Epoch: [63][0/1]	Time  0.940 ( 0.940)	Data  0.259 ( 0.259)	Loss 7.8464e-02 (7.8464e-02)	Acc@1   0.93 (  0.93)	Acc@5   0.00 (  0.00)
[0.9276936216909986]
Test: [0/1]	Time  0.249 ( 0.249)	Loss 9.4657e-01 (9.4657e-01)	Acc@1   0.72 (  0.72)	Acc@5   0.00 (  0.00)
 * Acc@1 0.717 Acc@5 0.000
Test: [0/1]	Time  0.294 ( 0.294)	Loss 1.5821e-01 (1.5821e-01)	Acc@1   0.68 (  0.68)	Acc@5   0.00 (  0.00)
 * Acc@1 0.683 Acc@5 0.000
64
TRAINING
Epoch: [64][0/1]	Time  0.960 ( 0.960)	Data  0.272 ( 0.272)	Loss 7.8237e-02 (7.8237e-02)	Acc@1   0.93 (  0.93)	Acc@5   0.00 (  0.00)
[0.9286870162431049]
Test: [0/1]	Time  0.248 ( 0.248)	Loss 9.4618e-01 (9.4618e-01)	Acc@1   0.72 (  0.72)	Acc@5   0.00 (  0.00)
 * Acc@1 0.718 Acc@5 0.000
Test: [0/1]	Time  0.301 ( 0.301)	Loss 1.5784e-01 (1.5784e-01)	Acc@1   0.68 (  0.68)	Acc@5   0.00 (  0.00)
 * Acc@1 0.684 Acc@5 0.000
65
TRAINING
Epoch: [65][0/1]	Time  0.928 ( 0.928)	Data  0.258 ( 0.258)	Loss 7.8052e-02 (7.8052e-02)	Acc@1   0.93 (  0.93)	Acc@5   0.00 (  0.00)
[0.9293598652735502]
Test: [0/1]	Time  0.240 ( 0.240)	Loss 9.4580e-01 (9.4580e-01)	Acc@1   0.72 (  0.72)	Acc@5   0.00 (  0.00)
 * Acc@1 0.719 Acc@5 0.000
Test: [0/1]	Time  0.302 ( 0.302)	Loss 1.5751e-01 (1.5751e-01)	Acc@1   0.69 (  0.69)	Acc@5   0.00 (  0.00)
 * Acc@1 0.686 Acc@5 0.000
66
TRAINING
Epoch: [66][0/1]	Time  0.935 ( 0.935)	Data  0.257 ( 0.257)	Loss 7.7943e-02 (7.7943e-02)	Acc@1   0.93 (  0.93)	Acc@5   0.00 (  0.00)
[0.9296969764640155]
Test: [0/1]	Time  0.246 ( 0.246)	Loss 9.4544e-01 (9.4544e-01)	Acc@1   0.72 (  0.72)	Acc@5   0.00 (  0.00)
 * Acc@1 0.721 Acc@5 0.000
Test: [0/1]	Time  0.293 ( 0.293)	Loss 1.5725e-01 (1.5725e-01)	Acc@1   0.69 (  0.69)	Acc@5   0.00 (  0.00)
 * Acc@1 0.687 Acc@5 0.000
67
TRAINING
Epoch: [67][0/1]	Time  0.946 ( 0.946)	Data  0.257 ( 0.257)	Loss 7.7901e-02 (7.7901e-02)	Acc@1   0.93 (  0.93)	Acc@5   0.00 (  0.00)
[0.9302390347038509]
Test: [0/1]	Time  0.245 ( 0.245)	Loss 9.4513e-01 (9.4513e-01)	Acc@1   0.72 (  0.72)	Acc@5   0.00 (  0.00)
 * Acc@1 0.722 Acc@5 0.000
Test: [0/1]	Time  0.295 ( 0.295)	Loss 1.5704e-01 (1.5704e-01)	Acc@1   0.69 (  0.69)	Acc@5   0.00 (  0.00)
 * Acc@1 0.688 Acc@5 0.000
68
TRAINING
Epoch: [68][0/1]	Time  0.930 ( 0.930)	Data  0.259 ( 0.259)	Loss 7.7892e-02 (7.7892e-02)	Acc@1   0.93 (  0.93)	Acc@5   0.00 (  0.00)
[0.9306431642926984]
Test: [0/1]	Time  0.240 ( 0.240)	Loss 9.4488e-01 (9.4488e-01)	Acc@1   0.72 (  0.72)	Acc@5   0.00 (  0.00)
 * Acc@1 0.724 Acc@5 0.000
Test: [0/1]	Time  0.293 ( 0.293)	Loss 1.5685e-01 (1.5685e-01)	Acc@1   0.69 (  0.69)	Acc@5   0.00 (  0.00)
 * Acc@1 0.688 Acc@5 0.000
69
TRAINING
Epoch: [69][0/1]	Time  0.941 ( 0.941)	Data  0.260 ( 0.260)	Loss 7.7880e-02 (7.7880e-02)	Acc@1   0.93 (  0.93)	Acc@5   0.00 (  0.00)
[0.9309510010805496]
Test: [0/1]	Time  0.235 ( 0.235)	Loss 9.4469e-01 (9.4469e-01)	Acc@1   0.72 (  0.72)	Acc@5   0.00 (  0.00)
 * Acc@1 0.725 Acc@5 0.000
Test: [0/1]	Time  0.294 ( 0.294)	Loss 1.5667e-01 (1.5667e-01)	Acc@1   0.69 (  0.69)	Acc@5   0.00 (  0.00)
 * Acc@1 0.689 Acc@5 0.000
70
TRAINING
Epoch: [70][0/1]	Time  0.939 ( 0.939)	Data  0.242 ( 0.242)	Loss 7.7851e-02 (7.7851e-02)	Acc@1   0.93 (  0.93)	Acc@5   0.00 (  0.00)
[0.9311942396488826]
Test: [0/1]	Time  0.242 ( 0.242)	Loss 9.4455e-01 (9.4455e-01)	Acc@1   0.73 (  0.73)	Acc@5   0.00 (  0.00)
 * Acc@1 0.726 Acc@5 0.000
Test: [0/1]	Time  0.290 ( 0.290)	Loss 1.5651e-01 (1.5651e-01)	Acc@1   0.69 (  0.69)	Acc@5   0.00 (  0.00)
 * Acc@1 0.689 Acc@5 0.000
71
TRAINING
Epoch: [71][0/1]	Time  0.918 ( 0.918)	Data  0.247 ( 0.247)	Loss 7.7811e-02 (7.7811e-02)	Acc@1   0.93 (  0.93)	Acc@5   0.00 (  0.00)
[0.931442987990262]
Test: [0/1]	Time  0.240 ( 0.240)	Loss 9.4444e-01 (9.4444e-01)	Acc@1   0.73 (  0.73)	Acc@5   0.00 (  0.00)
 * Acc@1 0.727 Acc@5 0.000
Test: [0/1]	Time  0.293 ( 0.293)	Loss 1.5637e-01 (1.5637e-01)	Acc@1   0.69 (  0.69)	Acc@5   0.00 (  0.00)
 * Acc@1 0.690 Acc@5 0.000
72
TRAINING
Epoch: [72][0/1]	Time  0.928 ( 0.928)	Data  0.255 ( 0.255)	Loss 7.7780e-02 (7.7780e-02)	Acc@1   0.93 (  0.93)	Acc@5   0.00 (  0.00)
[0.931858537144436]
Test: [0/1]	Time  0.241 ( 0.241)	Loss 9.4435e-01 (9.4435e-01)	Acc@1   0.73 (  0.73)	Acc@5   0.00 (  0.00)
 * Acc@1 0.728 Acc@5 0.000
Test: [0/1]	Time  0.291 ( 0.291)	Loss 1.5626e-01 (1.5626e-01)	Acc@1   0.69 (  0.69)	Acc@5   0.00 (  0.00)
 * Acc@1 0.691 Acc@5 0.000
73
TRAINING
Epoch: [73][0/1]	Time  0.922 ( 0.922)	Data  0.250 ( 0.250)	Loss 7.7774e-02 (7.7774e-02)	Acc@1   0.93 (  0.93)	Acc@5   0.00 (  0.00)
[0.9321643331347744]
Test: [0/1]	Time  0.238 ( 0.238)	Loss 9.4427e-01 (9.4427e-01)	Acc@1   0.73 (  0.73)	Acc@5   0.00 (  0.00)
 * Acc@1 0.729 Acc@5 0.000
Test: [0/1]	Time  0.291 ( 0.291)	Loss 1.5618e-01 (1.5618e-01)	Acc@1   0.69 (  0.69)	Acc@5   0.00 (  0.00)
 * Acc@1 0.691 Acc@5 0.000
74
TRAINING
Epoch: [74][0/1]	Time  0.944 ( 0.944)	Data  0.242 ( 0.242)	Loss 7.7797e-02 (7.7797e-02)	Acc@1   0.93 (  0.93)	Acc@5   0.00 (  0.00)
[0.9323962649489468]
Test: [0/1]	Time  0.238 ( 0.238)	Loss 9.4416e-01 (9.4416e-01)	Acc@1   0.73 (  0.73)	Acc@5   0.00 (  0.00)
 * Acc@1 0.730 Acc@5 0.000
Test: [0/1]	Time  0.292 ( 0.292)	Loss 1.5610e-01 (1.5610e-01)	Acc@1   0.69 (  0.69)	Acc@5   0.00 (  0.00)
 * Acc@1 0.692 Acc@5 0.000
75
TRAINING
Epoch: [75][0/1]	Time  0.953 ( 0.953)	Data  0.251 ( 0.251)	Loss 7.7835e-02 (7.7835e-02)	Acc@1   0.93 (  0.93)	Acc@5   0.00 (  0.00)
[0.9325937877874437]
Test: [0/1]	Time  0.240 ( 0.240)	Loss 9.4402e-01 (9.4402e-01)	Acc@1   0.73 (  0.73)	Acc@5   0.00 (  0.00)
 * Acc@1 0.731 Acc@5 0.000
Test: [0/1]	Time  0.292 ( 0.292)	Loss 1.5599e-01 (1.5599e-01)	Acc@1   0.69 (  0.69)	Acc@5   0.00 (  0.00)
 * Acc@1 0.693 Acc@5 0.000
76
TRAINING
Epoch: [76][0/1]	Time  0.966 ( 0.966)	Data  0.258 ( 0.258)	Loss 7.7868e-02 (7.7868e-02)	Acc@1   0.93 (  0.93)	Acc@5   0.00 (  0.00)
[0.9327905214902692]
Test: [0/1]	Time  0.250 ( 0.250)	Loss 9.4384e-01 (9.4384e-01)	Acc@1   0.73 (  0.73)	Acc@5   0.00 (  0.00)
 * Acc@1 0.732 Acc@5 0.000
Test: [0/1]	Time  0.347 ( 0.347)	Loss 1.5585e-01 (1.5585e-01)	Acc@1   0.69 (  0.69)	Acc@5   0.00 (  0.00)
 * Acc@1 0.693 Acc@5 0.000
77
TRAINING
Epoch: [77][0/1]	Time  0.952 ( 0.952)	Data  0.255 ( 0.255)	Loss 7.7883e-02 (7.7883e-02)	Acc@1   0.93 (  0.93)	Acc@5   0.00 (  0.00)
[0.9330049572919574]
Test: [0/1]	Time  0.274 ( 0.274)	Loss 9.4363e-01 (9.4363e-01)	Acc@1   0.73 (  0.73)	Acc@5   0.00 (  0.00)
 * Acc@1 0.732 Acc@5 0.000
Test: [0/1]	Time  0.326 ( 0.326)	Loss 1.5567e-01 (1.5567e-01)	Acc@1   0.69 (  0.69)	Acc@5   0.00 (  0.00)
 * Acc@1 0.694 Acc@5 0.000
78
TRAINING
Epoch: [78][0/1]	Time  0.942 ( 0.942)	Data  0.246 ( 0.246)	Loss 7.7875e-02 (7.7875e-02)	Acc@1   0.93 (  0.93)	Acc@5   0.00 (  0.00)
[0.9331530848153375]
Test: [0/1]	Time  0.243 ( 0.243)	Loss 9.4339e-01 (9.4339e-01)	Acc@1   0.73 (  0.73)	Acc@5   0.00 (  0.00)
 * Acc@1 0.733 Acc@5 0.000
Test: [0/1]	Time  0.296 ( 0.296)	Loss 1.5546e-01 (1.5546e-01)	Acc@1   0.69 (  0.69)	Acc@5   0.00 (  0.00)
 * Acc@1 0.694 Acc@5 0.000
79
TRAINING
Epoch: [79][0/1]	Time  0.956 ( 0.956)	Data  0.243 ( 0.243)	Loss 7.7853e-02 (7.7853e-02)	Acc@1   0.93 (  0.93)	Acc@5   0.00 (  0.00)
[0.9332446193080082]
Test: [0/1]	Time  0.284 ( 0.284)	Loss 9.4314e-01 (9.4314e-01)	Acc@1   0.73 (  0.73)	Acc@5   0.00 (  0.00)
 * Acc@1 0.734 Acc@5 0.000
Test: [0/1]	Time  0.295 ( 0.295)	Loss 1.5526e-01 (1.5526e-01)	Acc@1   0.69 (  0.69)	Acc@5   0.00 (  0.00)
 * Acc@1 0.694 Acc@5 0.000
80
TRAINING
Epoch: [80][0/1]	Time  0.965 ( 0.965)	Data  0.265 ( 0.265)	Loss 7.7829e-02 (7.7829e-02)	Acc@1   0.93 (  0.93)	Acc@5   0.00 (  0.00)
[0.9333203583940465]
Test: [0/1]	Time  0.251 ( 0.251)	Loss 9.4291e-01 (9.4291e-01)	Acc@1   0.73 (  0.73)	Acc@5   0.00 (  0.00)
 * Acc@1 0.735 Acc@5 0.000
Test: [0/1]	Time  0.303 ( 0.303)	Loss 1.5507e-01 (1.5507e-01)	Acc@1   0.69 (  0.69)	Acc@5   0.00 (  0.00)
 * Acc@1 0.695 Acc@5 0.000
81
TRAINING
Epoch: [81][0/1]	Time  0.971 ( 0.971)	Data  0.267 ( 0.267)	Loss 7.7814e-02 (7.7814e-02)	Acc@1   0.93 (  0.93)	Acc@5   0.00 (  0.00)
[0.9331584660319863]
Test: [0/1]	Time  0.266 ( 0.266)	Loss 9.4269e-01 (9.4269e-01)	Acc@1   0.74 (  0.74)	Acc@5   0.00 (  0.00)
 * Acc@1 0.736 Acc@5 0.000
Test: [0/1]	Time  0.318 ( 0.318)	Loss 1.5490e-01 (1.5490e-01)	Acc@1   0.69 (  0.69)	Acc@5   0.00 (  0.00)
 * Acc@1 0.695 Acc@5 0.000
82
TRAINING
Epoch: [82][0/1]	Time  0.933 ( 0.933)	Data  0.247 ( 0.247)	Loss 7.7810e-02 (7.7810e-02)	Acc@1   0.93 (  0.93)	Acc@5   0.00 (  0.00)
[0.933003980271739]
Test: [0/1]	Time  0.243 ( 0.243)	Loss 9.4251e-01 (9.4251e-01)	Acc@1   0.74 (  0.74)	Acc@5   0.00 (  0.00)
 * Acc@1 0.736 Acc@5 0.000
Test: [0/1]	Time  0.295 ( 0.295)	Loss 1.5477e-01 (1.5477e-01)	Acc@1   0.70 (  0.70)	Acc@5   0.00 (  0.00)
 * Acc@1 0.695 Acc@5 0.000
83
TRAINING
Epoch: [83][0/1]	Time  0.967 ( 0.967)	Data  0.272 ( 0.272)	Loss 7.7813e-02 (7.7813e-02)	Acc@1   0.93 (  0.93)	Acc@5   0.00 (  0.00)
[0.9329093599474799]
Test: [0/1]	Time  0.254 ( 0.254)	Loss 9.4238e-01 (9.4238e-01)	Acc@1   0.74 (  0.74)	Acc@5   0.00 (  0.00)
 * Acc@1 0.737 Acc@5 0.000
Test: [0/1]	Time  0.309 ( 0.309)	Loss 1.5466e-01 (1.5466e-01)	Acc@1   0.70 (  0.70)	Acc@5   0.00 (  0.00)
 * Acc@1 0.695 Acc@5 0.000
84
TRAINING
Epoch: [84][0/1]	Time  0.939 ( 0.939)	Data  0.246 ( 0.246)	Loss 7.7815e-02 (7.7815e-02)	Acc@1   0.93 (  0.93)	Acc@5   0.00 (  0.00)
[0.9329990012958758]
Test: [0/1]	Time  0.243 ( 0.243)	Loss 9.4228e-01 (9.4228e-01)	Acc@1   0.74 (  0.74)	Acc@5   0.00 (  0.00)
 * Acc@1 0.737 Acc@5 0.000
Test: [0/1]	Time  0.298 ( 0.298)	Loss 1.5457e-01 (1.5457e-01)	Acc@1   0.70 (  0.70)	Acc@5   0.00 (  0.00)
 * Acc@1 0.695 Acc@5 0.000
85
TRAINING
Epoch: [85][0/1]	Time  1.340 ( 1.340)	Data  0.631 ( 0.631)	Loss 7.7812e-02 (7.7812e-02)	Acc@1   0.93 (  0.93)	Acc@5   0.00 (  0.00)
[0.9330847399771456]
Test: [0/1]	Time  0.268 ( 0.268)	Loss 9.4222e-01 (9.4222e-01)	Acc@1   0.74 (  0.74)	Acc@5   0.00 (  0.00)
 * Acc@1 0.738 Acc@5 0.000
Test: [0/1]	Time  0.321 ( 0.321)	Loss 1.5450e-01 (1.5450e-01)	Acc@1   0.70 (  0.70)	Acc@5   0.00 (  0.00)
 * Acc@1 0.695 Acc@5 0.000
86
TRAINING
Epoch: [86][0/1]	Time  0.951 ( 0.951)	Data  0.278 ( 0.278)	Loss 7.7803e-02 (7.7803e-02)	Acc@1   0.93 (  0.93)	Acc@5   0.00 (  0.00)
[0.9331598158232415]
Test: [0/1]	Time  0.246 ( 0.246)	Loss 9.4220e-01 (9.4220e-01)	Acc@1   0.74 (  0.74)	Acc@5   0.00 (  0.00)
 * Acc@1 0.738 Acc@5 0.000
Test: [0/1]	Time  0.302 ( 0.302)	Loss 1.5445e-01 (1.5445e-01)	Acc@1   0.70 (  0.70)	Acc@5   0.00 (  0.00)
 * Acc@1 0.695 Acc@5 0.000
87
TRAINING
Epoch: [87][0/1]	Time  0.954 ( 0.954)	Data  0.272 ( 0.272)	Loss 7.7791e-02 (7.7791e-02)	Acc@1   0.93 (  0.93)	Acc@5   0.00 (  0.00)
[0.9332171288249642]
Test: [0/1]	Time  0.246 ( 0.246)	Loss 9.4219e-01 (9.4219e-01)	Acc@1   0.74 (  0.74)	Acc@5   0.00 (  0.00)
 * Acc@1 0.738 Acc@5 0.000
Test: [0/1]	Time  0.303 ( 0.303)	Loss 1.5441e-01 (1.5441e-01)	Acc@1   0.70 (  0.70)	Acc@5   0.00 (  0.00)
 * Acc@1 0.695 Acc@5 0.000
88
TRAINING
Epoch: [88][0/1]	Time  0.951 ( 0.951)	Data  0.277 ( 0.277)	Loss 7.7779e-02 (7.7779e-02)	Acc@1   0.93 (  0.93)	Acc@5   0.00 (  0.00)
[0.933171074684948]
Test: [0/1]	Time  0.246 ( 0.246)	Loss 9.4221e-01 (9.4221e-01)	Acc@1   0.74 (  0.74)	Acc@5   0.00 (  0.00)
 * Acc@1 0.739 Acc@5 0.000
Test: [0/1]	Time  0.297 ( 0.297)	Loss 1.5439e-01 (1.5439e-01)	Acc@1   0.69 (  0.69)	Acc@5   0.00 (  0.00)
 * Acc@1 0.695 Acc@5 0.000
89
TRAINING
Epoch: [89][0/1]	Time  0.963 ( 0.963)	Data  0.278 ( 0.278)	Loss 7.7770e-02 (7.7770e-02)	Acc@1   0.93 (  0.93)	Acc@5   0.00 (  0.00)
[0.9331256504031581]
Test: [0/1]	Time  0.246 ( 0.246)	Loss 9.4222e-01 (9.4222e-01)	Acc@1   0.74 (  0.74)	Acc@5   0.00 (  0.00)
 * Acc@1 0.739 Acc@5 0.000
Test: [0/1]	Time  0.300 ( 0.300)	Loss 1.5437e-01 (1.5437e-01)	Acc@1   0.69 (  0.69)	Acc@5   0.00 (  0.00)
 * Acc@1 0.695 Acc@5 0.000
90
TRAINING
Epoch: [90][0/1]	Time  0.942 ( 0.942)	Data  0.247 ( 0.247)	Loss 7.7762e-02 (7.7762e-02)	Acc@1   0.93 (  0.93)	Acc@5   0.00 (  0.00)
[0.9330622082705803]
Test: [0/1]	Time  0.241 ( 0.241)	Loss 9.4222e-01 (9.4222e-01)	Acc@1   0.74 (  0.74)	Acc@5   0.00 (  0.00)
 * Acc@1 0.739 Acc@5 0.000
Test: [0/1]	Time  0.288 ( 0.288)	Loss 1.5434e-01 (1.5434e-01)	Acc@1   0.69 (  0.69)	Acc@5   0.00 (  0.00)
 * Acc@1 0.695 Acc@5 0.000
91
TRAINING
Epoch: [91][0/1]	Time  0.927 ( 0.927)	Data  0.252 ( 0.252)	Loss 7.7752e-02 (7.7752e-02)	Acc@1   0.93 (  0.93)	Acc@5   0.00 (  0.00)
[0.9330831134668391]
Test: [0/1]	Time  0.240 ( 0.240)	Loss 9.4220e-01 (9.4220e-01)	Acc@1   0.74 (  0.74)	Acc@5   0.00 (  0.00)
 * Acc@1 0.739 Acc@5 0.000
Test: [0/1]	Time  0.292 ( 0.292)	Loss 1.5430e-01 (1.5430e-01)	Acc@1   0.69 (  0.69)	Acc@5   0.00 (  0.00)
 * Acc@1 0.695 Acc@5 0.000
92
TRAINING
Epoch: [92][0/1]	Time  0.920 ( 0.920)	Data  0.247 ( 0.247)	Loss 7.7737e-02 (7.7737e-02)	Acc@1   0.93 (  0.93)	Acc@5   0.00 (  0.00)
[0.9330958040765083]
Test: [0/1]	Time  0.242 ( 0.242)	Loss 9.4217e-01 (9.4217e-01)	Acc@1   0.74 (  0.74)	Acc@5   0.00 (  0.00)
 * Acc@1 0.739 Acc@5 0.000
Test: [0/1]	Time  0.294 ( 0.294)	Loss 1.5426e-01 (1.5426e-01)	Acc@1   0.69 (  0.69)	Acc@5   0.00 (  0.00)
 * Acc@1 0.695 Acc@5 0.000
93
TRAINING
Epoch: [93][0/1]	Time  0.921 ( 0.921)	Data  0.249 ( 0.249)	Loss 7.7715e-02 (7.7715e-02)	Acc@1   0.93 (  0.93)	Acc@5   0.00 (  0.00)
[0.9331000141250655]
Test: [0/1]	Time  0.242 ( 0.242)	Loss 9.4212e-01 (9.4212e-01)	Acc@1   0.74 (  0.74)	Acc@5   0.00 (  0.00)
 * Acc@1 0.739 Acc@5 0.000
Test: [0/1]	Time  0.293 ( 0.293)	Loss 1.5420e-01 (1.5420e-01)	Acc@1   0.69 (  0.69)	Acc@5   0.00 (  0.00)
 * Acc@1 0.695 Acc@5 0.000
94
TRAINING
Epoch: [94][0/1]	Time  0.938 ( 0.938)	Data  0.252 ( 0.252)	Loss 7.7687e-02 (7.7687e-02)	Acc@1   0.93 (  0.93)	Acc@5   0.00 (  0.00)
[0.9330963562088155]
Test: [0/1]	Time  0.238 ( 0.238)	Loss 9.4206e-01 (9.4206e-01)	Acc@1   0.74 (  0.74)	Acc@5   0.00 (  0.00)
 * Acc@1 0.739 Acc@5 0.000
Test: [0/1]	Time  0.291 ( 0.291)	Loss 1.5413e-01 (1.5413e-01)	Acc@1   0.69 (  0.69)	Acc@5   0.00 (  0.00)
 * Acc@1 0.695 Acc@5 0.000
95
TRAINING
Epoch: [95][0/1]	Time  0.921 ( 0.921)	Data  0.248 ( 0.248)	Loss 7.7657e-02 (7.7657e-02)	Acc@1   0.93 (  0.93)	Acc@5   0.00 (  0.00)
[0.9330323065316398]
Test: [0/1]	Time  0.243 ( 0.243)	Loss 9.4199e-01 (9.4199e-01)	Acc@1   0.74 (  0.74)	Acc@5   0.00 (  0.00)
 * Acc@1 0.740 Acc@5 0.000
Test: [0/1]	Time  0.293 ( 0.293)	Loss 1.5406e-01 (1.5406e-01)	Acc@1   0.69 (  0.69)	Acc@5   0.00 (  0.00)
 * Acc@1 0.695 Acc@5 0.000
96
TRAINING
Epoch: [96][0/1]	Time  0.924 ( 0.924)	Data  0.253 ( 0.253)	Loss 7.7627e-02 (7.7627e-02)	Acc@1   0.93 (  0.93)	Acc@5   0.00 (  0.00)
[0.9329622081400792]
Test: [0/1]	Time  0.240 ( 0.240)	Loss 9.4192e-01 (9.4192e-01)	Acc@1   0.74 (  0.74)	Acc@5   0.00 (  0.00)
 * Acc@1 0.740 Acc@5 0.000
Test: [0/1]	Time  0.294 ( 0.294)	Loss 1.5400e-01 (1.5400e-01)	Acc@1   0.69 (  0.69)	Acc@5   0.00 (  0.00)
 * Acc@1 0.695 Acc@5 0.000
97
TRAINING
Epoch: [97][0/1]	Time  0.923 ( 0.923)	Data  0.249 ( 0.249)	Loss 7.7600e-02 (7.7600e-02)	Acc@1   0.93 (  0.93)	Acc@5   0.00 (  0.00)
[0.9329010967151812]
Test: [0/1]	Time  0.237 ( 0.237)	Loss 9.4186e-01 (9.4186e-01)	Acc@1   0.74 (  0.74)	Acc@5   0.00 (  0.00)
 * Acc@1 0.740 Acc@5 0.000
Test: [0/1]	Time  0.295 ( 0.295)	Loss 1.5395e-01 (1.5395e-01)	Acc@1   0.69 (  0.69)	Acc@5   0.00 (  0.00)
 * Acc@1 0.695 Acc@5 0.000
98
TRAINING
Epoch: [98][0/1]	Time  0.929 ( 0.929)	Data  0.248 ( 0.248)	Loss 7.7577e-02 (7.7577e-02)	Acc@1   0.93 (  0.93)	Acc@5   0.00 (  0.00)
[0.9328864247288452]
Test: [0/1]	Time  0.271 ( 0.271)	Loss 9.4181e-01 (9.4181e-01)	Acc@1   0.74 (  0.74)	Acc@5   0.00 (  0.00)
 * Acc@1 0.740 Acc@5 0.000
Test: [0/1]	Time  0.319 ( 0.319)	Loss 1.5391e-01 (1.5391e-01)	Acc@1   0.69 (  0.69)	Acc@5   0.00 (  0.00)
 * Acc@1 0.695 Acc@5 0.000
99
TRAINING
Epoch: [99][0/1]	Time  0.950 ( 0.950)	Data  0.271 ( 0.271)	Loss 7.7555e-02 (7.7555e-02)	Acc@1   0.93 (  0.93)	Acc@5   0.00 (  0.00)
[0.9328926578261635]
Test: [0/1]	Time  0.249 ( 0.249)	Loss 9.4177e-01 (9.4177e-01)	Acc@1   0.74 (  0.74)	Acc@5   0.00 (  0.00)
 * Acc@1 0.740 Acc@5 0.000
Test: [0/1]	Time  0.297 ( 0.297)	Loss 1.5388e-01 (1.5388e-01)	Acc@1   0.69 (  0.69)	Acc@5   0.00 (  0.00)
 * Acc@1 0.695 Acc@5 0.000
=> using pre-trained model 'st_resnet'
s/ohp/session_1
torch.Size([640, 3, 224, 224])
(640, 22)
attach reg
0
TRAINING
/home/helenr6/Adv_mapper/train_split.py:125: UserWarning: You have chosen to seed training. This will turn on the CUDNN deterministic setting, which can slow down your training considerably! You may see unexpected behavior when restarting from checkpoints.
  warnings.warn('You have chosen to seed training. '
/localscratch/helenr6.6279052.0/env/lib/python3.7/site-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  cpuset_checked))
Epoch: [0][0/1]	Time  5.284 ( 5.284)	Data  1.885 ( 1.885)	Loss 1.7179e+00 (1.7179e+00)	Acc@1   0.04 (  0.04)	Acc@5   0.00 (  0.00)
[0.0401182303091928]
Test: [0/1]	Time  0.435 ( 0.435)	Loss 1.1069e+00 (1.1069e+00)	Acc@1   0.02 (  0.02)	Acc@5   0.00 (  0.00)
 * Acc@1 0.016 Acc@5 0.000
Test: [0/1]	Time  0.550 ( 0.550)	Loss 9.7318e-01 (9.7318e-01)	Acc@1   0.04 (  0.04)	Acc@5   0.00 (  0.00)
 * Acc@1 0.037 Acc@5 0.000
1
TRAINING
Epoch: [1][0/1]	Time  0.966 ( 0.966)	Data  0.262 ( 0.262)	Loss 1.6359e+00 (1.6359e+00)	Acc@1   0.04 (  0.04)	Acc@5   0.00 (  0.00)
[0.043230510423196825]
Test: [0/1]	Time  0.251 ( 0.251)	Loss 1.0990e+00 (1.0990e+00)	Acc@1   0.01 (  0.01)	Acc@5   0.00 (  0.00)
 * Acc@1 0.014 Acc@5 0.000
Test: [0/1]	Time  0.307 ( 0.307)	Loss 9.1957e-01 (9.1957e-01)	Acc@1   0.04 (  0.04)	Acc@5   0.00 (  0.00)
 * Acc@1 0.044 Acc@5 0.000
2
TRAINING
Epoch: [2][0/1]	Time  0.939 ( 0.939)	Data  0.244 ( 0.244)	Loss 1.5123e+00 (1.5123e+00)	Acc@1   0.05 (  0.05)	Acc@5   0.00 (  0.00)
[0.048408908384539096]
Test: [0/1]	Time  0.236 ( 0.236)	Loss 1.0917e+00 (1.0917e+00)	Acc@1   0.02 (  0.02)	Acc@5   0.00 (  0.00)
 * Acc@1 0.025 Acc@5 0.000
Test: [0/1]	Time  0.290 ( 0.290)	Loss 8.7295e-01 (8.7295e-01)	Acc@1   0.05 (  0.05)	Acc@5   0.00 (  0.00)
 * Acc@1 0.053 Acc@5 0.000
3
TRAINING
Epoch: [3][0/1]	Time  0.963 ( 0.963)	Data  0.251 ( 0.251)	Loss 1.3919e+00 (1.3919e+00)	Acc@1   0.06 (  0.06)	Acc@5   0.00 (  0.00)
[0.0554864853809185]
Test: [0/1]	Time  0.239 ( 0.239)	Loss 1.0863e+00 (1.0863e+00)	Acc@1   0.04 (  0.04)	Acc@5   0.00 (  0.00)
 * Acc@1 0.038 Acc@5 0.000
Test: [0/1]	Time  0.293 ( 0.293)	Loss 8.4634e-01 (8.4634e-01)	Acc@1   0.06 (  0.06)	Acc@5   0.00 (  0.00)
 * Acc@1 0.064 Acc@5 0.000
4
TRAINING
Epoch: [4][0/1]	Time  0.931 ( 0.931)	Data  0.235 ( 0.235)	Loss 1.3001e+00 (1.3001e+00)	Acc@1   0.06 (  0.06)	Acc@5   0.00 (  0.00)
[0.06480928257764705]
Test: [0/1]	Time  0.232 ( 0.232)	Loss 1.0818e+00 (1.0818e+00)	Acc@1   0.05 (  0.05)	Acc@5   0.00 (  0.00)
 * Acc@1 0.052 Acc@5 0.000
Test: [0/1]	Time  0.307 ( 0.307)	Loss 8.3592e-01 (8.3592e-01)	Acc@1   0.07 (  0.07)	Acc@5   0.00 (  0.00)
 * Acc@1 0.065 Acc@5 0.000
5
TRAINING
Epoch: [5][0/1]	Time  0.936 ( 0.936)	Data  0.246 ( 0.246)	Loss 1.2343e+00 (1.2343e+00)	Acc@1   0.08 (  0.08)	Acc@5   0.00 (  0.00)
[0.07641688801310048]
Test: [0/1]	Time  0.244 ( 0.244)	Loss 1.0762e+00 (1.0762e+00)	Acc@1   0.07 (  0.07)	Acc@5   0.00 (  0.00)
 * Acc@1 0.067 Acc@5 0.000
Test: [0/1]	Time  0.298 ( 0.298)	Loss 8.2661e-01 (8.2661e-01)	Acc@1   0.07 (  0.07)	Acc@5   0.00 (  0.00)
 * Acc@1 0.067 Acc@5 0.000
6
TRAINING
Epoch: [6][0/1]	Time  0.948 ( 0.948)	Data  0.234 ( 0.234)	Loss 1.1733e+00 (1.1733e+00)	Acc@1   0.09 (  0.09)	Acc@5   0.00 (  0.00)
[0.0943260995652263]
Test: [0/1]	Time  0.235 ( 0.235)	Loss 1.0674e+00 (1.0674e+00)	Acc@1   0.08 (  0.08)	Acc@5   0.00 (  0.00)
 * Acc@1 0.083 Acc@5 0.000
Test: [0/1]	Time  0.286 ( 0.286)	Loss 8.0286e-01 (8.0286e-01)	Acc@1   0.08 (  0.08)	Acc@5   0.00 (  0.00)
 * Acc@1 0.078 Acc@5 0.000
7
TRAINING
Epoch: [7][0/1]	Time  0.972 ( 0.972)	Data  0.260 ( 0.260)	Loss 1.0957e+00 (1.0957e+00)	Acc@1   0.12 (  0.12)	Acc@5   0.00 (  0.00)
[0.11747500955284185]
Test: [0/1]	Time  0.239 ( 0.239)	Loss 1.0553e+00 (1.0553e+00)	Acc@1   0.11 (  0.11)	Acc@5   0.00 (  0.00)
 * Acc@1 0.106 Acc@5 0.000
Test: [0/1]	Time  0.287 ( 0.287)	Loss 7.5856e-01 (7.5856e-01)	Acc@1   0.10 (  0.10)	Acc@5   0.00 (  0.00)
 * Acc@1 0.097 Acc@5 0.000
8
TRAINING
Epoch: [8][0/1]	Time  0.927 ( 0.927)	Data  0.241 ( 0.241)	Loss 9.9368e-01 (9.9368e-01)	Acc@1   0.14 (  0.14)	Acc@5   0.00 (  0.00)
[0.1350605507280267]
Test: [0/1]	Time  0.242 ( 0.242)	Loss 1.0413e+00 (1.0413e+00)	Acc@1   0.15 (  0.15)	Acc@5   0.00 (  0.00)
 * Acc@1 0.151 Acc@5 0.000
Test: [0/1]	Time  0.293 ( 0.293)	Loss 6.9994e-01 (6.9994e-01)	Acc@1   0.12 (  0.12)	Acc@5   0.00 (  0.00)
 * Acc@1 0.116 Acc@5 0.000
9
TRAINING
Epoch: [9][0/1]	Time  0.997 ( 0.997)	Data  0.281 ( 0.281)	Loss 8.7656e-01 (8.7656e-01)	Acc@1   0.15 (  0.15)	Acc@5   0.00 (  0.00)
[0.15164318293583384]
Test: [0/1]	Time  0.264 ( 0.264)	Loss 1.0279e+00 (1.0279e+00)	Acc@1   0.18 (  0.18)	Acc@5   0.00 (  0.00)
 * Acc@1 0.183 Acc@5 0.000
Test: [0/1]	Time  0.310 ( 0.310)	Loss 6.4069e-01 (6.4069e-01)	Acc@1   0.12 (  0.12)	Acc@5   0.00 (  0.00)
 * Acc@1 0.123 Acc@5 0.000
10
TRAINING
Epoch: [10][0/1]	Time  0.957 ( 0.957)	Data  0.245 ( 0.245)	Loss 7.6301e-01 (7.6301e-01)	Acc@1   0.17 (  0.17)	Acc@5   0.00 (  0.00)
[0.16890253578246495]
Test: [0/1]	Time  0.238 ( 0.238)	Loss 1.0174e+00 (1.0174e+00)	Acc@1   0.20 (  0.20)	Acc@5   0.00 (  0.00)
 * Acc@1 0.197 Acc@5 0.000
Test: [0/1]	Time  0.291 ( 0.291)	Loss 5.9324e-01 (5.9324e-01)	Acc@1   0.13 (  0.13)	Acc@5   0.00 (  0.00)
 * Acc@1 0.131 Acc@5 0.000
11
TRAINING
Epoch: [11][0/1]	Time  0.923 ( 0.923)	Data  0.237 ( 0.237)	Loss 6.6900e-01 (6.6900e-01)	Acc@1   0.19 (  0.19)	Acc@5   0.00 (  0.00)
[0.18974938699527188]
Test: [0/1]	Time  0.247 ( 0.247)	Loss 1.0105e+00 (1.0105e+00)	Acc@1   0.22 (  0.22)	Acc@5   0.00 (  0.00)
 * Acc@1 0.223 Acc@5 0.000
Test: [0/1]	Time  0.298 ( 0.298)	Loss 5.6190e-01 (5.6190e-01)	Acc@1   0.14 (  0.14)	Acc@5   0.00 (  0.00)
 * Acc@1 0.141 Acc@5 0.000
12
TRAINING
Epoch: [12][0/1]	Time  1.023 ( 1.023)	Data  0.307 ( 0.307)	Loss 5.9929e-01 (5.9929e-01)	Acc@1   0.22 (  0.22)	Acc@5   0.00 (  0.00)
[0.21661498952750538]
Test: [0/1]	Time  0.244 ( 0.244)	Loss 1.0061e+00 (1.0061e+00)	Acc@1   0.26 (  0.26)	Acc@5   0.00 (  0.00)
 * Acc@1 0.260 Acc@5 0.000
Test: [0/1]	Time  0.319 ( 0.319)	Loss 5.4167e-01 (5.4167e-01)	Acc@1   0.15 (  0.15)	Acc@5   0.00 (  0.00)
 * Acc@1 0.151 Acc@5 0.000
13
TRAINING
Epoch: [13][0/1]	Time  1.008 ( 1.008)	Data  0.299 ( 0.299)	Loss 5.4698e-01 (5.4698e-01)	Acc@1   0.25 (  0.25)	Acc@5   0.00 (  0.00)
[0.24755151282500096]
Test: [0/1]	Time  0.245 ( 0.245)	Loss 1.0023e+00 (1.0023e+00)	Acc@1   0.27 (  0.27)	Acc@5   0.00 (  0.00)
 * Acc@1 0.274 Acc@5 0.000
Test: [0/1]	Time  0.290 ( 0.290)	Loss 5.2263e-01 (5.2263e-01)	Acc@1   0.16 (  0.16)	Acc@5   0.00 (  0.00)
 * Acc@1 0.162 Acc@5 0.000
14
TRAINING
Epoch: [14][0/1]	Time  0.987 ( 0.987)	Data  0.290 ( 0.290)	Loss 4.9964e-01 (4.9964e-01)	Acc@1   0.28 (  0.28)	Acc@5   0.00 (  0.00)
[0.27661829101335134]
Test: [0/1]	Time  0.231 ( 0.231)	Loss 9.9743e-01 (9.9743e-01)	Acc@1   0.29 (  0.29)	Acc@5   0.00 (  0.00)
 * Acc@1 0.291 Acc@5 0.000
Test: [0/1]	Time  0.298 ( 0.298)	Loss 4.9642e-01 (4.9642e-01)	Acc@1   0.19 (  0.19)	Acc@5   0.00 (  0.00)
 * Acc@1 0.186 Acc@5 0.000
15
TRAINING
Epoch: [15][0/1]	Time  0.938 ( 0.938)	Data  0.240 ( 0.240)	Loss 4.4757e-01 (4.4757e-01)	Acc@1   0.31 (  0.31)	Acc@5   0.00 (  0.00)
[0.3108087800457856]
Test: [0/1]	Time  0.241 ( 0.241)	Loss 9.9076e-01 (9.9076e-01)	Acc@1   0.34 (  0.34)	Acc@5   0.00 (  0.00)
 * Acc@1 0.336 Acc@5 0.000
Test: [0/1]	Time  0.292 ( 0.292)	Loss 4.6086e-01 (4.6086e-01)	Acc@1   0.21 (  0.21)	Acc@5   0.00 (  0.00)
 * Acc@1 0.212 Acc@5 0.000
16
TRAINING
Epoch: [16][0/1]	Time  0.942 ( 0.942)	Data  0.239 ( 0.239)	Loss 3.8882e-01 (3.8882e-01)	Acc@1   0.35 (  0.35)	Acc@5   0.00 (  0.00)
[0.3453957684033064]
Test: [0/1]	Time  0.237 ( 0.237)	Loss 9.8277e-01 (9.8277e-01)	Acc@1   0.38 (  0.38)	Acc@5   0.00 (  0.00)
 * Acc@1 0.385 Acc@5 0.000
Test: [0/1]	Time  0.287 ( 0.287)	Loss 4.2015e-01 (4.2015e-01)	Acc@1   0.24 (  0.24)	Acc@5   0.00 (  0.00)
 * Acc@1 0.238 Acc@5 0.000
17
TRAINING
Epoch: [17][0/1]	Time  0.948 ( 0.948)	Data  0.254 ( 0.254)	Loss 3.2884e-01 (3.2884e-01)	Acc@1   0.38 (  0.38)	Acc@5   0.00 (  0.00)
[0.3833308265963345]
Test: [0/1]	Time  0.239 ( 0.239)	Loss 9.7462e-01 (9.7462e-01)	Acc@1   0.45 (  0.45)	Acc@5   0.00 (  0.00)
 * Acc@1 0.451 Acc@5 0.000
Test: [0/1]	Time  0.303 ( 0.303)	Loss 3.8150e-01 (3.8150e-01)	Acc@1   0.27 (  0.27)	Acc@5   0.00 (  0.00)
 * Acc@1 0.268 Acc@5 0.000
18
TRAINING
Epoch: [18][0/1]	Time  0.948 ( 0.948)	Data  0.255 ( 0.255)	Loss 2.7583e-01 (2.7583e-01)	Acc@1   0.42 (  0.42)	Acc@5   0.00 (  0.00)
[0.4243341016925921]
Test: [0/1]	Time  0.280 ( 0.280)	Loss 9.6739e-01 (9.6739e-01)	Acc@1   0.51 (  0.51)	Acc@5   0.00 (  0.00)
 * Acc@1 0.514 Acc@5 0.000
Test: [0/1]	Time  0.315 ( 0.315)	Loss 3.5046e-01 (3.5046e-01)	Acc@1   0.29 (  0.29)	Acc@5   0.00 (  0.00)
 * Acc@1 0.285 Acc@5 0.000
19
TRAINING
Epoch: [19][0/1]	Time  1.010 ( 1.010)	Data  0.290 ( 0.290)	Loss 2.3545e-01 (2.3545e-01)	Acc@1   0.47 (  0.47)	Acc@5   0.00 (  0.00)
[0.46777272768774797]
Test: [0/1]	Time  0.248 ( 0.248)	Loss 9.6162e-01 (9.6162e-01)	Acc@1   0.55 (  0.55)	Acc@5   0.00 (  0.00)
 * Acc@1 0.551 Acc@5 0.000
Test: [0/1]	Time  0.297 ( 0.297)	Loss 3.2820e-01 (3.2820e-01)	Acc@1   0.30 (  0.30)	Acc@5   0.00 (  0.00)
 * Acc@1 0.301 Acc@5 0.000
20
TRAINING
Epoch: [20][0/1]	Time  0.962 ( 0.962)	Data  0.261 ( 0.261)	Loss 2.0797e-01 (2.0797e-01)	Acc@1   0.51 (  0.51)	Acc@5   0.00 (  0.00)
[0.5127444237313509]
Test: [0/1]	Time  0.247 ( 0.247)	Loss 9.5722e-01 (9.5722e-01)	Acc@1   0.58 (  0.58)	Acc@5   0.00 (  0.00)
 * Acc@1 0.576 Acc@5 0.000
Test: [0/1]	Time  0.298 ( 0.298)	Loss 3.1175e-01 (3.1175e-01)	Acc@1   0.32 (  0.32)	Acc@5   0.00 (  0.00)
 * Acc@1 0.316 Acc@5 0.000
21
TRAINING
Epoch: [21][0/1]	Time  0.947 ( 0.947)	Data  0.253 ( 0.253)	Loss 1.8897e-01 (1.8897e-01)	Acc@1   0.56 (  0.56)	Acc@5   0.00 (  0.00)
[0.5591844632931937]
Test: [0/1]	Time  0.247 ( 0.247)	Loss 9.5380e-01 (9.5380e-01)	Acc@1   0.59 (  0.59)	Acc@5   0.00 (  0.00)
 * Acc@1 0.589 Acc@5 0.000
Test: [0/1]	Time  0.297 ( 0.297)	Loss 2.9667e-01 (2.9667e-01)	Acc@1   0.33 (  0.33)	Acc@5   0.00 (  0.00)
 * Acc@1 0.332 Acc@5 0.000
22
TRAINING
Epoch: [22][0/1]	Time  0.938 ( 0.938)	Data  0.247 ( 0.247)	Loss 1.7268e-01 (1.7268e-01)	Acc@1   0.61 (  0.61)	Acc@5   0.00 (  0.00)
[0.6069333049467659]
Test: [0/1]	Time  0.260 ( 0.260)	Loss 9.5107e-01 (9.5107e-01)	Acc@1   0.60 (  0.60)	Acc@5   0.00 (  0.00)
 * Acc@1 0.599 Acc@5 0.000
Test: [0/1]	Time  0.310 ( 0.310)	Loss 2.7995e-01 (2.7995e-01)	Acc@1   0.35 (  0.35)	Acc@5   0.00 (  0.00)
 * Acc@1 0.349 Acc@5 0.000
23
TRAINING
Epoch: [23][0/1]	Time  0.954 ( 0.954)	Data  0.236 ( 0.236)	Loss 1.5537e-01 (1.5537e-01)	Acc@1   0.65 (  0.65)	Acc@5   0.00 (  0.00)
[0.6539546268384806]
Test: [0/1]	Time  0.237 ( 0.237)	Loss 9.4901e-01 (9.4901e-01)	Acc@1   0.61 (  0.61)	Acc@5   0.00 (  0.00)
 * Acc@1 0.607 Acc@5 0.000
Test: [0/1]	Time  0.286 ( 0.286)	Loss 2.6155e-01 (2.6155e-01)	Acc@1   0.38 (  0.38)	Acc@5   0.00 (  0.00)
 * Acc@1 0.377 Acc@5 0.000
24
TRAINING
Epoch: [24][0/1]	Time  0.953 ( 0.953)	Data  0.257 ( 0.257)	Loss 1.3682e-01 (1.3682e-01)	Acc@1   0.70 (  0.70)	Acc@5   0.00 (  0.00)
[0.6962052960073801]
Test: [0/1]	Time  0.241 ( 0.241)	Loss 9.4783e-01 (9.4783e-01)	Acc@1   0.61 (  0.61)	Acc@5   0.00 (  0.00)
 * Acc@1 0.612 Acc@5 0.000
Test: [0/1]	Time  0.291 ( 0.291)	Loss 2.4377e-01 (2.4377e-01)	Acc@1   0.40 (  0.40)	Acc@5   0.00 (  0.00)
 * Acc@1 0.405 Acc@5 0.000
25
TRAINING
Epoch: [25][0/1]	Time  0.949 ( 0.949)	Data  0.241 ( 0.241)	Loss 1.1957e-01 (1.1957e-01)	Acc@1   0.73 (  0.73)	Acc@5   0.00 (  0.00)
[0.7328621701168786]
Test: [0/1]	Time  0.255 ( 0.255)	Loss 9.4765e-01 (9.4765e-01)	Acc@1   0.62 (  0.62)	Acc@5   0.00 (  0.00)
 * Acc@1 0.615 Acc@5 0.000
Test: [0/1]	Time  0.314 ( 0.314)	Loss 2.2933e-01 (2.2933e-01)	Acc@1   0.43 (  0.43)	Acc@5   0.00 (  0.00)
 * Acc@1 0.432 Acc@5 0.000
26
TRAINING
Epoch: [26][0/1]	Time  0.947 ( 0.947)	Data  0.253 ( 0.253)	Loss 1.0658e-01 (1.0658e-01)	Acc@1   0.76 (  0.76)	Acc@5   0.00 (  0.00)
[0.7639563359416959]
Test: [0/1]	Time  0.242 ( 0.242)	Loss 9.4835e-01 (9.4835e-01)	Acc@1   0.63 (  0.63)	Acc@5   0.00 (  0.00)
 * Acc@1 0.625 Acc@5 0.000
Test: [0/1]	Time  0.301 ( 0.301)	Loss 2.1946e-01 (2.1946e-01)	Acc@1   0.46 (  0.46)	Acc@5   0.00 (  0.00)
 * Acc@1 0.460 Acc@5 0.000
27
TRAINING
Epoch: [27][0/1]	Time  0.933 ( 0.933)	Data  0.236 ( 0.236)	Loss 9.9152e-02 (9.9152e-02)	Acc@1   0.79 (  0.79)	Acc@5   0.00 (  0.00)
[0.7941643859480936]
Test: [0/1]	Time  0.255 ( 0.255)	Loss 9.4949e-01 (9.4949e-01)	Acc@1   0.63 (  0.63)	Acc@5   0.00 (  0.00)
 * Acc@1 0.632 Acc@5 0.000
Test: [0/1]	Time  0.312 ( 0.312)	Loss 2.1328e-01 (2.1328e-01)	Acc@1   0.49 (  0.49)	Acc@5   0.00 (  0.00)
 * Acc@1 0.487 Acc@5 0.000
28
TRAINING
Epoch: [28][0/1]	Time  1.000 ( 1.000)	Data  0.301 ( 0.301)	Loss 9.6253e-02 (9.6253e-02)	Acc@1   0.82 (  0.82)	Acc@5   0.00 (  0.00)
[0.8175953232852827]
Test: [0/1]	Time  0.268 ( 0.268)	Loss 9.5049e-01 (9.5049e-01)	Acc@1   0.64 (  0.64)	Acc@5   0.00 (  0.00)
 * Acc@1 0.638 Acc@5 0.000
Test: [0/1]	Time  0.313 ( 0.313)	Loss 2.0850e-01 (2.0850e-01)	Acc@1   0.51 (  0.51)	Acc@5   0.00 (  0.00)
 * Acc@1 0.515 Acc@5 0.000
29
TRAINING
Epoch: [29][0/1]	Time  0.934 ( 0.934)	Data  0.241 ( 0.241)	Loss 9.5302e-02 (9.5302e-02)	Acc@1   0.84 (  0.84)	Acc@5   0.00 (  0.00)
[0.8359242851490698]
Test: [0/1]	Time  0.236 ( 0.236)	Loss 9.5088e-01 (9.5088e-01)	Acc@1   0.64 (  0.64)	Acc@5   0.00 (  0.00)
 * Acc@1 0.643 Acc@5 0.000
Test: [0/1]	Time  0.335 ( 0.335)	Loss 2.0287e-01 (2.0287e-01)	Acc@1   0.54 (  0.54)	Acc@5   0.00 (  0.00)
 * Acc@1 0.542 Acc@5 0.000
30
TRAINING
Epoch: [30][0/1]	Time  0.948 ( 0.948)	Data  0.257 ( 0.257)	Loss 9.3783e-02 (9.3783e-02)	Acc@1   0.85 (  0.85)	Acc@5   0.00 (  0.00)
[0.8495896670410653]
Test: [0/1]	Time  0.246 ( 0.246)	Loss 9.5049e-01 (9.5049e-01)	Acc@1   0.65 (  0.65)	Acc@5   0.00 (  0.00)
 * Acc@1 0.649 Acc@5 0.000
Test: [0/1]	Time  0.296 ( 0.296)	Loss 1.9544e-01 (1.9544e-01)	Acc@1   0.57 (  0.57)	Acc@5   0.00 (  0.00)
 * Acc@1 0.569 Acc@5 0.000
31
TRAINING
Epoch: [31][0/1]	Time  0.989 ( 0.989)	Data  0.294 ( 0.294)	Loss 9.0541e-02 (9.0541e-02)	Acc@1   0.86 (  0.86)	Acc@5   0.00 (  0.00)
[0.8578095436421564]
Test: [0/1]	Time  0.275 ( 0.275)	Loss 9.4946e-01 (9.4946e-01)	Acc@1   0.65 (  0.65)	Acc@5   0.00 (  0.00)
 * Acc@1 0.654 Acc@5 0.000
Test: [0/1]	Time  0.325 ( 0.325)	Loss 1.8681e-01 (1.8681e-01)	Acc@1   0.59 (  0.59)	Acc@5   0.00 (  0.00)
 * Acc@1 0.595 Acc@5 0.000
32
TRAINING
Epoch: [32][0/1]	Time  0.978 ( 0.978)	Data  0.273 ( 0.273)	Loss 8.6087e-02 (8.6087e-02)	Acc@1   0.86 (  0.86)	Acc@5   0.00 (  0.00)
[0.8641932114417206]
Test: [0/1]	Time  0.290 ( 0.290)	Loss 9.4818e-01 (9.4818e-01)	Acc@1   0.65 (  0.65)	Acc@5   0.00 (  0.00)
 * Acc@1 0.653 Acc@5 0.000
Test: [0/1]	Time  0.340 ( 0.340)	Loss 1.7854e-01 (1.7854e-01)	Acc@1   0.62 (  0.62)	Acc@5   0.00 (  0.00)
 * Acc@1 0.620 Acc@5 0.000
33
TRAINING
Epoch: [33][0/1]	Time  0.940 ( 0.940)	Data  0.251 ( 0.251)	Loss 8.1908e-02 (8.1908e-02)	Acc@1   0.87 (  0.87)	Acc@5   0.00 (  0.00)
[0.8688686783790294]
Test: [0/1]	Time  0.247 ( 0.247)	Loss 9.4702e-01 (9.4702e-01)	Acc@1   0.65 (  0.65)	Acc@5   0.00 (  0.00)
 * Acc@1 0.653 Acc@5 0.000
Test: [0/1]	Time  0.297 ( 0.297)	Loss 1.7206e-01 (1.7206e-01)	Acc@1   0.64 (  0.64)	Acc@5   0.00 (  0.00)
 * Acc@1 0.644 Acc@5 0.000
34
TRAINING
Epoch: [34][0/1]	Time  0.980 ( 0.980)	Data  0.265 ( 0.265)	Loss 7.9366e-02 (7.9366e-02)	Acc@1   0.87 (  0.87)	Acc@5   0.00 (  0.00)
[0.8731898940980123]
Test: [0/1]	Time  0.253 ( 0.253)	Loss 9.4624e-01 (9.4624e-01)	Acc@1   0.65 (  0.65)	Acc@5   0.00 (  0.00)
 * Acc@1 0.653 Acc@5 0.000
Test: [0/1]	Time  0.298 ( 0.298)	Loss 1.6791e-01 (1.6791e-01)	Acc@1   0.66 (  0.66)	Acc@5   0.00 (  0.00)
 * Acc@1 0.664 Acc@5 0.000
35
TRAINING
Epoch: [35][0/1]	Time  0.952 ( 0.952)	Data  0.240 ( 0.240)	Loss 7.8894e-02 (7.8894e-02)	Acc@1   0.88 (  0.88)	Acc@5   0.00 (  0.00)
[0.8751922279455518]
Test: [0/1]	Time  0.277 ( 0.277)	Loss 9.4594e-01 (9.4594e-01)	Acc@1   0.65 (  0.65)	Acc@5   0.00 (  0.00)
 * Acc@1 0.653 Acc@5 0.000
Test: [0/1]	Time  0.321 ( 0.321)	Loss 1.6562e-01 (1.6562e-01)	Acc@1   0.68 (  0.68)	Acc@5   0.00 (  0.00)
 * Acc@1 0.681 Acc@5 0.000
36
TRAINING
Epoch: [36][0/1]	Time  0.936 ( 0.936)	Data  0.240 ( 0.240)	Loss 7.9885e-02 (7.9885e-02)	Acc@1   0.88 (  0.88)	Acc@5   0.00 (  0.00)
[0.8759688489205417]
Test: [0/1]	Time  0.293 ( 0.293)	Loss 9.4608e-01 (9.4608e-01)	Acc@1   0.65 (  0.65)	Acc@5   0.00 (  0.00)
 * Acc@1 0.652 Acc@5 0.000
Test: [0/1]	Time  0.323 ( 0.323)	Loss 1.6419e-01 (1.6419e-01)	Acc@1   0.69 (  0.69)	Acc@5   0.00 (  0.00)
 * Acc@1 0.694 Acc@5 0.000
37
TRAINING
Epoch: [37][0/1]	Time  0.968 ( 0.968)	Data  0.279 ( 0.279)	Loss 8.1211e-02 (8.1211e-02)	Acc@1   0.88 (  0.88)	Acc@5   0.00 (  0.00)
[0.8753279462758068]
Test: [0/1]	Time  0.251 ( 0.251)	Loss 9.4658e-01 (9.4658e-01)	Acc@1   0.65 (  0.65)	Acc@5   0.00 (  0.00)
 * Acc@1 0.650 Acc@5 0.000
Test: [0/1]	Time  0.301 ( 0.301)	Loss 1.6273e-01 (1.6273e-01)	Acc@1   0.70 (  0.70)	Acc@5   0.00 (  0.00)
 * Acc@1 0.704 Acc@5 0.000
38
TRAINING
Epoch: [38][0/1]	Time  0.942 ( 0.942)	Data  0.256 ( 0.256)	Loss 8.1934e-02 (8.1934e-02)	Acc@1   0.87 (  0.87)	Acc@5   0.00 (  0.00)
[0.8740638421123792]
Test: [0/1]	Time  0.254 ( 0.254)	Loss 9.4735e-01 (9.4735e-01)	Acc@1   0.65 (  0.65)	Acc@5   0.00 (  0.00)
 * Acc@1 0.648 Acc@5 0.000
Test: [0/1]	Time  0.329 ( 0.329)	Loss 1.6094e-01 (1.6094e-01)	Acc@1   0.71 (  0.71)	Acc@5   0.00 (  0.00)
 * Acc@1 0.713 Acc@5 0.000
39
TRAINING
Epoch: [39][0/1]	Time  0.960 ( 0.960)	Data  0.244 ( 0.244)	Loss 8.1780e-02 (8.1780e-02)	Acc@1   0.87 (  0.87)	Acc@5   0.00 (  0.00)
[0.8725917879152877]
Test: [0/1]	Time  0.289 ( 0.289)	Loss 9.4834e-01 (9.4834e-01)	Acc@1   0.65 (  0.65)	Acc@5   0.00 (  0.00)
 * Acc@1 0.645 Acc@5 0.000
Test: [0/1]	Time  0.321 ( 0.321)	Loss 1.5907e-01 (1.5907e-01)	Acc@1   0.72 (  0.72)	Acc@5   0.00 (  0.00)
 * Acc@1 0.717 Acc@5 0.000
40
TRAINING
Epoch: [40][0/1]	Time  0.963 ( 0.963)	Data  0.276 ( 0.276)	Loss 8.1123e-02 (8.1123e-02)	Acc@1   0.87 (  0.87)	Acc@5   0.00 (  0.00)
[0.8715155753976109]
Test: [0/1]	Time  0.258 ( 0.258)	Loss 9.4948e-01 (9.4948e-01)	Acc@1   0.64 (  0.64)	Acc@5   0.00 (  0.00)
 * Acc@1 0.643 Acc@5 0.000
Test: [0/1]	Time  0.312 ( 0.312)	Loss 1.5766e-01 (1.5766e-01)	Acc@1   0.72 (  0.72)	Acc@5   0.00 (  0.00)
 * Acc@1 0.723 Acc@5 0.000
41
TRAINING
Epoch: [41][0/1]	Time  1.001 ( 1.001)	Data  0.304 ( 0.304)	Loss 8.0607e-02 (8.0607e-02)	Acc@1   0.87 (  0.87)	Acc@5   0.00 (  0.00)
[0.8706424586942088]
Test: [0/1]	Time  0.262 ( 0.262)	Loss 9.5070e-01 (9.5070e-01)	Acc@1   0.64 (  0.64)	Acc@5   0.00 (  0.00)
 * Acc@1 0.640 Acc@5 0.000
Test: [0/1]	Time  0.311 ( 0.311)	Loss 1.5704e-01 (1.5704e-01)	Acc@1   0.73 (  0.73)	Acc@5   0.00 (  0.00)
 * Acc@1 0.729 Acc@5 0.000
42
TRAINING
Epoch: [42][0/1]	Time  0.927 ( 0.927)	Data  0.239 ( 0.239)	Loss 8.0680e-02 (8.0680e-02)	Acc@1   0.87 (  0.87)	Acc@5   0.00 (  0.00)
[0.8705848998791741]
Test: [0/1]	Time  0.260 ( 0.260)	Loss 9.5185e-01 (9.5185e-01)	Acc@1   0.64 (  0.64)	Acc@5   0.00 (  0.00)
 * Acc@1 0.638 Acc@5 0.000
Test: [0/1]	Time  0.310 ( 0.310)	Loss 1.5714e-01 (1.5714e-01)	Acc@1   0.73 (  0.73)	Acc@5   0.00 (  0.00)
 * Acc@1 0.734 Acc@5 0.000
43
TRAINING
Epoch: [43][0/1]	Time  0.993 ( 0.993)	Data  0.292 ( 0.292)	Loss 8.1344e-02 (8.1344e-02)	Acc@1   0.87 (  0.87)	Acc@5   0.00 (  0.00)
[0.8711943523965123]
Test: [0/1]	Time  0.264 ( 0.264)	Loss 9.5278e-01 (9.5278e-01)	Acc@1   0.64 (  0.64)	Acc@5   0.00 (  0.00)
 * Acc@1 0.636 Acc@5 0.000
Test: [0/1]	Time  0.307 ( 0.307)	Loss 1.5758e-01 (1.5758e-01)	Acc@1   0.74 (  0.74)	Acc@5   0.00 (  0.00)
 * Acc@1 0.737 Acc@5 0.000
44
TRAINING
Epoch: [44][0/1]	Time  0.947 ( 0.947)	Data  0.249 ( 0.249)	Loss 8.2210e-02 (8.2210e-02)	Acc@1   0.87 (  0.87)	Acc@5   0.00 (  0.00)
[0.8724493157258897]
Test: [0/1]	Time  0.278 ( 0.278)	Loss 9.5339e-01 (9.5339e-01)	Acc@1   0.63 (  0.63)	Acc@5   0.00 (  0.00)
 * Acc@1 0.635 Acc@5 0.000
Test: [0/1]	Time  0.324 ( 0.324)	Loss 1.5786e-01 (1.5786e-01)	Acc@1   0.74 (  0.74)	Acc@5   0.00 (  0.00)
 * Acc@1 0.740 Acc@5 0.000
45
TRAINING
Epoch: [45][0/1]	Time  0.977 ( 0.977)	Data  0.271 ( 0.271)	Loss 8.2788e-02 (8.2788e-02)	Acc@1   0.87 (  0.87)	Acc@5   0.00 (  0.00)
[0.87418016491723]
Test: [0/1]	Time  0.288 ( 0.288)	Loss 9.5363e-01 (9.5363e-01)	Acc@1   0.63 (  0.63)	Acc@5   0.00 (  0.00)
 * Acc@1 0.635 Acc@5 0.000
Test: [0/1]	Time  0.301 ( 0.301)	Loss 1.5770e-01 (1.5770e-01)	Acc@1   0.74 (  0.74)	Acc@5   0.00 (  0.00)
 * Acc@1 0.743 Acc@5 0.000
46
TRAINING
Epoch: [46][0/1]	Time  0.948 ( 0.948)	Data  0.250 ( 0.250)	Loss 8.2786e-02 (8.2786e-02)	Acc@1   0.88 (  0.88)	Acc@5   0.00 (  0.00)
[0.8770069973291699]
Test: [0/1]	Time  0.244 ( 0.244)	Loss 9.5356e-01 (9.5356e-01)	Acc@1   0.64 (  0.64)	Acc@5   0.00 (  0.00)
 * Acc@1 0.635 Acc@5 0.000
Test: [0/1]	Time  0.303 ( 0.303)	Loss 1.5717e-01 (1.5717e-01)	Acc@1   0.74 (  0.74)	Acc@5   0.00 (  0.00)
 * Acc@1 0.745 Acc@5 0.000
47
TRAINING
Epoch: [47][0/1]	Time  1.033 ( 1.033)	Data  0.325 ( 0.325)	Loss 8.2243e-02 (8.2243e-02)	Acc@1   0.88 (  0.88)	Acc@5   0.00 (  0.00)
[0.8809748042627348]
Test: [0/1]	Time  0.268 ( 0.268)	Loss 9.5332e-01 (9.5332e-01)	Acc@1   0.64 (  0.64)	Acc@5   0.00 (  0.00)
 * Acc@1 0.637 Acc@5 0.000
Test: [0/1]	Time  0.316 ( 0.316)	Loss 1.5652e-01 (1.5652e-01)	Acc@1   0.75 (  0.75)	Acc@5   0.00 (  0.00)
 * Acc@1 0.746 Acc@5 0.000
48
TRAINING
Epoch: [48][0/1]	Time  0.981 ( 0.981)	Data  0.268 ( 0.268)	Loss 8.1460e-02 (8.1460e-02)	Acc@1   0.89 (  0.89)	Acc@5   0.00 (  0.00)
[0.8854665242154833]
Test: [0/1]	Time  0.273 ( 0.273)	Loss 9.5300e-01 (9.5300e-01)	Acc@1   0.64 (  0.64)	Acc@5   0.00 (  0.00)
 * Acc@1 0.638 Acc@5 0.000
Test: [0/1]	Time  0.323 ( 0.323)	Loss 1.5606e-01 (1.5606e-01)	Acc@1   0.75 (  0.75)	Acc@5   0.00 (  0.00)
 * Acc@1 0.748 Acc@5 0.000
49
TRAINING
Epoch: [49][0/1]	Time  0.998 ( 0.998)	Data  0.288 ( 0.288)	Loss 8.0783e-02 (8.0783e-02)	Acc@1   0.89 (  0.89)	Acc@5   0.00 (  0.00)
[0.8897026694370164]
Test: [0/1]	Time  0.283 ( 0.283)	Loss 9.5273e-01 (9.5273e-01)	Acc@1   0.64 (  0.64)	Acc@5   0.00 (  0.00)
 * Acc@1 0.640 Acc@5 0.000
Test: [0/1]	Time  0.327 ( 0.327)	Loss 1.5598e-01 (1.5598e-01)	Acc@1   0.75 (  0.75)	Acc@5   0.00 (  0.00)
 * Acc@1 0.748 Acc@5 0.000
50
TRAINING
Epoch: [50][0/1]	Time  0.992 ( 0.992)	Data  0.293 ( 0.293)	Loss 8.0415e-02 (8.0415e-02)	Acc@1   0.89 (  0.89)	Acc@5   0.00 (  0.00)
[0.8930871008317331]
Test: [0/1]	Time  0.264 ( 0.264)	Loss 9.5256e-01 (9.5256e-01)	Acc@1   0.64 (  0.64)	Acc@5   0.00 (  0.00)
 * Acc@1 0.644 Acc@5 0.000
Test: [0/1]	Time  0.315 ( 0.315)	Loss 1.5622e-01 (1.5622e-01)	Acc@1   0.75 (  0.75)	Acc@5   0.00 (  0.00)
 * Acc@1 0.748 Acc@5 0.000
51
TRAINING
Epoch: [51][0/1]	Time  1.002 ( 1.002)	Data  0.289 ( 0.289)	Loss 8.0339e-02 (8.0339e-02)	Acc@1   0.90 (  0.90)	Acc@5   0.00 (  0.00)
[0.8961701380453237]
Test: [0/1]	Time  0.269 ( 0.269)	Loss 9.5251e-01 (9.5251e-01)	Acc@1   0.65 (  0.65)	Acc@5   0.00 (  0.00)
 * Acc@1 0.649 Acc@5 0.000
Test: [0/1]	Time  0.321 ( 0.321)	Loss 1.5659e-01 (1.5659e-01)	Acc@1   0.75 (  0.75)	Acc@5   0.00 (  0.00)
 * Acc@1 0.748 Acc@5 0.000
52
TRAINING
Epoch: [52][0/1]	Time  0.952 ( 0.952)	Data  0.257 ( 0.257)	Loss 8.0379e-02 (8.0379e-02)	Acc@1   0.90 (  0.90)	Acc@5   0.00 (  0.00)
[0.8998577074392653]
Test: [0/1]	Time  0.241 ( 0.241)	Loss 9.5257e-01 (9.5257e-01)	Acc@1   0.65 (  0.65)	Acc@5   0.00 (  0.00)
 * Acc@1 0.654 Acc@5 0.000
Test: [0/1]	Time  0.290 ( 0.290)	Loss 1.5687e-01 (1.5687e-01)	Acc@1   0.75 (  0.75)	Acc@5   0.00 (  0.00)
 * Acc@1 0.747 Acc@5 0.000
53
TRAINING
Epoch: [53][0/1]	Time  0.968 ( 0.968)	Data  0.285 ( 0.285)	Loss 8.0342e-02 (8.0342e-02)	Acc@1   0.90 (  0.90)	Acc@5   0.00 (  0.00)
[0.9040680051690498]
Test: [0/1]	Time  0.249 ( 0.249)	Loss 9.5274e-01 (9.5274e-01)	Acc@1   0.66 (  0.66)	Acc@5   0.00 (  0.00)
 * Acc@1 0.659 Acc@5 0.000
Test: [0/1]	Time  0.304 ( 0.304)	Loss 1.5697e-01 (1.5697e-01)	Acc@1   0.75 (  0.75)	Acc@5   0.00 (  0.00)
 * Acc@1 0.746 Acc@5 0.000
54
TRAINING
Epoch: [54][0/1]	Time  0.942 ( 0.942)	Data  0.260 ( 0.260)	Loss 8.0135e-02 (8.0135e-02)	Acc@1   0.91 (  0.91)	Acc@5   0.00 (  0.00)
[0.9076461761227881]
Test: [0/1]	Time  0.242 ( 0.242)	Loss 9.5299e-01 (9.5299e-01)	Acc@1   0.66 (  0.66)	Acc@5   0.00 (  0.00)
 * Acc@1 0.664 Acc@5 0.000
Test: [0/1]	Time  0.294 ( 0.294)	Loss 1.5690e-01 (1.5690e-01)	Acc@1   0.75 (  0.75)	Acc@5   0.00 (  0.00)
 * Acc@1 0.745 Acc@5 0.000
55
TRAINING
Epoch: [55][0/1]	Time  0.930 ( 0.930)	Data  0.258 ( 0.258)	Loss 7.9803e-02 (7.9803e-02)	Acc@1   0.91 (  0.91)	Acc@5   0.00 (  0.00)
[0.9108629649543541]
Test: [0/1]	Time  0.238 ( 0.238)	Loss 9.5330e-01 (9.5330e-01)	Acc@1   0.67 (  0.67)	Acc@5   0.00 (  0.00)
 * Acc@1 0.668 Acc@5 0.000
Test: [0/1]	Time  0.293 ( 0.293)	Loss 1.5678e-01 (1.5678e-01)	Acc@1   0.74 (  0.74)	Acc@5   0.00 (  0.00)
 * Acc@1 0.745 Acc@5 0.000
56
TRAINING
Epoch: [56][0/1]	Time  0.932 ( 0.932)	Data  0.255 ( 0.255)	Loss 7.9469e-02 (7.9469e-02)	Acc@1   0.91 (  0.91)	Acc@5   0.00 (  0.00)
[0.9138649278548312]
Test: [0/1]	Time  0.239 ( 0.239)	Loss 9.5365e-01 (9.5365e-01)	Acc@1   0.67 (  0.67)	Acc@5   0.00 (  0.00)
 * Acc@1 0.673 Acc@5 0.000
Test: [0/1]	Time  0.290 ( 0.290)	Loss 1.5671e-01 (1.5671e-01)	Acc@1   0.74 (  0.74)	Acc@5   0.00 (  0.00)
 * Acc@1 0.744 Acc@5 0.000
57
TRAINING
Epoch: [57][0/1]	Time  0.934 ( 0.934)	Data  0.256 ( 0.256)	Loss 7.9247e-02 (7.9247e-02)	Acc@1   0.92 (  0.92)	Acc@5   0.00 (  0.00)
[0.9162095772112215]
Test: [0/1]	Time  0.268 ( 0.268)	Loss 9.5400e-01 (9.5400e-01)	Acc@1   0.68 (  0.68)	Acc@5   0.00 (  0.00)
 * Acc@1 0.676 Acc@5 0.000
Test: [0/1]	Time  0.310 ( 0.310)	Loss 1.5673e-01 (1.5673e-01)	Acc@1   0.74 (  0.74)	Acc@5   0.00 (  0.00)
 * Acc@1 0.743 Acc@5 0.000
58
TRAINING
Epoch: [58][0/1]	Time  0.944 ( 0.944)	Data  0.271 ( 0.271)	Loss 7.9172e-02 (7.9172e-02)	Acc@1   0.92 (  0.92)	Acc@5   0.00 (  0.00)
[0.9184965926248962]
Test: [0/1]	Time  0.244 ( 0.244)	Loss 9.5430e-01 (9.5430e-01)	Acc@1   0.68 (  0.68)	Acc@5   0.00 (  0.00)
 * Acc@1 0.680 Acc@5 0.000
Test: [0/1]	Time  0.298 ( 0.298)	Loss 1.5680e-01 (1.5680e-01)	Acc@1   0.74 (  0.74)	Acc@5   0.00 (  0.00)
 * Acc@1 0.742 Acc@5 0.000
59
TRAINING
Epoch: [59][0/1]	Time  0.942 ( 0.942)	Data  0.264 ( 0.264)	Loss 7.9187e-02 (7.9187e-02)	Acc@1   0.92 (  0.92)	Acc@5   0.00 (  0.00)
[0.920908448818401]
Test: [0/1]	Time  0.239 ( 0.239)	Loss 9.5452e-01 (9.5452e-01)	Acc@1   0.68 (  0.68)	Acc@5   0.00 (  0.00)
 * Acc@1 0.683 Acc@5 0.000
Test: [0/1]	Time  0.292 ( 0.292)	Loss 1.5685e-01 (1.5685e-01)	Acc@1   0.74 (  0.74)	Acc@5   0.00 (  0.00)
 * Acc@1 0.742 Acc@5 0.000
60
TRAINING
Epoch: [60][0/1]	Time  0.935 ( 0.935)	Data  0.247 ( 0.247)	Loss 7.9195e-02 (7.9195e-02)	Acc@1   0.92 (  0.92)	Acc@5   0.00 (  0.00)
[0.9231220209198789]
Test: [0/1]	Time  0.237 ( 0.237)	Loss 9.5464e-01 (9.5464e-01)	Acc@1   0.69 (  0.69)	Acc@5   0.00 (  0.00)
 * Acc@1 0.686 Acc@5 0.000
Test: [0/1]	Time  0.286 ( 0.286)	Loss 1.5681e-01 (1.5681e-01)	Acc@1   0.74 (  0.74)	Acc@5   0.00 (  0.00)
 * Acc@1 0.742 Acc@5 0.000
61
TRAINING
Epoch: [61][0/1]	Time  0.921 ( 0.921)	Data  0.248 ( 0.248)	Loss 7.9115e-02 (7.9115e-02)	Acc@1   0.92 (  0.92)	Acc@5   0.00 (  0.00)
[0.9246532237487786]
Test: [0/1]	Time  0.237 ( 0.237)	Loss 9.5466e-01 (9.5466e-01)	Acc@1   0.69 (  0.69)	Acc@5   0.00 (  0.00)
 * Acc@1 0.688 Acc@5 0.000
Test: [0/1]	Time  0.286 ( 0.286)	Loss 1.5668e-01 (1.5668e-01)	Acc@1   0.74 (  0.74)	Acc@5   0.00 (  0.00)
 * Acc@1 0.742 Acc@5 0.000
62
TRAINING
Epoch: [62][0/1]	Time  0.924 ( 0.924)	Data  0.251 ( 0.251)	Loss 7.8931e-02 (7.8931e-02)	Acc@1   0.93 (  0.93)	Acc@5   0.00 (  0.00)
[0.925997384193881]
Test: [0/1]	Time  0.236 ( 0.236)	Loss 9.5460e-01 (9.5460e-01)	Acc@1   0.69 (  0.69)	Acc@5   0.00 (  0.00)
 * Acc@1 0.691 Acc@5 0.000
Test: [0/1]	Time  0.288 ( 0.288)	Loss 1.5648e-01 (1.5648e-01)	Acc@1   0.74 (  0.74)	Acc@5   0.00 (  0.00)
 * Acc@1 0.743 Acc@5 0.000
63
TRAINING
Epoch: [63][0/1]	Time  0.958 ( 0.958)	Data  0.286 ( 0.286)	Loss 7.8689e-02 (7.8689e-02)	Acc@1   0.93 (  0.93)	Acc@5   0.00 (  0.00)
[0.9272659721436638]
Test: [0/1]	Time  0.251 ( 0.251)	Loss 9.5449e-01 (9.5449e-01)	Acc@1   0.69 (  0.69)	Acc@5   0.00 (  0.00)
 * Acc@1 0.693 Acc@5 0.000
Test: [0/1]	Time  0.307 ( 0.307)	Loss 1.5628e-01 (1.5628e-01)	Acc@1   0.74 (  0.74)	Acc@5   0.00 (  0.00)
 * Acc@1 0.744 Acc@5 0.000
64
TRAINING
Epoch: [64][0/1]	Time  0.936 ( 0.936)	Data  0.262 ( 0.262)	Loss 7.8460e-02 (7.8460e-02)	Acc@1   0.93 (  0.93)	Acc@5   0.00 (  0.00)
[0.9286618697132611]
Test: [0/1]	Time  0.248 ( 0.248)	Loss 9.5435e-01 (9.5435e-01)	Acc@1   0.69 (  0.69)	Acc@5   0.00 (  0.00)
 * Acc@1 0.694 Acc@5 0.000
Test: [0/1]	Time  0.294 ( 0.294)	Loss 1.5613e-01 (1.5613e-01)	Acc@1   0.74 (  0.74)	Acc@5   0.00 (  0.00)
 * Acc@1 0.745 Acc@5 0.000
65
TRAINING
Epoch: [65][0/1]	Time  0.946 ( 0.946)	Data  0.273 ( 0.273)	Loss 7.8297e-02 (7.8297e-02)	Acc@1   0.93 (  0.93)	Acc@5   0.00 (  0.00)
[0.9299322239959062]
Test: [0/1]	Time  0.246 ( 0.246)	Loss 9.5420e-01 (9.5420e-01)	Acc@1   0.70 (  0.70)	Acc@5   0.00 (  0.00)
 * Acc@1 0.696 Acc@5 0.000
Test: [0/1]	Time  0.298 ( 0.298)	Loss 1.5603e-01 (1.5603e-01)	Acc@1   0.75 (  0.75)	Acc@5   0.00 (  0.00)
 * Acc@1 0.746 Acc@5 0.000
66
TRAINING
Epoch: [66][0/1]	Time  0.945 ( 0.945)	Data  0.266 ( 0.266)	Loss 7.8215e-02 (7.8215e-02)	Acc@1   0.93 (  0.93)	Acc@5   0.00 (  0.00)
[0.9308056742377249]
Test: [0/1]	Time  0.243 ( 0.243)	Loss 9.5407e-01 (9.5407e-01)	Acc@1   0.70 (  0.70)	Acc@5   0.00 (  0.00)
 * Acc@1 0.697 Acc@5 0.000
Test: [0/1]	Time  0.296 ( 0.296)	Loss 1.5596e-01 (1.5596e-01)	Acc@1   0.75 (  0.75)	Acc@5   0.00 (  0.00)
 * Acc@1 0.747 Acc@5 0.000
67
TRAINING
Epoch: [67][0/1]	Time  0.933 ( 0.933)	Data  0.261 ( 0.261)	Loss 7.8186e-02 (7.8186e-02)	Acc@1   0.93 (  0.93)	Acc@5   0.00 (  0.00)
[0.9312794185271269]
Test: [0/1]	Time  0.242 ( 0.242)	Loss 9.5397e-01 (9.5397e-01)	Acc@1   0.70 (  0.70)	Acc@5   0.00 (  0.00)
 * Acc@1 0.698 Acc@5 0.000
Test: [0/1]	Time  0.333 ( 0.333)	Loss 1.5586e-01 (1.5586e-01)	Acc@1   0.75 (  0.75)	Acc@5   0.00 (  0.00)
 * Acc@1 0.748 Acc@5 0.000
68
TRAINING
Epoch: [68][0/1]	Time  0.931 ( 0.931)	Data  0.259 ( 0.259)	Loss 7.8171e-02 (7.8171e-02)	Acc@1   0.93 (  0.93)	Acc@5   0.00 (  0.00)
[0.9316395216575268]
Test: [0/1]	Time  0.240 ( 0.240)	Loss 9.5388e-01 (9.5388e-01)	Acc@1   0.70 (  0.70)	Acc@5   0.00 (  0.00)
 * Acc@1 0.699 Acc@5 0.000
Test: [0/1]	Time  0.297 ( 0.297)	Loss 1.5573e-01 (1.5573e-01)	Acc@1   0.75 (  0.75)	Acc@5   0.00 (  0.00)
 * Acc@1 0.749 Acc@5 0.000
69
TRAINING
Epoch: [69][0/1]	Time  0.936 ( 0.936)	Data  0.237 ( 0.237)	Loss 7.8139e-02 (7.8139e-02)	Acc@1   0.93 (  0.93)	Acc@5   0.00 (  0.00)
[0.9319143905957568]
Test: [0/1]	Time  0.232 ( 0.232)	Loss 9.5382e-01 (9.5382e-01)	Acc@1   0.70 (  0.70)	Acc@5   0.00 (  0.00)
 * Acc@1 0.700 Acc@5 0.000
Test: [0/1]	Time  0.288 ( 0.288)	Loss 1.5555e-01 (1.5555e-01)	Acc@1   0.75 (  0.75)	Acc@5   0.00 (  0.00)
 * Acc@1 0.749 Acc@5 0.000
70
TRAINING
Epoch: [70][0/1]	Time  0.948 ( 0.948)	Data  0.241 ( 0.241)	Loss 7.8090e-02 (7.8090e-02)	Acc@1   0.93 (  0.93)	Acc@5   0.00 (  0.00)
[0.9321308313767365]
Test: [0/1]	Time  0.238 ( 0.238)	Loss 9.5378e-01 (9.5378e-01)	Acc@1   0.70 (  0.70)	Acc@5   0.00 (  0.00)
 * Acc@1 0.701 Acc@5 0.000
Test: [0/1]	Time  0.288 ( 0.288)	Loss 1.5536e-01 (1.5536e-01)	Acc@1   0.75 (  0.75)	Acc@5   0.00 (  0.00)
 * Acc@1 0.750 Acc@5 0.000
71
TRAINING
Epoch: [71][0/1]	Time  0.989 ( 0.989)	Data  0.294 ( 0.294)	Loss 7.8040e-02 (7.8040e-02)	Acc@1   0.93 (  0.93)	Acc@5   0.00 (  0.00)
[0.9323114680651698]
Test: [0/1]	Time  0.249 ( 0.249)	Loss 9.5375e-01 (9.5375e-01)	Acc@1   0.70 (  0.70)	Acc@5   0.00 (  0.00)
 * Acc@1 0.702 Acc@5 0.000
Test: [0/1]	Time  0.302 ( 0.302)	Loss 1.5518e-01 (1.5518e-01)	Acc@1   0.75 (  0.75)	Acc@5   0.00 (  0.00)
 * Acc@1 0.750 Acc@5 0.000
72
TRAINING
Epoch: [72][0/1]	Time  1.038 ( 1.038)	Data  0.328 ( 0.328)	Loss 7.8014e-02 (7.8014e-02)	Acc@1   0.93 (  0.93)	Acc@5   0.00 (  0.00)
[0.9324749260255281]
Test: [0/1]	Time  0.273 ( 0.273)	Loss 9.5371e-01 (9.5371e-01)	Acc@1   0.70 (  0.70)	Acc@5   0.00 (  0.00)
 * Acc@1 0.703 Acc@5 0.000
Test: [0/1]	Time  0.320 ( 0.320)	Loss 1.5503e-01 (1.5503e-01)	Acc@1   0.75 (  0.75)	Acc@5   0.00 (  0.00)
 * Acc@1 0.750 Acc@5 0.000
73
TRAINING
Epoch: [73][0/1]	Time  0.955 ( 0.955)	Data  0.251 ( 0.251)	Loss 7.8020e-02 (7.8020e-02)	Acc@1   0.93 (  0.93)	Acc@5   0.00 (  0.00)
[0.9326367361717735]
Test: [0/1]	Time  0.236 ( 0.236)	Loss 9.5365e-01 (9.5365e-01)	Acc@1   0.70 (  0.70)	Acc@5   0.00 (  0.00)
 * Acc@1 0.703 Acc@5 0.000
Test: [0/1]	Time  0.291 ( 0.291)	Loss 1.5491e-01 (1.5491e-01)	Acc@1   0.75 (  0.75)	Acc@5   0.00 (  0.00)
 * Acc@1 0.751 Acc@5 0.000
74
TRAINING
Epoch: [74][0/1]	Time  0.995 ( 0.995)	Data  0.286 ( 0.286)	Loss 7.8051e-02 (7.8051e-02)	Acc@1   0.93 (  0.93)	Acc@5   0.00 (  0.00)
[0.9328091958600935]
Test: [0/1]	Time  0.250 ( 0.250)	Loss 9.5357e-01 (9.5357e-01)	Acc@1   0.70 (  0.70)	Acc@5   0.00 (  0.00)
 * Acc@1 0.704 Acc@5 0.000
Test: [0/1]	Time  0.305 ( 0.305)	Loss 1.5481e-01 (1.5481e-01)	Acc@1   0.75 (  0.75)	Acc@5   0.00 (  0.00)
 * Acc@1 0.751 Acc@5 0.000
75
TRAINING
Epoch: [75][0/1]	Time  0.939 ( 0.939)	Data  0.252 ( 0.252)	Loss 7.8087e-02 (7.8087e-02)	Acc@1   0.93 (  0.93)	Acc@5   0.00 (  0.00)
[0.9329998456282669]
Test: [0/1]	Time  0.286 ( 0.286)	Loss 9.5345e-01 (9.5345e-01)	Acc@1   0.70 (  0.70)	Acc@5   0.00 (  0.00)
 * Acc@1 0.705 Acc@5 0.000
Test: [0/1]	Time  0.322 ( 0.322)	Loss 1.5471e-01 (1.5471e-01)	Acc@1   0.75 (  0.75)	Acc@5   0.00 (  0.00)
 * Acc@1 0.753 Acc@5 0.000
76
TRAINING
Epoch: [76][0/1]	Time  0.956 ( 0.956)	Data  0.252 ( 0.252)	Loss 7.8108e-02 (7.8108e-02)	Acc@1   0.93 (  0.93)	Acc@5   0.00 (  0.00)
[0.9330742502549871]
Test: [0/1]	Time  0.239 ( 0.239)	Loss 9.5330e-01 (9.5330e-01)	Acc@1   0.71 (  0.71)	Acc@5   0.00 (  0.00)
 * Acc@1 0.705 Acc@5 0.000
Test: [0/1]	Time  0.292 ( 0.292)	Loss 1.5460e-01 (1.5460e-01)	Acc@1   0.75 (  0.75)	Acc@5   0.00 (  0.00)
 * Acc@1 0.755 Acc@5 0.000
77
TRAINING
Epoch: [77][0/1]	Time  1.020 ( 1.020)	Data  0.322 ( 0.322)	Loss 7.8104e-02 (7.8104e-02)	Acc@1   0.93 (  0.93)	Acc@5   0.00 (  0.00)
[0.9330176837783376]
Test: [0/1]	Time  0.272 ( 0.272)	Loss 9.5311e-01 (9.5311e-01)	Acc@1   0.71 (  0.71)	Acc@5   0.00 (  0.00)
 * Acc@1 0.706 Acc@5 0.000
Test: [0/1]	Time  0.359 ( 0.359)	Loss 1.5450e-01 (1.5450e-01)	Acc@1   0.76 (  0.76)	Acc@5   0.00 (  0.00)
 * Acc@1 0.756 Acc@5 0.000
78
TRAINING
Epoch: [78][0/1]	Time  0.982 ( 0.982)	Data  0.272 ( 0.272)	Loss 7.8080e-02 (7.8080e-02)	Acc@1   0.93 (  0.93)	Acc@5   0.00 (  0.00)
[0.9329636959453944]
Test: [0/1]	Time  0.291 ( 0.291)	Loss 9.5292e-01 (9.5292e-01)	Acc@1   0.71 (  0.71)	Acc@5   0.00 (  0.00)
 * Acc@1 0.706 Acc@5 0.000
Test: [0/1]	Time  0.335 ( 0.335)	Loss 1.5440e-01 (1.5440e-01)	Acc@1   0.76 (  0.76)	Acc@5   0.00 (  0.00)
 * Acc@1 0.758 Acc@5 0.000
79
TRAINING
Epoch: [79][0/1]	Time  0.942 ( 0.942)	Data  0.248 ( 0.248)	Loss 7.8050e-02 (7.8050e-02)	Acc@1   0.93 (  0.93)	Acc@5   0.00 (  0.00)
[0.9329107315892471]
Test: [0/1]	Time  0.241 ( 0.241)	Loss 9.5271e-01 (9.5271e-01)	Acc@1   0.71 (  0.71)	Acc@5   0.00 (  0.00)
 * Acc@1 0.707 Acc@5 0.000
Test: [0/1]	Time  0.290 ( 0.290)	Loss 1.5433e-01 (1.5433e-01)	Acc@1   0.76 (  0.76)	Acc@5   0.00 (  0.00)
 * Acc@1 0.760 Acc@5 0.000
80
TRAINING
Epoch: [80][0/1]	Time  1.019 ( 1.019)	Data  0.321 ( 0.321)	Loss 7.8027e-02 (7.8027e-02)	Acc@1   0.93 (  0.93)	Acc@5   0.00 (  0.00)
[0.9328580156597142]
Test: [0/1]	Time  0.255 ( 0.255)	Loss 9.5252e-01 (9.5252e-01)	Acc@1   0.71 (  0.71)	Acc@5   0.00 (  0.00)
 * Acc@1 0.707 Acc@5 0.000
Test: [0/1]	Time  0.306 ( 0.306)	Loss 1.5428e-01 (1.5428e-01)	Acc@1   0.76 (  0.76)	Acc@5   0.00 (  0.00)
 * Acc@1 0.761 Acc@5 0.000
81
TRAINING
Epoch: [81][0/1]	Time  1.005 ( 1.005)	Data  0.293 ( 0.293)	Loss 7.8017e-02 (7.8017e-02)	Acc@1   0.93 (  0.93)	Acc@5   0.00 (  0.00)
[0.9328067808351695]
Test: [0/1]	Time  0.294 ( 0.294)	Loss 9.5234e-01 (9.5234e-01)	Acc@1   0.71 (  0.71)	Acc@5   0.00 (  0.00)
 * Acc@1 0.708 Acc@5 0.000
Test: [0/1]	Time  0.337 ( 0.337)	Loss 1.5423e-01 (1.5423e-01)	Acc@1   0.76 (  0.76)	Acc@5   0.00 (  0.00)
 * Acc@1 0.763 Acc@5 0.000
82
TRAINING
Epoch: [82][0/1]	Time  0.932 ( 0.932)	Data  0.237 ( 0.237)	Loss 7.8017e-02 (7.8017e-02)	Acc@1   0.93 (  0.93)	Acc@5   0.00 (  0.00)
[0.9327602605595854]
Test: [0/1]	Time  0.230 ( 0.230)	Loss 9.5219e-01 (9.5219e-01)	Acc@1   0.71 (  0.71)	Acc@5   0.00 (  0.00)
 * Acc@1 0.708 Acc@5 0.000
Test: [0/1]	Time  0.286 ( 0.286)	Loss 1.5419e-01 (1.5419e-01)	Acc@1   0.76 (  0.76)	Acc@5   0.00 (  0.00)
 * Acc@1 0.764 Acc@5 0.000
83
TRAINING
Epoch: [83][0/1]	Time  0.929 ( 0.929)	Data  0.240 ( 0.240)	Loss 7.8021e-02 (7.8021e-02)	Acc@1   0.93 (  0.93)	Acc@5   0.00 (  0.00)
[0.9327663682952715]
Test: [0/1]	Time  0.233 ( 0.233)	Loss 9.5207e-01 (9.5207e-01)	Acc@1   0.71 (  0.71)	Acc@5   0.00 (  0.00)
 * Acc@1 0.709 Acc@5 0.000
Test: [0/1]	Time  0.298 ( 0.298)	Loss 1.5415e-01 (1.5415e-01)	Acc@1   0.77 (  0.77)	Acc@5   0.00 (  0.00)
 * Acc@1 0.765 Acc@5 0.000
84
TRAINING
Epoch: [84][0/1]	Time  0.992 ( 0.992)	Data  0.291 ( 0.291)	Loss 7.8022e-02 (7.8022e-02)	Acc@1   0.93 (  0.93)	Acc@5   0.00 (  0.00)
[0.932746946361565]
Test: [0/1]	Time  0.267 ( 0.267)	Loss 9.5197e-01 (9.5197e-01)	Acc@1   0.71 (  0.71)	Acc@5   0.00 (  0.00)
 * Acc@1 0.709 Acc@5 0.000
Test: [0/1]	Time  0.324 ( 0.324)	Loss 1.5410e-01 (1.5410e-01)	Acc@1   0.77 (  0.77)	Acc@5   0.00 (  0.00)
 * Acc@1 0.766 Acc@5 0.000
85
TRAINING
Epoch: [85][0/1]	Time  0.957 ( 0.957)	Data  0.244 ( 0.244)	Loss 7.8017e-02 (7.8017e-02)	Acc@1   0.93 (  0.93)	Acc@5   0.00 (  0.00)
[0.9327636324233828]
Test: [0/1]	Time  0.278 ( 0.278)	Loss 9.5189e-01 (9.5189e-01)	Acc@1   0.71 (  0.71)	Acc@5   0.00 (  0.00)
 * Acc@1 0.710 Acc@5 0.000
Test: [0/1]	Time  0.324 ( 0.324)	Loss 1.5404e-01 (1.5404e-01)	Acc@1   0.77 (  0.77)	Acc@5   0.00 (  0.00)
 * Acc@1 0.767 Acc@5 0.000
86
TRAINING
Epoch: [86][0/1]	Time  0.979 ( 0.979)	Data  0.290 ( 0.290)	Loss 7.8008e-02 (7.8008e-02)	Acc@1   0.93 (  0.93)	Acc@5   0.00 (  0.00)
[0.9328162796107263]
Test: [0/1]	Time  0.266 ( 0.266)	Loss 9.5183e-01 (9.5183e-01)	Acc@1   0.71 (  0.71)	Acc@5   0.00 (  0.00)
 * Acc@1 0.710 Acc@5 0.000
Test: [0/1]	Time  0.314 ( 0.314)	Loss 1.5399e-01 (1.5399e-01)	Acc@1   0.77 (  0.77)	Acc@5   0.00 (  0.00)
 * Acc@1 0.767 Acc@5 0.000
87
TRAINING
Epoch: [87][0/1]	Time  1.012 ( 1.012)	Data  0.309 ( 0.309)	Loss 7.7999e-02 (7.7999e-02)	Acc@1   0.93 (  0.93)	Acc@5   0.00 (  0.00)
[0.9328997167465216]
Test: [0/1]	Time  0.265 ( 0.265)	Loss 9.5178e-01 (9.5178e-01)	Acc@1   0.71 (  0.71)	Acc@5   0.00 (  0.00)
 * Acc@1 0.710 Acc@5 0.000
Test: [0/1]	Time  0.315 ( 0.315)	Loss 1.5394e-01 (1.5394e-01)	Acc@1   0.77 (  0.77)	Acc@5   0.00 (  0.00)
 * Acc@1 0.768 Acc@5 0.000
88
TRAINING
Epoch: [88][0/1]	Time  0.934 ( 0.934)	Data  0.245 ( 0.245)	Loss 7.7994e-02 (7.7994e-02)	Acc@1   0.93 (  0.93)	Acc@5   0.00 (  0.00)
[0.9330071029409334]
Test: [0/1]	Time  0.243 ( 0.243)	Loss 9.5174e-01 (9.5174e-01)	Acc@1   0.71 (  0.71)	Acc@5   0.00 (  0.00)
 * Acc@1 0.710 Acc@5 0.000
Test: [0/1]	Time  0.347 ( 0.347)	Loss 1.5390e-01 (1.5390e-01)	Acc@1   0.77 (  0.77)	Acc@5   0.00 (  0.00)
 * Acc@1 0.768 Acc@5 0.000
89
TRAINING
Epoch: [89][0/1]	Time  0.969 ( 0.969)	Data  0.260 ( 0.260)	Loss 7.7991e-02 (7.7991e-02)	Acc@1   0.93 (  0.93)	Acc@5   0.00 (  0.00)
[0.9331313369813922]
Test: [0/1]	Time  0.303 ( 0.303)	Loss 9.5169e-01 (9.5169e-01)	Acc@1   0.71 (  0.71)	Acc@5   0.00 (  0.00)
 * Acc@1 0.711 Acc@5 0.000
Test: [0/1]	Time  0.364 ( 0.364)	Loss 1.5387e-01 (1.5387e-01)	Acc@1   0.77 (  0.77)	Acc@5   0.00 (  0.00)
 * Acc@1 0.768 Acc@5 0.000
90
TRAINING
Epoch: [90][0/1]	Time  0.976 ( 0.976)	Data  0.271 ( 0.271)	Loss 7.7986e-02 (7.7986e-02)	Acc@1   0.93 (  0.93)	Acc@5   0.00 (  0.00)
[0.9332658566494663]
Test: [0/1]	Time  0.257 ( 0.257)	Loss 9.5164e-01 (9.5164e-01)	Acc@1   0.71 (  0.71)	Acc@5   0.00 (  0.00)
 * Acc@1 0.711 Acc@5 0.000
Test: [0/1]	Time  0.301 ( 0.301)	Loss 1.5385e-01 (1.5385e-01)	Acc@1   0.77 (  0.77)	Acc@5   0.00 (  0.00)
 * Acc@1 0.768 Acc@5 0.000
91
TRAINING
Epoch: [91][0/1]	Time  0.942 ( 0.942)	Data  0.244 ( 0.244)	Loss 7.7977e-02 (7.7977e-02)	Acc@1   0.93 (  0.93)	Acc@5   0.00 (  0.00)
[0.9334048803848369]
Test: [0/1]	Time  0.259 ( 0.259)	Loss 9.5157e-01 (9.5157e-01)	Acc@1   0.71 (  0.71)	Acc@5   0.00 (  0.00)
 * Acc@1 0.711 Acc@5 0.000
Test: [0/1]	Time  0.352 ( 0.352)	Loss 1.5383e-01 (1.5383e-01)	Acc@1   0.77 (  0.77)	Acc@5   0.00 (  0.00)
 * Acc@1 0.769 Acc@5 0.000
92
TRAINING
Epoch: [92][0/1]	Time  0.989 ( 0.989)	Data  0.291 ( 0.291)	Loss 7.7960e-02 (7.7960e-02)	Acc@1   0.93 (  0.93)	Acc@5   0.00 (  0.00)
[0.9335434021756078]
Test: [0/1]	Time  0.280 ( 0.280)	Loss 9.5150e-01 (9.5150e-01)	Acc@1   0.71 (  0.71)	Acc@5   0.00 (  0.00)
 * Acc@1 0.711 Acc@5 0.000
Test: [0/1]	Time  0.327 ( 0.327)	Loss 1.5381e-01 (1.5381e-01)	Acc@1   0.77 (  0.77)	Acc@5   0.00 (  0.00)
 * Acc@1 0.769 Acc@5 0.000
93
TRAINING
Epoch: [93][0/1]	Time  1.035 ( 1.035)	Data  0.294 ( 0.294)	Loss 7.7935e-02 (7.7935e-02)	Acc@1   0.93 (  0.93)	Acc@5   0.00 (  0.00)
[0.9335750997669492]
Test: [0/1]	Time  0.262 ( 0.262)	Loss 9.5142e-01 (9.5142e-01)	Acc@1   0.71 (  0.71)	Acc@5   0.00 (  0.00)
 * Acc@1 0.711 Acc@5 0.000
Test: [0/1]	Time  0.334 ( 0.334)	Loss 1.5379e-01 (1.5379e-01)	Acc@1   0.77 (  0.77)	Acc@5   0.00 (  0.00)
 * Acc@1 0.769 Acc@5 0.000
94
TRAINING
Epoch: [94][0/1]	Time  0.950 ( 0.950)	Data  0.246 ( 0.246)	Loss 7.7906e-02 (7.7906e-02)	Acc@1   0.93 (  0.93)	Acc@5   0.00 (  0.00)
[0.9335652831638506]
Test: [0/1]	Time  0.240 ( 0.240)	Loss 9.5133e-01 (9.5133e-01)	Acc@1   0.71 (  0.71)	Acc@5   0.00 (  0.00)
 * Acc@1 0.711 Acc@5 0.000
Test: [0/1]	Time  0.293 ( 0.293)	Loss 1.5378e-01 (1.5378e-01)	Acc@1   0.77 (  0.77)	Acc@5   0.00 (  0.00)
 * Acc@1 0.769 Acc@5 0.000
95
TRAINING
Epoch: [95][0/1]	Time  0.985 ( 0.985)	Data  0.270 ( 0.270)	Loss 7.7877e-02 (7.7877e-02)	Acc@1   0.93 (  0.93)	Acc@5   0.00 (  0.00)
[0.9335464579874763]
Test: [0/1]	Time  0.245 ( 0.245)	Loss 9.5125e-01 (9.5125e-01)	Acc@1   0.71 (  0.71)	Acc@5   0.00 (  0.00)
 * Acc@1 0.711 Acc@5 0.000
Test: [0/1]	Time  0.302 ( 0.302)	Loss 1.5378e-01 (1.5378e-01)	Acc@1   0.77 (  0.77)	Acc@5   0.00 (  0.00)
 * Acc@1 0.769 Acc@5 0.000
96
TRAINING
Epoch: [96][0/1]	Time  0.941 ( 0.941)	Data  0.244 ( 0.244)	Loss 7.7850e-02 (7.7850e-02)	Acc@1   0.93 (  0.93)	Acc@5   0.00 (  0.00)
[0.9335226277466219]
Test: [0/1]	Time  0.239 ( 0.239)	Loss 9.5118e-01 (9.5118e-01)	Acc@1   0.71 (  0.71)	Acc@5   0.00 (  0.00)
 * Acc@1 0.711 Acc@5 0.000
Test: [0/1]	Time  0.287 ( 0.287)	Loss 1.5377e-01 (1.5377e-01)	Acc@1   0.77 (  0.77)	Acc@5   0.00 (  0.00)
 * Acc@1 0.769 Acc@5 0.000
97
TRAINING
Epoch: [97][0/1]	Time  0.992 ( 0.992)	Data  0.292 ( 0.292)	Loss 7.7826e-02 (7.7826e-02)	Acc@1   0.93 (  0.93)	Acc@5   0.00 (  0.00)
[0.9335048102442117]
Test: [0/1]	Time  0.268 ( 0.268)	Loss 9.5111e-01 (9.5111e-01)	Acc@1   0.71 (  0.71)	Acc@5   0.00 (  0.00)
 * Acc@1 0.711 Acc@5 0.000
Test: [0/1]	Time  0.316 ( 0.316)	Loss 1.5377e-01 (1.5377e-01)	Acc@1   0.77 (  0.77)	Acc@5   0.00 (  0.00)
 * Acc@1 0.769 Acc@5 0.000
98
TRAINING
Epoch: [98][0/1]	Time  0.949 ( 0.949)	Data  0.242 ( 0.242)	Loss 7.7805e-02 (7.7805e-02)	Acc@1   0.93 (  0.93)	Acc@5   0.00 (  0.00)
[0.933617234374226]
Test: [0/1]	Time  0.239 ( 0.239)	Loss 9.5106e-01 (9.5106e-01)	Acc@1   0.71 (  0.71)	Acc@5   0.00 (  0.00)
 * Acc@1 0.711 Acc@5 0.000
Test: [0/1]	Time  0.284 ( 0.284)	Loss 1.5377e-01 (1.5377e-01)	Acc@1   0.77 (  0.77)	Acc@5   0.00 (  0.00)
 * Acc@1 0.769 Acc@5 0.000
99
TRAINING
Epoch: [99][0/1]	Time  0.971 ( 0.971)	Data  0.260 ( 0.260)	Loss 7.7786e-02 (7.7786e-02)	Acc@1   0.93 (  0.93)	Acc@5   0.00 (  0.00)
[0.9337205302249808]
Test: [0/1]	Time  0.278 ( 0.278)	Loss 9.5101e-01 (9.5101e-01)	Acc@1   0.71 (  0.71)	Acc@5   0.00 (  0.00)
 * Acc@1 0.711 Acc@5 0.000
Test: [0/1]	Time  0.322 ( 0.322)	Loss 1.5376e-01 (1.5376e-01)	Acc@1   0.77 (  0.77)	Acc@5   0.00 (  0.00)
 * Acc@1 0.769 Acc@5 0.000
=> using pre-trained model 'st_resnet'
s/ohp/session_1
torch.Size([640, 3, 224, 224])
(640, 22)
attach reg
0
TRAINING
/home/helenr6/Adv_mapper/train_split.py:125: UserWarning: You have chosen to seed training. This will turn on the CUDNN deterministic setting, which can slow down your training considerably! You may see unexpected behavior when restarting from checkpoints.
  warnings.warn('You have chosen to seed training. '
/localscratch/helenr6.6279052.0/env/lib/python3.7/site-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  cpuset_checked))
Epoch: [0][0/1]	Time  5.212 ( 5.212)	Data  1.778 ( 1.778)	Loss 1.7222e+00 (1.7222e+00)	Acc@1   0.02 (  0.02)	Acc@5   0.00 (  0.00)
[0.022562333058444524]
Test: [0/1]	Time  0.476 ( 0.476)	Loss 1.1070e+00 (1.1070e+00)	Acc@1   0.02 (  0.02)	Acc@5   0.00 (  0.00)
 * Acc@1 0.015 Acc@5 0.000
Test: [0/1]	Time  0.566 ( 0.566)	Loss 9.4832e-01 (9.4832e-01)	Acc@1   0.04 (  0.04)	Acc@5   0.00 (  0.00)
 * Acc@1 0.041 Acc@5 0.000
1
TRAINING
Epoch: [1][0/1]	Time  0.957 ( 0.957)	Data  0.245 ( 0.245)	Loss 1.6399e+00 (1.6399e+00)	Acc@1   0.02 (  0.02)	Acc@5   0.00 (  0.00)
[0.0243595204610398]
Test: [0/1]	Time  0.276 ( 0.276)	Loss 1.0989e+00 (1.0989e+00)	Acc@1   0.01 (  0.01)	Acc@5   0.00 (  0.00)
 * Acc@1 0.014 Acc@5 0.000
Test: [0/1]	Time  0.325 ( 0.325)	Loss 8.9506e-01 (8.9506e-01)	Acc@1   0.04 (  0.04)	Acc@5   0.00 (  0.00)
 * Acc@1 0.044 Acc@5 0.000
2
TRAINING
Epoch: [2][0/1]	Time  0.957 ( 0.957)	Data  0.245 ( 0.245)	Loss 1.5151e+00 (1.5151e+00)	Acc@1   0.03 (  0.03)	Acc@5   0.00 (  0.00)
[0.02797643602214287]
Test: [0/1]	Time  0.242 ( 0.242)	Loss 1.0916e+00 (1.0916e+00)	Acc@1   0.03 (  0.03)	Acc@5   0.00 (  0.00)
 * Acc@1 0.025 Acc@5 0.000
Test: [0/1]	Time  0.314 ( 0.314)	Loss 8.5099e-01 (8.5099e-01)	Acc@1   0.05 (  0.05)	Acc@5   0.00 (  0.00)
 * Acc@1 0.047 Acc@5 0.000
3
TRAINING
Epoch: [3][0/1]	Time  1.012 ( 1.012)	Data  0.308 ( 0.308)	Loss 1.3928e+00 (1.3928e+00)	Acc@1   0.04 (  0.04)	Acc@5   0.00 (  0.00)
[0.03622522031018336]
Test: [0/1]	Time  0.265 ( 0.265)	Loss 1.0862e+00 (1.0862e+00)	Acc@1   0.04 (  0.04)	Acc@5   0.00 (  0.00)
 * Acc@1 0.039 Acc@5 0.000
Test: [0/1]	Time  0.317 ( 0.317)	Loss 8.2936e-01 (8.2936e-01)	Acc@1   0.05 (  0.05)	Acc@5   0.00 (  0.00)
 * Acc@1 0.050 Acc@5 0.000
4
TRAINING
Epoch: [4][0/1]	Time  0.978 ( 0.978)	Data  0.262 ( 0.262)	Loss 1.2986e+00 (1.2986e+00)	Acc@1   0.05 (  0.05)	Acc@5   0.00 (  0.00)
[0.05139718769114826]
Test: [0/1]	Time  0.255 ( 0.255)	Loss 1.0818e+00 (1.0818e+00)	Acc@1   0.05 (  0.05)	Acc@5   0.00 (  0.00)
 * Acc@1 0.055 Acc@5 0.000
Test: [0/1]	Time  0.301 ( 0.301)	Loss 8.2569e-01 (8.2569e-01)	Acc@1   0.06 (  0.06)	Acc@5   0.00 (  0.00)
 * Acc@1 0.058 Acc@5 0.000
5
TRAINING
Epoch: [5][0/1]	Time  0.958 ( 0.958)	Data  0.249 ( 0.249)	Loss 1.2309e+00 (1.2309e+00)	Acc@1   0.07 (  0.07)	Acc@5   0.00 (  0.00)
[0.06946872982174557]
Test: [0/1]	Time  0.247 ( 0.247)	Loss 1.0761e+00 (1.0761e+00)	Acc@1   0.07 (  0.07)	Acc@5   0.00 (  0.00)
 * Acc@1 0.071 Acc@5 0.000
Test: [0/1]	Time  0.301 ( 0.301)	Loss 8.2305e-01 (8.2305e-01)	Acc@1   0.07 (  0.07)	Acc@5   0.00 (  0.00)
 * Acc@1 0.069 Acc@5 0.000
6
TRAINING
Epoch: [6][0/1]	Time  0.956 ( 0.956)	Data  0.254 ( 0.254)	Loss 1.1695e+00 (1.1695e+00)	Acc@1   0.09 (  0.09)	Acc@5   0.00 (  0.00)
[0.09126101755593762]
Test: [0/1]	Time  0.247 ( 0.247)	Loss 1.0671e+00 (1.0671e+00)	Acc@1   0.11 (  0.11)	Acc@5   0.00 (  0.00)
 * Acc@1 0.106 Acc@5 0.000
Test: [0/1]	Time  0.298 ( 0.298)	Loss 8.0402e-01 (8.0402e-01)	Acc@1   0.08 (  0.08)	Acc@5   0.00 (  0.00)
 * Acc@1 0.077 Acc@5 0.000
7
TRAINING
Epoch: [7][0/1]	Time  0.945 ( 0.945)	Data  0.248 ( 0.248)	Loss 1.0927e+00 (1.0927e+00)	Acc@1   0.11 (  0.11)	Acc@5   0.00 (  0.00)
[0.11415413576948749]
Test: [0/1]	Time  0.241 ( 0.241)	Loss 1.0541e+00 (1.0541e+00)	Acc@1   0.15 (  0.15)	Acc@5   0.00 (  0.00)
 * Acc@1 0.155 Acc@5 0.000
Test: [0/1]	Time  0.291 ( 0.291)	Loss 7.6130e-01 (7.6130e-01)	Acc@1   0.09 (  0.09)	Acc@5   0.00 (  0.00)
 * Acc@1 0.088 Acc@5 0.000
8
TRAINING
Epoch: [8][0/1]	Time  0.950 ( 0.950)	Data  0.249 ( 0.249)	Loss 9.9223e-01 (9.9223e-01)	Acc@1   0.14 (  0.14)	Acc@5   0.00 (  0.00)
[0.1374135325753545]
Test: [0/1]	Time  0.242 ( 0.242)	Loss 1.0388e+00 (1.0388e+00)	Acc@1   0.17 (  0.17)	Acc@5   0.00 (  0.00)
 * Acc@1 0.170 Acc@5 0.000
Test: [0/1]	Time  0.296 ( 0.296)	Loss 7.0115e-01 (7.0115e-01)	Acc@1   0.11 (  0.11)	Acc@5   0.00 (  0.00)
 * Acc@1 0.106 Acc@5 0.000
9
TRAINING
Epoch: [9][0/1]	Time  0.983 ( 0.983)	Data  0.283 ( 0.283)	Loss 8.7645e-01 (8.7645e-01)	Acc@1   0.15 (  0.15)	Acc@5   0.00 (  0.00)
[0.15095999071525845]
Test: [0/1]	Time  0.256 ( 0.256)	Loss 1.0236e+00 (1.0236e+00)	Acc@1   0.18 (  0.18)	Acc@5   0.00 (  0.00)
 * Acc@1 0.180 Acc@5 0.000
Test: [0/1]	Time  0.312 ( 0.312)	Loss 6.3839e-01 (6.3839e-01)	Acc@1   0.13 (  0.13)	Acc@5   0.00 (  0.00)
 * Acc@1 0.127 Acc@5 0.000
10
TRAINING
Epoch: [10][0/1]	Time  1.016 ( 1.016)	Data  0.250 ( 0.250)	Loss 7.6336e-01 (7.6336e-01)	Acc@1   0.17 (  0.17)	Acc@5   0.00 (  0.00)
[0.16707581639137847]
Test: [0/1]	Time  0.244 ( 0.244)	Loss 1.0111e+00 (1.0111e+00)	Acc@1   0.19 (  0.19)	Acc@5   0.00 (  0.00)
 * Acc@1 0.191 Acc@5 0.000
Test: [0/1]	Time  0.297 ( 0.297)	Loss 5.8715e-01 (5.8715e-01)	Acc@1   0.15 (  0.15)	Acc@5   0.00 (  0.00)
 * Acc@1 0.150 Acc@5 0.000
11
TRAINING
Epoch: [11][0/1]	Time  0.940 ( 0.940)	Data  0.243 ( 0.243)	Loss 6.6900e-01 (6.6900e-01)	Acc@1   0.19 (  0.19)	Acc@5   0.00 (  0.00)
[0.18677057721591905]
Test: [0/1]	Time  0.249 ( 0.249)	Loss 1.0021e+00 (1.0021e+00)	Acc@1   0.22 (  0.22)	Acc@5   0.00 (  0.00)
 * Acc@1 0.223 Acc@5 0.000
Test: [0/1]	Time  0.307 ( 0.307)	Loss 5.5313e-01 (5.5313e-01)	Acc@1   0.17 (  0.17)	Acc@5   0.00 (  0.00)
 * Acc@1 0.168 Acc@5 0.000
12
TRAINING
Epoch: [12][0/1]	Time  0.996 ( 0.996)	Data  0.294 ( 0.294)	Loss 5.9879e-01 (5.9879e-01)	Acc@1   0.22 (  0.22)	Acc@5   0.00 (  0.00)
[0.21502362823916307]
Test: [0/1]	Time  0.241 ( 0.241)	Loss 9.9606e-01 (9.9606e-01)	Acc@1   0.26 (  0.26)	Acc@5   0.00 (  0.00)
 * Acc@1 0.260 Acc@5 0.000
Test: [0/1]	Time  0.297 ( 0.297)	Loss 5.3200e-01 (5.3200e-01)	Acc@1   0.18 (  0.18)	Acc@5   0.00 (  0.00)
 * Acc@1 0.184 Acc@5 0.000
13
TRAINING
Epoch: [13][0/1]	Time  1.019 ( 1.019)	Data  0.305 ( 0.305)	Loss 5.4656e-01 (5.4656e-01)	Acc@1   0.24 (  0.24)	Acc@5   0.00 (  0.00)
[0.24053965450010828]
Test: [0/1]	Time  0.241 ( 0.241)	Loss 9.9111e-01 (9.9111e-01)	Acc@1   0.27 (  0.27)	Acc@5   0.00 (  0.00)
 * Acc@1 0.271 Acc@5 0.000
Test: [0/1]	Time  0.295 ( 0.295)	Loss 5.1350e-01 (5.1350e-01)	Acc@1   0.20 (  0.20)	Acc@5   0.00 (  0.00)
 * Acc@1 0.196 Acc@5 0.000
14
TRAINING
Epoch: [14][0/1]	Time  1.021 ( 1.021)	Data  0.302 ( 0.302)	Loss 5.0020e-01 (5.0020e-01)	Acc@1   0.28 (  0.28)	Acc@5   0.00 (  0.00)
[0.27694061439279166]
Test: [0/1]	Time  0.241 ( 0.241)	Loss 9.8562e-01 (9.8562e-01)	Acc@1   0.30 (  0.30)	Acc@5   0.00 (  0.00)
 * Acc@1 0.295 Acc@5 0.000
Test: [0/1]	Time  0.298 ( 0.298)	Loss 4.8841e-01 (4.8841e-01)	Acc@1   0.21 (  0.21)	Acc@5   0.00 (  0.00)
 * Acc@1 0.208 Acc@5 0.000
15
TRAINING
Epoch: [15][0/1]	Time  0.989 ( 0.989)	Data  0.280 ( 0.280)	Loss 4.4966e-01 (4.4966e-01)	Acc@1   0.31 (  0.31)	Acc@5   0.00 (  0.00)
[0.3095354887246847]
Test: [0/1]	Time  0.259 ( 0.259)	Loss 9.7883e-01 (9.7883e-01)	Acc@1   0.34 (  0.34)	Acc@5   0.00 (  0.00)
 * Acc@1 0.338 Acc@5 0.000
Test: [0/1]	Time  0.305 ( 0.305)	Loss 4.5368e-01 (4.5368e-01)	Acc@1   0.23 (  0.23)	Acc@5   0.00 (  0.00)
 * Acc@1 0.228 Acc@5 0.000
16
TRAINING
Epoch: [16][0/1]	Time  0.948 ( 0.948)	Data  0.251 ( 0.251)	Loss 3.9228e-01 (3.9228e-01)	Acc@1   0.34 (  0.34)	Acc@5   0.00 (  0.00)
[0.34054867867543287]
Test: [0/1]	Time  0.273 ( 0.273)	Loss 9.7111e-01 (9.7111e-01)	Acc@1   0.41 (  0.41)	Acc@5   0.00 (  0.00)
 * Acc@1 0.407 Acc@5 0.000
Test: [0/1]	Time  0.321 ( 0.321)	Loss 4.1320e-01 (4.1320e-01)	Acc@1   0.25 (  0.25)	Acc@5   0.00 (  0.00)
 * Acc@1 0.248 Acc@5 0.000
17
TRAINING
Epoch: [17][0/1]	Time  0.943 ( 0.943)	Data  0.248 ( 0.248)	Loss 3.3283e-01 (3.3283e-01)	Acc@1   0.38 (  0.38)	Acc@5   0.00 (  0.00)
[0.3777999825148751]
Test: [0/1]	Time  0.274 ( 0.274)	Loss 9.6347e-01 (9.6347e-01)	Acc@1   0.46 (  0.46)	Acc@5   0.00 (  0.00)
 * Acc@1 0.462 Acc@5 0.000
Test: [0/1]	Time  0.318 ( 0.318)	Loss 3.7439e-01 (3.7439e-01)	Acc@1   0.27 (  0.27)	Acc@5   0.00 (  0.00)
 * Acc@1 0.269 Acc@5 0.000
18
TRAINING
Epoch: [18][0/1]	Time  0.979 ( 0.979)	Data  0.289 ( 0.289)	Loss 2.7937e-01 (2.7937e-01)	Acc@1   0.42 (  0.42)	Acc@5   0.00 (  0.00)
[0.41895296937746973]
Test: [0/1]	Time  0.274 ( 0.274)	Loss 9.5688e-01 (9.5688e-01)	Acc@1   0.50 (  0.50)	Acc@5   0.00 (  0.00)
 * Acc@1 0.503 Acc@5 0.000
Test: [0/1]	Time  0.319 ( 0.319)	Loss 3.4338e-01 (3.4338e-01)	Acc@1   0.28 (  0.28)	Acc@5   0.00 (  0.00)
 * Acc@1 0.282 Acc@5 0.000
19
TRAINING
Epoch: [19][0/1]	Time  0.959 ( 0.959)	Data  0.248 ( 0.248)	Loss 2.3794e-01 (2.3794e-01)	Acc@1   0.46 (  0.46)	Acc@5   0.00 (  0.00)
[0.4632086324366404]
Test: [0/1]	Time  0.259 ( 0.259)	Loss 9.5176e-01 (9.5176e-01)	Acc@1   0.51 (  0.51)	Acc@5   0.00 (  0.00)
 * Acc@1 0.513 Acc@5 0.000
Test: [0/1]	Time  0.305 ( 0.305)	Loss 3.2174e-01 (3.2174e-01)	Acc@1   0.30 (  0.30)	Acc@5   0.00 (  0.00)
 * Acc@1 0.301 Acc@5 0.000
20
TRAINING
Epoch: [20][0/1]	Time  1.046 ( 1.046)	Data  0.327 ( 0.327)	Loss 2.0949e-01 (2.0949e-01)	Acc@1   0.51 (  0.51)	Acc@5   0.00 (  0.00)
[0.5093193771220139]
Test: [0/1]	Time  0.255 ( 0.255)	Loss 9.4794e-01 (9.4794e-01)	Acc@1   0.52 (  0.52)	Acc@5   0.00 (  0.00)
 * Acc@1 0.521 Acc@5 0.000
Test: [0/1]	Time  0.304 ( 0.304)	Loss 3.0648e-01 (3.0648e-01)	Acc@1   0.33 (  0.33)	Acc@5   0.00 (  0.00)
 * Acc@1 0.326 Acc@5 0.000
21
TRAINING
Epoch: [21][0/1]	Time  0.936 ( 0.936)	Data  0.249 ( 0.249)	Loss 1.9014e-01 (1.9014e-01)	Acc@1   0.56 (  0.56)	Acc@5   0.00 (  0.00)
[0.5601157367757339]
Test: [0/1]	Time  0.246 ( 0.246)	Loss 9.4492e-01 (9.4492e-01)	Acc@1   0.54 (  0.54)	Acc@5   0.00 (  0.00)
 * Acc@1 0.543 Acc@5 0.000
Test: [0/1]	Time  0.293 ( 0.293)	Loss 2.9264e-01 (2.9264e-01)	Acc@1   0.35 (  0.35)	Acc@5   0.00 (  0.00)
 * Acc@1 0.355 Acc@5 0.000
22
TRAINING
Epoch: [22][0/1]	Time  1.003 ( 1.003)	Data  0.315 ( 0.315)	Loss 1.7422e-01 (1.7422e-01)	Acc@1   0.61 (  0.61)	Acc@5   0.00 (  0.00)
[0.6095936511345056]
Test: [0/1]	Time  0.268 ( 0.268)	Loss 9.4231e-01 (9.4231e-01)	Acc@1   0.57 (  0.57)	Acc@5   0.00 (  0.00)
 * Acc@1 0.565 Acc@5 0.000
Test: [0/1]	Time  0.316 ( 0.316)	Loss 2.7657e-01 (2.7657e-01)	Acc@1   0.38 (  0.38)	Acc@5   0.00 (  0.00)
 * Acc@1 0.384 Acc@5 0.000
23
TRAINING
Epoch: [23][0/1]	Time  1.024 ( 1.024)	Data  0.324 ( 0.324)	Loss 1.5765e-01 (1.5765e-01)	Acc@1   0.65 (  0.65)	Acc@5   0.00 (  0.00)
[0.6515678190948693]
Test: [0/1]	Time  0.263 ( 0.263)	Loss 9.4007e-01 (9.4007e-01)	Acc@1   0.58 (  0.58)	Acc@5   0.00 (  0.00)
 * Acc@1 0.582 Acc@5 0.000
Test: [0/1]	Time  0.319 ( 0.319)	Loss 2.5776e-01 (2.5776e-01)	Acc@1   0.41 (  0.41)	Acc@5   0.00 (  0.00)
 * Acc@1 0.407 Acc@5 0.000
24
TRAINING
Epoch: [24][0/1]	Time  0.951 ( 0.951)	Data  0.253 ( 0.253)	Loss 1.3970e-01 (1.3970e-01)	Acc@1   0.69 (  0.69)	Acc@5   0.00 (  0.00)
[0.6949474960160784]
Test: [0/1]	Time  0.274 ( 0.274)	Loss 9.3848e-01 (9.3848e-01)	Acc@1   0.59 (  0.59)	Acc@5   0.00 (  0.00)
 * Acc@1 0.593 Acc@5 0.000
Test: [0/1]	Time  0.318 ( 0.318)	Loss 2.3855e-01 (2.3855e-01)	Acc@1   0.43 (  0.43)	Acc@5   0.00 (  0.00)
 * Acc@1 0.430 Acc@5 0.000
25
TRAINING
Epoch: [25][0/1]	Time  0.987 ( 0.987)	Data  0.285 ( 0.285)	Loss 1.2252e-01 (1.2252e-01)	Acc@1   0.74 (  0.74)	Acc@5   0.00 (  0.00)
[0.7350085580615291]
Test: [0/1]	Time  0.258 ( 0.258)	Loss 9.3781e-01 (9.3781e-01)	Acc@1   0.61 (  0.61)	Acc@5   0.00 (  0.00)
 * Acc@1 0.610 Acc@5 0.000
Test: [0/1]	Time  0.309 ( 0.309)	Loss 2.2214e-01 (2.2214e-01)	Acc@1   0.45 (  0.45)	Acc@5   0.00 (  0.00)
 * Acc@1 0.453 Acc@5 0.000
26
TRAINING
Epoch: [26][0/1]	Time  0.992 ( 0.992)	Data  0.278 ( 0.278)	Loss 1.0907e-01 (1.0907e-01)	Acc@1   0.77 (  0.77)	Acc@5   0.00 (  0.00)
[0.7666380503380332]
Test: [0/1]	Time  0.257 ( 0.257)	Loss 9.3810e-01 (9.3810e-01)	Acc@1   0.62 (  0.62)	Acc@5   0.00 (  0.00)
 * Acc@1 0.624 Acc@5 0.000
Test: [0/1]	Time  0.309 ( 0.309)	Loss 2.1044e-01 (2.1044e-01)	Acc@1   0.47 (  0.47)	Acc@5   0.00 (  0.00)
 * Acc@1 0.475 Acc@5 0.000
27
TRAINING
Epoch: [27][0/1]	Time  0.980 ( 0.980)	Data  0.288 ( 0.288)	Loss 1.0096e-01 (1.0096e-01)	Acc@1   0.79 (  0.79)	Acc@5   0.00 (  0.00)
[0.7909986699710085]
Test: [0/1]	Time  0.267 ( 0.267)	Loss 9.3908e-01 (9.3908e-01)	Acc@1   0.63 (  0.63)	Acc@5   0.00 (  0.00)
 * Acc@1 0.633 Acc@5 0.000
Test: [0/1]	Time  0.312 ( 0.312)	Loss 2.0309e-01 (2.0309e-01)	Acc@1   0.50 (  0.50)	Acc@5   0.00 (  0.00)
 * Acc@1 0.497 Acc@5 0.000
28
TRAINING
Epoch: [28][0/1]	Time  0.936 ( 0.936)	Data  0.250 ( 0.250)	Loss 9.7546e-02 (9.7546e-02)	Acc@1   0.81 (  0.81)	Acc@5   0.00 (  0.00)
[0.8102265988993573]
Test: [0/1]	Time  0.286 ( 0.286)	Loss 9.4024e-01 (9.4024e-01)	Acc@1   0.63 (  0.63)	Acc@5   0.00 (  0.00)
 * Acc@1 0.634 Acc@5 0.000
Test: [0/1]	Time  0.335 ( 0.335)	Loss 1.9796e-01 (1.9796e-01)	Acc@1   0.52 (  0.52)	Acc@5   0.00 (  0.00)
 * Acc@1 0.520 Acc@5 0.000
29
TRAINING
Epoch: [29][0/1]	Time  0.948 ( 0.948)	Data  0.256 ( 0.256)	Loss 9.6488e-02 (9.6488e-02)	Acc@1   0.83 (  0.83)	Acc@5   0.00 (  0.00)
[0.8253074933185864]
Test: [0/1]	Time  0.256 ( 0.256)	Loss 9.4108e-01 (9.4108e-01)	Acc@1   0.63 (  0.63)	Acc@5   0.00 (  0.00)
 * Acc@1 0.631 Acc@5 0.000
Test: [0/1]	Time  0.303 ( 0.303)	Loss 1.9263e-01 (1.9263e-01)	Acc@1   0.54 (  0.54)	Acc@5   0.00 (  0.00)
 * Acc@1 0.543 Acc@5 0.000
30
TRAINING
Epoch: [30][0/1]	Time  1.036 ( 1.036)	Data  0.337 ( 0.337)	Loss 9.5227e-02 (9.5227e-02)	Acc@1   0.84 (  0.84)	Acc@5   0.00 (  0.00)
[0.8370147088673187]
Test: [0/1]	Time  0.260 ( 0.260)	Loss 9.4136e-01 (9.4136e-01)	Acc@1   0.63 (  0.63)	Acc@5   0.00 (  0.00)
 * Acc@1 0.627 Acc@5 0.000
Test: [0/1]	Time  0.311 ( 0.311)	Loss 1.8577e-01 (1.8577e-01)	Acc@1   0.57 (  0.57)	Acc@5   0.00 (  0.00)
 * Acc@1 0.567 Acc@5 0.000
31
TRAINING
Epoch: [31][0/1]	Time  1.005 ( 1.005)	Data  0.313 ( 0.313)	Loss 9.2351e-02 (9.2351e-02)	Acc@1   0.85 (  0.85)	Acc@5   0.00 (  0.00)
[0.8479854778124998]
Test: [0/1]	Time  0.264 ( 0.264)	Loss 9.4112e-01 (9.4112e-01)	Acc@1   0.62 (  0.62)	Acc@5   0.00 (  0.00)
 * Acc@1 0.622 Acc@5 0.000
Test: [0/1]	Time  0.315 ( 0.315)	Loss 1.7768e-01 (1.7768e-01)	Acc@1   0.59 (  0.59)	Acc@5   0.00 (  0.00)
 * Acc@1 0.590 Acc@5 0.000
32
TRAINING
Epoch: [32][0/1]	Time  0.954 ( 0.954)	Data  0.247 ( 0.247)	Loss 8.8080e-02 (8.8080e-02)	Acc@1   0.86 (  0.86)	Acc@5   0.00 (  0.00)
[0.8573993518258229]
Test: [0/1]	Time  0.245 ( 0.245)	Loss 9.4061e-01 (9.4061e-01)	Acc@1   0.62 (  0.62)	Acc@5   0.00 (  0.00)
 * Acc@1 0.617 Acc@5 0.000
Test: [0/1]	Time  0.310 ( 0.310)	Loss 1.6976e-01 (1.6976e-01)	Acc@1   0.61 (  0.61)	Acc@5   0.00 (  0.00)
 * Acc@1 0.615 Acc@5 0.000
33
TRAINING
Epoch: [33][0/1]	Time  0.948 ( 0.948)	Data  0.262 ( 0.262)	Loss 8.3760e-02 (8.3760e-02)	Acc@1   0.86 (  0.86)	Acc@5   0.00 (  0.00)
[0.8645190500158071]
Test: [0/1]	Time  0.251 ( 0.251)	Loss 9.4016e-01 (9.4016e-01)	Acc@1   0.61 (  0.61)	Acc@5   0.00 (  0.00)
 * Acc@1 0.612 Acc@5 0.000
Test: [0/1]	Time  0.313 ( 0.313)	Loss 1.6353e-01 (1.6353e-01)	Acc@1   0.64 (  0.64)	Acc@5   0.00 (  0.00)
 * Acc@1 0.644 Acc@5 0.000
34
TRAINING
Epoch: [34][0/1]	Time  0.954 ( 0.954)	Data  0.246 ( 0.246)	Loss 8.0825e-02 (8.0825e-02)	Acc@1   0.87 (  0.87)	Acc@5   0.00 (  0.00)
[0.8703456087722004]
Test: [0/1]	Time  0.258 ( 0.258)	Loss 9.3999e-01 (9.3999e-01)	Acc@1   0.61 (  0.61)	Acc@5   0.00 (  0.00)
 * Acc@1 0.608 Acc@5 0.000
Test: [0/1]	Time  0.307 ( 0.307)	Loss 1.5971e-01 (1.5971e-01)	Acc@1   0.67 (  0.67)	Acc@5   0.00 (  0.00)
 * Acc@1 0.671 Acc@5 0.000
35
TRAINING
Epoch: [35][0/1]	Time  0.956 ( 0.956)	Data  0.245 ( 0.245)	Loss 7.9922e-02 (7.9922e-02)	Acc@1   0.87 (  0.87)	Acc@5   0.00 (  0.00)
[0.8736618629778985]
Test: [0/1]	Time  0.246 ( 0.246)	Loss 9.4018e-01 (9.4018e-01)	Acc@1   0.61 (  0.61)	Acc@5   0.00 (  0.00)
 * Acc@1 0.605 Acc@5 0.000
Test: [0/1]	Time  0.290 ( 0.290)	Loss 1.5791e-01 (1.5791e-01)	Acc@1   0.69 (  0.69)	Acc@5   0.00 (  0.00)
 * Acc@1 0.692 Acc@5 0.000
36
TRAINING
Epoch: [36][0/1]	Time  0.975 ( 0.975)	Data  0.277 ( 0.277)	Loss 8.0661e-02 (8.0661e-02)	Acc@1   0.87 (  0.87)	Acc@5   0.00 (  0.00)
[0.8740418299178767]
Test: [0/1]	Time  0.262 ( 0.262)	Loss 9.4071e-01 (9.4071e-01)	Acc@1   0.60 (  0.60)	Acc@5   0.00 (  0.00)
 * Acc@1 0.604 Acc@5 0.000
Test: [0/1]	Time  0.306 ( 0.306)	Loss 1.5707e-01 (1.5707e-01)	Acc@1   0.70 (  0.70)	Acc@5   0.00 (  0.00)
 * Acc@1 0.702 Acc@5 0.000
37
TRAINING
Epoch: [37][0/1]	Time  1.000 ( 1.000)	Data  0.299 ( 0.299)	Loss 8.1997e-02 (8.1997e-02)	Acc@1   0.87 (  0.87)	Acc@5   0.00 (  0.00)
[0.8732632249610879]
Test: [0/1]	Time  0.268 ( 0.268)	Loss 9.4147e-01 (9.4147e-01)	Acc@1   0.60 (  0.60)	Acc@5   0.00 (  0.00)
 * Acc@1 0.604 Acc@5 0.000
Test: [0/1]	Time  0.317 ( 0.317)	Loss 1.5617e-01 (1.5617e-01)	Acc@1   0.71 (  0.71)	Acc@5   0.00 (  0.00)
 * Acc@1 0.712 Acc@5 0.000
38
TRAINING
Epoch: [38][0/1]	Time  0.959 ( 0.959)	Data  0.262 ( 0.262)	Loss 8.2921e-02 (8.2921e-02)	Acc@1   0.87 (  0.87)	Acc@5   0.00 (  0.00)
[0.8720960363470471]
Test: [0/1]	Time  0.254 ( 0.254)	Loss 9.4241e-01 (9.4241e-01)	Acc@1   0.60 (  0.60)	Acc@5   0.00 (  0.00)
 * Acc@1 0.605 Acc@5 0.000
Test: [0/1]	Time  0.303 ( 0.303)	Loss 1.5471e-01 (1.5471e-01)	Acc@1   0.72 (  0.72)	Acc@5   0.00 (  0.00)
 * Acc@1 0.719 Acc@5 0.000
39
TRAINING
Epoch: [39][0/1]	Time  0.997 ( 0.997)	Data  0.284 ( 0.284)	Loss 8.2988e-02 (8.2988e-02)	Acc@1   0.87 (  0.87)	Acc@5   0.00 (  0.00)
[0.8707066437167391]
Test: [0/1]	Time  0.263 ( 0.263)	Loss 9.4348e-01 (9.4348e-01)	Acc@1   0.61 (  0.61)	Acc@5   0.00 (  0.00)
 * Acc@1 0.607 Acc@5 0.000
Test: [0/1]	Time  0.311 ( 0.311)	Loss 1.5291e-01 (1.5291e-01)	Acc@1   0.73 (  0.73)	Acc@5   0.00 (  0.00)
 * Acc@1 0.726 Acc@5 0.000
40
TRAINING
Epoch: [40][0/1]	Time  0.947 ( 0.947)	Data  0.253 ( 0.253)	Loss 8.2420e-02 (8.2420e-02)	Acc@1   0.87 (  0.87)	Acc@5   0.00 (  0.00)
[0.8703026697122268]
Test: [0/1]	Time  0.251 ( 0.251)	Loss 9.4467e-01 (9.4467e-01)	Acc@1   0.61 (  0.61)	Acc@5   0.00 (  0.00)
 * Acc@1 0.610 Acc@5 0.000
Test: [0/1]	Time  0.298 ( 0.298)	Loss 1.5132e-01 (1.5132e-01)	Acc@1   0.73 (  0.73)	Acc@5   0.00 (  0.00)
 * Acc@1 0.731 Acc@5 0.000
41
TRAINING
Epoch: [41][0/1]	Time  0.945 ( 0.945)	Data  0.249 ( 0.249)	Loss 8.1813e-02 (8.1813e-02)	Acc@1   0.87 (  0.87)	Acc@5   0.00 (  0.00)
[0.8691894971709864]
Test: [0/1]	Time  0.245 ( 0.245)	Loss 9.4592e-01 (9.4592e-01)	Acc@1   0.61 (  0.61)	Acc@5   0.00 (  0.00)
 * Acc@1 0.614 Acc@5 0.000
Test: [0/1]	Time  0.294 ( 0.294)	Loss 1.5045e-01 (1.5045e-01)	Acc@1   0.73 (  0.73)	Acc@5   0.00 (  0.00)
 * Acc@1 0.735 Acc@5 0.000
42
TRAINING
Epoch: [42][0/1]	Time  0.960 ( 0.960)	Data  0.253 ( 0.253)	Loss 8.1680e-02 (8.1680e-02)	Acc@1   0.87 (  0.87)	Acc@5   0.00 (  0.00)
[0.8683433233177822]
Test: [0/1]	Time  0.266 ( 0.266)	Loss 9.4712e-01 (9.4712e-01)	Acc@1   0.62 (  0.62)	Acc@5   0.00 (  0.00)
 * Acc@1 0.618 Acc@5 0.000
Test: [0/1]	Time  0.306 ( 0.306)	Loss 1.5042e-01 (1.5042e-01)	Acc@1   0.74 (  0.74)	Acc@5   0.00 (  0.00)
 * Acc@1 0.738 Acc@5 0.000
43
TRAINING
Epoch: [43][0/1]	Time  0.943 ( 0.943)	Data  0.248 ( 0.248)	Loss 8.2146e-02 (8.2146e-02)	Acc@1   0.87 (  0.87)	Acc@5   0.00 (  0.00)
[0.86901485067154]
Test: [0/1]	Time  0.267 ( 0.267)	Loss 9.4815e-01 (9.4815e-01)	Acc@1   0.62 (  0.62)	Acc@5   0.00 (  0.00)
 * Acc@1 0.622 Acc@5 0.000
Test: [0/1]	Time  0.314 ( 0.314)	Loss 1.5089e-01 (1.5089e-01)	Acc@1   0.74 (  0.74)	Acc@5   0.00 (  0.00)
 * Acc@1 0.741 Acc@5 0.000
44
TRAINING
Epoch: [44][0/1]	Time  1.008 ( 1.008)	Data  0.322 ( 0.322)	Loss 8.2921e-02 (8.2921e-02)	Acc@1   0.87 (  0.87)	Acc@5   0.00 (  0.00)
[0.8704657949504659]
Test: [0/1]	Time  0.266 ( 0.266)	Loss 9.4888e-01 (9.4888e-01)	Acc@1   0.63 (  0.63)	Acc@5   0.00 (  0.00)
 * Acc@1 0.626 Acc@5 0.000
Test: [0/1]	Time  0.324 ( 0.324)	Loss 1.5139e-01 (1.5139e-01)	Acc@1   0.74 (  0.74)	Acc@5   0.00 (  0.00)
 * Acc@1 0.745 Acc@5 0.000
45
TRAINING
Epoch: [45][0/1]	Time  0.990 ( 0.990)	Data  0.280 ( 0.280)	Loss 8.3537e-02 (8.3537e-02)	Acc@1   0.87 (  0.87)	Acc@5   0.00 (  0.00)
[0.8725885750199573]
Test: [0/1]	Time  0.260 ( 0.260)	Loss 9.4925e-01 (9.4925e-01)	Acc@1   0.63 (  0.63)	Acc@5   0.00 (  0.00)
 * Acc@1 0.631 Acc@5 0.000
Test: [0/1]	Time  0.311 ( 0.311)	Loss 1.5156e-01 (1.5156e-01)	Acc@1   0.75 (  0.75)	Acc@5   0.00 (  0.00)
 * Acc@1 0.748 Acc@5 0.000
46
TRAINING
Epoch: [46][0/1]	Time  0.977 ( 0.977)	Data  0.273 ( 0.273)	Loss 8.3641e-02 (8.3641e-02)	Acc@1   0.88 (  0.88)	Acc@5   0.00 (  0.00)
[0.8753956647790534]
Test: [0/1]	Time  0.260 ( 0.260)	Loss 9.4928e-01 (9.4928e-01)	Acc@1   0.64 (  0.64)	Acc@5   0.00 (  0.00)
 * Acc@1 0.635 Acc@5 0.000
Test: [0/1]	Time  0.318 ( 0.318)	Loss 1.5133e-01 (1.5133e-01)	Acc@1   0.75 (  0.75)	Acc@5   0.00 (  0.00)
 * Acc@1 0.752 Acc@5 0.000
47
TRAINING
Epoch: [47][0/1]	Time  0.935 ( 0.935)	Data  0.247 ( 0.247)	Loss 8.3183e-02 (8.3183e-02)	Acc@1   0.88 (  0.88)	Acc@5   0.00 (  0.00)
[0.8789359814757092]
Test: [0/1]	Time  0.265 ( 0.265)	Loss 9.4907e-01 (9.4907e-01)	Acc@1   0.64 (  0.64)	Acc@5   0.00 (  0.00)
 * Acc@1 0.640 Acc@5 0.000
Test: [0/1]	Time  0.315 ( 0.315)	Loss 1.5093e-01 (1.5093e-01)	Acc@1   0.76 (  0.76)	Acc@5   0.00 (  0.00)
 * Acc@1 0.756 Acc@5 0.000
48
TRAINING
Epoch: [48][0/1]	Time  0.982 ( 0.982)	Data  0.271 ( 0.271)	Loss 8.2397e-02 (8.2397e-02)	Acc@1   0.88 (  0.88)	Acc@5   0.00 (  0.00)
[0.8828461256276152]
Test: [0/1]	Time  0.263 ( 0.263)	Loss 9.4874e-01 (9.4874e-01)	Acc@1   0.64 (  0.64)	Acc@5   0.00 (  0.00)
 * Acc@1 0.645 Acc@5 0.000
Test: [0/1]	Time  0.315 ( 0.315)	Loss 1.5068e-01 (1.5068e-01)	Acc@1   0.76 (  0.76)	Acc@5   0.00 (  0.00)
 * Acc@1 0.759 Acc@5 0.000
49
TRAINING
Epoch: [49][0/1]	Time  0.977 ( 0.977)	Data  0.265 ( 0.265)	Loss 8.1629e-02 (8.1629e-02)	Acc@1   0.89 (  0.89)	Acc@5   0.00 (  0.00)
[0.8875928248189611]
Test: [0/1]	Time  0.258 ( 0.258)	Loss 9.4838e-01 (9.4838e-01)	Acc@1   0.65 (  0.65)	Acc@5   0.00 (  0.00)
 * Acc@1 0.649 Acc@5 0.000
Test: [0/1]	Time  0.315 ( 0.315)	Loss 1.5078e-01 (1.5078e-01)	Acc@1   0.76 (  0.76)	Acc@5   0.00 (  0.00)
 * Acc@1 0.761 Acc@5 0.000
50
TRAINING
Epoch: [50][0/1]	Time  1.023 ( 1.023)	Data  0.318 ( 0.318)	Loss 8.1132e-02 (8.1132e-02)	Acc@1   0.89 (  0.89)	Acc@5   0.00 (  0.00)
[0.8925870097553481]
Test: [0/1]	Time  0.276 ( 0.276)	Loss 9.4806e-01 (9.4806e-01)	Acc@1   0.65 (  0.65)	Acc@5   0.00 (  0.00)
 * Acc@1 0.654 Acc@5 0.000
Test: [0/1]	Time  0.334 ( 0.334)	Loss 1.5124e-01 (1.5124e-01)	Acc@1   0.76 (  0.76)	Acc@5   0.00 (  0.00)
 * Acc@1 0.762 Acc@5 0.000
51
TRAINING
Epoch: [51][0/1]	Time  0.970 ( 0.970)	Data  0.278 ( 0.278)	Loss 8.0954e-02 (8.0954e-02)	Acc@1   0.90 (  0.90)	Acc@5   0.00 (  0.00)
[0.8960801847621006]
Test: [0/1]	Time  0.261 ( 0.261)	Loss 9.4783e-01 (9.4783e-01)	Acc@1   0.66 (  0.66)	Acc@5   0.00 (  0.00)
 * Acc@1 0.659 Acc@5 0.000
Test: [0/1]	Time  0.319 ( 0.319)	Loss 1.5187e-01 (1.5187e-01)	Acc@1   0.76 (  0.76)	Acc@5   0.00 (  0.00)
 * Acc@1 0.762 Acc@5 0.000
52
TRAINING
Epoch: [52][0/1]	Time  0.948 ( 0.948)	Data  0.259 ( 0.259)	Loss 8.0960e-02 (8.0960e-02)	Acc@1   0.90 (  0.90)	Acc@5   0.00 (  0.00)
[0.8990019497428621]
Test: [0/1]	Time  0.249 ( 0.249)	Loss 9.4768e-01 (9.4768e-01)	Acc@1   0.66 (  0.66)	Acc@5   0.00 (  0.00)
 * Acc@1 0.662 Acc@5 0.000
Test: [0/1]	Time  0.297 ( 0.297)	Loss 1.5242e-01 (1.5242e-01)	Acc@1   0.76 (  0.76)	Acc@5   0.00 (  0.00)
 * Acc@1 0.761 Acc@5 0.000
53
TRAINING
Epoch: [53][0/1]	Time  0.927 ( 0.927)	Data  0.255 ( 0.255)	Loss 8.0955e-02 (8.0955e-02)	Acc@1   0.90 (  0.90)	Acc@5   0.00 (  0.00)
[0.9019717302057928]
Test: [0/1]	Time  0.257 ( 0.257)	Loss 9.4759e-01 (9.4759e-01)	Acc@1   0.66 (  0.66)	Acc@5   0.00 (  0.00)
 * Acc@1 0.665 Acc@5 0.000
Test: [0/1]	Time  0.314 ( 0.314)	Loss 1.5273e-01 (1.5273e-01)	Acc@1   0.76 (  0.76)	Acc@5   0.00 (  0.00)
 * Acc@1 0.761 Acc@5 0.000
54
TRAINING
Epoch: [54][0/1]	Time  0.947 ( 0.947)	Data  0.265 ( 0.265)	Loss 8.0807e-02 (8.0807e-02)	Acc@1   0.91 (  0.91)	Acc@5   0.00 (  0.00)
[0.9050689636236043]
Test: [0/1]	Time  0.258 ( 0.258)	Loss 9.4757e-01 (9.4757e-01)	Acc@1   0.67 (  0.67)	Acc@5   0.00 (  0.00)
 * Acc@1 0.668 Acc@5 0.000
Test: [0/1]	Time  0.308 ( 0.308)	Loss 1.5280e-01 (1.5280e-01)	Acc@1   0.76 (  0.76)	Acc@5   0.00 (  0.00)
 * Acc@1 0.760 Acc@5 0.000
55
TRAINING
Epoch: [55][0/1]	Time  0.945 ( 0.945)	Data  0.272 ( 0.272)	Loss 8.0513e-02 (8.0513e-02)	Acc@1   0.91 (  0.91)	Acc@5   0.00 (  0.00)
[0.9076608869332672]
Test: [0/1]	Time  0.248 ( 0.248)	Loss 9.4760e-01 (9.4760e-01)	Acc@1   0.67 (  0.67)	Acc@5   0.00 (  0.00)
 * Acc@1 0.671 Acc@5 0.000
Test: [0/1]	Time  0.301 ( 0.301)	Loss 1.5271e-01 (1.5271e-01)	Acc@1   0.76 (  0.76)	Acc@5   0.00 (  0.00)
 * Acc@1 0.760 Acc@5 0.000
56
TRAINING
Epoch: [56][0/1]	Time  0.938 ( 0.938)	Data  0.263 ( 0.263)	Loss 8.0173e-02 (8.0173e-02)	Acc@1   0.91 (  0.91)	Acc@5   0.00 (  0.00)
[0.9101755632520041]
Test: [0/1]	Time  0.245 ( 0.245)	Loss 9.4766e-01 (9.4766e-01)	Acc@1   0.67 (  0.67)	Acc@5   0.00 (  0.00)
 * Acc@1 0.674 Acc@5 0.000
Test: [0/1]	Time  0.298 ( 0.298)	Loss 1.5263e-01 (1.5263e-01)	Acc@1   0.76 (  0.76)	Acc@5   0.00 (  0.00)
 * Acc@1 0.760 Acc@5 0.000
57
TRAINING
Epoch: [57][0/1]	Time  0.935 ( 0.935)	Data  0.261 ( 0.261)	Loss 7.9907e-02 (7.9907e-02)	Acc@1   0.91 (  0.91)	Acc@5   0.00 (  0.00)
[0.9133922069131627]
Test: [0/1]	Time  0.247 ( 0.247)	Loss 9.4773e-01 (9.4773e-01)	Acc@1   0.68 (  0.68)	Acc@5   0.00 (  0.00)
 * Acc@1 0.678 Acc@5 0.000
Test: [0/1]	Time  0.297 ( 0.297)	Loss 1.5263e-01 (1.5263e-01)	Acc@1   0.76 (  0.76)	Acc@5   0.00 (  0.00)
 * Acc@1 0.760 Acc@5 0.000
58
TRAINING
Epoch: [58][0/1]	Time  0.933 ( 0.933)	Data  0.261 ( 0.261)	Loss 7.9779e-02 (7.9779e-02)	Acc@1   0.92 (  0.92)	Acc@5   0.00 (  0.00)
[0.9164327681191105]
Test: [0/1]	Time  0.243 ( 0.243)	Loss 9.4777e-01 (9.4777e-01)	Acc@1   0.68 (  0.68)	Acc@5   0.00 (  0.00)
 * Acc@1 0.681 Acc@5 0.000
Test: [0/1]	Time  0.296 ( 0.296)	Loss 1.5272e-01 (1.5272e-01)	Acc@1   0.76 (  0.76)	Acc@5   0.00 (  0.00)
 * Acc@1 0.760 Acc@5 0.000
59
TRAINING
Epoch: [59][0/1]	Time  0.937 ( 0.937)	Data  0.262 ( 0.262)	Loss 7.9765e-02 (7.9765e-02)	Acc@1   0.92 (  0.92)	Acc@5   0.00 (  0.00)
[0.9192095682045542]
Test: [0/1]	Time  0.242 ( 0.242)	Loss 9.4774e-01 (9.4774e-01)	Acc@1   0.68 (  0.68)	Acc@5   0.00 (  0.00)
 * Acc@1 0.683 Acc@5 0.000
Test: [0/1]	Time  0.302 ( 0.302)	Loss 1.5283e-01 (1.5283e-01)	Acc@1   0.76 (  0.76)	Acc@5   0.00 (  0.00)
 * Acc@1 0.760 Acc@5 0.000
60
TRAINING
Epoch: [60][0/1]	Time  0.946 ( 0.946)	Data  0.247 ( 0.247)	Loss 7.9782e-02 (7.9782e-02)	Acc@1   0.92 (  0.92)	Acc@5   0.00 (  0.00)
[0.9214042290627316]
Test: [0/1]	Time  0.242 ( 0.242)	Loss 9.4761e-01 (9.4761e-01)	Acc@1   0.68 (  0.68)	Acc@5   0.00 (  0.00)
 * Acc@1 0.685 Acc@5 0.000
Test: [0/1]	Time  0.291 ( 0.291)	Loss 1.5289e-01 (1.5289e-01)	Acc@1   0.76 (  0.76)	Acc@5   0.00 (  0.00)
 * Acc@1 0.761 Acc@5 0.000
61
TRAINING
Epoch: [61][0/1]	Time  0.926 ( 0.926)	Data  0.250 ( 0.250)	Loss 7.9741e-02 (7.9741e-02)	Acc@1   0.92 (  0.92)	Acc@5   0.00 (  0.00)
[0.9231308266374136]
Test: [0/1]	Time  0.243 ( 0.243)	Loss 9.4739e-01 (9.4739e-01)	Acc@1   0.69 (  0.69)	Acc@5   0.00 (  0.00)
 * Acc@1 0.687 Acc@5 0.000
Test: [0/1]	Time  0.290 ( 0.290)	Loss 1.5286e-01 (1.5286e-01)	Acc@1   0.76 (  0.76)	Acc@5   0.00 (  0.00)
 * Acc@1 0.761 Acc@5 0.000
62
TRAINING
Epoch: [62][0/1]	Time  0.931 ( 0.931)	Data  0.257 ( 0.257)	Loss 7.9602e-02 (7.9602e-02)	Acc@1   0.92 (  0.92)	Acc@5   0.00 (  0.00)
[0.9245711766284863]
Test: [0/1]	Time  0.259 ( 0.259)	Loss 9.4709e-01 (9.4709e-01)	Acc@1   0.69 (  0.69)	Acc@5   0.00 (  0.00)
 * Acc@1 0.688 Acc@5 0.000
Test: [0/1]	Time  0.308 ( 0.308)	Loss 1.5277e-01 (1.5277e-01)	Acc@1   0.76 (  0.76)	Acc@5   0.00 (  0.00)
 * Acc@1 0.761 Acc@5 0.000
63
TRAINING
Epoch: [63][0/1]	Time  0.984 ( 0.984)	Data  0.268 ( 0.268)	Loss 7.9390e-02 (7.9390e-02)	Acc@1   0.93 (  0.93)	Acc@5   0.00 (  0.00)
[0.9256160601142762]
Test: [0/1]	Time  0.248 ( 0.248)	Loss 9.4672e-01 (9.4672e-01)	Acc@1   0.69 (  0.69)	Acc@5   0.00 (  0.00)
 * Acc@1 0.690 Acc@5 0.000
Test: [0/1]	Time  0.296 ( 0.296)	Loss 1.5266e-01 (1.5266e-01)	Acc@1   0.76 (  0.76)	Acc@5   0.00 (  0.00)
 * Acc@1 0.762 Acc@5 0.000
64
TRAINING
Epoch: [64][0/1]	Time  0.949 ( 0.949)	Data  0.244 ( 0.244)	Loss 7.9167e-02 (7.9167e-02)	Acc@1   0.93 (  0.93)	Acc@5   0.00 (  0.00)
[0.9264989058276772]
Test: [0/1]	Time  0.243 ( 0.243)	Loss 9.4633e-01 (9.4633e-01)	Acc@1   0.69 (  0.69)	Acc@5   0.00 (  0.00)
 * Acc@1 0.692 Acc@5 0.000
Test: [0/1]	Time  0.291 ( 0.291)	Loss 1.5258e-01 (1.5258e-01)	Acc@1   0.76 (  0.76)	Acc@5   0.00 (  0.00)
 * Acc@1 0.762 Acc@5 0.000
65
TRAINING
Epoch: [65][0/1]	Time  0.945 ( 0.945)	Data  0.251 ( 0.251)	Loss 7.8996e-02 (7.8996e-02)	Acc@1   0.93 (  0.93)	Acc@5   0.00 (  0.00)
[0.9271232354190485]
Test: [0/1]	Time  0.244 ( 0.244)	Loss 9.4593e-01 (9.4593e-01)	Acc@1   0.69 (  0.69)	Acc@5   0.00 (  0.00)
 * Acc@1 0.693 Acc@5 0.000
Test: [0/1]	Time  0.296 ( 0.296)	Loss 1.5256e-01 (1.5256e-01)	Acc@1   0.76 (  0.76)	Acc@5   0.00 (  0.00)
 * Acc@1 0.762 Acc@5 0.000
66
TRAINING
Epoch: [66][0/1]	Time  0.951 ( 0.951)	Data  0.247 ( 0.247)	Loss 7.8906e-02 (7.8906e-02)	Acc@1   0.93 (  0.93)	Acc@5   0.00 (  0.00)
[0.9278964341007745]
Test: [0/1]	Time  0.243 ( 0.243)	Loss 9.4556e-01 (9.4556e-01)	Acc@1   0.69 (  0.69)	Acc@5   0.00 (  0.00)
 * Acc@1 0.694 Acc@5 0.000
Test: [0/1]	Time  0.289 ( 0.289)	Loss 1.5255e-01 (1.5255e-01)	Acc@1   0.76 (  0.76)	Acc@5   0.00 (  0.00)
 * Acc@1 0.763 Acc@5 0.000
67
TRAINING
Epoch: [67][0/1]	Time  0.961 ( 0.961)	Data  0.264 ( 0.264)	Loss 7.8885e-02 (7.8885e-02)	Acc@1   0.93 (  0.93)	Acc@5   0.00 (  0.00)
[0.928529978047824]
Test: [0/1]	Time  0.247 ( 0.247)	Loss 9.4521e-01 (9.4521e-01)	Acc@1   0.70 (  0.70)	Acc@5   0.00 (  0.00)
 * Acc@1 0.696 Acc@5 0.000
Test: [0/1]	Time  0.303 ( 0.303)	Loss 1.5252e-01 (1.5252e-01)	Acc@1   0.76 (  0.76)	Acc@5   0.00 (  0.00)
 * Acc@1 0.763 Acc@5 0.000
68
TRAINING
Epoch: [68][0/1]	Time  0.979 ( 0.979)	Data  0.271 ( 0.271)	Loss 7.8896e-02 (7.8896e-02)	Acc@1   0.93 (  0.93)	Acc@5   0.00 (  0.00)
[0.9289259693986618]
Test: [0/1]	Time  0.295 ( 0.295)	Loss 9.4490e-01 (9.4490e-01)	Acc@1   0.70 (  0.70)	Acc@5   0.00 (  0.00)
 * Acc@1 0.697 Acc@5 0.000
Test: [0/1]	Time  0.342 ( 0.342)	Loss 1.5243e-01 (1.5243e-01)	Acc@1   0.76 (  0.76)	Acc@5   0.00 (  0.00)
 * Acc@1 0.764 Acc@5 0.000
69
TRAINING
Epoch: [69][0/1]	Time  0.981 ( 0.981)	Data  0.280 ( 0.280)	Loss 7.8904e-02 (7.8904e-02)	Acc@1   0.93 (  0.93)	Acc@5   0.00 (  0.00)
[0.9289742778713115]
Test: [0/1]	Time  0.287 ( 0.287)	Loss 9.4464e-01 (9.4464e-01)	Acc@1   0.70 (  0.70)	Acc@5   0.00 (  0.00)
 * Acc@1 0.699 Acc@5 0.000
Test: [0/1]	Time  0.332 ( 0.332)	Loss 1.5227e-01 (1.5227e-01)	Acc@1   0.76 (  0.76)	Acc@5   0.00 (  0.00)
 * Acc@1 0.764 Acc@5 0.000
70
TRAINING
Epoch: [70][0/1]	Time  1.011 ( 1.011)	Data  0.315 ( 0.315)	Loss 7.8893e-02 (7.8893e-02)	Acc@1   0.93 (  0.93)	Acc@5   0.00 (  0.00)
[0.9290417795831348]
Test: [0/1]	Time  0.272 ( 0.272)	Loss 9.4441e-01 (9.4441e-01)	Acc@1   0.70 (  0.70)	Acc@5   0.00 (  0.00)
 * Acc@1 0.700 Acc@5 0.000
Test: [0/1]	Time  0.324 ( 0.324)	Loss 1.5205e-01 (1.5205e-01)	Acc@1   0.77 (  0.77)	Acc@5   0.00 (  0.00)
 * Acc@1 0.765 Acc@5 0.000
71
TRAINING
Epoch: [71][0/1]	Time  0.964 ( 0.964)	Data  0.277 ( 0.277)	Loss 7.8873e-02 (7.8873e-02)	Acc@1   0.93 (  0.93)	Acc@5   0.00 (  0.00)
[0.9291354758277912]
Test: [0/1]	Time  0.259 ( 0.259)	Loss 9.4420e-01 (9.4420e-01)	Acc@1   0.70 (  0.70)	Acc@5   0.00 (  0.00)
 * Acc@1 0.701 Acc@5 0.000
Test: [0/1]	Time  0.341 ( 0.341)	Loss 1.5182e-01 (1.5182e-01)	Acc@1   0.77 (  0.77)	Acc@5   0.00 (  0.00)
 * Acc@1 0.766 Acc@5 0.000
72
TRAINING
Epoch: [72][0/1]	Time  0.972 ( 0.972)	Data  0.274 ( 0.274)	Loss 7.8865e-02 (7.8865e-02)	Acc@1   0.93 (  0.93)	Acc@5   0.00 (  0.00)
[0.9292556638460642]
Test: [0/1]	Time  0.290 ( 0.290)	Loss 9.4402e-01 (9.4402e-01)	Acc@1   0.70 (  0.70)	Acc@5   0.00 (  0.00)
 * Acc@1 0.702 Acc@5 0.000
Test: [0/1]	Time  0.333 ( 0.333)	Loss 1.5160e-01 (1.5160e-01)	Acc@1   0.77 (  0.77)	Acc@5   0.00 (  0.00)
 * Acc@1 0.767 Acc@5 0.000
73
TRAINING
Epoch: [73][0/1]	Time  1.045 ( 1.045)	Data  0.312 ( 0.312)	Loss 7.8883e-02 (7.8883e-02)	Acc@1   0.93 (  0.93)	Acc@5   0.00 (  0.00)
[0.9293982948001789]
Test: [0/1]	Time  0.276 ( 0.276)	Loss 9.4384e-01 (9.4384e-01)	Acc@1   0.70 (  0.70)	Acc@5   0.00 (  0.00)
 * Acc@1 0.704 Acc@5 0.000
Test: [0/1]	Time  0.328 ( 0.328)	Loss 1.5141e-01 (1.5141e-01)	Acc@1   0.77 (  0.77)	Acc@5   0.00 (  0.00)
 * Acc@1 0.767 Acc@5 0.000
74
TRAINING
Epoch: [74][0/1]	Time  0.992 ( 0.992)	Data  0.288 ( 0.288)	Loss 7.8929e-02 (7.8929e-02)	Acc@1   0.93 (  0.93)	Acc@5   0.00 (  0.00)
[0.9295572667773635]
Test: [0/1]	Time  0.267 ( 0.267)	Loss 9.4365e-01 (9.4365e-01)	Acc@1   0.70 (  0.70)	Acc@5   0.00 (  0.00)
 * Acc@1 0.705 Acc@5 0.000
Test: [0/1]	Time  0.314 ( 0.314)	Loss 1.5125e-01 (1.5125e-01)	Acc@1   0.77 (  0.77)	Acc@5   0.00 (  0.00)
 * Acc@1 0.768 Acc@5 0.000
75
TRAINING
Epoch: [75][0/1]	Time  0.995 ( 0.995)	Data  0.292 ( 0.292)	Loss 7.8986e-02 (7.8986e-02)	Acc@1   0.93 (  0.93)	Acc@5   0.00 (  0.00)
[0.9297260219015036]
Test: [0/1]	Time  0.271 ( 0.271)	Loss 9.4345e-01 (9.4345e-01)	Acc@1   0.71 (  0.71)	Acc@5   0.00 (  0.00)
 * Acc@1 0.706 Acc@5 0.000
Test: [0/1]	Time  0.348 ( 0.348)	Loss 1.5111e-01 (1.5111e-01)	Acc@1   0.77 (  0.77)	Acc@5   0.00 (  0.00)
 * Acc@1 0.768 Acc@5 0.000
76
TRAINING
Epoch: [76][0/1]	Time  0.956 ( 0.956)	Data  0.244 ( 0.244)	Loss 7.9035e-02 (7.9035e-02)	Acc@1   0.93 (  0.93)	Acc@5   0.00 (  0.00)
[0.9298612928128096]
Test: [0/1]	Time  0.271 ( 0.271)	Loss 9.4323e-01 (9.4323e-01)	Acc@1   0.71 (  0.71)	Acc@5   0.00 (  0.00)
 * Acc@1 0.707 Acc@5 0.000
Test: [0/1]	Time  0.325 ( 0.325)	Loss 1.5097e-01 (1.5097e-01)	Acc@1   0.77 (  0.77)	Acc@5   0.00 (  0.00)
 * Acc@1 0.768 Acc@5 0.000
77
TRAINING
Epoch: [77][0/1]	Time  0.958 ( 0.958)	Data  0.270 ( 0.270)	Loss 7.9061e-02 (7.9061e-02)	Acc@1   0.93 (  0.93)	Acc@5   0.00 (  0.00)
[0.9299797427754644]
Test: [0/1]	Time  0.256 ( 0.256)	Loss 9.4299e-01 (9.4299e-01)	Acc@1   0.71 (  0.71)	Acc@5   0.00 (  0.00)
 * Acc@1 0.708 Acc@5 0.000
Test: [0/1]	Time  0.301 ( 0.301)	Loss 1.5083e-01 (1.5083e-01)	Acc@1   0.77 (  0.77)	Acc@5   0.00 (  0.00)
 * Acc@1 0.768 Acc@5 0.000
78
TRAINING
Epoch: [78][0/1]	Time  1.014 ( 1.014)	Data  0.300 ( 0.300)	Loss 7.9062e-02 (7.9062e-02)	Acc@1   0.93 (  0.93)	Acc@5   0.00 (  0.00)
[0.930118860600518]
Test: [0/1]	Time  0.259 ( 0.259)	Loss 9.4275e-01 (9.4275e-01)	Acc@1   0.71 (  0.71)	Acc@5   0.00 (  0.00)
 * Acc@1 0.709 Acc@5 0.000
Test: [0/1]	Time  0.308 ( 0.308)	Loss 1.5071e-01 (1.5071e-01)	Acc@1   0.77 (  0.77)	Acc@5   0.00 (  0.00)
 * Acc@1 0.769 Acc@5 0.000
79
TRAINING
Epoch: [79][0/1]	Time  1.009 ( 1.009)	Data  0.306 ( 0.306)	Loss 7.9048e-02 (7.9048e-02)	Acc@1   0.93 (  0.93)	Acc@5   0.00 (  0.00)
[0.9302735377725414]
Test: [0/1]	Time  0.262 ( 0.262)	Loss 9.4252e-01 (9.4252e-01)	Acc@1   0.71 (  0.71)	Acc@5   0.00 (  0.00)
 * Acc@1 0.710 Acc@5 0.000
Test: [0/1]	Time  0.320 ( 0.320)	Loss 1.5062e-01 (1.5062e-01)	Acc@1   0.77 (  0.77)	Acc@5   0.00 (  0.00)
 * Acc@1 0.769 Acc@5 0.000
80
TRAINING
Epoch: [80][0/1]	Time  0.940 ( 0.940)	Data  0.254 ( 0.254)	Loss 7.9032e-02 (7.9032e-02)	Acc@1   0.93 (  0.93)	Acc@5   0.00 (  0.00)
[0.9304381647504578]
Test: [0/1]	Time  0.242 ( 0.242)	Loss 9.4230e-01 (9.4230e-01)	Acc@1   0.71 (  0.71)	Acc@5   0.00 (  0.00)
 * Acc@1 0.711 Acc@5 0.000
Test: [0/1]	Time  0.295 ( 0.295)	Loss 1.5054e-01 (1.5054e-01)	Acc@1   0.77 (  0.77)	Acc@5   0.00 (  0.00)
 * Acc@1 0.769 Acc@5 0.000
81
TRAINING
Epoch: [81][0/1]	Time  0.997 ( 0.997)	Data  0.279 ( 0.279)	Loss 7.9026e-02 (7.9026e-02)	Acc@1   0.93 (  0.93)	Acc@5   0.00 (  0.00)
[0.9303830197868305]
Test: [0/1]	Time  0.260 ( 0.260)	Loss 9.4211e-01 (9.4211e-01)	Acc@1   0.71 (  0.71)	Acc@5   0.00 (  0.00)
 * Acc@1 0.711 Acc@5 0.000
Test: [0/1]	Time  0.331 ( 0.331)	Loss 1.5048e-01 (1.5048e-01)	Acc@1   0.77 (  0.77)	Acc@5   0.00 (  0.00)
 * Acc@1 0.769 Acc@5 0.000
82
TRAINING
Epoch: [82][0/1]	Time  0.991 ( 0.991)	Data  0.301 ( 0.301)	Loss 7.9030e-02 (7.9030e-02)	Acc@1   0.93 (  0.93)	Acc@5   0.00 (  0.00)
[0.9302796416226883]
Test: [0/1]	Time  0.269 ( 0.269)	Loss 9.4195e-01 (9.4195e-01)	Acc@1   0.71 (  0.71)	Acc@5   0.00 (  0.00)
 * Acc@1 0.712 Acc@5 0.000
Test: [0/1]	Time  0.325 ( 0.325)	Loss 1.5042e-01 (1.5042e-01)	Acc@1   0.77 (  0.77)	Acc@5   0.00 (  0.00)
 * Acc@1 0.770 Acc@5 0.000
83
TRAINING
Epoch: [83][0/1]	Time  1.004 ( 1.004)	Data  0.305 ( 0.305)	Loss 7.9040e-02 (7.9040e-02)	Acc@1   0.93 (  0.93)	Acc@5   0.00 (  0.00)
[0.9301474236898728]
Test: [0/1]	Time  0.279 ( 0.279)	Loss 9.4183e-01 (9.4183e-01)	Acc@1   0.71 (  0.71)	Acc@5   0.00 (  0.00)
 * Acc@1 0.713 Acc@5 0.000
Test: [0/1]	Time  0.321 ( 0.321)	Loss 1.5036e-01 (1.5036e-01)	Acc@1   0.77 (  0.77)	Acc@5   0.00 (  0.00)
 * Acc@1 0.770 Acc@5 0.000
84
TRAINING
Epoch: [84][0/1]	Time  0.961 ( 0.961)	Data  0.264 ( 0.264)	Loss 7.9050e-02 (7.9050e-02)	Acc@1   0.93 (  0.93)	Acc@5   0.00 (  0.00)
[0.9300559014889673]
Test: [0/1]	Time  0.276 ( 0.276)	Loss 9.4174e-01 (9.4174e-01)	Acc@1   0.71 (  0.71)	Acc@5   0.00 (  0.00)
 * Acc@1 0.713 Acc@5 0.000
Test: [0/1]	Time  0.315 ( 0.315)	Loss 1.5028e-01 (1.5028e-01)	Acc@1   0.77 (  0.77)	Acc@5   0.00 (  0.00)
 * Acc@1 0.770 Acc@5 0.000
85
TRAINING
Epoch: [85][0/1]	Time  0.964 ( 0.964)	Data  0.272 ( 0.272)	Loss 7.9053e-02 (7.9053e-02)	Acc@1   0.93 (  0.93)	Acc@5   0.00 (  0.00)
[0.9300262909754573]
Test: [0/1]	Time  0.291 ( 0.291)	Loss 9.4168e-01 (9.4168e-01)	Acc@1   0.71 (  0.71)	Acc@5   0.00 (  0.00)
 * Acc@1 0.714 Acc@5 0.000
Test: [0/1]	Time  0.346 ( 0.346)	Loss 1.5019e-01 (1.5019e-01)	Acc@1   0.77 (  0.77)	Acc@5   0.00 (  0.00)
 * Acc@1 0.770 Acc@5 0.000
86
TRAINING
Epoch: [86][0/1]	Time  1.003 ( 1.003)	Data  0.308 ( 0.308)	Loss 7.9050e-02 (7.9050e-02)	Acc@1   0.93 (  0.93)	Acc@5   0.00 (  0.00)
[0.929991212331003]
Test: [0/1]	Time  0.267 ( 0.267)	Loss 9.4165e-01 (9.4165e-01)	Acc@1   0.71 (  0.71)	Acc@5   0.00 (  0.00)
 * Acc@1 0.714 Acc@5 0.000
Test: [0/1]	Time  0.322 ( 0.322)	Loss 1.5009e-01 (1.5009e-01)	Acc@1   0.77 (  0.77)	Acc@5   0.00 (  0.00)
 * Acc@1 0.770 Acc@5 0.000
87
TRAINING
Epoch: [87][0/1]	Time  0.950 ( 0.950)	Data  0.248 ( 0.248)	Loss 7.9044e-02 (7.9044e-02)	Acc@1   0.93 (  0.93)	Acc@5   0.00 (  0.00)
[0.9299572247485844]
Test: [0/1]	Time  0.242 ( 0.242)	Loss 9.4164e-01 (9.4164e-01)	Acc@1   0.71 (  0.71)	Acc@5   0.00 (  0.00)
 * Acc@1 0.714 Acc@5 0.000
Test: [0/1]	Time  0.293 ( 0.293)	Loss 1.4999e-01 (1.4999e-01)	Acc@1   0.77 (  0.77)	Acc@5   0.00 (  0.00)
 * Acc@1 0.770 Acc@5 0.000
88
TRAINING
Epoch: [88][0/1]	Time  0.983 ( 0.983)	Data  0.287 ( 0.287)	Loss 7.9039e-02 (7.9039e-02)	Acc@1   0.93 (  0.93)	Acc@5   0.00 (  0.00)
[0.9299997479236848]
Test: [0/1]	Time  0.261 ( 0.261)	Loss 9.4163e-01 (9.4163e-01)	Acc@1   0.71 (  0.71)	Acc@5   0.00 (  0.00)
 * Acc@1 0.715 Acc@5 0.000
Test: [0/1]	Time  0.309 ( 0.309)	Loss 1.4991e-01 (1.4991e-01)	Acc@1   0.77 (  0.77)	Acc@5   0.00 (  0.00)
 * Acc@1 0.771 Acc@5 0.000
89
TRAINING
Epoch: [89][0/1]	Time  0.954 ( 0.954)	Data  0.256 ( 0.256)	Loss 7.9036e-02 (7.9036e-02)	Acc@1   0.93 (  0.93)	Acc@5   0.00 (  0.00)
[0.9300274472509733]
Test: [0/1]	Time  0.284 ( 0.284)	Loss 9.4163e-01 (9.4163e-01)	Acc@1   0.71 (  0.71)	Acc@5   0.00 (  0.00)
 * Acc@1 0.715 Acc@5 0.000
Test: [0/1]	Time  0.324 ( 0.324)	Loss 1.4983e-01 (1.4983e-01)	Acc@1   0.77 (  0.77)	Acc@5   0.00 (  0.00)
 * Acc@1 0.771 Acc@5 0.000
90
TRAINING
Epoch: [90][0/1]	Time  0.958 ( 0.958)	Data  0.259 ( 0.259)	Loss 7.9033e-02 (7.9033e-02)	Acc@1   0.93 (  0.93)	Acc@5   0.00 (  0.00)
[0.930078308315522]
Test: [0/1]	Time  0.249 ( 0.249)	Loss 9.4163e-01 (9.4163e-01)	Acc@1   0.71 (  0.71)	Acc@5   0.00 (  0.00)
 * Acc@1 0.714 Acc@5 0.000
Test: [0/1]	Time  0.299 ( 0.299)	Loss 1.4977e-01 (1.4977e-01)	Acc@1   0.77 (  0.77)	Acc@5   0.00 (  0.00)
 * Acc@1 0.771 Acc@5 0.000
91
TRAINING
Epoch: [91][0/1]	Time  0.948 ( 0.948)	Data  0.245 ( 0.245)	Loss 7.9026e-02 (7.9026e-02)	Acc@1   0.93 (  0.93)	Acc@5   0.00 (  0.00)
[0.9301696289426882]
Test: [0/1]	Time  0.243 ( 0.243)	Loss 9.4162e-01 (9.4162e-01)	Acc@1   0.71 (  0.71)	Acc@5   0.00 (  0.00)
 * Acc@1 0.714 Acc@5 0.000
Test: [0/1]	Time  0.298 ( 0.298)	Loss 1.4972e-01 (1.4972e-01)	Acc@1   0.77 (  0.77)	Acc@5   0.00 (  0.00)
 * Acc@1 0.771 Acc@5 0.000
92
TRAINING
Epoch: [92][0/1]	Time  0.956 ( 0.956)	Data  0.266 ( 0.266)	Loss 7.9012e-02 (7.9012e-02)	Acc@1   0.93 (  0.93)	Acc@5   0.00 (  0.00)
[0.9302980635011029]
Test: [0/1]	Time  0.258 ( 0.258)	Loss 9.4160e-01 (9.4160e-01)	Acc@1   0.71 (  0.71)	Acc@5   0.00 (  0.00)
 * Acc@1 0.714 Acc@5 0.000
Test: [0/1]	Time  0.308 ( 0.308)	Loss 1.4969e-01 (1.4969e-01)	Acc@1   0.77 (  0.77)	Acc@5   0.00 (  0.00)
 * Acc@1 0.771 Acc@5 0.000
93
TRAINING
Epoch: [93][0/1]	Time  0.960 ( 0.960)	Data  0.262 ( 0.262)	Loss 7.8989e-02 (7.8989e-02)	Acc@1   0.93 (  0.93)	Acc@5   0.00 (  0.00)
[0.9304032932176868]
Test: [0/1]	Time  0.268 ( 0.268)	Loss 9.4157e-01 (9.4157e-01)	Acc@1   0.71 (  0.71)	Acc@5   0.00 (  0.00)
 * Acc@1 0.714 Acc@5 0.000
Test: [0/1]	Time  0.314 ( 0.314)	Loss 1.4966e-01 (1.4966e-01)	Acc@1   0.77 (  0.77)	Acc@5   0.00 (  0.00)
 * Acc@1 0.771 Acc@5 0.000
94
TRAINING
Epoch: [94][0/1]	Time  0.945 ( 0.945)	Data  0.257 ( 0.257)	Loss 7.8960e-02 (7.8960e-02)	Acc@1   0.93 (  0.93)	Acc@5   0.00 (  0.00)
[0.9304385680855405]
Test: [0/1]	Time  0.261 ( 0.261)	Loss 9.4153e-01 (9.4153e-01)	Acc@1   0.71 (  0.71)	Acc@5   0.00 (  0.00)
 * Acc@1 0.714 Acc@5 0.000
Test: [0/1]	Time  0.325 ( 0.325)	Loss 1.4964e-01 (1.4964e-01)	Acc@1   0.77 (  0.77)	Acc@5   0.00 (  0.00)
 * Acc@1 0.771 Acc@5 0.000
95
TRAINING
Epoch: [95][0/1]	Time  0.982 ( 0.982)	Data  0.288 ( 0.288)	Loss 7.8927e-02 (7.8927e-02)	Acc@1   0.93 (  0.93)	Acc@5   0.00 (  0.00)
[0.9304744030991073]
Test: [0/1]	Time  0.260 ( 0.260)	Loss 9.4150e-01 (9.4150e-01)	Acc@1   0.71 (  0.71)	Acc@5   0.00 (  0.00)
 * Acc@1 0.714 Acc@5 0.000
Test: [0/1]	Time  0.308 ( 0.308)	Loss 1.4963e-01 (1.4963e-01)	Acc@1   0.77 (  0.77)	Acc@5   0.00 (  0.00)
 * Acc@1 0.772 Acc@5 0.000
96
TRAINING
Epoch: [96][0/1]	Time  0.953 ( 0.953)	Data  0.264 ( 0.264)	Loss 7.8895e-02 (7.8895e-02)	Acc@1   0.93 (  0.93)	Acc@5   0.00 (  0.00)
[0.930509351301624]
Test: [0/1]	Time  0.251 ( 0.251)	Loss 9.4146e-01 (9.4146e-01)	Acc@1   0.71 (  0.71)	Acc@5   0.00 (  0.00)
 * Acc@1 0.714 Acc@5 0.000
Test: [0/1]	Time  0.301 ( 0.301)	Loss 1.4962e-01 (1.4962e-01)	Acc@1   0.77 (  0.77)	Acc@5   0.00 (  0.00)
 * Acc@1 0.772 Acc@5 0.000
97
TRAINING
Epoch: [97][0/1]	Time  0.976 ( 0.976)	Data  0.292 ( 0.292)	Loss 7.8866e-02 (7.8866e-02)	Acc@1   0.93 (  0.93)	Acc@5   0.00 (  0.00)
[0.9305427390614753]
Test: [0/1]	Time  0.265 ( 0.265)	Loss 9.4143e-01 (9.4143e-01)	Acc@1   0.71 (  0.71)	Acc@5   0.00 (  0.00)
 * Acc@1 0.714 Acc@5 0.000
Test: [0/1]	Time  0.317 ( 0.317)	Loss 1.4962e-01 (1.4962e-01)	Acc@1   0.77 (  0.77)	Acc@5   0.00 (  0.00)
 * Acc@1 0.772 Acc@5 0.000
98
TRAINING
Epoch: [98][0/1]	Time  0.959 ( 0.959)	Data  0.251 ( 0.251)	Loss 7.8839e-02 (7.8839e-02)	Acc@1   0.93 (  0.93)	Acc@5   0.00 (  0.00)
[0.9305746102871066]
Test: [0/1]	Time  0.241 ( 0.241)	Loss 9.4140e-01 (9.4140e-01)	Acc@1   0.71 (  0.71)	Acc@5   0.00 (  0.00)
 * Acc@1 0.714 Acc@5 0.000
Test: [0/1]	Time  0.321 ( 0.321)	Loss 1.4961e-01 (1.4961e-01)	Acc@1   0.77 (  0.77)	Acc@5   0.00 (  0.00)
 * Acc@1 0.772 Acc@5 0.000
99
TRAINING
Epoch: [99][0/1]	Time  0.967 ( 0.967)	Data  0.268 ( 0.268)	Loss 7.8815e-02 (7.8815e-02)	Acc@1   0.93 (  0.93)	Acc@5   0.00 (  0.00)
[0.9306053996120072]
Test: [0/1]	Time  0.259 ( 0.259)	Loss 9.4139e-01 (9.4139e-01)	Acc@1   0.71 (  0.71)	Acc@5   0.00 (  0.00)
 * Acc@1 0.714 Acc@5 0.000
Test: [0/1]	Time  0.308 ( 0.308)	Loss 1.4959e-01 (1.4959e-01)	Acc@1   0.77 (  0.77)	Acc@5   0.00 (  0.00)
 * Acc@1 0.772 Acc@5 0.000
=> using pre-trained model 'st_resnet'
s/ohp/session_1
torch.Size([640, 3, 224, 224])
(640, 22)
attach reg
0
TRAINING
/home/helenr6/Adv_mapper/train_split.py:125: UserWarning: You have chosen to seed training. This will turn on the CUDNN deterministic setting, which can slow down your training considerably! You may see unexpected behavior when restarting from checkpoints.
  warnings.warn('You have chosen to seed training. '
/localscratch/helenr6.6279052.0/env/lib/python3.7/site-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  cpuset_checked))
Epoch: [0][0/1]	Time  5.203 ( 5.203)	Data  1.802 ( 1.802)	Loss 1.7121e+00 (1.7121e+00)	Acc@1   0.03 (  0.03)	Acc@5   0.00 (  0.00)
[0.034467714381834616]
Test: [0/1]	Time  0.452 ( 0.452)	Loss 1.1069e+00 (1.1069e+00)	Acc@1   0.02 (  0.02)	Acc@5   0.00 (  0.00)
 * Acc@1 0.015 Acc@5 0.000
Test: [0/1]	Time  0.570 ( 0.570)	Loss 9.6530e-01 (9.6530e-01)	Acc@1   0.02 (  0.02)	Acc@5   0.00 (  0.00)
 * Acc@1 0.025 Acc@5 0.000
1
TRAINING
Epoch: [1][0/1]	Time  0.941 ( 0.941)	Data  0.244 ( 0.244)	Loss 1.6307e+00 (1.6307e+00)	Acc@1   0.04 (  0.04)	Acc@5   0.00 (  0.00)
[0.03801813313495149]
Test: [0/1]	Time  0.247 ( 0.247)	Loss 1.0988e+00 (1.0988e+00)	Acc@1   0.01 (  0.01)	Acc@5   0.00 (  0.00)
 * Acc@1 0.013 Acc@5 0.000
Test: [0/1]	Time  0.332 ( 0.332)	Loss 9.0664e-01 (9.0664e-01)	Acc@1   0.03 (  0.03)	Acc@5   0.00 (  0.00)
 * Acc@1 0.031 Acc@5 0.000
2
TRAINING
Epoch: [2][0/1]	Time  0.940 ( 0.940)	Data  0.247 ( 0.247)	Loss 1.5081e+00 (1.5081e+00)	Acc@1   0.04 (  0.04)	Acc@5   0.00 (  0.00)
[0.044859484770353356]
Test: [0/1]	Time  0.253 ( 0.253)	Loss 1.0914e+00 (1.0914e+00)	Acc@1   0.02 (  0.02)	Acc@5   0.00 (  0.00)
 * Acc@1 0.024 Acc@5 0.000
Test: [0/1]	Time  0.305 ( 0.305)	Loss 8.5473e-01 (8.5473e-01)	Acc@1   0.04 (  0.04)	Acc@5   0.00 (  0.00)
 * Acc@1 0.044 Acc@5 0.000
3
TRAINING
Epoch: [3][0/1]	Time  0.954 ( 0.954)	Data  0.250 ( 0.250)	Loss 1.3889e+00 (1.3889e+00)	Acc@1   0.05 (  0.05)	Acc@5   0.00 (  0.00)
[0.05250560172122129]
Test: [0/1]	Time  0.247 ( 0.247)	Loss 1.0860e+00 (1.0860e+00)	Acc@1   0.04 (  0.04)	Acc@5   0.00 (  0.00)
 * Acc@1 0.037 Acc@5 0.000
Test: [0/1]	Time  0.296 ( 0.296)	Loss 8.2302e-01 (8.2302e-01)	Acc@1   0.06 (  0.06)	Acc@5   0.00 (  0.00)
 * Acc@1 0.056 Acc@5 0.000
4
TRAINING
Epoch: [4][0/1]	Time  0.958 ( 0.958)	Data  0.251 ( 0.251)	Loss 1.2980e+00 (1.2980e+00)	Acc@1   0.06 (  0.06)	Acc@5   0.00 (  0.00)
[0.06150535225084462]
Test: [0/1]	Time  0.247 ( 0.247)	Loss 1.0816e+00 (1.0816e+00)	Acc@1   0.05 (  0.05)	Acc@5   0.00 (  0.00)
 * Acc@1 0.051 Acc@5 0.000
Test: [0/1]	Time  0.292 ( 0.292)	Loss 8.0866e-01 (8.0866e-01)	Acc@1   0.06 (  0.06)	Acc@5   0.00 (  0.00)
 * Acc@1 0.064 Acc@5 0.000
5
TRAINING
Epoch: [5][0/1]	Time  0.995 ( 0.995)	Data  0.283 ( 0.283)	Loss 1.2324e+00 (1.2324e+00)	Acc@1   0.07 (  0.07)	Acc@5   0.00 (  0.00)
[0.0725932990821259]
Test: [0/1]	Time  0.257 ( 0.257)	Loss 1.0760e+00 (1.0760e+00)	Acc@1   0.06 (  0.06)	Acc@5   0.00 (  0.00)
 * Acc@1 0.065 Acc@5 0.000
Test: [0/1]	Time  0.314 ( 0.314)	Loss 7.9722e-01 (7.9722e-01)	Acc@1   0.07 (  0.07)	Acc@5   0.00 (  0.00)
 * Acc@1 0.074 Acc@5 0.000
6
TRAINING
Epoch: [6][0/1]	Time  0.985 ( 0.985)	Data  0.288 ( 0.288)	Loss 1.1708e+00 (1.1708e+00)	Acc@1   0.09 (  0.09)	Acc@5   0.00 (  0.00)
[0.0869487208599634]
Test: [0/1]	Time  0.260 ( 0.260)	Loss 1.0674e+00 (1.0674e+00)	Acc@1   0.08 (  0.08)	Acc@5   0.00 (  0.00)
 * Acc@1 0.081 Acc@5 0.000
Test: [0/1]	Time  0.323 ( 0.323)	Loss 7.7368e-01 (7.7368e-01)	Acc@1   0.08 (  0.08)	Acc@5   0.00 (  0.00)
 * Acc@1 0.085 Acc@5 0.000
7
TRAINING
Epoch: [7][0/1]	Time  0.965 ( 0.965)	Data  0.253 ( 0.253)	Loss 1.0919e+00 (1.0919e+00)	Acc@1   0.11 (  0.11)	Acc@5   0.00 (  0.00)
[0.10788284254713074]
Test: [0/1]	Time  0.246 ( 0.246)	Loss 1.0554e+00 (1.0554e+00)	Acc@1   0.13 (  0.13)	Acc@5   0.00 (  0.00)
 * Acc@1 0.126 Acc@5 0.000
Test: [0/1]	Time  0.293 ( 0.293)	Loss 7.3187e-01 (7.3187e-01)	Acc@1   0.10 (  0.10)	Acc@5   0.00 (  0.00)
 * Acc@1 0.097 Acc@5 0.000
8
TRAINING
Epoch: [8][0/1]	Time  0.990 ( 0.990)	Data  0.253 ( 0.253)	Loss 9.8860e-01 (9.8860e-01)	Acc@1   0.13 (  0.13)	Acc@5   0.00 (  0.00)
[0.13039028306957787]
Test: [0/1]	Time  0.243 ( 0.243)	Loss 1.0416e+00 (1.0416e+00)	Acc@1   0.16 (  0.16)	Acc@5   0.00 (  0.00)
 * Acc@1 0.156 Acc@5 0.000
Test: [0/1]	Time  0.296 ( 0.296)	Loss 6.7750e-01 (6.7750e-01)	Acc@1   0.11 (  0.11)	Acc@5   0.00 (  0.00)
 * Acc@1 0.113 Acc@5 0.000
9
TRAINING
Epoch: [9][0/1]	Time  0.967 ( 0.967)	Data  0.252 ( 0.252)	Loss 8.7078e-01 (8.7078e-01)	Acc@1   0.15 (  0.15)	Acc@5   0.00 (  0.00)
[0.149696692813899]
Test: [0/1]	Time  0.265 ( 0.265)	Loss 1.0286e+00 (1.0286e+00)	Acc@1   0.17 (  0.17)	Acc@5   0.00 (  0.00)
 * Acc@1 0.174 Acc@5 0.000
Test: [0/1]	Time  0.312 ( 0.312)	Loss 6.2328e-01 (6.2328e-01)	Acc@1   0.13 (  0.13)	Acc@5   0.00 (  0.00)
 * Acc@1 0.127 Acc@5 0.000
10
TRAINING
Epoch: [10][0/1]	Time  0.941 ( 0.941)	Data  0.251 ( 0.251)	Loss 7.5736e-01 (7.5736e-01)	Acc@1   0.18 (  0.18)	Acc@5   0.00 (  0.00)
[0.17884449286491907]
Test: [0/1]	Time  0.288 ( 0.288)	Loss 1.0185e+00 (1.0185e+00)	Acc@1   0.18 (  0.18)	Acc@5   0.00 (  0.00)
 * Acc@1 0.183 Acc@5 0.000
Test: [0/1]	Time  0.341 ( 0.341)	Loss 5.8060e-01 (5.8060e-01)	Acc@1   0.14 (  0.14)	Acc@5   0.00 (  0.00)
 * Acc@1 0.137 Acc@5 0.000
11
TRAINING
Epoch: [11][0/1]	Time  0.981 ( 0.981)	Data  0.279 ( 0.279)	Loss 6.6410e-01 (6.6410e-01)	Acc@1   0.20 (  0.20)	Acc@5   0.00 (  0.00)
[0.2028639597569216]
Test: [0/1]	Time  0.277 ( 0.277)	Loss 1.0119e+00 (1.0119e+00)	Acc@1   0.22 (  0.22)	Acc@5   0.00 (  0.00)
 * Acc@1 0.222 Acc@5 0.000
Test: [0/1]	Time  0.314 ( 0.314)	Loss 5.5290e-01 (5.5290e-01)	Acc@1   0.15 (  0.15)	Acc@5   0.00 (  0.00)
 * Acc@1 0.147 Acc@5 0.000
12
TRAINING
Epoch: [12][0/1]	Time  0.993 ( 0.993)	Data  0.296 ( 0.296)	Loss 5.9529e-01 (5.9529e-01)	Acc@1   0.23 (  0.23)	Acc@5   0.00 (  0.00)
[0.22965426506140074]
Test: [0/1]	Time  0.244 ( 0.244)	Loss 1.0078e+00 (1.0078e+00)	Acc@1   0.25 (  0.25)	Acc@5   0.00 (  0.00)
 * Acc@1 0.255 Acc@5 0.000
Test: [0/1]	Time  0.294 ( 0.294)	Loss 5.3488e-01 (5.3488e-01)	Acc@1   0.16 (  0.16)	Acc@5   0.00 (  0.00)
 * Acc@1 0.162 Acc@5 0.000
13
TRAINING
Epoch: [13][0/1]	Time  1.009 ( 1.009)	Data  0.297 ( 0.297)	Loss 5.4355e-01 (5.4355e-01)	Acc@1   0.26 (  0.26)	Acc@5   0.00 (  0.00)
[0.2618560855618063]
Test: [0/1]	Time  0.245 ( 0.245)	Loss 1.0042e+00 (1.0042e+00)	Acc@1   0.27 (  0.27)	Acc@5   0.00 (  0.00)
 * Acc@1 0.265 Acc@5 0.000
Test: [0/1]	Time  0.296 ( 0.296)	Loss 5.1679e-01 (5.1679e-01)	Acc@1   0.18 (  0.18)	Acc@5   0.00 (  0.00)
 * Acc@1 0.180 Acc@5 0.000
14
TRAINING
Epoch: [14][0/1]	Time  1.007 ( 1.007)	Data  0.303 ( 0.303)	Loss 4.9635e-01 (4.9635e-01)	Acc@1   0.30 (  0.30)	Acc@5   0.00 (  0.00)
[0.2982430585131278]
Test: [0/1]	Time  0.266 ( 0.266)	Loss 9.9936e-01 (9.9936e-01)	Acc@1   0.29 (  0.29)	Acc@5   0.00 (  0.00)
 * Acc@1 0.292 Acc@5 0.000
Test: [0/1]	Time  0.324 ( 0.324)	Loss 4.9086e-01 (4.9086e-01)	Acc@1   0.20 (  0.20)	Acc@5   0.00 (  0.00)
 * Acc@1 0.204 Acc@5 0.000
15
TRAINING
Epoch: [15][0/1]	Time  0.956 ( 0.956)	Data  0.251 ( 0.251)	Loss 4.4420e-01 (4.4420e-01)	Acc@1   0.33 (  0.33)	Acc@5   0.00 (  0.00)
[0.33302427428725934]
Test: [0/1]	Time  0.255 ( 0.255)	Loss 9.9270e-01 (9.9270e-01)	Acc@1   0.34 (  0.34)	Acc@5   0.00 (  0.00)
 * Acc@1 0.336 Acc@5 0.000
Test: [0/1]	Time  0.340 ( 0.340)	Loss 4.5550e-01 (4.5550e-01)	Acc@1   0.22 (  0.22)	Acc@5   0.00 (  0.00)
 * Acc@1 0.223 Acc@5 0.000
16
TRAINING
Epoch: [16][0/1]	Time  0.952 ( 0.952)	Data  0.246 ( 0.246)	Loss 3.8556e-01 (3.8556e-01)	Acc@1   0.37 (  0.37)	Acc@5   0.00 (  0.00)
[0.36844240603084033]
Test: [0/1]	Time  0.246 ( 0.246)	Loss 9.8471e-01 (9.8471e-01)	Acc@1   0.41 (  0.41)	Acc@5   0.00 (  0.00)
 * Acc@1 0.414 Acc@5 0.000
Test: [0/1]	Time  0.298 ( 0.298)	Loss 4.1530e-01 (4.1530e-01)	Acc@1   0.24 (  0.24)	Acc@5   0.00 (  0.00)
 * Acc@1 0.242 Acc@5 0.000
17
TRAINING
Epoch: [17][0/1]	Time  0.981 ( 0.981)	Data  0.258 ( 0.258)	Loss 3.2613e-01 (3.2613e-01)	Acc@1   0.40 (  0.40)	Acc@5   0.00 (  0.00)
[0.4048418926732411]
Test: [0/1]	Time  0.269 ( 0.269)	Loss 9.7654e-01 (9.7654e-01)	Acc@1   0.48 (  0.48)	Acc@5   0.00 (  0.00)
 * Acc@1 0.477 Acc@5 0.000
Test: [0/1]	Time  0.322 ( 0.322)	Loss 3.7747e-01 (3.7747e-01)	Acc@1   0.26 (  0.26)	Acc@5   0.00 (  0.00)
 * Acc@1 0.261 Acc@5 0.000
18
TRAINING
Epoch: [18][0/1]	Time  0.933 ( 0.933)	Data  0.248 ( 0.248)	Loss 2.7408e-01 (2.7408e-01)	Acc@1   0.44 (  0.44)	Acc@5   0.00 (  0.00)
[0.4421715011322923]
Test: [0/1]	Time  0.270 ( 0.270)	Loss 9.6924e-01 (9.6924e-01)	Acc@1   0.51 (  0.51)	Acc@5   0.00 (  0.00)
 * Acc@1 0.514 Acc@5 0.000
Test: [0/1]	Time  0.319 ( 0.319)	Loss 3.4728e-01 (3.4728e-01)	Acc@1   0.28 (  0.28)	Acc@5   0.00 (  0.00)
 * Acc@1 0.281 Acc@5 0.000
19
TRAINING
Epoch: [19][0/1]	Time  0.968 ( 0.968)	Data  0.253 ( 0.253)	Loss 2.3473e-01 (2.3473e-01)	Acc@1   0.48 (  0.48)	Acc@5   0.00 (  0.00)
[0.48197515454073697]
Test: [0/1]	Time  0.244 ( 0.244)	Loss 9.6334e-01 (9.6334e-01)	Acc@1   0.52 (  0.52)	Acc@5   0.00 (  0.00)
 * Acc@1 0.522 Acc@5 0.000
Test: [0/1]	Time  0.296 ( 0.296)	Loss 3.2558e-01 (3.2558e-01)	Acc@1   0.30 (  0.30)	Acc@5   0.00 (  0.00)
 * Acc@1 0.301 Acc@5 0.000
20
TRAINING
Epoch: [20][0/1]	Time  0.966 ( 0.966)	Data  0.258 ( 0.258)	Loss 2.0791e-01 (2.0791e-01)	Acc@1   0.53 (  0.53)	Acc@5   0.00 (  0.00)
[0.5256641700131771]
Test: [0/1]	Time  0.241 ( 0.241)	Loss 9.5873e-01 (9.5873e-01)	Acc@1   0.53 (  0.53)	Acc@5   0.00 (  0.00)
 * Acc@1 0.527 Acc@5 0.000
Test: [0/1]	Time  0.293 ( 0.293)	Loss 3.0930e-01 (3.0930e-01)	Acc@1   0.32 (  0.32)	Acc@5   0.00 (  0.00)
 * Acc@1 0.321 Acc@5 0.000
21
TRAINING
Epoch: [21][0/1]	Time  0.946 ( 0.946)	Data  0.250 ( 0.250)	Loss 1.8900e-01 (1.8900e-01)	Acc@1   0.58 (  0.58)	Acc@5   0.00 (  0.00)
[0.5770259633110155]
Test: [0/1]	Time  0.244 ( 0.244)	Loss 9.5505e-01 (9.5505e-01)	Acc@1   0.53 (  0.53)	Acc@5   0.00 (  0.00)
 * Acc@1 0.528 Acc@5 0.000
Test: [0/1]	Time  0.294 ( 0.294)	Loss 2.9413e-01 (2.9413e-01)	Acc@1   0.34 (  0.34)	Acc@5   0.00 (  0.00)
 * Acc@1 0.339 Acc@5 0.000
22
TRAINING
Epoch: [22][0/1]	Time  0.990 ( 0.990)	Data  0.271 ( 0.271)	Loss 1.7230e-01 (1.7230e-01)	Acc@1   0.62 (  0.62)	Acc@5   0.00 (  0.00)
[0.6228156639318798]
Test: [0/1]	Time  0.311 ( 0.311)	Loss 9.5206e-01 (9.5206e-01)	Acc@1   0.53 (  0.53)	Acc@5   0.00 (  0.00)
 * Acc@1 0.525 Acc@5 0.000
Test: [0/1]	Time  0.310 ( 0.310)	Loss 2.7737e-01 (2.7737e-01)	Acc@1   0.36 (  0.36)	Acc@5   0.00 (  0.00)
 * Acc@1 0.360 Acc@5 0.000
23
TRAINING
Epoch: [23][0/1]	Time  0.935 ( 0.935)	Data  0.246 ( 0.246)	Loss 1.5439e-01 (1.5439e-01)	Acc@1   0.67 (  0.67)	Acc@5   0.00 (  0.00)
[0.6654224008246508]
Test: [0/1]	Time  0.243 ( 0.243)	Loss 9.4982e-01 (9.4982e-01)	Acc@1   0.52 (  0.52)	Acc@5   0.00 (  0.00)
 * Acc@1 0.519 Acc@5 0.000
Test: [0/1]	Time  0.294 ( 0.294)	Loss 2.5929e-01 (2.5929e-01)	Acc@1   0.38 (  0.38)	Acc@5   0.00 (  0.00)
 * Acc@1 0.382 Acc@5 0.000
24
TRAINING
Epoch: [24][0/1]	Time  0.984 ( 0.984)	Data  0.282 ( 0.282)	Loss 1.3544e-01 (1.3544e-01)	Acc@1   0.71 (  0.71)	Acc@5   0.00 (  0.00)
[0.705783163385886]
Test: [0/1]	Time  0.261 ( 0.261)	Loss 9.4854e-01 (9.4854e-01)	Acc@1   0.52 (  0.52)	Acc@5   0.00 (  0.00)
 * Acc@1 0.520 Acc@5 0.000
Test: [0/1]	Time  0.308 ( 0.308)	Loss 2.4226e-01 (2.4226e-01)	Acc@1   0.40 (  0.40)	Acc@5   0.00 (  0.00)
 * Acc@1 0.398 Acc@5 0.000
25
TRAINING
Epoch: [25][0/1]	Time  0.956 ( 0.956)	Data  0.249 ( 0.249)	Loss 1.1819e-01 (1.1819e-01)	Acc@1   0.74 (  0.74)	Acc@5   0.00 (  0.00)
[0.7439379306848433]
Test: [0/1]	Time  0.244 ( 0.244)	Loss 9.4831e-01 (9.4831e-01)	Acc@1   0.54 (  0.54)	Acc@5   0.00 (  0.00)
 * Acc@1 0.535 Acc@5 0.000
Test: [0/1]	Time  0.292 ( 0.292)	Loss 2.2883e-01 (2.2883e-01)	Acc@1   0.41 (  0.41)	Acc@5   0.00 (  0.00)
 * Acc@1 0.413 Acc@5 0.000
26
TRAINING
Epoch: [26][0/1]	Time  0.967 ( 0.967)	Data  0.254 ( 0.254)	Loss 1.0556e-01 (1.0556e-01)	Acc@1   0.78 (  0.78)	Acc@5   0.00 (  0.00)
[0.7782816885520436]
Test: [0/1]	Time  0.248 ( 0.248)	Loss 9.4897e-01 (9.4897e-01)	Acc@1   0.55 (  0.55)	Acc@5   0.00 (  0.00)
 * Acc@1 0.547 Acc@5 0.000
Test: [0/1]	Time  0.319 ( 0.319)	Loss 2.1994e-01 (2.1994e-01)	Acc@1   0.44 (  0.44)	Acc@5   0.00 (  0.00)
 * Acc@1 0.437 Acc@5 0.000
27
TRAINING
Epoch: [27][0/1]	Time  0.946 ( 0.946)	Data  0.245 ( 0.245)	Loss 9.8638e-02 (9.8638e-02)	Acc@1   0.80 (  0.80)	Acc@5   0.00 (  0.00)
[0.8030955079703141]
Test: [0/1]	Time  0.271 ( 0.271)	Loss 9.5002e-01 (9.5002e-01)	Acc@1   0.56 (  0.56)	Acc@5   0.00 (  0.00)
 * Acc@1 0.556 Acc@5 0.000
Test: [0/1]	Time  0.313 ( 0.313)	Loss 2.1446e-01 (2.1446e-01)	Acc@1   0.46 (  0.46)	Acc@5   0.00 (  0.00)
 * Acc@1 0.462 Acc@5 0.000
28
TRAINING
Epoch: [28][0/1]	Time  0.996 ( 0.996)	Data  0.303 ( 0.303)	Loss 9.6135e-02 (9.6135e-02)	Acc@1   0.82 (  0.82)	Acc@5   0.00 (  0.00)
[0.820481722443801]
Test: [0/1]	Time  0.275 ( 0.275)	Loss 9.5086e-01 (9.5086e-01)	Acc@1   0.56 (  0.56)	Acc@5   0.00 (  0.00)
 * Acc@1 0.561 Acc@5 0.000
Test: [0/1]	Time  0.303 ( 0.303)	Loss 2.0997e-01 (2.0997e-01)	Acc@1   0.49 (  0.49)	Acc@5   0.00 (  0.00)
 * Acc@1 0.486 Acc@5 0.000
29
TRAINING
Epoch: [29][0/1]	Time  0.955 ( 0.955)	Data  0.249 ( 0.249)	Loss 9.5343e-02 (9.5343e-02)	Acc@1   0.84 (  0.84)	Acc@5   0.00 (  0.00)
[0.8361712655765168]
Test: [0/1]	Time  0.241 ( 0.241)	Loss 9.5103e-01 (9.5103e-01)	Acc@1   0.57 (  0.57)	Acc@5   0.00 (  0.00)
 * Acc@1 0.565 Acc@5 0.000
Test: [0/1]	Time  0.294 ( 0.294)	Loss 2.0430e-01 (2.0430e-01)	Acc@1   0.51 (  0.51)	Acc@5   0.00 (  0.00)
 * Acc@1 0.510 Acc@5 0.000
30
TRAINING
Epoch: [30][0/1]	Time  0.954 ( 0.954)	Data  0.251 ( 0.251)	Loss 9.3790e-02 (9.3790e-02)	Acc@1   0.85 (  0.85)	Acc@5   0.00 (  0.00)
[0.850137791396602]
Test: [0/1]	Time  0.241 ( 0.241)	Loss 9.5038e-01 (9.5038e-01)	Acc@1   0.57 (  0.57)	Acc@5   0.00 (  0.00)
 * Acc@1 0.568 Acc@5 0.000
Test: [0/1]	Time  0.317 ( 0.317)	Loss 1.9668e-01 (1.9668e-01)	Acc@1   0.53 (  0.53)	Acc@5   0.00 (  0.00)
 * Acc@1 0.534 Acc@5 0.000
31
TRAINING
Epoch: [31][0/1]	Time  0.998 ( 0.998)	Data  0.305 ( 0.305)	Loss 9.0476e-02 (9.0476e-02)	Acc@1   0.86 (  0.86)	Acc@5   0.00 (  0.00)
[0.8592852868385943]
Test: [0/1]	Time  0.274 ( 0.274)	Loss 9.4911e-01 (9.4911e-01)	Acc@1   0.57 (  0.57)	Acc@5   0.00 (  0.00)
 * Acc@1 0.569 Acc@5 0.000
Test: [0/1]	Time  0.320 ( 0.320)	Loss 1.8786e-01 (1.8786e-01)	Acc@1   0.56 (  0.56)	Acc@5   0.00 (  0.00)
 * Acc@1 0.556 Acc@5 0.000
32
TRAINING
Epoch: [32][0/1]	Time  0.996 ( 0.996)	Data  0.293 ( 0.293)	Loss 8.6058e-02 (8.6058e-02)	Acc@1   0.87 (  0.87)	Acc@5   0.00 (  0.00)
[0.8678683119016921]
Test: [0/1]	Time  0.270 ( 0.270)	Loss 9.4760e-01 (9.4760e-01)	Acc@1   0.57 (  0.57)	Acc@5   0.00 (  0.00)
 * Acc@1 0.570 Acc@5 0.000
Test: [0/1]	Time  0.321 ( 0.321)	Loss 1.7945e-01 (1.7945e-01)	Acc@1   0.58 (  0.58)	Acc@5   0.00 (  0.00)
 * Acc@1 0.577 Acc@5 0.000
33
TRAINING
Epoch: [33][0/1]	Time  0.946 ( 0.946)	Data  0.249 ( 0.249)	Loss 8.2065e-02 (8.2065e-02)	Acc@1   0.87 (  0.87)	Acc@5   0.00 (  0.00)
[0.8728115111676104]
Test: [0/1]	Time  0.243 ( 0.243)	Loss 9.4627e-01 (9.4627e-01)	Acc@1   0.57 (  0.57)	Acc@5   0.00 (  0.00)
 * Acc@1 0.571 Acc@5 0.000
Test: [0/1]	Time  0.299 ( 0.299)	Loss 1.7280e-01 (1.7280e-01)	Acc@1   0.60 (  0.60)	Acc@5   0.00 (  0.00)
 * Acc@1 0.597 Acc@5 0.000
34
TRAINING
Epoch: [34][0/1]	Time  1.092 ( 1.092)	Data  0.336 ( 0.336)	Loss 7.9779e-02 (7.9779e-02)	Acc@1   0.87 (  0.87)	Acc@5   0.00 (  0.00)
[0.8745567011463535]
Test: [0/1]	Time  0.278 ( 0.278)	Loss 9.4536e-01 (9.4536e-01)	Acc@1   0.57 (  0.57)	Acc@5   0.00 (  0.00)
 * Acc@1 0.571 Acc@5 0.000
Test: [0/1]	Time  0.328 ( 0.328)	Loss 1.6837e-01 (1.6837e-01)	Acc@1   0.62 (  0.62)	Acc@5   0.00 (  0.00)
 * Acc@1 0.619 Acc@5 0.000
35
TRAINING
Epoch: [35][0/1]	Time  1.003 ( 1.003)	Data  0.313 ( 0.313)	Loss 7.9494e-02 (7.9494e-02)	Acc@1   0.88 (  0.88)	Acc@5   0.00 (  0.00)
[0.8751510555026187]
Test: [0/1]	Time  0.274 ( 0.274)	Loss 9.4497e-01 (9.4497e-01)	Acc@1   0.57 (  0.57)	Acc@5   0.00 (  0.00)
 * Acc@1 0.572 Acc@5 0.000
Test: [0/1]	Time  0.332 ( 0.332)	Loss 1.6566e-01 (1.6566e-01)	Acc@1   0.64 (  0.64)	Acc@5   0.00 (  0.00)
 * Acc@1 0.640 Acc@5 0.000
36
TRAINING
Epoch: [36][0/1]	Time  0.954 ( 0.954)	Data  0.257 ( 0.257)	Loss 8.0502e-02 (8.0502e-02)	Acc@1   0.88 (  0.88)	Acc@5   0.00 (  0.00)
[0.8759761384151858]
Test: [0/1]	Time  0.243 ( 0.243)	Loss 9.4505e-01 (9.4505e-01)	Acc@1   0.57 (  0.57)	Acc@5   0.00 (  0.00)
 * Acc@1 0.573 Acc@5 0.000
Test: [0/1]	Time  0.303 ( 0.303)	Loss 1.6369e-01 (1.6369e-01)	Acc@1   0.66 (  0.66)	Acc@5   0.00 (  0.00)
 * Acc@1 0.658 Acc@5 0.000
37
TRAINING
Epoch: [37][0/1]	Time  1.022 ( 1.022)	Data  0.310 ( 0.310)	Loss 8.1669e-02 (8.1669e-02)	Acc@1   0.87 (  0.87)	Acc@5   0.00 (  0.00)
[0.8747599048175994]
Test: [0/1]	Time  0.272 ( 0.272)	Loss 9.4551e-01 (9.4551e-01)	Acc@1   0.58 (  0.58)	Acc@5   0.00 (  0.00)
 * Acc@1 0.575 Acc@5 0.000
Test: [0/1]	Time  0.326 ( 0.326)	Loss 1.6170e-01 (1.6170e-01)	Acc@1   0.67 (  0.67)	Acc@5   0.00 (  0.00)
 * Acc@1 0.673 Acc@5 0.000
38
TRAINING
Epoch: [38][0/1]	Time  1.005 ( 1.005)	Data  0.309 ( 0.309)	Loss 8.2148e-02 (8.2148e-02)	Acc@1   0.87 (  0.87)	Acc@5   0.00 (  0.00)
[0.8747267541262298]
Test: [0/1]	Time  0.271 ( 0.271)	Loss 9.4628e-01 (9.4628e-01)	Acc@1   0.58 (  0.58)	Acc@5   0.00 (  0.00)
 * Acc@1 0.578 Acc@5 0.000
Test: [0/1]	Time  0.311 ( 0.311)	Loss 1.5950e-01 (1.5950e-01)	Acc@1   0.69 (  0.69)	Acc@5   0.00 (  0.00)
 * Acc@1 0.688 Acc@5 0.000
39
TRAINING
Epoch: [39][0/1]	Time  0.954 ( 0.954)	Data  0.254 ( 0.254)	Loss 8.1793e-02 (8.1793e-02)	Acc@1   0.87 (  0.87)	Acc@5   0.00 (  0.00)
[0.8742294389848222]
Test: [0/1]	Time  0.242 ( 0.242)	Loss 9.4728e-01 (9.4728e-01)	Acc@1   0.58 (  0.58)	Acc@5   0.00 (  0.00)
 * Acc@1 0.581 Acc@5 0.000
Test: [0/1]	Time  0.296 ( 0.296)	Loss 1.5742e-01 (1.5742e-01)	Acc@1   0.70 (  0.70)	Acc@5   0.00 (  0.00)
 * Acc@1 0.700 Acc@5 0.000
40
TRAINING
Epoch: [40][0/1]	Time  0.997 ( 0.997)	Data  0.287 ( 0.287)	Loss 8.1069e-02 (8.1069e-02)	Acc@1   0.87 (  0.87)	Acc@5   0.00 (  0.00)
[0.8736161415164667]
Test: [0/1]	Time  0.266 ( 0.266)	Loss 9.4844e-01 (9.4844e-01)	Acc@1   0.58 (  0.58)	Acc@5   0.00 (  0.00)
 * Acc@1 0.584 Acc@5 0.000
Test: [0/1]	Time  0.310 ( 0.310)	Loss 1.5597e-01 (1.5597e-01)	Acc@1   0.71 (  0.71)	Acc@5   0.00 (  0.00)
 * Acc@1 0.711 Acc@5 0.000
41
TRAINING
Epoch: [41][0/1]	Time  1.010 ( 1.010)	Data  0.320 ( 0.320)	Loss 8.0632e-02 (8.0632e-02)	Acc@1   0.87 (  0.87)	Acc@5   0.00 (  0.00)
[0.873159031561731]
Test: [0/1]	Time  0.278 ( 0.278)	Loss 9.4962e-01 (9.4962e-01)	Acc@1   0.59 (  0.59)	Acc@5   0.00 (  0.00)
 * Acc@1 0.587 Acc@5 0.000
Test: [0/1]	Time  0.320 ( 0.320)	Loss 1.5539e-01 (1.5539e-01)	Acc@1   0.72 (  0.72)	Acc@5   0.00 (  0.00)
 * Acc@1 0.720 Acc@5 0.000
42
TRAINING
Epoch: [42][0/1]	Time  0.962 ( 0.962)	Data  0.253 ( 0.253)	Loss 8.0872e-02 (8.0872e-02)	Acc@1   0.87 (  0.87)	Acc@5   0.00 (  0.00)
[0.8731218740301385]
Test: [0/1]	Time  0.321 ( 0.321)	Loss 9.5069e-01 (9.5069e-01)	Acc@1   0.59 (  0.59)	Acc@5   0.00 (  0.00)
 * Acc@1 0.590 Acc@5 0.000
Test: [0/1]	Time  0.339 ( 0.339)	Loss 1.5551e-01 (1.5551e-01)	Acc@1   0.72 (  0.72)	Acc@5   0.00 (  0.00)
 * Acc@1 0.723 Acc@5 0.000
43
TRAINING
Epoch: [43][0/1]	Time  1.003 ( 1.003)	Data  0.299 ( 0.299)	Loss 8.1701e-02 (8.1701e-02)	Acc@1   0.87 (  0.87)	Acc@5   0.00 (  0.00)
[0.8736049420277823]
Test: [0/1]	Time  0.267 ( 0.267)	Loss 9.5146e-01 (9.5146e-01)	Acc@1   0.59 (  0.59)	Acc@5   0.00 (  0.00)
 * Acc@1 0.593 Acc@5 0.000
Test: [0/1]	Time  0.340 ( 0.340)	Loss 1.5587e-01 (1.5587e-01)	Acc@1   0.73 (  0.73)	Acc@5   0.00 (  0.00)
 * Acc@1 0.728 Acc@5 0.000
44
TRAINING
Epoch: [44][0/1]	Time  1.015 ( 1.015)	Data  0.329 ( 0.329)	Loss 8.2671e-02 (8.2671e-02)	Acc@1   0.87 (  0.87)	Acc@5   0.00 (  0.00)
[0.8745457650330195]
Test: [0/1]	Time  0.283 ( 0.283)	Loss 9.5186e-01 (9.5186e-01)	Acc@1   0.60 (  0.60)	Acc@5   0.00 (  0.00)
 * Acc@1 0.597 Acc@5 0.000
Test: [0/1]	Time  0.341 ( 0.341)	Loss 1.5599e-01 (1.5599e-01)	Acc@1   0.73 (  0.73)	Acc@5   0.00 (  0.00)
 * Acc@1 0.732 Acc@5 0.000
45
TRAINING
Epoch: [45][0/1]	Time  0.953 ( 0.953)	Data  0.257 ( 0.257)	Loss 8.3283e-02 (8.3283e-02)	Acc@1   0.88 (  0.88)	Acc@5   0.00 (  0.00)
[0.87588677653311]
Test: [0/1]	Time  0.293 ( 0.293)	Loss 9.5183e-01 (9.5183e-01)	Acc@1   0.60 (  0.60)	Acc@5   0.00 (  0.00)
 * Acc@1 0.601 Acc@5 0.000
Test: [0/1]	Time  0.349 ( 0.349)	Loss 1.5560e-01 (1.5560e-01)	Acc@1   0.73 (  0.73)	Acc@5   0.00 (  0.00)
 * Acc@1 0.735 Acc@5 0.000
46
TRAINING
Epoch: [46][0/1]	Time  0.950 ( 0.950)	Data  0.254 ( 0.254)	Loss 8.3281e-02 (8.3281e-02)	Acc@1   0.88 (  0.88)	Acc@5   0.00 (  0.00)
[0.8777138379370528]
Test: [0/1]	Time  0.251 ( 0.251)	Loss 9.5147e-01 (9.5147e-01)	Acc@1   0.61 (  0.61)	Acc@5   0.00 (  0.00)
 * Acc@1 0.605 Acc@5 0.000
Test: [0/1]	Time  0.337 ( 0.337)	Loss 1.5480e-01 (1.5480e-01)	Acc@1   0.74 (  0.74)	Acc@5   0.00 (  0.00)
 * Acc@1 0.737 Acc@5 0.000
47
TRAINING
Epoch: [47][0/1]	Time  0.994 ( 0.994)	Data  0.308 ( 0.308)	Loss 8.2750e-02 (8.2750e-02)	Acc@1   0.88 (  0.88)	Acc@5   0.00 (  0.00)
[0.8799852580531965]
Test: [0/1]	Time  0.267 ( 0.267)	Loss 9.5091e-01 (9.5091e-01)	Acc@1   0.61 (  0.61)	Acc@5   0.00 (  0.00)
 * Acc@1 0.610 Acc@5 0.000
Test: [0/1]	Time  0.318 ( 0.318)	Loss 1.5390e-01 (1.5390e-01)	Acc@1   0.74 (  0.74)	Acc@5   0.00 (  0.00)
 * Acc@1 0.739 Acc@5 0.000
48
TRAINING
Epoch: [48][0/1]	Time  0.969 ( 0.969)	Data  0.256 ( 0.256)	Loss 8.2013e-02 (8.2013e-02)	Acc@1   0.88 (  0.88)	Acc@5   0.00 (  0.00)
[0.8827585373539241]
Test: [0/1]	Time  0.255 ( 0.255)	Loss 9.5028e-01 (9.5028e-01)	Acc@1   0.61 (  0.61)	Acc@5   0.00 (  0.00)
 * Acc@1 0.615 Acc@5 0.000
Test: [0/1]	Time  0.301 ( 0.301)	Loss 1.5320e-01 (1.5320e-01)	Acc@1   0.74 (  0.74)	Acc@5   0.00 (  0.00)
 * Acc@1 0.742 Acc@5 0.000
49
TRAINING
Epoch: [49][0/1]	Time  1.023 ( 1.023)	Data  0.315 ( 0.315)	Loss 8.1406e-02 (8.1406e-02)	Acc@1   0.89 (  0.89)	Acc@5   0.00 (  0.00)
[0.8859526028357286]
Test: [0/1]	Time  0.273 ( 0.273)	Loss 9.4968e-01 (9.4968e-01)	Acc@1   0.62 (  0.62)	Acc@5   0.00 (  0.00)
 * Acc@1 0.619 Acc@5 0.000
Test: [0/1]	Time  0.320 ( 0.320)	Loss 1.5285e-01 (1.5285e-01)	Acc@1   0.75 (  0.75)	Acc@5   0.00 (  0.00)
 * Acc@1 0.745 Acc@5 0.000
50
TRAINING
Epoch: [50][0/1]	Time  0.993 ( 0.993)	Data  0.285 ( 0.285)	Loss 8.1093e-02 (8.1093e-02)	Acc@1   0.89 (  0.89)	Acc@5   0.00 (  0.00)
[0.8893778122964833]
Test: [0/1]	Time  0.261 ( 0.261)	Loss 9.4917e-01 (9.4917e-01)	Acc@1   0.62 (  0.62)	Acc@5   0.00 (  0.00)
 * Acc@1 0.623 Acc@5 0.000
Test: [0/1]	Time  0.359 ( 0.359)	Loss 1.5281e-01 (1.5281e-01)	Acc@1   0.75 (  0.75)	Acc@5   0.00 (  0.00)
 * Acc@1 0.746 Acc@5 0.000
51
TRAINING
Epoch: [51][0/1]	Time  0.971 ( 0.971)	Data  0.251 ( 0.251)	Loss 8.1022e-02 (8.1022e-02)	Acc@1   0.89 (  0.89)	Acc@5   0.00 (  0.00)
[0.8930857544571932]
Test: [0/1]	Time  0.249 ( 0.249)	Loss 9.4879e-01 (9.4879e-01)	Acc@1   0.63 (  0.63)	Acc@5   0.00 (  0.00)
 * Acc@1 0.627 Acc@5 0.000
Test: [0/1]	Time  0.300 ( 0.300)	Loss 1.5290e-01 (1.5290e-01)	Acc@1   0.75 (  0.75)	Acc@5   0.00 (  0.00)
 * Acc@1 0.745 Acc@5 0.000
52
TRAINING
Epoch: [52][0/1]	Time  0.957 ( 0.957)	Data  0.272 ( 0.272)	Loss 8.1006e-02 (8.1006e-02)	Acc@1   0.90 (  0.90)	Acc@5   0.00 (  0.00)
[0.8976144528420646]
Test: [0/1]	Time  0.248 ( 0.248)	Loss 9.4851e-01 (9.4851e-01)	Acc@1   0.63 (  0.63)	Acc@5   0.00 (  0.00)
 * Acc@1 0.629 Acc@5 0.000
Test: [0/1]	Time  0.302 ( 0.302)	Loss 1.5296e-01 (1.5296e-01)	Acc@1   0.74 (  0.74)	Acc@5   0.00 (  0.00)
 * Acc@1 0.745 Acc@5 0.000
53
TRAINING
Epoch: [53][0/1]	Time  0.929 ( 0.929)	Data  0.254 ( 0.254)	Loss 8.0871e-02 (8.0871e-02)	Acc@1   0.90 (  0.90)	Acc@5   0.00 (  0.00)
[0.9020801906538971]
Test: [0/1]	Time  0.245 ( 0.245)	Loss 9.4833e-01 (9.4833e-01)	Acc@1   0.63 (  0.63)	Acc@5   0.00 (  0.00)
 * Acc@1 0.631 Acc@5 0.000
Test: [0/1]	Time  0.294 ( 0.294)	Loss 1.5292e-01 (1.5292e-01)	Acc@1   0.74 (  0.74)	Acc@5   0.00 (  0.00)
 * Acc@1 0.743 Acc@5 0.000
54
TRAINING
Epoch: [54][0/1]	Time  0.972 ( 0.972)	Data  0.300 ( 0.300)	Loss 8.0560e-02 (8.0560e-02)	Acc@1   0.91 (  0.91)	Acc@5   0.00 (  0.00)
[0.9064294304307351]
Test: [0/1]	Time  0.257 ( 0.257)	Loss 9.4822e-01 (9.4822e-01)	Acc@1   0.63 (  0.63)	Acc@5   0.00 (  0.00)
 * Acc@1 0.633 Acc@5 0.000
Test: [0/1]	Time  0.312 ( 0.312)	Loss 1.5282e-01 (1.5282e-01)	Acc@1   0.74 (  0.74)	Acc@5   0.00 (  0.00)
 * Acc@1 0.742 Acc@5 0.000
55
TRAINING
Epoch: [55][0/1]	Time  0.951 ( 0.951)	Data  0.273 ( 0.273)	Loss 8.0147e-02 (8.0147e-02)	Acc@1   0.91 (  0.91)	Acc@5   0.00 (  0.00)
[0.9103831049681448]
Test: [0/1]	Time  0.247 ( 0.247)	Loss 9.4818e-01 (9.4818e-01)	Acc@1   0.63 (  0.63)	Acc@5   0.00 (  0.00)
 * Acc@1 0.634 Acc@5 0.000
Test: [0/1]	Time  0.297 ( 0.297)	Loss 1.5277e-01 (1.5277e-01)	Acc@1   0.74 (  0.74)	Acc@5   0.00 (  0.00)
 * Acc@1 0.740 Acc@5 0.000
56
TRAINING
Epoch: [56][0/1]	Time  0.953 ( 0.953)	Data  0.274 ( 0.274)	Loss 7.9771e-02 (7.9771e-02)	Acc@1   0.91 (  0.91)	Acc@5   0.00 (  0.00)
[0.9134476577956521]
Test: [0/1]	Time  0.251 ( 0.251)	Loss 9.4816e-01 (9.4816e-01)	Acc@1   0.64 (  0.64)	Acc@5   0.00 (  0.00)
 * Acc@1 0.637 Acc@5 0.000
Test: [0/1]	Time  0.299 ( 0.299)	Loss 1.5284e-01 (1.5284e-01)	Acc@1   0.74 (  0.74)	Acc@5   0.00 (  0.00)
 * Acc@1 0.741 Acc@5 0.000
57
TRAINING
Epoch: [57][0/1]	Time  0.945 ( 0.945)	Data  0.270 ( 0.270)	Loss 7.9536e-02 (7.9536e-02)	Acc@1   0.92 (  0.92)	Acc@5   0.00 (  0.00)
[0.9162133118481843]
Test: [0/1]	Time  0.248 ( 0.248)	Loss 9.4814e-01 (9.4814e-01)	Acc@1   0.64 (  0.64)	Acc@5   0.00 (  0.00)
 * Acc@1 0.640 Acc@5 0.000
Test: [0/1]	Time  0.298 ( 0.298)	Loss 1.5300e-01 (1.5300e-01)	Acc@1   0.74 (  0.74)	Acc@5   0.00 (  0.00)
 * Acc@1 0.741 Acc@5 0.000
58
TRAINING
Epoch: [58][0/1]	Time  0.942 ( 0.942)	Data  0.269 ( 0.269)	Loss 7.9452e-02 (7.9452e-02)	Acc@1   0.92 (  0.92)	Acc@5   0.00 (  0.00)
[0.918727927754704]
Test: [0/1]	Time  0.252 ( 0.252)	Loss 9.4807e-01 (9.4807e-01)	Acc@1   0.64 (  0.64)	Acc@5   0.00 (  0.00)
 * Acc@1 0.643 Acc@5 0.000
Test: [0/1]	Time  0.301 ( 0.301)	Loss 1.5319e-01 (1.5319e-01)	Acc@1   0.74 (  0.74)	Acc@5   0.00 (  0.00)
 * Acc@1 0.740 Acc@5 0.000
59
TRAINING
Epoch: [59][0/1]	Time  0.945 ( 0.945)	Data  0.271 ( 0.271)	Loss 7.9447e-02 (7.9447e-02)	Acc@1   0.92 (  0.92)	Acc@5   0.00 (  0.00)
[0.9214387396099897]
Test: [0/1]	Time  0.255 ( 0.255)	Loss 9.4792e-01 (9.4792e-01)	Acc@1   0.65 (  0.65)	Acc@5   0.00 (  0.00)
 * Acc@1 0.646 Acc@5 0.000
Test: [0/1]	Time  0.304 ( 0.304)	Loss 1.5330e-01 (1.5330e-01)	Acc@1   0.74 (  0.74)	Acc@5   0.00 (  0.00)
 * Acc@1 0.739 Acc@5 0.000
60
TRAINING
Epoch: [60][0/1]	Time  0.963 ( 0.963)	Data  0.252 ( 0.252)	Loss 7.9415e-02 (7.9415e-02)	Acc@1   0.92 (  0.92)	Acc@5   0.00 (  0.00)
[0.923776352920596]
Test: [0/1]	Time  0.242 ( 0.242)	Loss 9.4769e-01 (9.4769e-01)	Acc@1   0.65 (  0.65)	Acc@5   0.00 (  0.00)
 * Acc@1 0.648 Acc@5 0.000
Test: [0/1]	Time  0.299 ( 0.299)	Loss 1.5327e-01 (1.5327e-01)	Acc@1   0.74 (  0.74)	Acc@5   0.00 (  0.00)
 * Acc@1 0.737 Acc@5 0.000
61
TRAINING
Epoch: [61][0/1]	Time  1.001 ( 1.001)	Data  0.304 ( 0.304)	Loss 7.9286e-02 (7.9286e-02)	Acc@1   0.93 (  0.93)	Acc@5   0.00 (  0.00)
[0.925412029822675]
Test: [0/1]	Time  0.249 ( 0.249)	Loss 9.4739e-01 (9.4739e-01)	Acc@1   0.65 (  0.65)	Acc@5   0.00 (  0.00)
 * Acc@1 0.651 Acc@5 0.000
Test: [0/1]	Time  0.299 ( 0.299)	Loss 1.5310e-01 (1.5310e-01)	Acc@1   0.74 (  0.74)	Acc@5   0.00 (  0.00)
 * Acc@1 0.737 Acc@5 0.000
62
TRAINING
Epoch: [62][0/1]	Time  0.945 ( 0.945)	Data  0.273 ( 0.273)	Loss 7.9056e-02 (7.9056e-02)	Acc@1   0.93 (  0.93)	Acc@5   0.00 (  0.00)
[0.9265773239892239]
Test: [0/1]	Time  0.251 ( 0.251)	Loss 9.4703e-01 (9.4703e-01)	Acc@1   0.65 (  0.65)	Acc@5   0.00 (  0.00)
 * Acc@1 0.653 Acc@5 0.000
Test: [0/1]	Time  0.307 ( 0.307)	Loss 1.5285e-01 (1.5285e-01)	Acc@1   0.74 (  0.74)	Acc@5   0.00 (  0.00)
 * Acc@1 0.736 Acc@5 0.000
63
TRAINING
Epoch: [63][0/1]	Time  0.941 ( 0.941)	Data  0.266 ( 0.266)	Loss 7.8779e-02 (7.8779e-02)	Acc@1   0.93 (  0.93)	Acc@5   0.00 (  0.00)
[0.9281763286036554]
Test: [0/1]	Time  0.246 ( 0.246)	Loss 9.4664e-01 (9.4664e-01)	Acc@1   0.66 (  0.66)	Acc@5   0.00 (  0.00)
 * Acc@1 0.655 Acc@5 0.000
Test: [0/1]	Time  0.301 ( 0.301)	Loss 1.5258e-01 (1.5258e-01)	Acc@1   0.74 (  0.74)	Acc@5   0.00 (  0.00)
 * Acc@1 0.736 Acc@5 0.000
64
TRAINING
Epoch: [64][0/1]	Time  0.959 ( 0.959)	Data  0.264 ( 0.264)	Loss 7.8529e-02 (7.8529e-02)	Acc@1   0.93 (  0.93)	Acc@5   0.00 (  0.00)
[0.9292128765641632]
Test: [0/1]	Time  0.246 ( 0.246)	Loss 9.4626e-01 (9.4626e-01)	Acc@1   0.66 (  0.66)	Acc@5   0.00 (  0.00)
 * Acc@1 0.658 Acc@5 0.000
Test: [0/1]	Time  0.296 ( 0.296)	Loss 1.5235e-01 (1.5235e-01)	Acc@1   0.74 (  0.74)	Acc@5   0.00 (  0.00)
 * Acc@1 0.736 Acc@5 0.000
65
TRAINING
Epoch: [65][0/1]	Time  0.956 ( 0.956)	Data  0.266 ( 0.266)	Loss 7.8350e-02 (7.8350e-02)	Acc@1   0.93 (  0.93)	Acc@5   0.00 (  0.00)
[0.9299187421828414]
Test: [0/1]	Time  0.253 ( 0.253)	Loss 9.4590e-01 (9.4590e-01)	Acc@1   0.66 (  0.66)	Acc@5   0.00 (  0.00)
 * Acc@1 0.660 Acc@5 0.000
Test: [0/1]	Time  0.301 ( 0.301)	Loss 1.5219e-01 (1.5219e-01)	Acc@1   0.74 (  0.74)	Acc@5   0.00 (  0.00)
 * Acc@1 0.737 Acc@5 0.000
66
TRAINING
Epoch: [66][0/1]	Time  0.936 ( 0.936)	Data  0.256 ( 0.256)	Loss 7.8247e-02 (7.8247e-02)	Acc@1   0.93 (  0.93)	Acc@5   0.00 (  0.00)
[0.9307689792210112]
Test: [0/1]	Time  0.247 ( 0.247)	Loss 9.4559e-01 (9.4559e-01)	Acc@1   0.66 (  0.66)	Acc@5   0.00 (  0.00)
 * Acc@1 0.661 Acc@5 0.000
Test: [0/1]	Time  0.296 ( 0.296)	Loss 1.5206e-01 (1.5206e-01)	Acc@1   0.74 (  0.74)	Acc@5   0.00 (  0.00)
 * Acc@1 0.737 Acc@5 0.000
67
TRAINING
Epoch: [67][0/1]	Time  0.933 ( 0.933)	Data  0.256 ( 0.256)	Loss 7.8186e-02 (7.8186e-02)	Acc@1   0.93 (  0.93)	Acc@5   0.00 (  0.00)
[0.9312408845682036]
Test: [0/1]	Time  0.243 ( 0.243)	Loss 9.4531e-01 (9.4531e-01)	Acc@1   0.66 (  0.66)	Acc@5   0.00 (  0.00)
 * Acc@1 0.663 Acc@5 0.000
Test: [0/1]	Time  0.298 ( 0.298)	Loss 1.5194e-01 (1.5194e-01)	Acc@1   0.74 (  0.74)	Acc@5   0.00 (  0.00)
 * Acc@1 0.737 Acc@5 0.000
68
TRAINING
Epoch: [68][0/1]	Time  0.940 ( 0.940)	Data  0.260 ( 0.260)	Loss 7.8130e-02 (7.8130e-02)	Acc@1   0.93 (  0.93)	Acc@5   0.00 (  0.00)
[0.9316463549096049]
Test: [0/1]	Time  0.246 ( 0.246)	Loss 9.4509e-01 (9.4509e-01)	Acc@1   0.66 (  0.66)	Acc@5   0.00 (  0.00)
 * Acc@1 0.664 Acc@5 0.000
Test: [0/1]	Time  0.293 ( 0.293)	Loss 1.5182e-01 (1.5182e-01)	Acc@1   0.74 (  0.74)	Acc@5   0.00 (  0.00)
 * Acc@1 0.738 Acc@5 0.000
69
TRAINING
Epoch: [69][0/1]	Time  0.927 ( 0.927)	Data  0.254 ( 0.254)	Loss 7.8057e-02 (7.8057e-02)	Acc@1   0.93 (  0.93)	Acc@5   0.00 (  0.00)
[0.931984227228474]
Test: [0/1]	Time  0.241 ( 0.241)	Loss 9.4491e-01 (9.4491e-01)	Acc@1   0.67 (  0.67)	Acc@5   0.00 (  0.00)
 * Acc@1 0.666 Acc@5 0.000
Test: [0/1]	Time  0.302 ( 0.302)	Loss 1.5170e-01 (1.5170e-01)	Acc@1   0.74 (  0.74)	Acc@5   0.00 (  0.00)
 * Acc@1 0.738 Acc@5 0.000
70
TRAINING
Epoch: [70][0/1]	Time  0.959 ( 0.959)	Data  0.247 ( 0.247)	Loss 7.7973e-02 (7.7973e-02)	Acc@1   0.93 (  0.93)	Acc@5   0.00 (  0.00)
[0.9321670239634978]
Test: [0/1]	Time  0.242 ( 0.242)	Loss 9.4477e-01 (9.4477e-01)	Acc@1   0.67 (  0.67)	Acc@5   0.00 (  0.00)
 * Acc@1 0.667 Acc@5 0.000
Test: [0/1]	Time  0.292 ( 0.292)	Loss 1.5160e-01 (1.5160e-01)	Acc@1   0.74 (  0.74)	Acc@5   0.00 (  0.00)
 * Acc@1 0.739 Acc@5 0.000
71
TRAINING
Epoch: [71][0/1]	Time  0.928 ( 0.928)	Data  0.255 ( 0.255)	Loss 7.7901e-02 (7.7901e-02)	Acc@1   0.93 (  0.93)	Acc@5   0.00 (  0.00)
[0.932210806105229]
Test: [0/1]	Time  0.246 ( 0.246)	Loss 9.4464e-01 (9.4464e-01)	Acc@1   0.67 (  0.67)	Acc@5   0.00 (  0.00)
 * Acc@1 0.668 Acc@5 0.000
Test: [0/1]	Time  0.294 ( 0.294)	Loss 1.5154e-01 (1.5154e-01)	Acc@1   0.74 (  0.74)	Acc@5   0.00 (  0.00)
 * Acc@1 0.739 Acc@5 0.000
72
TRAINING
Epoch: [72][0/1]	Time  0.930 ( 0.930)	Data  0.252 ( 0.252)	Loss 7.7863e-02 (7.7863e-02)	Acc@1   0.93 (  0.93)	Acc@5   0.00 (  0.00)
[0.9322428058566865]
Test: [0/1]	Time  0.251 ( 0.251)	Loss 9.4453e-01 (9.4453e-01)	Acc@1   0.67 (  0.67)	Acc@5   0.00 (  0.00)
 * Acc@1 0.669 Acc@5 0.000
Test: [0/1]	Time  0.303 ( 0.303)	Loss 1.5150e-01 (1.5150e-01)	Acc@1   0.74 (  0.74)	Acc@5   0.00 (  0.00)
 * Acc@1 0.740 Acc@5 0.000
73
TRAINING
Epoch: [73][0/1]	Time  0.984 ( 0.984)	Data  0.257 ( 0.257)	Loss 7.7863e-02 (7.7863e-02)	Acc@1   0.93 (  0.93)	Acc@5   0.00 (  0.00)
[0.9322670522371376]
Test: [0/1]	Time  0.244 ( 0.244)	Loss 9.4441e-01 (9.4441e-01)	Acc@1   0.67 (  0.67)	Acc@5   0.00 (  0.00)
 * Acc@1 0.670 Acc@5 0.000
Test: [0/1]	Time  0.294 ( 0.294)	Loss 1.5149e-01 (1.5149e-01)	Acc@1   0.74 (  0.74)	Acc@5   0.00 (  0.00)
 * Acc@1 0.741 Acc@5 0.000
74
TRAINING
Epoch: [74][0/1]	Time  0.925 ( 0.925)	Data  0.253 ( 0.253)	Loss 7.7888e-02 (7.7888e-02)	Acc@1   0.93 (  0.93)	Acc@5   0.00 (  0.00)
[0.9322655153493282]
Test: [0/1]	Time  0.244 ( 0.244)	Loss 9.4429e-01 (9.4429e-01)	Acc@1   0.67 (  0.67)	Acc@5   0.00 (  0.00)
 * Acc@1 0.670 Acc@5 0.000
Test: [0/1]	Time  0.293 ( 0.293)	Loss 1.5148e-01 (1.5148e-01)	Acc@1   0.74 (  0.74)	Acc@5   0.00 (  0.00)
 * Acc@1 0.741 Acc@5 0.000
75
TRAINING
Epoch: [75][0/1]	Time  0.931 ( 0.931)	Data  0.253 ( 0.253)	Loss 7.7914e-02 (7.7914e-02)	Acc@1   0.93 (  0.93)	Acc@5   0.00 (  0.00)
[0.9322605532531814]
Test: [0/1]	Time  0.242 ( 0.242)	Loss 9.4414e-01 (9.4414e-01)	Acc@1   0.67 (  0.67)	Acc@5   0.00 (  0.00)
 * Acc@1 0.671 Acc@5 0.000
Test: [0/1]	Time  0.296 ( 0.296)	Loss 1.5145e-01 (1.5145e-01)	Acc@1   0.74 (  0.74)	Acc@5   0.00 (  0.00)
 * Acc@1 0.742 Acc@5 0.000
76
TRAINING
Epoch: [76][0/1]	Time  0.937 ( 0.937)	Data  0.256 ( 0.256)	Loss 7.7924e-02 (7.7924e-02)	Acc@1   0.93 (  0.93)	Acc@5   0.00 (  0.00)
[0.9323294287963793]
Test: [0/1]	Time  0.247 ( 0.247)	Loss 9.4398e-01 (9.4398e-01)	Acc@1   0.67 (  0.67)	Acc@5   0.00 (  0.00)
 * Acc@1 0.672 Acc@5 0.000
Test: [0/1]	Time  0.298 ( 0.298)	Loss 1.5140e-01 (1.5140e-01)	Acc@1   0.74 (  0.74)	Acc@5   0.00 (  0.00)
 * Acc@1 0.742 Acc@5 0.000
77
TRAINING
Epoch: [77][0/1]	Time  0.934 ( 0.934)	Data  0.250 ( 0.250)	Loss 7.7911e-02 (7.7911e-02)	Acc@1   0.93 (  0.93)	Acc@5   0.00 (  0.00)
[0.9323646100880562]
Test: [0/1]	Time  0.248 ( 0.248)	Loss 9.4380e-01 (9.4380e-01)	Acc@1   0.67 (  0.67)	Acc@5   0.00 (  0.00)
 * Acc@1 0.673 Acc@5 0.000
Test: [0/1]	Time  0.293 ( 0.293)	Loss 1.5133e-01 (1.5133e-01)	Acc@1   0.74 (  0.74)	Acc@5   0.00 (  0.00)
 * Acc@1 0.743 Acc@5 0.000
78
TRAINING
Epoch: [78][0/1]	Time  0.926 ( 0.926)	Data  0.252 ( 0.252)	Loss 7.7882e-02 (7.7882e-02)	Acc@1   0.93 (  0.93)	Acc@5   0.00 (  0.00)
[0.9324037146808285]
Test: [0/1]	Time  0.241 ( 0.241)	Loss 9.4363e-01 (9.4363e-01)	Acc@1   0.67 (  0.67)	Acc@5   0.00 (  0.00)
 * Acc@1 0.673 Acc@5 0.000
Test: [0/1]	Time  0.293 ( 0.293)	Loss 1.5126e-01 (1.5126e-01)	Acc@1   0.74 (  0.74)	Acc@5   0.00 (  0.00)
 * Acc@1 0.743 Acc@5 0.000
79
TRAINING
Epoch: [79][0/1]	Time  0.932 ( 0.932)	Data  0.251 ( 0.251)	Loss 7.7852e-02 (7.7852e-02)	Acc@1   0.93 (  0.93)	Acc@5   0.00 (  0.00)
[0.932451265051195]
Test: [0/1]	Time  0.245 ( 0.245)	Loss 9.4347e-01 (9.4347e-01)	Acc@1   0.67 (  0.67)	Acc@5   0.00 (  0.00)
 * Acc@1 0.674 Acc@5 0.000
Test: [0/1]	Time  0.299 ( 0.299)	Loss 1.5121e-01 (1.5121e-01)	Acc@1   0.74 (  0.74)	Acc@5   0.00 (  0.00)
 * Acc@1 0.744 Acc@5 0.000
80
TRAINING
Epoch: [80][0/1]	Time  0.950 ( 0.950)	Data  0.249 ( 0.249)	Loss 7.7833e-02 (7.7833e-02)	Acc@1   0.93 (  0.93)	Acc@5   0.00 (  0.00)
[0.9325073167284932]
Test: [0/1]	Time  0.241 ( 0.241)	Loss 9.4334e-01 (9.4334e-01)	Acc@1   0.67 (  0.67)	Acc@5   0.00 (  0.00)
 * Acc@1 0.675 Acc@5 0.000
Test: [0/1]	Time  0.303 ( 0.303)	Loss 1.5118e-01 (1.5118e-01)	Acc@1   0.74 (  0.74)	Acc@5   0.00 (  0.00)
 * Acc@1 0.744 Acc@5 0.000
81
TRAINING
Epoch: [81][0/1]	Time  0.944 ( 0.944)	Data  0.254 ( 0.254)	Loss 7.7828e-02 (7.7828e-02)	Acc@1   0.93 (  0.93)	Acc@5   0.00 (  0.00)
[0.932571536668471]
Test: [0/1]	Time  0.245 ( 0.245)	Loss 9.4323e-01 (9.4323e-01)	Acc@1   0.68 (  0.68)	Acc@5   0.00 (  0.00)
 * Acc@1 0.675 Acc@5 0.000
Test: [0/1]	Time  0.294 ( 0.294)	Loss 1.5117e-01 (1.5117e-01)	Acc@1   0.74 (  0.74)	Acc@5   0.00 (  0.00)
 * Acc@1 0.744 Acc@5 0.000
82
TRAINING
Epoch: [82][0/1]	Time  0.929 ( 0.929)	Data  0.253 ( 0.253)	Loss 7.7833e-02 (7.7833e-02)	Acc@1   0.93 (  0.93)	Acc@5   0.00 (  0.00)
[0.9327127223777114]
Test: [0/1]	Time  0.244 ( 0.244)	Loss 9.4315e-01 (9.4315e-01)	Acc@1   0.68 (  0.68)	Acc@5   0.00 (  0.00)
 * Acc@1 0.676 Acc@5 0.000
Test: [0/1]	Time  0.296 ( 0.296)	Loss 1.5117e-01 (1.5117e-01)	Acc@1   0.74 (  0.74)	Acc@5   0.00 (  0.00)
 * Acc@1 0.745 Acc@5 0.000
83
TRAINING
Epoch: [83][0/1]	Time  0.930 ( 0.930)	Data  0.253 ( 0.253)	Loss 7.7840e-02 (7.7840e-02)	Acc@1   0.93 (  0.93)	Acc@5   0.00 (  0.00)
[0.9327570644850135]
Test: [0/1]	Time  0.247 ( 0.247)	Loss 9.4310e-01 (9.4310e-01)	Acc@1   0.68 (  0.68)	Acc@5   0.00 (  0.00)
 * Acc@1 0.676 Acc@5 0.000
Test: [0/1]	Time  0.294 ( 0.294)	Loss 1.5118e-01 (1.5118e-01)	Acc@1   0.75 (  0.75)	Acc@5   0.00 (  0.00)
 * Acc@1 0.745 Acc@5 0.000
84
TRAINING
Epoch: [84][0/1]	Time  0.924 ( 0.924)	Data  0.252 ( 0.252)	Loss 7.7844e-02 (7.7844e-02)	Acc@1   0.93 (  0.93)	Acc@5   0.00 (  0.00)
[0.9327926343769037]
Test: [0/1]	Time  0.253 ( 0.253)	Loss 9.4309e-01 (9.4309e-01)	Acc@1   0.68 (  0.68)	Acc@5   0.00 (  0.00)
 * Acc@1 0.677 Acc@5 0.000
Test: [0/1]	Time  0.295 ( 0.295)	Loss 1.5119e-01 (1.5119e-01)	Acc@1   0.75 (  0.75)	Acc@5   0.00 (  0.00)
 * Acc@1 0.745 Acc@5 0.000
85
TRAINING
Epoch: [85][0/1]	Time  0.936 ( 0.936)	Data  0.251 ( 0.251)	Loss 7.7843e-02 (7.7843e-02)	Acc@1   0.93 (  0.93)	Acc@5   0.00 (  0.00)
[0.9328220140890524]
Test: [0/1]	Time  0.247 ( 0.247)	Loss 9.4309e-01 (9.4309e-01)	Acc@1   0.68 (  0.68)	Acc@5   0.00 (  0.00)
 * Acc@1 0.677 Acc@5 0.000
Test: [0/1]	Time  0.300 ( 0.300)	Loss 1.5121e-01 (1.5121e-01)	Acc@1   0.75 (  0.75)	Acc@5   0.00 (  0.00)
 * Acc@1 0.746 Acc@5 0.000
86
TRAINING
Epoch: [86][0/1]	Time  0.955 ( 0.955)	Data  0.246 ( 0.246)	Loss 7.7841e-02 (7.7841e-02)	Acc@1   0.93 (  0.93)	Acc@5   0.00 (  0.00)
[0.9328465123058173]
Test: [0/1]	Time  0.252 ( 0.252)	Loss 9.4312e-01 (9.4312e-01)	Acc@1   0.68 (  0.68)	Acc@5   0.00 (  0.00)
 * Acc@1 0.677 Acc@5 0.000
Test: [0/1]	Time  0.296 ( 0.296)	Loss 1.5124e-01 (1.5124e-01)	Acc@1   0.75 (  0.75)	Acc@5   0.00 (  0.00)
 * Acc@1 0.745 Acc@5 0.000
87
TRAINING
Epoch: [87][0/1]	Time  0.929 ( 0.929)	Data  0.254 ( 0.254)	Loss 7.7842e-02 (7.7842e-02)	Acc@1   0.93 (  0.93)	Acc@5   0.00 (  0.00)
[0.932867726053389]
Test: [0/1]	Time  0.247 ( 0.247)	Loss 9.4315e-01 (9.4315e-01)	Acc@1   0.68 (  0.68)	Acc@5   0.00 (  0.00)
 * Acc@1 0.677 Acc@5 0.000
Test: [0/1]	Time  0.297 ( 0.297)	Loss 1.5128e-01 (1.5128e-01)	Acc@1   0.75 (  0.75)	Acc@5   0.00 (  0.00)
 * Acc@1 0.745 Acc@5 0.000
88
TRAINING
Epoch: [88][0/1]	Time  0.968 ( 0.968)	Data  0.293 ( 0.293)	Loss 7.7847e-02 (7.7847e-02)	Acc@1   0.93 (  0.93)	Acc@5   0.00 (  0.00)
[0.9328696667086265]
Test: [0/1]	Time  0.246 ( 0.246)	Loss 9.4318e-01 (9.4318e-01)	Acc@1   0.68 (  0.68)	Acc@5   0.00 (  0.00)
 * Acc@1 0.677 Acc@5 0.000
Test: [0/1]	Time  0.292 ( 0.292)	Loss 1.5131e-01 (1.5131e-01)	Acc@1   0.75 (  0.75)	Acc@5   0.00 (  0.00)
 * Acc@1 0.745 Acc@5 0.000
89
TRAINING
Epoch: [89][0/1]	Time  0.933 ( 0.933)	Data  0.249 ( 0.249)	Loss 7.7854e-02 (7.7854e-02)	Acc@1   0.93 (  0.93)	Acc@5   0.00 (  0.00)
[0.9328444295512661]
Test: [0/1]	Time  0.244 ( 0.244)	Loss 9.4322e-01 (9.4322e-01)	Acc@1   0.68 (  0.68)	Acc@5   0.00 (  0.00)
 * Acc@1 0.678 Acc@5 0.000
Test: [0/1]	Time  0.297 ( 0.297)	Loss 1.5135e-01 (1.5135e-01)	Acc@1   0.75 (  0.75)	Acc@5   0.00 (  0.00)
 * Acc@1 0.745 Acc@5 0.000
90
TRAINING
Epoch: [90][0/1]	Time  0.964 ( 0.964)	Data  0.249 ( 0.249)	Loss 7.7859e-02 (7.7859e-02)	Acc@1   0.93 (  0.93)	Acc@5   0.00 (  0.00)
[0.9328342442332958]
Test: [0/1]	Time  0.247 ( 0.247)	Loss 9.4324e-01 (9.4324e-01)	Acc@1   0.68 (  0.68)	Acc@5   0.00 (  0.00)
 * Acc@1 0.678 Acc@5 0.000
Test: [0/1]	Time  0.292 ( 0.292)	Loss 1.5138e-01 (1.5138e-01)	Acc@1   0.75 (  0.75)	Acc@5   0.00 (  0.00)
 * Acc@1 0.745 Acc@5 0.000
91
TRAINING
Epoch: [91][0/1]	Time  0.922 ( 0.922)	Data  0.249 ( 0.249)	Loss 7.7856e-02 (7.7856e-02)	Acc@1   0.93 (  0.93)	Acc@5   0.00 (  0.00)
[0.9328410293451]
Test: [0/1]	Time  0.249 ( 0.249)	Loss 9.4325e-01 (9.4325e-01)	Acc@1   0.68 (  0.68)	Acc@5   0.00 (  0.00)
 * Acc@1 0.678 Acc@5 0.000
Test: [0/1]	Time  0.300 ( 0.300)	Loss 1.5139e-01 (1.5139e-01)	Acc@1   0.75 (  0.75)	Acc@5   0.00 (  0.00)
 * Acc@1 0.745 Acc@5 0.000
92
TRAINING
Epoch: [92][0/1]	Time  0.928 ( 0.928)	Data  0.255 ( 0.255)	Loss 7.7845e-02 (7.7845e-02)	Acc@1   0.93 (  0.93)	Acc@5   0.00 (  0.00)
[0.9328649227067004]
Test: [0/1]	Time  0.244 ( 0.244)	Loss 9.4325e-01 (9.4325e-01)	Acc@1   0.68 (  0.68)	Acc@5   0.00 (  0.00)
 * Acc@1 0.678 Acc@5 0.000
Test: [0/1]	Time  0.308 ( 0.308)	Loss 1.5140e-01 (1.5140e-01)	Acc@1   0.75 (  0.75)	Acc@5   0.00 (  0.00)
 * Acc@1 0.746 Acc@5 0.000
93
TRAINING
Epoch: [93][0/1]	Time  0.943 ( 0.943)	Data  0.250 ( 0.250)	Loss 7.7826e-02 (7.7826e-02)	Acc@1   0.93 (  0.93)	Acc@5   0.00 (  0.00)
[0.9329043274021136]
Test: [0/1]	Time  0.241 ( 0.241)	Loss 9.4325e-01 (9.4325e-01)	Acc@1   0.68 (  0.68)	Acc@5   0.00 (  0.00)
 * Acc@1 0.678 Acc@5 0.000
Test: [0/1]	Time  0.302 ( 0.302)	Loss 1.5141e-01 (1.5141e-01)	Acc@1   0.75 (  0.75)	Acc@5   0.00 (  0.00)
 * Acc@1 0.746 Acc@5 0.000
94
TRAINING
Epoch: [94][0/1]	Time  0.959 ( 0.959)	Data  0.261 ( 0.261)	Loss 7.7803e-02 (7.7803e-02)	Acc@1   0.93 (  0.93)	Acc@5   0.00 (  0.00)
[0.9329562682107186]
Test: [0/1]	Time  0.250 ( 0.250)	Loss 9.4324e-01 (9.4324e-01)	Acc@1   0.68 (  0.68)	Acc@5   0.00 (  0.00)
 * Acc@1 0.678 Acc@5 0.000
Test: [0/1]	Time  0.298 ( 0.298)	Loss 1.5141e-01 (1.5141e-01)	Acc@1   0.75 (  0.75)	Acc@5   0.00 (  0.00)
 * Acc@1 0.746 Acc@5 0.000
95
TRAINING
Epoch: [95][0/1]	Time  0.974 ( 0.974)	Data  0.269 ( 0.269)	Loss 7.7779e-02 (7.7779e-02)	Acc@1   0.93 (  0.93)	Acc@5   0.00 (  0.00)
[0.9329991868019227]
Test: [0/1]	Time  0.259 ( 0.259)	Loss 9.4323e-01 (9.4323e-01)	Acc@1   0.68 (  0.68)	Acc@5   0.00 (  0.00)
 * Acc@1 0.678 Acc@5 0.000
Test: [0/1]	Time  0.307 ( 0.307)	Loss 1.5141e-01 (1.5141e-01)	Acc@1   0.75 (  0.75)	Acc@5   0.00 (  0.00)
 * Acc@1 0.746 Acc@5 0.000
96
TRAINING
Epoch: [96][0/1]	Time  0.974 ( 0.974)	Data  0.261 ( 0.261)	Loss 7.7758e-02 (7.7758e-02)	Acc@1   0.93 (  0.93)	Acc@5   0.00 (  0.00)
[0.9329527913244166]
Test: [0/1]	Time  0.256 ( 0.256)	Loss 9.4323e-01 (9.4323e-01)	Acc@1   0.68 (  0.68)	Acc@5   0.00 (  0.00)
 * Acc@1 0.678 Acc@5 0.000
Test: [0/1]	Time  0.305 ( 0.305)	Loss 1.5142e-01 (1.5142e-01)	Acc@1   0.75 (  0.75)	Acc@5   0.00 (  0.00)
 * Acc@1 0.746 Acc@5 0.000
97
TRAINING
Epoch: [97][0/1]	Time  0.958 ( 0.958)	Data  0.251 ( 0.251)	Loss 7.7739e-02 (7.7739e-02)	Acc@1   0.93 (  0.93)	Acc@5   0.00 (  0.00)
[0.9329078741907892]
Test: [0/1]	Time  0.243 ( 0.243)	Loss 9.4323e-01 (9.4323e-01)	Acc@1   0.68 (  0.68)	Acc@5   0.00 (  0.00)
 * Acc@1 0.678 Acc@5 0.000
Test: [0/1]	Time  0.296 ( 0.296)	Loss 1.5143e-01 (1.5143e-01)	Acc@1   0.75 (  0.75)	Acc@5   0.00 (  0.00)
 * Acc@1 0.747 Acc@5 0.000
98
TRAINING
Epoch: [98][0/1]	Time  0.950 ( 0.950)	Data  0.251 ( 0.251)	Loss 7.7721e-02 (7.7721e-02)	Acc@1   0.93 (  0.93)	Acc@5   0.00 (  0.00)
[0.932867811587482]
Test: [0/1]	Time  0.249 ( 0.249)	Loss 9.4324e-01 (9.4324e-01)	Acc@1   0.68 (  0.68)	Acc@5   0.00 (  0.00)
 * Acc@1 0.678 Acc@5 0.000
Test: [0/1]	Time  0.305 ( 0.305)	Loss 1.5145e-01 (1.5145e-01)	Acc@1   0.75 (  0.75)	Acc@5   0.00 (  0.00)
 * Acc@1 0.747 Acc@5 0.000
99
TRAINING
Epoch: [99][0/1]	Time  0.968 ( 0.968)	Data  0.255 ( 0.255)	Loss 7.7704e-02 (7.7704e-02)	Acc@1   0.93 (  0.93)	Acc@5   0.00 (  0.00)
[0.9328352383004436]
Test: [0/1]	Time  0.253 ( 0.253)	Loss 9.4326e-01 (9.4326e-01)	Acc@1   0.68 (  0.68)	Acc@5   0.00 (  0.00)
 * Acc@1 0.678 Acc@5 0.000
Test: [0/1]	Time  0.304 ( 0.304)	Loss 1.5146e-01 (1.5146e-01)	Acc@1   0.75 (  0.75)	Acc@5   0.00 (  0.00)
 * Acc@1 0.747 Acc@5 0.000
=> using pre-trained model 'st_resnet'
s/ohp/session_1
torch.Size([640, 3, 224, 224])
(640, 22)
attach reg
0
TRAINING
/home/helenr6/Adv_mapper/train_split.py:125: UserWarning: You have chosen to seed training. This will turn on the CUDNN deterministic setting, which can slow down your training considerably! You may see unexpected behavior when restarting from checkpoints.
  warnings.warn('You have chosen to seed training. '
/localscratch/helenr6.6279052.0/env/lib/python3.7/site-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  cpuset_checked))
Epoch: [0][0/1]	Time  5.307 ( 5.307)	Data  1.841 ( 1.841)	Loss 1.7864e+00 (1.7864e+00)	Acc@1   0.01 (  0.01)	Acc@5   0.00 (  0.00)
[0.009764215936117168]
Test: [0/1]	Time  0.436 ( 0.436)	Loss 1.2836e+00 (1.2836e+00)	Acc@1   0.03 (  0.03)	Acc@5   0.00 (  0.00)
 * Acc@1 0.028 Acc@5 0.000
Test: [0/1]	Time  0.573 ( 0.573)	Loss 9.5395e-01 (9.5395e-01)	Acc@1  -0.00 ( -0.00)	Acc@5   0.00 (  0.00)
 * Acc@1 -0.004 Acc@5 0.000
1
TRAINING
Epoch: [1][0/1]	Time  0.933 ( 0.933)	Data  0.241 ( 0.241)	Loss 1.6801e+00 (1.6801e+00)	Acc@1   0.01 (  0.01)	Acc@5   0.00 (  0.00)
[0.011623688809236404]
Test: [0/1]	Time  0.248 ( 0.248)	Loss 1.2585e+00 (1.2585e+00)	Acc@1   0.03 (  0.03)	Acc@5   0.00 (  0.00)
 * Acc@1 0.033 Acc@5 0.000
Test: [0/1]	Time  0.296 ( 0.296)	Loss 8.8590e-01 (8.8590e-01)	Acc@1   0.00 (  0.00)	Acc@5   0.00 (  0.00)
 * Acc@1 0.003 Acc@5 0.000
2
TRAINING
Epoch: [2][0/1]	Time  0.966 ( 0.966)	Data  0.250 ( 0.250)	Loss 1.5243e+00 (1.5243e+00)	Acc@1   0.02 (  0.02)	Acc@5   0.00 (  0.00)
[0.015367550428098928]
Test: [0/1]	Time  0.251 ( 0.251)	Loss 1.2306e+00 (1.2306e+00)	Acc@1   0.03 (  0.03)	Acc@5   0.00 (  0.00)
 * Acc@1 0.033 Acc@5 0.000
Test: [0/1]	Time  0.298 ( 0.298)	Loss 8.3367e-01 (8.3367e-01)	Acc@1   0.01 (  0.01)	Acc@5   0.00 (  0.00)
 * Acc@1 0.013 Acc@5 0.000
3
TRAINING
Epoch: [3][0/1]	Time  0.978 ( 0.978)	Data  0.264 ( 0.264)	Loss 1.3818e+00 (1.3818e+00)	Acc@1   0.02 (  0.02)	Acc@5   0.00 (  0.00)
[0.02182372489255327]
Test: [0/1]	Time  0.249 ( 0.249)	Loss 1.2060e+00 (1.2060e+00)	Acc@1   0.05 (  0.05)	Acc@5   0.00 (  0.00)
 * Acc@1 0.046 Acc@5 0.000
Test: [0/1]	Time  0.300 ( 0.300)	Loss 8.1570e-01 (8.1570e-01)	Acc@1   0.02 (  0.02)	Acc@5   0.00 (  0.00)
 * Acc@1 0.022 Acc@5 0.000
4
TRAINING
Epoch: [4][0/1]	Time  0.953 ( 0.953)	Data  0.246 ( 0.246)	Loss 1.2875e+00 (1.2875e+00)	Acc@1   0.04 (  0.04)	Acc@5   0.00 (  0.00)
[0.03593575811342652]
Test: [0/1]	Time  0.239 ( 0.239)	Loss 1.1869e+00 (1.1869e+00)	Acc@1   0.07 (  0.07)	Acc@5   0.00 (  0.00)
 * Acc@1 0.075 Acc@5 0.000
Test: [0/1]	Time  0.296 ( 0.296)	Loss 8.2484e-01 (8.2484e-01)	Acc@1   0.03 (  0.03)	Acc@5   0.00 (  0.00)
 * Acc@1 0.029 Acc@5 0.000
5
TRAINING
Epoch: [5][0/1]	Time  0.969 ( 0.969)	Data  0.252 ( 0.252)	Loss 1.2354e+00 (1.2354e+00)	Acc@1   0.06 (  0.06)	Acc@5   0.00 (  0.00)
[0.06059524169754382]
Test: [0/1]	Time  0.246 ( 0.246)	Loss 1.1720e+00 (1.1720e+00)	Acc@1   0.11 (  0.11)	Acc@5   0.00 (  0.00)
 * Acc@1 0.107 Acc@5 0.000
Test: [0/1]	Time  0.298 ( 0.298)	Loss 8.3593e-01 (8.3593e-01)	Acc@1   0.04 (  0.04)	Acc@5   0.00 (  0.00)
 * Acc@1 0.038 Acc@5 0.000
6
TRAINING
Epoch: [6][0/1]	Time  0.957 ( 0.957)	Data  0.248 ( 0.248)	Loss 1.1928e+00 (1.1928e+00)	Acc@1   0.08 (  0.08)	Acc@5   0.00 (  0.00)
[0.0768544376230113]
Test: [0/1]	Time  0.249 ( 0.249)	Loss 1.1590e+00 (1.1590e+00)	Acc@1   0.12 (  0.12)	Acc@5   0.00 (  0.00)
 * Acc@1 0.123 Acc@5 0.000
Test: [0/1]	Time  0.295 ( 0.295)	Loss 8.2332e-01 (8.2332e-01)	Acc@1   0.04 (  0.04)	Acc@5   0.00 (  0.00)
 * Acc@1 0.042 Acc@5 0.000
7
TRAINING
Epoch: [7][0/1]	Time  1.000 ( 1.000)	Data  0.297 ( 0.297)	Loss 1.1260e+00 (1.1260e+00)	Acc@1   0.09 (  0.09)	Acc@5   0.00 (  0.00)
[0.0862933444765982]
Test: [0/1]	Time  0.243 ( 0.243)	Loss 1.1464e+00 (1.1464e+00)	Acc@1   0.14 (  0.14)	Acc@5   0.00 (  0.00)
 * Acc@1 0.142 Acc@5 0.000
Test: [0/1]	Time  0.293 ( 0.293)	Loss 7.7634e-01 (7.7634e-01)	Acc@1   0.05 (  0.05)	Acc@5   0.00 (  0.00)
 * Acc@1 0.047 Acc@5 0.000
8
TRAINING
Epoch: [8][0/1]	Time  0.950 ( 0.950)	Data  0.262 ( 0.262)	Loss 1.0219e+00 (1.0219e+00)	Acc@1   0.11 (  0.11)	Acc@5   0.00 (  0.00)
[0.10728811887938851]
Test: [0/1]	Time  0.248 ( 0.248)	Loss 1.1345e+00 (1.1345e+00)	Acc@1   0.17 (  0.17)	Acc@5   0.00 (  0.00)
 * Acc@1 0.166 Acc@5 0.000
Test: [0/1]	Time  0.302 ( 0.302)	Loss 7.0422e-01 (7.0422e-01)	Acc@1   0.05 (  0.05)	Acc@5   0.00 (  0.00)
 * Acc@1 0.051 Acc@5 0.000
9
TRAINING
Epoch: [9][0/1]	Time  1.015 ( 1.015)	Data  0.249 ( 0.249)	Loss 8.9272e-01 (8.9272e-01)	Acc@1   0.12 (  0.12)	Acc@5   0.00 (  0.00)
[0.12385643266097868]
Test: [0/1]	Time  0.241 ( 0.241)	Loss 1.1247e+00 (1.1247e+00)	Acc@1   0.19 (  0.19)	Acc@5   0.00 (  0.00)
 * Acc@1 0.188 Acc@5 0.000
Test: [0/1]	Time  0.295 ( 0.295)	Loss 6.2858e-01 (6.2858e-01)	Acc@1   0.07 (  0.07)	Acc@5   0.00 (  0.00)
 * Acc@1 0.066 Acc@5 0.000
10
TRAINING
Epoch: [10][0/1]	Time  0.956 ( 0.956)	Data  0.256 ( 0.256)	Loss 7.6517e-01 (7.6517e-01)	Acc@1   0.15 (  0.15)	Acc@5   0.00 (  0.00)
[0.14737283898509881]
Test: [0/1]	Time  0.247 ( 0.247)	Loss 1.1182e+00 (1.1182e+00)	Acc@1   0.21 (  0.21)	Acc@5   0.00 (  0.00)
 * Acc@1 0.205 Acc@5 0.000
Test: [0/1]	Time  0.294 ( 0.294)	Loss 5.6983e-01 (5.6983e-01)	Acc@1   0.09 (  0.09)	Acc@5   0.00 (  0.00)
 * Acc@1 0.091 Acc@5 0.000
11
TRAINING
Epoch: [11][0/1]	Time  0.952 ( 0.952)	Data  0.253 ( 0.253)	Loss 6.6288e-01 (6.6288e-01)	Acc@1   0.17 (  0.17)	Acc@5   0.00 (  0.00)
[0.1719773826002946]
Test: [0/1]	Time  0.243 ( 0.243)	Loss 1.1141e+00 (1.1141e+00)	Acc@1   0.24 (  0.24)	Acc@5   0.00 (  0.00)
 * Acc@1 0.237 Acc@5 0.000
Test: [0/1]	Time  0.296 ( 0.296)	Loss 5.3595e-01 (5.3595e-01)	Acc@1   0.12 (  0.12)	Acc@5   0.00 (  0.00)
 * Acc@1 0.116 Acc@5 0.000
12
TRAINING
Epoch: [12][0/1]	Time  0.993 ( 0.993)	Data  0.298 ( 0.298)	Loss 5.9368e-01 (5.9368e-01)	Acc@1   0.20 (  0.20)	Acc@5   0.00 (  0.00)
[0.20465643005172085]
Test: [0/1]	Time  0.240 ( 0.240)	Loss 1.1102e+00 (1.1102e+00)	Acc@1   0.31 (  0.31)	Acc@5   0.00 (  0.00)
 * Acc@1 0.313 Acc@5 0.000
Test: [0/1]	Time  0.290 ( 0.290)	Loss 5.2022e-01 (5.2022e-01)	Acc@1   0.14 (  0.14)	Acc@5   0.00 (  0.00)
 * Acc@1 0.136 Acc@5 0.000
13
TRAINING
Epoch: [13][0/1]	Time  1.009 ( 1.009)	Data  0.302 ( 0.302)	Loss 5.4822e-01 (5.4822e-01)	Acc@1   0.24 (  0.24)	Acc@5   0.00 (  0.00)
[0.24139365255398962]
Test: [0/1]	Time  0.239 ( 0.239)	Loss 1.1036e+00 (1.1036e+00)	Acc@1   0.35 (  0.35)	Acc@5   0.00 (  0.00)
 * Acc@1 0.350 Acc@5 0.000
Test: [0/1]	Time  0.294 ( 0.294)	Loss 5.0750e-01 (5.0750e-01)	Acc@1   0.16 (  0.16)	Acc@5   0.00 (  0.00)
 * Acc@1 0.164 Acc@5 0.000
14
TRAINING
Epoch: [14][0/1]	Time  1.010 ( 1.010)	Data  0.295 ( 0.295)	Loss 5.0858e-01 (5.0858e-01)	Acc@1   0.28 (  0.28)	Acc@5   0.00 (  0.00)
[0.2826088788221882]
Test: [0/1]	Time  0.245 ( 0.245)	Loss 1.0922e+00 (1.0922e+00)	Acc@1   0.38 (  0.38)	Acc@5   0.00 (  0.00)
 * Acc@1 0.385 Acc@5 0.000
Test: [0/1]	Time  0.297 ( 0.297)	Loss 4.8448e-01 (4.8448e-01)	Acc@1   0.19 (  0.19)	Acc@5   0.00 (  0.00)
 * Acc@1 0.188 Acc@5 0.000
15
TRAINING
Epoch: [15][0/1]	Time  0.964 ( 0.964)	Data  0.250 ( 0.250)	Loss 4.6022e-01 (4.6022e-01)	Acc@1   0.33 (  0.33)	Acc@5   0.00 (  0.00)
[0.3277370070271801]
Test: [0/1]	Time  0.242 ( 0.242)	Loss 1.0760e+00 (1.0760e+00)	Acc@1   0.42 (  0.42)	Acc@5   0.00 (  0.00)
 * Acc@1 0.419 Acc@5 0.000
Test: [0/1]	Time  0.298 ( 0.298)	Loss 4.4710e-01 (4.4710e-01)	Acc@1   0.21 (  0.21)	Acc@5   0.00 (  0.00)
 * Acc@1 0.212 Acc@5 0.000
16
TRAINING
Epoch: [16][0/1]	Time  0.954 ( 0.954)	Data  0.252 ( 0.252)	Loss 3.9956e-01 (3.9956e-01)	Acc@1   0.37 (  0.37)	Acc@5   0.00 (  0.00)
[0.3715012622863626]
Test: [0/1]	Time  0.247 ( 0.247)	Loss 1.0568e+00 (1.0568e+00)	Acc@1   0.45 (  0.45)	Acc@5   0.00 (  0.00)
 * Acc@1 0.451 Acc@5 0.000
Test: [0/1]	Time  0.294 ( 0.294)	Loss 4.0128e-01 (4.0128e-01)	Acc@1   0.23 (  0.23)	Acc@5   0.00 (  0.00)
 * Acc@1 0.234 Acc@5 0.000
17
TRAINING
Epoch: [17][0/1]	Time  0.956 ( 0.956)	Data  0.245 ( 0.245)	Loss 3.3399e-01 (3.3399e-01)	Acc@1   0.41 (  0.41)	Acc@5   0.00 (  0.00)
[0.41197362271579774]
Test: [0/1]	Time  0.240 ( 0.240)	Loss 1.0371e+00 (1.0371e+00)	Acc@1   0.48 (  0.48)	Acc@5   0.00 (  0.00)
 * Acc@1 0.483 Acc@5 0.000
Test: [0/1]	Time  0.302 ( 0.302)	Loss 3.5785e-01 (3.5785e-01)	Acc@1   0.26 (  0.26)	Acc@5   0.00 (  0.00)
 * Acc@1 0.257 Acc@5 0.000
18
TRAINING
Epoch: [18][0/1]	Time  0.951 ( 0.951)	Data  0.257 ( 0.257)	Loss 2.7537e-01 (2.7537e-01)	Acc@1   0.46 (  0.46)	Acc@5   0.00 (  0.00)
[0.45583046979609254]
Test: [0/1]	Time  0.245 ( 0.245)	Loss 1.0194e+00 (1.0194e+00)	Acc@1   0.51 (  0.51)	Acc@5   0.00 (  0.00)
 * Acc@1 0.511 Acc@5 0.000
Test: [0/1]	Time  0.304 ( 0.304)	Loss 3.2537e-01 (3.2537e-01)	Acc@1   0.28 (  0.28)	Acc@5   0.00 (  0.00)
 * Acc@1 0.279 Acc@5 0.000
19
TRAINING
Epoch: [19][0/1]	Time  0.963 ( 0.963)	Data  0.250 ( 0.250)	Loss 2.3239e-01 (2.3239e-01)	Acc@1   0.50 (  0.50)	Acc@5   0.00 (  0.00)
[0.5034584891854617]
Test: [0/1]	Time  0.266 ( 0.266)	Loss 1.0049e+00 (1.0049e+00)	Acc@1   0.53 (  0.53)	Acc@5   0.00 (  0.00)
 * Acc@1 0.534 Acc@5 0.000
Test: [0/1]	Time  0.302 ( 0.302)	Loss 3.0564e-01 (3.0564e-01)	Acc@1   0.30 (  0.30)	Acc@5   0.00 (  0.00)
 * Acc@1 0.301 Acc@5 0.000
20
TRAINING
Epoch: [20][0/1]	Time  1.003 ( 1.003)	Data  0.253 ( 0.253)	Loss 2.0602e-01 (2.0602e-01)	Acc@1   0.55 (  0.55)	Acc@5   0.00 (  0.00)
[0.5509068181952257]
Test: [0/1]	Time  0.247 ( 0.247)	Loss 9.9352e-01 (9.9352e-01)	Acc@1   0.55 (  0.55)	Acc@5   0.00 (  0.00)
 * Acc@1 0.554 Acc@5 0.000
Test: [0/1]	Time  0.298 ( 0.298)	Loss 2.9387e-01 (2.9387e-01)	Acc@1   0.32 (  0.32)	Acc@5   0.00 (  0.00)
 * Acc@1 0.323 Acc@5 0.000
21
TRAINING
Epoch: [21][0/1]	Time  0.955 ( 0.955)	Data  0.258 ( 0.258)	Loss 1.9033e-01 (1.9033e-01)	Acc@1   0.60 (  0.60)	Acc@5   0.00 (  0.00)
[0.597392337269271]
Test: [0/1]	Time  0.247 ( 0.247)	Loss 9.8442e-01 (9.8442e-01)	Acc@1   0.57 (  0.57)	Acc@5   0.00 (  0.00)
 * Acc@1 0.572 Acc@5 0.000
Test: [0/1]	Time  0.300 ( 0.300)	Loss 2.8275e-01 (2.8275e-01)	Acc@1   0.34 (  0.34)	Acc@5   0.00 (  0.00)
 * Acc@1 0.340 Acc@5 0.000
22
TRAINING
Epoch: [22][0/1]	Time  0.967 ( 0.967)	Data  0.270 ( 0.270)	Loss 1.7705e-01 (1.7705e-01)	Acc@1   0.64 (  0.64)	Acc@5   0.00 (  0.00)
[0.6367154383113642]
Test: [0/1]	Time  0.259 ( 0.259)	Loss 9.7688e-01 (9.7688e-01)	Acc@1   0.59 (  0.59)	Acc@5   0.00 (  0.00)
 * Acc@1 0.586 Acc@5 0.000
Test: [0/1]	Time  0.315 ( 0.315)	Loss 2.6719e-01 (2.6719e-01)	Acc@1   0.36 (  0.36)	Acc@5   0.00 (  0.00)
 * Acc@1 0.356 Acc@5 0.000
23
TRAINING
Epoch: [23][0/1]	Time  0.963 ( 0.963)	Data  0.251 ( 0.251)	Loss 1.6056e-01 (1.6056e-01)	Acc@1   0.68 (  0.68)	Acc@5   0.00 (  0.00)
[0.6770173844457323]
Test: [0/1]	Time  0.267 ( 0.267)	Loss 9.7057e-01 (9.7057e-01)	Acc@1   0.60 (  0.60)	Acc@5   0.00 (  0.00)
 * Acc@1 0.598 Acc@5 0.000
Test: [0/1]	Time  0.319 ( 0.319)	Loss 2.4689e-01 (2.4689e-01)	Acc@1   0.38 (  0.38)	Acc@5   0.00 (  0.00)
 * Acc@1 0.377 Acc@5 0.000
24
TRAINING
Epoch: [24][0/1]	Time  0.939 ( 0.939)	Data  0.246 ( 0.246)	Loss 1.4039e-01 (1.4039e-01)	Acc@1   0.72 (  0.72)	Acc@5   0.00 (  0.00)
[0.717027696744314]
Test: [0/1]	Time  0.243 ( 0.243)	Loss 9.6558e-01 (9.6558e-01)	Acc@1   0.61 (  0.61)	Acc@5   0.00 (  0.00)
 * Acc@1 0.608 Acc@5 0.000
Test: [0/1]	Time  0.301 ( 0.301)	Loss 2.2558e-01 (2.2558e-01)	Acc@1   0.39 (  0.39)	Acc@5   0.00 (  0.00)
 * Acc@1 0.390 Acc@5 0.000
25
TRAINING
Epoch: [25][0/1]	Time  0.943 ( 0.943)	Data  0.257 ( 0.257)	Loss 1.2023e-01 (1.2023e-01)	Acc@1   0.75 (  0.75)	Acc@5   0.00 (  0.00)
[0.7503446907062551]
Test: [0/1]	Time  0.249 ( 0.249)	Loss 9.6206e-01 (9.6206e-01)	Acc@1   0.62 (  0.62)	Acc@5   0.00 (  0.00)
 * Acc@1 0.615 Acc@5 0.000
Test: [0/1]	Time  0.298 ( 0.298)	Loss 2.0806e-01 (2.0806e-01)	Acc@1   0.40 (  0.40)	Acc@5   0.00 (  0.00)
 * Acc@1 0.403 Acc@5 0.000
26
TRAINING
Epoch: [26][0/1]	Time  0.943 ( 0.943)	Data  0.251 ( 0.251)	Loss 1.0475e-01 (1.0475e-01)	Acc@1   0.78 (  0.78)	Acc@5   0.00 (  0.00)
[0.7779095928741198]
Test: [0/1]	Time  0.242 ( 0.242)	Loss 9.5986e-01 (9.5986e-01)	Acc@1   0.62 (  0.62)	Acc@5   0.00 (  0.00)
 * Acc@1 0.621 Acc@5 0.000
Test: [0/1]	Time  0.290 ( 0.290)	Loss 1.9702e-01 (1.9702e-01)	Acc@1   0.42 (  0.42)	Acc@5   0.00 (  0.00)
 * Acc@1 0.419 Acc@5 0.000
27
TRAINING
Epoch: [27][0/1]	Time  0.947 ( 0.947)	Data  0.252 ( 0.252)	Loss 9.6439e-02 (9.6439e-02)	Acc@1   0.80 (  0.80)	Acc@5   0.00 (  0.00)
[0.8013112234724709]
Test: [0/1]	Time  0.247 ( 0.247)	Loss 9.5844e-01 (9.5844e-01)	Acc@1   0.63 (  0.63)	Acc@5   0.00 (  0.00)
 * Acc@1 0.626 Acc@5 0.000
Test: [0/1]	Time  0.298 ( 0.298)	Loss 1.9176e-01 (1.9176e-01)	Acc@1   0.44 (  0.44)	Acc@5   0.00 (  0.00)
 * Acc@1 0.436 Acc@5 0.000
28
TRAINING
Epoch: [28][0/1]	Time  0.957 ( 0.957)	Data  0.246 ( 0.246)	Loss 9.4337e-02 (9.4337e-02)	Acc@1   0.82 (  0.82)	Acc@5   0.00 (  0.00)
[0.821939391899857]
Test: [0/1]	Time  0.257 ( 0.257)	Loss 9.5700e-01 (9.5700e-01)	Acc@1   0.63 (  0.63)	Acc@5   0.00 (  0.00)
 * Acc@1 0.629 Acc@5 0.000
Test: [0/1]	Time  0.309 ( 0.309)	Loss 1.8902e-01 (1.8902e-01)	Acc@1   0.45 (  0.45)	Acc@5   0.00 (  0.00)
 * Acc@1 0.454 Acc@5 0.000
29
TRAINING
Epoch: [29][0/1]	Time  0.965 ( 0.965)	Data  0.254 ( 0.254)	Loss 9.5014e-02 (9.5014e-02)	Acc@1   0.84 (  0.84)	Acc@5   0.00 (  0.00)
[0.8389578426946303]
Test: [0/1]	Time  0.242 ( 0.242)	Loss 9.5485e-01 (9.5485e-01)	Acc@1   0.63 (  0.63)	Acc@5   0.00 (  0.00)
 * Acc@1 0.634 Acc@5 0.000
Test: [0/1]	Time  0.296 ( 0.296)	Loss 1.8526e-01 (1.8526e-01)	Acc@1   0.48 (  0.48)	Acc@5   0.00 (  0.00)
 * Acc@1 0.475 Acc@5 0.000
30
TRAINING
Epoch: [30][0/1]	Time  0.941 ( 0.941)	Data  0.251 ( 0.251)	Loss 9.4826e-02 (9.4826e-02)	Acc@1   0.85 (  0.85)	Acc@5   0.00 (  0.00)
[0.8524186679112491]
Test: [0/1]	Time  0.248 ( 0.248)	Loss 9.5171e-01 (9.5171e-01)	Acc@1   0.64 (  0.64)	Acc@5   0.00 (  0.00)
 * Acc@1 0.639 Acc@5 0.000
Test: [0/1]	Time  0.293 ( 0.293)	Loss 1.7865e-01 (1.7865e-01)	Acc@1   0.50 (  0.50)	Acc@5   0.00 (  0.00)
 * Acc@1 0.500 Acc@5 0.000
31
TRAINING
Epoch: [31][0/1]	Time  0.947 ( 0.947)	Data  0.245 ( 0.245)	Loss 9.1901e-02 (9.1901e-02)	Acc@1   0.86 (  0.86)	Acc@5   0.00 (  0.00)
[0.8639930685693953]
Test: [0/1]	Time  0.239 ( 0.239)	Loss 9.4773e-01 (9.4773e-01)	Acc@1   0.64 (  0.64)	Acc@5   0.00 (  0.00)
 * Acc@1 0.644 Acc@5 0.000
Test: [0/1]	Time  0.292 ( 0.292)	Loss 1.6975e-01 (1.6975e-01)	Acc@1   0.53 (  0.53)	Acc@5   0.00 (  0.00)
 * Acc@1 0.525 Acc@5 0.000
32
TRAINING
Epoch: [32][0/1]	Time  0.944 ( 0.944)	Data  0.249 ( 0.249)	Loss 8.6768e-02 (8.6768e-02)	Acc@1   0.87 (  0.87)	Acc@5   0.00 (  0.00)
[0.8736118132148956]
Test: [0/1]	Time  0.283 ( 0.283)	Loss 9.4342e-01 (9.4342e-01)	Acc@1   0.64 (  0.64)	Acc@5   0.00 (  0.00)
 * Acc@1 0.643 Acc@5 0.000
Test: [0/1]	Time  0.324 ( 0.324)	Loss 1.6074e-01 (1.6074e-01)	Acc@1   0.55 (  0.55)	Acc@5   0.00 (  0.00)
 * Acc@1 0.548 Acc@5 0.000
33
TRAINING
Epoch: [33][0/1]	Time  0.963 ( 0.963)	Data  0.252 ( 0.252)	Loss 8.1514e-02 (8.1514e-02)	Acc@1   0.88 (  0.88)	Acc@5   0.00 (  0.00)
[0.8809477054004354]
Test: [0/1]	Time  0.243 ( 0.243)	Loss 9.3935e-01 (9.3935e-01)	Acc@1   0.64 (  0.64)	Acc@5   0.00 (  0.00)
 * Acc@1 0.641 Acc@5 0.000
Test: [0/1]	Time  0.295 ( 0.295)	Loss 1.5381e-01 (1.5381e-01)	Acc@1   0.57 (  0.57)	Acc@5   0.00 (  0.00)
 * Acc@1 0.570 Acc@5 0.000
34
TRAINING
Epoch: [34][0/1]	Time  0.961 ( 0.961)	Data  0.269 ( 0.269)	Loss 7.8230e-02 (7.8230e-02)	Acc@1   0.89 (  0.89)	Acc@5   0.00 (  0.00)
[0.8853097661317166]
Test: [0/1]	Time  0.252 ( 0.252)	Loss 9.3593e-01 (9.3593e-01)	Acc@1   0.64 (  0.64)	Acc@5   0.00 (  0.00)
 * Acc@1 0.638 Acc@5 0.000
Test: [0/1]	Time  0.304 ( 0.304)	Loss 1.4994e-01 (1.4994e-01)	Acc@1   0.59 (  0.59)	Acc@5   0.00 (  0.00)
 * Acc@1 0.590 Acc@5 0.000
35
TRAINING
Epoch: [35][0/1]	Time  0.960 ( 0.960)	Data  0.248 ( 0.248)	Loss 7.7760e-02 (7.7760e-02)	Acc@1   0.89 (  0.89)	Acc@5   0.00 (  0.00)
[0.8878387779914279]
Test: [0/1]	Time  0.265 ( 0.265)	Loss 9.3335e-01 (9.3335e-01)	Acc@1   0.63 (  0.63)	Acc@5   0.00 (  0.00)
 * Acc@1 0.635 Acc@5 0.000
Test: [0/1]	Time  0.310 ( 0.310)	Loss 1.4855e-01 (1.4855e-01)	Acc@1   0.61 (  0.61)	Acc@5   0.00 (  0.00)
 * Acc@1 0.609 Acc@5 0.000
36
TRAINING
Epoch: [36][0/1]	Time  0.951 ( 0.951)	Data  0.246 ( 0.246)	Loss 7.9420e-02 (7.9420e-02)	Acc@1   0.89 (  0.89)	Acc@5   0.00 (  0.00)
[0.8878352287219193]
Test: [0/1]	Time  0.250 ( 0.250)	Loss 9.3163e-01 (9.3163e-01)	Acc@1   0.63 (  0.63)	Acc@5   0.00 (  0.00)
 * Acc@1 0.632 Acc@5 0.000
Test: [0/1]	Time  0.304 ( 0.304)	Loss 1.4816e-01 (1.4816e-01)	Acc@1   0.63 (  0.63)	Acc@5   0.00 (  0.00)
 * Acc@1 0.625 Acc@5 0.000
37
TRAINING
Epoch: [37][0/1]	Time  0.951 ( 0.951)	Data  0.254 ( 0.254)	Loss 8.1643e-02 (8.1643e-02)	Acc@1   0.89 (  0.89)	Acc@5   0.00 (  0.00)
[0.8863753877162717]
Test: [0/1]	Time  0.241 ( 0.241)	Loss 9.3069e-01 (9.3069e-01)	Acc@1   0.63 (  0.63)	Acc@5   0.00 (  0.00)
 * Acc@1 0.630 Acc@5 0.000
Test: [0/1]	Time  0.294 ( 0.294)	Loss 1.4739e-01 (1.4739e-01)	Acc@1   0.64 (  0.64)	Acc@5   0.00 (  0.00)
 * Acc@1 0.643 Acc@5 0.000
38
TRAINING
Epoch: [38][0/1]	Time  0.953 ( 0.953)	Data  0.264 ( 0.264)	Loss 8.3012e-02 (8.3012e-02)	Acc@1   0.88 (  0.88)	Acc@5   0.00 (  0.00)
[0.8843217763797327]
Test: [0/1]	Time  0.280 ( 0.280)	Loss 9.3047e-01 (9.3047e-01)	Acc@1   0.63 (  0.63)	Acc@5   0.00 (  0.00)
 * Acc@1 0.628 Acc@5 0.000
Test: [0/1]	Time  0.323 ( 0.323)	Loss 1.4574e-01 (1.4574e-01)	Acc@1   0.65 (  0.65)	Acc@5   0.00 (  0.00)
 * Acc@1 0.652 Acc@5 0.000
39
TRAINING
Epoch: [39][0/1]	Time  0.953 ( 0.953)	Data  0.254 ( 0.254)	Loss 8.3008e-02 (8.3008e-02)	Acc@1   0.88 (  0.88)	Acc@5   0.00 (  0.00)
[0.8824990830677588]
Test: [0/1]	Time  0.241 ( 0.241)	Loss 9.3090e-01 (9.3090e-01)	Acc@1   0.63 (  0.63)	Acc@5   0.00 (  0.00)
 * Acc@1 0.627 Acc@5 0.000
Test: [0/1]	Time  0.290 ( 0.290)	Loss 1.4364e-01 (1.4364e-01)	Acc@1   0.66 (  0.66)	Acc@5   0.00 (  0.00)
 * Acc@1 0.661 Acc@5 0.000
40
TRAINING
Epoch: [40][0/1]	Time  0.948 ( 0.948)	Data  0.251 ( 0.251)	Loss 8.2093e-02 (8.2093e-02)	Acc@1   0.88 (  0.88)	Acc@5   0.00 (  0.00)
[0.8821343419560413]
Test: [0/1]	Time  0.245 ( 0.245)	Loss 9.3190e-01 (9.3190e-01)	Acc@1   0.63 (  0.63)	Acc@5   0.00 (  0.00)
 * Acc@1 0.627 Acc@5 0.000
Test: [0/1]	Time  0.294 ( 0.294)	Loss 1.4199e-01 (1.4199e-01)	Acc@1   0.67 (  0.67)	Acc@5   0.00 (  0.00)
 * Acc@1 0.669 Acc@5 0.000
41
TRAINING
Epoch: [41][0/1]	Time  0.933 ( 0.933)	Data  0.246 ( 0.246)	Loss 8.1215e-02 (8.1215e-02)	Acc@1   0.88 (  0.88)	Acc@5   0.00 (  0.00)
[0.8815838284305179]
Test: [0/1]	Time  0.239 ( 0.239)	Loss 9.3330e-01 (9.3330e-01)	Acc@1   0.63 (  0.63)	Acc@5   0.00 (  0.00)
 * Acc@1 0.627 Acc@5 0.000
Test: [0/1]	Time  0.293 ( 0.293)	Loss 1.4144e-01 (1.4144e-01)	Acc@1   0.68 (  0.68)	Acc@5   0.00 (  0.00)
 * Acc@1 0.678 Acc@5 0.000
42
TRAINING
Epoch: [42][0/1]	Time  1.002 ( 1.002)	Data  0.293 ( 0.293)	Loss 8.1133e-02 (8.1133e-02)	Acc@1   0.88 (  0.88)	Acc@5   0.00 (  0.00)
[0.881195394180331]
Test: [0/1]	Time  0.262 ( 0.262)	Loss 9.3485e-01 (9.3485e-01)	Acc@1   0.63 (  0.63)	Acc@5   0.00 (  0.00)
 * Acc@1 0.628 Acc@5 0.000
Test: [0/1]	Time  0.312 ( 0.312)	Loss 1.4203e-01 (1.4203e-01)	Acc@1   0.68 (  0.68)	Acc@5   0.00 (  0.00)
 * Acc@1 0.684 Acc@5 0.000
43
TRAINING
Epoch: [43][0/1]	Time  0.944 ( 0.944)	Data  0.250 ( 0.250)	Loss 8.1977e-02 (8.1977e-02)	Acc@1   0.88 (  0.88)	Acc@5   0.00 (  0.00)
[0.8812740027266541]
Test: [0/1]	Time  0.240 ( 0.240)	Loss 9.3625e-01 (9.3625e-01)	Acc@1   0.63 (  0.63)	Acc@5   0.00 (  0.00)
 * Acc@1 0.628 Acc@5 0.000
Test: [0/1]	Time  0.292 ( 0.292)	Loss 1.4320e-01 (1.4320e-01)	Acc@1   0.69 (  0.69)	Acc@5   0.00 (  0.00)
 * Acc@1 0.688 Acc@5 0.000
44
TRAINING
Epoch: [44][0/1]	Time  0.946 ( 0.946)	Data  0.248 ( 0.248)	Loss 8.3273e-02 (8.3273e-02)	Acc@1   0.88 (  0.88)	Acc@5   0.00 (  0.00)
[0.8816593967551556]
Test: [0/1]	Time  0.251 ( 0.251)	Loss 9.3725e-01 (9.3725e-01)	Acc@1   0.63 (  0.63)	Acc@5   0.00 (  0.00)
 * Acc@1 0.629 Acc@5 0.000
Test: [0/1]	Time  0.296 ( 0.296)	Loss 1.4416e-01 (1.4416e-01)	Acc@1   0.69 (  0.69)	Acc@5   0.00 (  0.00)
 * Acc@1 0.692 Acc@5 0.000
45
TRAINING
Epoch: [45][0/1]	Time  1.000 ( 1.000)	Data  0.286 ( 0.286)	Loss 8.4309e-02 (8.4309e-02)	Acc@1   0.88 (  0.88)	Acc@5   0.00 (  0.00)
[0.88277698690457]
Test: [0/1]	Time  0.260 ( 0.260)	Loss 9.3771e-01 (9.3771e-01)	Acc@1   0.63 (  0.63)	Acc@5   0.00 (  0.00)
 * Acc@1 0.629 Acc@5 0.000
Test: [0/1]	Time  0.309 ( 0.309)	Loss 1.4438e-01 (1.4438e-01)	Acc@1   0.69 (  0.69)	Acc@5   0.00 (  0.00)
 * Acc@1 0.695 Acc@5 0.000
46
TRAINING
Epoch: [46][0/1]	Time  0.937 ( 0.937)	Data  0.248 ( 0.248)	Loss 8.4586e-02 (8.4586e-02)	Acc@1   0.88 (  0.88)	Acc@5   0.00 (  0.00)
[0.8846996577377538]
Test: [0/1]	Time  0.241 ( 0.241)	Loss 9.3765e-01 (9.3765e-01)	Acc@1   0.63 (  0.63)	Acc@5   0.00 (  0.00)
 * Acc@1 0.630 Acc@5 0.000
Test: [0/1]	Time  0.294 ( 0.294)	Loss 1.4383e-01 (1.4383e-01)	Acc@1   0.70 (  0.70)	Acc@5   0.00 (  0.00)
 * Acc@1 0.698 Acc@5 0.000
47
TRAINING
Epoch: [47][0/1]	Time  0.953 ( 0.953)	Data  0.249 ( 0.249)	Loss 8.4070e-02 (8.4070e-02)	Acc@1   0.89 (  0.89)	Acc@5   0.00 (  0.00)
[0.8872351493946323]
Test: [0/1]	Time  0.244 ( 0.244)	Loss 9.3724e-01 (9.3724e-01)	Acc@1   0.63 (  0.63)	Acc@5   0.00 (  0.00)
 * Acc@1 0.631 Acc@5 0.000
Test: [0/1]	Time  0.291 ( 0.291)	Loss 1.4287e-01 (1.4287e-01)	Acc@1   0.70 (  0.70)	Acc@5   0.00 (  0.00)
 * Acc@1 0.701 Acc@5 0.000
48
TRAINING
Epoch: [48][0/1]	Time  0.998 ( 0.998)	Data  0.299 ( 0.299)	Loss 8.3127e-02 (8.3127e-02)	Acc@1   0.89 (  0.89)	Acc@5   0.00 (  0.00)
[0.8903671728899099]
Test: [0/1]	Time  0.272 ( 0.272)	Loss 9.3668e-01 (9.3668e-01)	Acc@1   0.63 (  0.63)	Acc@5   0.00 (  0.00)
 * Acc@1 0.632 Acc@5 0.000
Test: [0/1]	Time  0.317 ( 0.317)	Loss 1.4202e-01 (1.4202e-01)	Acc@1   0.70 (  0.70)	Acc@5   0.00 (  0.00)
 * Acc@1 0.702 Acc@5 0.000
49
TRAINING
Epoch: [49][0/1]	Time  0.956 ( 0.956)	Data  0.247 ( 0.247)	Loss 8.2258e-02 (8.2258e-02)	Acc@1   0.89 (  0.89)	Acc@5   0.00 (  0.00)
[0.8937263408410816]
Test: [0/1]	Time  0.240 ( 0.240)	Loss 9.3616e-01 (9.3616e-01)	Acc@1   0.63 (  0.63)	Acc@5   0.00 (  0.00)
 * Acc@1 0.633 Acc@5 0.000
Test: [0/1]	Time  0.293 ( 0.293)	Loss 1.4163e-01 (1.4163e-01)	Acc@1   0.71 (  0.71)	Acc@5   0.00 (  0.00)
 * Acc@1 0.707 Acc@5 0.000
50
TRAINING
Epoch: [50][0/1]	Time  0.954 ( 0.954)	Data  0.268 ( 0.268)	Loss 8.1796e-02 (8.1796e-02)	Acc@1   0.90 (  0.90)	Acc@5   0.00 (  0.00)
[0.8977124483984715]
Test: [0/1]	Time  0.256 ( 0.256)	Loss 9.3585e-01 (9.3585e-01)	Acc@1   0.63 (  0.63)	Acc@5   0.00 (  0.00)
 * Acc@1 0.635 Acc@5 0.000
Test: [0/1]	Time  0.355 ( 0.355)	Loss 1.4173e-01 (1.4173e-01)	Acc@1   0.71 (  0.71)	Acc@5   0.00 (  0.00)
 * Acc@1 0.710 Acc@5 0.000
51
TRAINING
Epoch: [51][0/1]	Time  0.974 ( 0.974)	Data  0.277 ( 0.277)	Loss 8.1766e-02 (8.1766e-02)	Acc@1   0.90 (  0.90)	Acc@5   0.00 (  0.00)
[0.9014652407105598]
Test: [0/1]	Time  0.303 ( 0.303)	Loss 9.3585e-01 (9.3585e-01)	Acc@1   0.64 (  0.64)	Acc@5   0.00 (  0.00)
 * Acc@1 0.637 Acc@5 0.000
Test: [0/1]	Time  0.345 ( 0.345)	Loss 1.4211e-01 (1.4211e-01)	Acc@1   0.71 (  0.71)	Acc@5   0.00 (  0.00)
 * Acc@1 0.712 Acc@5 0.000
52
TRAINING
Epoch: [52][0/1]	Time  1.009 ( 1.009)	Data  0.315 ( 0.315)	Loss 8.1942e-02 (8.1942e-02)	Acc@1   0.90 (  0.90)	Acc@5   0.00 (  0.00)
[0.9049529198933306]
Test: [0/1]	Time  0.273 ( 0.273)	Loss 9.3618e-01 (9.3618e-01)	Acc@1   0.64 (  0.64)	Acc@5   0.00 (  0.00)
 * Acc@1 0.639 Acc@5 0.000
Test: [0/1]	Time  0.325 ( 0.325)	Loss 1.4248e-01 (1.4248e-01)	Acc@1   0.71 (  0.71)	Acc@5   0.00 (  0.00)
 * Acc@1 0.713 Acc@5 0.000
53
TRAINING
Epoch: [53][0/1]	Time  0.962 ( 0.962)	Data  0.248 ( 0.248)	Loss 8.2034e-02 (8.2034e-02)	Acc@1   0.91 (  0.91)	Acc@5   0.00 (  0.00)
[0.9084917777739436]
Test: [0/1]	Time  0.241 ( 0.241)	Loss 9.3682e-01 (9.3682e-01)	Acc@1   0.64 (  0.64)	Acc@5   0.00 (  0.00)
 * Acc@1 0.642 Acc@5 0.000
Test: [0/1]	Time  0.340 ( 0.340)	Loss 1.4264e-01 (1.4264e-01)	Acc@1   0.71 (  0.71)	Acc@5   0.00 (  0.00)
 * Acc@1 0.713 Acc@5 0.000
54
TRAINING
Epoch: [54][0/1]	Time  0.943 ( 0.943)	Data  0.269 ( 0.269)	Loss 8.1872e-02 (8.1872e-02)	Acc@1   0.91 (  0.91)	Acc@5   0.00 (  0.00)
[0.9116715700304356]
Test: [0/1]	Time  0.250 ( 0.250)	Loss 9.3775e-01 (9.3775e-01)	Acc@1   0.65 (  0.65)	Acc@5   0.00 (  0.00)
 * Acc@1 0.646 Acc@5 0.000
Test: [0/1]	Time  0.299 ( 0.299)	Loss 1.4261e-01 (1.4261e-01)	Acc@1   0.71 (  0.71)	Acc@5   0.00 (  0.00)
 * Acc@1 0.712 Acc@5 0.000
55
TRAINING
Epoch: [55][0/1]	Time  0.932 ( 0.932)	Data  0.259 ( 0.259)	Loss 8.1484e-02 (8.1484e-02)	Acc@1   0.91 (  0.91)	Acc@5   0.00 (  0.00)
[0.9140795080928469]
Test: [0/1]	Time  0.242 ( 0.242)	Loss 9.3890e-01 (9.3890e-01)	Acc@1   0.65 (  0.65)	Acc@5   0.00 (  0.00)
 * Acc@1 0.649 Acc@5 0.000
Test: [0/1]	Time  0.295 ( 0.295)	Loss 1.4252e-01 (1.4252e-01)	Acc@1   0.71 (  0.71)	Acc@5   0.00 (  0.00)
 * Acc@1 0.711 Acc@5 0.000
56
TRAINING
Epoch: [56][0/1]	Time  0.978 ( 0.978)	Data  0.307 ( 0.307)	Loss 8.1039e-02 (8.1039e-02)	Acc@1   0.92 (  0.92)	Acc@5   0.00 (  0.00)
[0.9166320833809045]
Test: [0/1]	Time  0.256 ( 0.256)	Loss 9.4019e-01 (9.4019e-01)	Acc@1   0.65 (  0.65)	Acc@5   0.00 (  0.00)
 * Acc@1 0.653 Acc@5 0.000
Test: [0/1]	Time  0.312 ( 0.312)	Loss 1.4253e-01 (1.4253e-01)	Acc@1   0.71 (  0.71)	Acc@5   0.00 (  0.00)
 * Acc@1 0.710 Acc@5 0.000
57
TRAINING
Epoch: [57][0/1]	Time  0.955 ( 0.955)	Data  0.282 ( 0.282)	Loss 8.0717e-02 (8.0717e-02)	Acc@1   0.92 (  0.92)	Acc@5   0.00 (  0.00)
[0.9189776571366495]
Test: [0/1]	Time  0.246 ( 0.246)	Loss 9.4150e-01 (9.4150e-01)	Acc@1   0.66 (  0.66)	Acc@5   0.00 (  0.00)
 * Acc@1 0.656 Acc@5 0.000
Test: [0/1]	Time  0.303 ( 0.303)	Loss 1.4270e-01 (1.4270e-01)	Acc@1   0.71 (  0.71)	Acc@5   0.00 (  0.00)
 * Acc@1 0.708 Acc@5 0.000
58
TRAINING
Epoch: [58][0/1]	Time  0.952 ( 0.952)	Data  0.277 ( 0.277)	Loss 8.0600e-02 (8.0600e-02)	Acc@1   0.92 (  0.92)	Acc@5   0.00 (  0.00)
[0.9209782303403751]
Test: [0/1]	Time  0.244 ( 0.244)	Loss 9.4274e-01 (9.4274e-01)	Acc@1   0.66 (  0.66)	Acc@5   0.00 (  0.00)
 * Acc@1 0.660 Acc@5 0.000
Test: [0/1]	Time  0.300 ( 0.300)	Loss 1.4297e-01 (1.4297e-01)	Acc@1   0.71 (  0.71)	Acc@5   0.00 (  0.00)
 * Acc@1 0.706 Acc@5 0.000
59
TRAINING
Epoch: [59][0/1]	Time  0.946 ( 0.946)	Data  0.271 ( 0.271)	Loss 8.0636e-02 (8.0636e-02)	Acc@1   0.92 (  0.92)	Acc@5   0.00 (  0.00)
[0.9225934336212886]
Test: [0/1]	Time  0.249 ( 0.249)	Loss 9.4378e-01 (9.4378e-01)	Acc@1   0.66 (  0.66)	Acc@5   0.00 (  0.00)
 * Acc@1 0.663 Acc@5 0.000
Test: [0/1]	Time  0.302 ( 0.302)	Loss 1.4319e-01 (1.4319e-01)	Acc@1   0.70 (  0.70)	Acc@5   0.00 (  0.00)
 * Acc@1 0.705 Acc@5 0.000
60
TRAINING
Epoch: [60][0/1]	Time  0.946 ( 0.946)	Data  0.244 ( 0.244)	Loss 8.0693e-02 (8.0693e-02)	Acc@1   0.92 (  0.92)	Acc@5   0.00 (  0.00)
[0.9240871977117299]
Test: [0/1]	Time  0.240 ( 0.240)	Loss 9.4457e-01 (9.4457e-01)	Acc@1   0.67 (  0.67)	Acc@5   0.00 (  0.00)
 * Acc@1 0.666 Acc@5 0.000
Test: [0/1]	Time  0.292 ( 0.292)	Loss 1.4324e-01 (1.4324e-01)	Acc@1   0.70 (  0.70)	Acc@5   0.00 (  0.00)
 * Acc@1 0.703 Acc@5 0.000
61
TRAINING
Epoch: [61][0/1]	Time  0.923 ( 0.923)	Data  0.249 ( 0.249)	Loss 8.0643e-02 (8.0643e-02)	Acc@1   0.93 (  0.93)	Acc@5   0.00 (  0.00)
[0.9253574445083975]
Test: [0/1]	Time  0.244 ( 0.244)	Loss 9.4511e-01 (9.4511e-01)	Acc@1   0.67 (  0.67)	Acc@5   0.00 (  0.00)
 * Acc@1 0.669 Acc@5 0.000
Test: [0/1]	Time  0.292 ( 0.292)	Loss 1.4309e-01 (1.4309e-01)	Acc@1   0.70 (  0.70)	Acc@5   0.00 (  0.00)
 * Acc@1 0.703 Acc@5 0.000
62
TRAINING
Epoch: [62][0/1]	Time  0.943 ( 0.943)	Data  0.272 ( 0.272)	Loss 8.0439e-02 (8.0439e-02)	Acc@1   0.93 (  0.93)	Acc@5   0.00 (  0.00)
[0.9262199615997693]
Test: [0/1]	Time  0.253 ( 0.253)	Loss 9.4542e-01 (9.4542e-01)	Acc@1   0.67 (  0.67)	Acc@5   0.00 (  0.00)
 * Acc@1 0.672 Acc@5 0.000
Test: [0/1]	Time  0.307 ( 0.307)	Loss 1.4277e-01 (1.4277e-01)	Acc@1   0.70 (  0.70)	Acc@5   0.00 (  0.00)
 * Acc@1 0.702 Acc@5 0.000
63
TRAINING
Epoch: [63][0/1]	Time  0.930 ( 0.930)	Data  0.258 ( 0.258)	Loss 8.0126e-02 (8.0126e-02)	Acc@1   0.93 (  0.93)	Acc@5   0.00 (  0.00)
[0.9279754130928187]
Test: [0/1]	Time  0.242 ( 0.242)	Loss 9.4556e-01 (9.4556e-01)	Acc@1   0.68 (  0.68)	Acc@5   0.00 (  0.00)
 * Acc@1 0.675 Acc@5 0.000
Test: [0/1]	Time  0.296 ( 0.296)	Loss 1.4241e-01 (1.4241e-01)	Acc@1   0.70 (  0.70)	Acc@5   0.00 (  0.00)
 * Acc@1 0.703 Acc@5 0.000
64
TRAINING
Epoch: [64][0/1]	Time  0.931 ( 0.931)	Data  0.259 ( 0.259)	Loss 7.9802e-02 (7.9802e-02)	Acc@1   0.93 (  0.93)	Acc@5   0.00 (  0.00)
[0.9295992898178562]
Test: [0/1]	Time  0.243 ( 0.243)	Loss 9.4561e-01 (9.4561e-01)	Acc@1   0.68 (  0.68)	Acc@5   0.00 (  0.00)
 * Acc@1 0.678 Acc@5 0.000
Test: [0/1]	Time  0.293 ( 0.293)	Loss 1.4209e-01 (1.4209e-01)	Acc@1   0.70 (  0.70)	Acc@5   0.00 (  0.00)
 * Acc@1 0.703 Acc@5 0.000
65
TRAINING
Epoch: [65][0/1]	Time  0.926 ( 0.926)	Data  0.251 ( 0.251)	Loss 7.9555e-02 (7.9555e-02)	Acc@1   0.93 (  0.93)	Acc@5   0.00 (  0.00)
[0.9310326746060678]
Test: [0/1]	Time  0.241 ( 0.241)	Loss 9.4563e-01 (9.4563e-01)	Acc@1   0.68 (  0.68)	Acc@5   0.00 (  0.00)
 * Acc@1 0.681 Acc@5 0.000
Test: [0/1]	Time  0.287 ( 0.287)	Loss 1.4186e-01 (1.4186e-01)	Acc@1   0.70 (  0.70)	Acc@5   0.00 (  0.00)
 * Acc@1 0.703 Acc@5 0.000
66
TRAINING
Epoch: [66][0/1]	Time  0.930 ( 0.930)	Data  0.255 ( 0.255)	Loss 7.9418e-02 (7.9418e-02)	Acc@1   0.93 (  0.93)	Acc@5   0.00 (  0.00)
[0.9317464429595247]
Test: [0/1]	Time  0.244 ( 0.244)	Loss 9.4568e-01 (9.4568e-01)	Acc@1   0.68 (  0.68)	Acc@5   0.00 (  0.00)
 * Acc@1 0.683 Acc@5 0.000
Test: [0/1]	Time  0.291 ( 0.291)	Loss 1.4171e-01 (1.4171e-01)	Acc@1   0.70 (  0.70)	Acc@5   0.00 (  0.00)
 * Acc@1 0.704 Acc@5 0.000
67
TRAINING
Epoch: [67][0/1]	Time  0.927 ( 0.927)	Data  0.254 ( 0.254)	Loss 7.9366e-02 (7.9366e-02)	Acc@1   0.93 (  0.93)	Acc@5   0.00 (  0.00)
[0.9319160321884793]
Test: [0/1]	Time  0.245 ( 0.245)	Loss 9.4579e-01 (9.4579e-01)	Acc@1   0.69 (  0.69)	Acc@5   0.00 (  0.00)
 * Acc@1 0.686 Acc@5 0.000
Test: [0/1]	Time  0.294 ( 0.294)	Loss 1.4159e-01 (1.4159e-01)	Acc@1   0.70 (  0.70)	Acc@5   0.00 (  0.00)
 * Acc@1 0.705 Acc@5 0.000
68
TRAINING
Epoch: [68][0/1]	Time  0.927 ( 0.927)	Data  0.254 ( 0.254)	Loss 7.9342e-02 (7.9342e-02)	Acc@1   0.93 (  0.93)	Acc@5   0.00 (  0.00)
[0.9320159515833745]
Test: [0/1]	Time  0.252 ( 0.252)	Loss 9.4597e-01 (9.4597e-01)	Acc@1   0.69 (  0.69)	Acc@5   0.00 (  0.00)
 * Acc@1 0.688 Acc@5 0.000
Test: [0/1]	Time  0.296 ( 0.296)	Loss 1.4144e-01 (1.4144e-01)	Acc@1   0.71 (  0.71)	Acc@5   0.00 (  0.00)
 * Acc@1 0.706 Acc@5 0.000
69
TRAINING
Epoch: [69][0/1]	Time  0.928 ( 0.928)	Data  0.256 ( 0.256)	Loss 7.9299e-02 (7.9299e-02)	Acc@1   0.93 (  0.93)	Acc@5   0.00 (  0.00)
[0.9321788011053065]
Test: [0/1]	Time  0.242 ( 0.242)	Loss 9.4623e-01 (9.4623e-01)	Acc@1   0.69 (  0.69)	Acc@5   0.00 (  0.00)
 * Acc@1 0.690 Acc@5 0.000
Test: [0/1]	Time  0.293 ( 0.293)	Loss 1.4127e-01 (1.4127e-01)	Acc@1   0.71 (  0.71)	Acc@5   0.00 (  0.00)
 * Acc@1 0.706 Acc@5 0.000
70
TRAINING
Epoch: [70][0/1]	Time  0.957 ( 0.957)	Data  0.245 ( 0.245)	Loss 7.9224e-02 (7.9224e-02)	Acc@1   0.93 (  0.93)	Acc@5   0.00 (  0.00)
[0.9324262029415246]
Test: [0/1]	Time  0.244 ( 0.244)	Loss 9.4653e-01 (9.4653e-01)	Acc@1   0.69 (  0.69)	Acc@5   0.00 (  0.00)
 * Acc@1 0.692 Acc@5 0.000
Test: [0/1]	Time  0.295 ( 0.295)	Loss 1.4108e-01 (1.4108e-01)	Acc@1   0.71 (  0.71)	Acc@5   0.00 (  0.00)
 * Acc@1 0.707 Acc@5 0.000
71
TRAINING
Epoch: [71][0/1]	Time  0.924 ( 0.924)	Data  0.250 ( 0.250)	Loss 7.9139e-02 (7.9139e-02)	Acc@1   0.93 (  0.93)	Acc@5   0.00 (  0.00)
[0.9326118213612101]
Test: [0/1]	Time  0.239 ( 0.239)	Loss 9.4684e-01 (9.4684e-01)	Acc@1   0.69 (  0.69)	Acc@5   0.00 (  0.00)
 * Acc@1 0.694 Acc@5 0.000
Test: [0/1]	Time  0.292 ( 0.292)	Loss 1.4091e-01 (1.4091e-01)	Acc@1   0.71 (  0.71)	Acc@5   0.00 (  0.00)
 * Acc@1 0.708 Acc@5 0.000
72
TRAINING
Epoch: [72][0/1]	Time  0.927 ( 0.927)	Data  0.251 ( 0.251)	Loss 7.9077e-02 (7.9077e-02)	Acc@1   0.93 (  0.93)	Acc@5   0.00 (  0.00)
[0.9328045040264674]
Test: [0/1]	Time  0.239 ( 0.239)	Loss 9.4712e-01 (9.4712e-01)	Acc@1   0.70 (  0.70)	Acc@5   0.00 (  0.00)
 * Acc@1 0.696 Acc@5 0.000
Test: [0/1]	Time  0.291 ( 0.291)	Loss 1.4079e-01 (1.4079e-01)	Acc@1   0.71 (  0.71)	Acc@5   0.00 (  0.00)
 * Acc@1 0.709 Acc@5 0.000
73
TRAINING
Epoch: [73][0/1]	Time  0.926 ( 0.926)	Data  0.255 ( 0.255)	Loss 7.9059e-02 (7.9059e-02)	Acc@1   0.93 (  0.93)	Acc@5   0.00 (  0.00)
[0.9329925709192306]
Test: [0/1]	Time  0.242 ( 0.242)	Loss 9.4733e-01 (9.4733e-01)	Acc@1   0.70 (  0.70)	Acc@5   0.00 (  0.00)
 * Acc@1 0.697 Acc@5 0.000
Test: [0/1]	Time  0.298 ( 0.298)	Loss 1.4070e-01 (1.4070e-01)	Acc@1   0.71 (  0.71)	Acc@5   0.00 (  0.00)
 * Acc@1 0.710 Acc@5 0.000
74
TRAINING
Epoch: [74][0/1]	Time  0.967 ( 0.967)	Data  0.296 ( 0.296)	Loss 7.9083e-02 (7.9083e-02)	Acc@1   0.93 (  0.93)	Acc@5   0.00 (  0.00)
[0.9331513461038408]
Test: [0/1]	Time  0.248 ( 0.248)	Loss 9.4744e-01 (9.4744e-01)	Acc@1   0.70 (  0.70)	Acc@5   0.00 (  0.00)
 * Acc@1 0.698 Acc@5 0.000
Test: [0/1]	Time  0.298 ( 0.298)	Loss 1.4062e-01 (1.4062e-01)	Acc@1   0.71 (  0.71)	Acc@5   0.00 (  0.00)
 * Acc@1 0.710 Acc@5 0.000
75
TRAINING
Epoch: [75][0/1]	Time  0.975 ( 0.975)	Data  0.283 ( 0.283)	Loss 7.9124e-02 (7.9124e-02)	Acc@1   0.93 (  0.93)	Acc@5   0.00 (  0.00)
[0.9332629827481902]
Test: [0/1]	Time  0.248 ( 0.248)	Loss 9.4742e-01 (9.4742e-01)	Acc@1   0.70 (  0.70)	Acc@5   0.00 (  0.00)
 * Acc@1 0.699 Acc@5 0.000
Test: [0/1]	Time  0.296 ( 0.296)	Loss 1.4053e-01 (1.4053e-01)	Acc@1   0.71 (  0.71)	Acc@5   0.00 (  0.00)
 * Acc@1 0.711 Acc@5 0.000
76
TRAINING
Epoch: [76][0/1]	Time  0.973 ( 0.973)	Data  0.283 ( 0.283)	Loss 7.9150e-02 (7.9150e-02)	Acc@1   0.93 (  0.93)	Acc@5   0.00 (  0.00)
[0.933318034367957]
Test: [0/1]	Time  0.246 ( 0.246)	Loss 9.4727e-01 (9.4727e-01)	Acc@1   0.70 (  0.70)	Acc@5   0.00 (  0.00)
 * Acc@1 0.700 Acc@5 0.000
Test: [0/1]	Time  0.298 ( 0.298)	Loss 1.4041e-01 (1.4041e-01)	Acc@1   0.71 (  0.71)	Acc@5   0.00 (  0.00)
 * Acc@1 0.712 Acc@5 0.000
77
TRAINING
Epoch: [77][0/1]	Time  0.941 ( 0.941)	Data  0.270 ( 0.270)	Loss 7.9145e-02 (7.9145e-02)	Acc@1   0.93 (  0.93)	Acc@5   0.00 (  0.00)
[0.9333152399175269]
Test: [0/1]	Time  0.247 ( 0.247)	Loss 9.4701e-01 (9.4701e-01)	Acc@1   0.70 (  0.70)	Acc@5   0.00 (  0.00)
 * Acc@1 0.701 Acc@5 0.000
Test: [0/1]	Time  0.300 ( 0.300)	Loss 1.4026e-01 (1.4026e-01)	Acc@1   0.71 (  0.71)	Acc@5   0.00 (  0.00)
 * Acc@1 0.712 Acc@5 0.000
78
TRAINING
Epoch: [78][0/1]	Time  0.947 ( 0.947)	Data  0.271 ( 0.271)	Loss 7.9107e-02 (7.9107e-02)	Acc@1   0.93 (  0.93)	Acc@5   0.00 (  0.00)
[0.9332607111991822]
Test: [0/1]	Time  0.246 ( 0.246)	Loss 9.4666e-01 (9.4666e-01)	Acc@1   0.70 (  0.70)	Acc@5   0.00 (  0.00)
 * Acc@1 0.702 Acc@5 0.000
Test: [0/1]	Time  0.296 ( 0.296)	Loss 1.4011e-01 (1.4011e-01)	Acc@1   0.71 (  0.71)	Acc@5   0.00 (  0.00)
 * Acc@1 0.713 Acc@5 0.000
79
TRAINING
Epoch: [79][0/1]	Time  0.942 ( 0.942)	Data  0.271 ( 0.271)	Loss 7.9055e-02 (7.9055e-02)	Acc@1   0.93 (  0.93)	Acc@5   0.00 (  0.00)
[0.9331670628023544]
Test: [0/1]	Time  0.245 ( 0.245)	Loss 9.4626e-01 (9.4626e-01)	Acc@1   0.70 (  0.70)	Acc@5   0.00 (  0.00)
 * Acc@1 0.703 Acc@5 0.000
Test: [0/1]	Time  0.295 ( 0.295)	Loss 1.3997e-01 (1.3997e-01)	Acc@1   0.71 (  0.71)	Acc@5   0.00 (  0.00)
 * Acc@1 0.713 Acc@5 0.000
80
TRAINING
Epoch: [80][0/1]	Time  0.975 ( 0.975)	Data  0.262 ( 0.262)	Loss 7.9008e-02 (7.9008e-02)	Acc@1   0.93 (  0.93)	Acc@5   0.00 (  0.00)
[0.9330522498476559]
Test: [0/1]	Time  0.248 ( 0.248)	Loss 9.4585e-01 (9.4585e-01)	Acc@1   0.70 (  0.70)	Acc@5   0.00 (  0.00)
 * Acc@1 0.703 Acc@5 0.000
Test: [0/1]	Time  0.295 ( 0.295)	Loss 1.3986e-01 (1.3986e-01)	Acc@1   0.71 (  0.71)	Acc@5   0.00 (  0.00)
 * Acc@1 0.714 Acc@5 0.000
81
TRAINING
Epoch: [81][0/1]	Time  0.991 ( 0.991)	Data  0.280 ( 0.280)	Loss 7.8979e-02 (7.8979e-02)	Acc@1   0.93 (  0.93)	Acc@5   0.00 (  0.00)
[0.9329375782846625]
Test: [0/1]	Time  0.261 ( 0.261)	Loss 9.4546e-01 (9.4546e-01)	Acc@1   0.70 (  0.70)	Acc@5   0.00 (  0.00)
 * Acc@1 0.704 Acc@5 0.000
Test: [0/1]	Time  0.312 ( 0.312)	Loss 1.3978e-01 (1.3978e-01)	Acc@1   0.71 (  0.71)	Acc@5   0.00 (  0.00)
 * Acc@1 0.714 Acc@5 0.000
82
TRAINING
Epoch: [82][0/1]	Time  0.959 ( 0.959)	Data  0.246 ( 0.246)	Loss 7.8969e-02 (7.8969e-02)	Acc@1   0.93 (  0.93)	Acc@5   0.00 (  0.00)
[0.9328446830060446]
Test: [0/1]	Time  0.240 ( 0.240)	Loss 9.4511e-01 (9.4511e-01)	Acc@1   0.70 (  0.70)	Acc@5   0.00 (  0.00)
 * Acc@1 0.704 Acc@5 0.000
Test: [0/1]	Time  0.293 ( 0.293)	Loss 1.3971e-01 (1.3971e-01)	Acc@1   0.71 (  0.71)	Acc@5   0.00 (  0.00)
 * Acc@1 0.715 Acc@5 0.000
83
TRAINING
Epoch: [83][0/1]	Time  0.992 ( 0.992)	Data  0.286 ( 0.286)	Loss 7.8969e-02 (7.8969e-02)	Acc@1   0.93 (  0.93)	Acc@5   0.00 (  0.00)
[0.9327919236943435]
Test: [0/1]	Time  0.269 ( 0.269)	Loss 9.4481e-01 (9.4481e-01)	Acc@1   0.70 (  0.70)	Acc@5   0.00 (  0.00)
 * Acc@1 0.705 Acc@5 0.000
Test: [0/1]	Time  0.320 ( 0.320)	Loss 1.3965e-01 (1.3965e-01)	Acc@1   0.72 (  0.72)	Acc@5   0.00 (  0.00)
 * Acc@1 0.715 Acc@5 0.000
84
TRAINING
Epoch: [84][0/1]	Time  0.950 ( 0.950)	Data  0.248 ( 0.248)	Loss 7.8968e-02 (7.8968e-02)	Acc@1   0.93 (  0.93)	Acc@5   0.00 (  0.00)
[0.932791147136274]
Test: [0/1]	Time  0.280 ( 0.280)	Loss 9.4457e-01 (9.4457e-01)	Acc@1   0.70 (  0.70)	Acc@5   0.00 (  0.00)
 * Acc@1 0.705 Acc@5 0.000
Test: [0/1]	Time  0.329 ( 0.329)	Loss 1.3959e-01 (1.3959e-01)	Acc@1   0.72 (  0.72)	Acc@5   0.00 (  0.00)
 * Acc@1 0.716 Acc@5 0.000
85
TRAINING
Epoch: [85][0/1]	Time  0.941 ( 0.941)	Data  0.247 ( 0.247)	Loss 7.8962e-02 (7.8962e-02)	Acc@1   0.93 (  0.93)	Acc@5   0.00 (  0.00)
[0.9328457915169258]
Test: [0/1]	Time  0.241 ( 0.241)	Loss 9.4439e-01 (9.4439e-01)	Acc@1   0.71 (  0.71)	Acc@5   0.00 (  0.00)
 * Acc@1 0.705 Acc@5 0.000
Test: [0/1]	Time  0.294 ( 0.294)	Loss 1.3953e-01 (1.3953e-01)	Acc@1   0.72 (  0.72)	Acc@5   0.00 (  0.00)
 * Acc@1 0.716 Acc@5 0.000
86
TRAINING
Epoch: [86][0/1]	Time  0.994 ( 0.994)	Data  0.307 ( 0.307)	Loss 7.8950e-02 (7.8950e-02)	Acc@1   0.93 (  0.93)	Acc@5   0.00 (  0.00)
[0.9329508672348351]
Test: [0/1]	Time  0.268 ( 0.268)	Loss 9.4425e-01 (9.4425e-01)	Acc@1   0.71 (  0.71)	Acc@5   0.00 (  0.00)
 * Acc@1 0.706 Acc@5 0.000
Test: [0/1]	Time  0.334 ( 0.334)	Loss 1.3948e-01 (1.3948e-01)	Acc@1   0.72 (  0.72)	Acc@5   0.00 (  0.00)
 * Acc@1 0.716 Acc@5 0.000
87
TRAINING
Epoch: [87][0/1]	Time  0.948 ( 0.948)	Data  0.247 ( 0.247)	Loss 7.8939e-02 (7.8939e-02)	Acc@1   0.93 (  0.93)	Acc@5   0.00 (  0.00)
[0.9330946975292933]
Test: [0/1]	Time  0.277 ( 0.277)	Loss 9.4413e-01 (9.4413e-01)	Acc@1   0.71 (  0.71)	Acc@5   0.00 (  0.00)
 * Acc@1 0.706 Acc@5 0.000
Test: [0/1]	Time  0.323 ( 0.323)	Loss 1.3943e-01 (1.3943e-01)	Acc@1   0.72 (  0.72)	Acc@5   0.00 (  0.00)
 * Acc@1 0.717 Acc@5 0.000
88
TRAINING
Epoch: [88][0/1]	Time  0.948 ( 0.948)	Data  0.242 ( 0.242)	Loss 7.8933e-02 (7.8933e-02)	Acc@1   0.93 (  0.93)	Acc@5   0.00 (  0.00)
[0.9332617642602058]
Test: [0/1]	Time  0.240 ( 0.240)	Loss 9.4402e-01 (9.4402e-01)	Acc@1   0.71 (  0.71)	Acc@5   0.00 (  0.00)
 * Acc@1 0.706 Acc@5 0.000
Test: [0/1]	Time  0.293 ( 0.293)	Loss 1.3940e-01 (1.3940e-01)	Acc@1   0.72 (  0.72)	Acc@5   0.00 (  0.00)
 * Acc@1 0.717 Acc@5 0.000
89
TRAINING
Epoch: [89][0/1]	Time  0.956 ( 0.956)	Data  0.245 ( 0.245)	Loss 7.8934e-02 (7.8934e-02)	Acc@1   0.93 (  0.93)	Acc@5   0.00 (  0.00)
[0.9334357943704445]
Test: [0/1]	Time  0.243 ( 0.243)	Loss 9.4391e-01 (9.4391e-01)	Acc@1   0.71 (  0.71)	Acc@5   0.00 (  0.00)
 * Acc@1 0.706 Acc@5 0.000
Test: [0/1]	Time  0.291 ( 0.291)	Loss 1.3937e-01 (1.3937e-01)	Acc@1   0.72 (  0.72)	Acc@5   0.00 (  0.00)
 * Acc@1 0.717 Acc@5 0.000
90
TRAINING
Epoch: [90][0/1]	Time  0.981 ( 0.981)	Data  0.279 ( 0.279)	Loss 7.8936e-02 (7.8936e-02)	Acc@1   0.93 (  0.93)	Acc@5   0.00 (  0.00)
[0.9336023637107922]
Test: [0/1]	Time  0.262 ( 0.262)	Loss 9.4377e-01 (9.4377e-01)	Acc@1   0.71 (  0.71)	Acc@5   0.00 (  0.00)
 * Acc@1 0.706 Acc@5 0.000
Test: [0/1]	Time  0.312 ( 0.312)	Loss 1.3934e-01 (1.3934e-01)	Acc@1   0.72 (  0.72)	Acc@5   0.00 (  0.00)
 * Acc@1 0.717 Acc@5 0.000
91
TRAINING
Epoch: [91][0/1]	Time  1.015 ( 1.015)	Data  0.306 ( 0.306)	Loss 7.8933e-02 (7.8933e-02)	Acc@1   0.93 (  0.93)	Acc@5   0.00 (  0.00)
[0.9337506426599098]
Test: [0/1]	Time  0.273 ( 0.273)	Loss 9.4361e-01 (9.4361e-01)	Acc@1   0.71 (  0.71)	Acc@5   0.00 (  0.00)
 * Acc@1 0.706 Acc@5 0.000
Test: [0/1]	Time  0.324 ( 0.324)	Loss 1.3931e-01 (1.3931e-01)	Acc@1   0.72 (  0.72)	Acc@5   0.00 (  0.00)
 * Acc@1 0.717 Acc@5 0.000
92
TRAINING
Epoch: [92][0/1]	Time  0.945 ( 0.945)	Data  0.272 ( 0.272)	Loss 7.8921e-02 (7.8921e-02)	Acc@1   0.93 (  0.93)	Acc@5   0.00 (  0.00)
[0.9338742540910332]
Test: [0/1]	Time  0.248 ( 0.248)	Loss 9.4341e-01 (9.4341e-01)	Acc@1   0.71 (  0.71)	Acc@5   0.00 (  0.00)
 * Acc@1 0.706 Acc@5 0.000
Test: [0/1]	Time  0.298 ( 0.298)	Loss 1.3927e-01 (1.3927e-01)	Acc@1   0.72 (  0.72)	Acc@5   0.00 (  0.00)
 * Acc@1 0.717 Acc@5 0.000
93
TRAINING
Epoch: [93][0/1]	Time  0.949 ( 0.949)	Data  0.275 ( 0.275)	Loss 7.8898e-02 (7.8898e-02)	Acc@1   0.93 (  0.93)	Acc@5   0.00 (  0.00)
[0.933971407405519]
Test: [0/1]	Time  0.249 ( 0.249)	Loss 9.4320e-01 (9.4320e-01)	Acc@1   0.71 (  0.71)	Acc@5   0.00 (  0.00)
 * Acc@1 0.707 Acc@5 0.000
Test: [0/1]	Time  0.303 ( 0.303)	Loss 1.3923e-01 (1.3923e-01)	Acc@1   0.72 (  0.72)	Acc@5   0.00 (  0.00)
 * Acc@1 0.717 Acc@5 0.000
94
TRAINING
Epoch: [94][0/1]	Time  0.945 ( 0.945)	Data  0.274 ( 0.274)	Loss 7.8868e-02 (7.8868e-02)	Acc@1   0.93 (  0.93)	Acc@5   0.00 (  0.00)
[0.9340444885667509]
Test: [0/1]	Time  0.264 ( 0.264)	Loss 9.4299e-01 (9.4299e-01)	Acc@1   0.71 (  0.71)	Acc@5   0.00 (  0.00)
 * Acc@1 0.707 Acc@5 0.000
Test: [0/1]	Time  0.317 ( 0.317)	Loss 1.3920e-01 (1.3920e-01)	Acc@1   0.72 (  0.72)	Acc@5   0.00 (  0.00)
 * Acc@1 0.717 Acc@5 0.000
95
TRAINING
Epoch: [95][0/1]	Time  0.944 ( 0.944)	Data  0.272 ( 0.272)	Loss 7.8836e-02 (7.8836e-02)	Acc@1   0.93 (  0.93)	Acc@5   0.00 (  0.00)
[0.9340992124736118]
Test: [0/1]	Time  0.247 ( 0.247)	Loss 9.4277e-01 (9.4277e-01)	Acc@1   0.71 (  0.71)	Acc@5   0.00 (  0.00)
 * Acc@1 0.707 Acc@5 0.000
Test: [0/1]	Time  0.298 ( 0.298)	Loss 1.3916e-01 (1.3916e-01)	Acc@1   0.72 (  0.72)	Acc@5   0.00 (  0.00)
 * Acc@1 0.717 Acc@5 0.000
96
TRAINING
Epoch: [96][0/1]	Time  0.942 ( 0.942)	Data  0.270 ( 0.270)	Loss 7.8805e-02 (7.8805e-02)	Acc@1   0.93 (  0.93)	Acc@5   0.00 (  0.00)
[0.9341433972795556]
Test: [0/1]	Time  0.251 ( 0.251)	Loss 9.4257e-01 (9.4257e-01)	Acc@1   0.71 (  0.71)	Acc@5   0.00 (  0.00)
 * Acc@1 0.707 Acc@5 0.000
Test: [0/1]	Time  0.301 ( 0.301)	Loss 1.3914e-01 (1.3914e-01)	Acc@1   0.72 (  0.72)	Acc@5   0.00 (  0.00)
 * Acc@1 0.717 Acc@5 0.000
97
TRAINING
Epoch: [97][0/1]	Time  0.942 ( 0.942)	Data  0.270 ( 0.270)	Loss 7.8778e-02 (7.8778e-02)	Acc@1   0.93 (  0.93)	Acc@5   0.00 (  0.00)
[0.934185461856494]
Test: [0/1]	Time  0.248 ( 0.248)	Loss 9.4240e-01 (9.4240e-01)	Acc@1   0.71 (  0.71)	Acc@5   0.00 (  0.00)
 * Acc@1 0.707 Acc@5 0.000
Test: [0/1]	Time  0.296 ( 0.296)	Loss 1.3912e-01 (1.3912e-01)	Acc@1   0.72 (  0.72)	Acc@5   0.00 (  0.00)
 * Acc@1 0.716 Acc@5 0.000
98
TRAINING
Epoch: [98][0/1]	Time  0.943 ( 0.943)	Data  0.270 ( 0.270)	Loss 7.8756e-02 (7.8756e-02)	Acc@1   0.93 (  0.93)	Acc@5   0.00 (  0.00)
[0.9342328519476562]
Test: [0/1]	Time  0.244 ( 0.244)	Loss 9.4227e-01 (9.4227e-01)	Acc@1   0.71 (  0.71)	Acc@5   0.00 (  0.00)
 * Acc@1 0.707 Acc@5 0.000
Test: [0/1]	Time  0.299 ( 0.299)	Loss 1.3910e-01 (1.3910e-01)	Acc@1   0.72 (  0.72)	Acc@5   0.00 (  0.00)
 * Acc@1 0.716 Acc@5 0.000
99
TRAINING
Epoch: [99][0/1]	Time  0.948 ( 0.948)	Data  0.274 ( 0.274)	Loss 7.8737e-02 (7.8737e-02)	Acc@1   0.93 (  0.93)	Acc@5   0.00 (  0.00)
[0.9342906871253067]
Test: [0/1]	Time  0.247 ( 0.247)	Loss 9.4217e-01 (9.4217e-01)	Acc@1   0.71 (  0.71)	Acc@5   0.00 (  0.00)
 * Acc@1 0.707 Acc@5 0.000
Test: [0/1]	Time  0.293 ( 0.293)	Loss 1.3908e-01 (1.3908e-01)	Acc@1   0.72 (  0.72)	Acc@5   0.00 (  0.00)
 * Acc@1 0.716 Acc@5 0.000
Traceback (most recent call last):
  File "/home/helenr6/Adv_mapper/train_split.py", line 636, in <module>
    main()
  File "/home/helenr6/Adv_mapper/train_split.py", line 150, in main
    main_worker(args.gpu, ngpus_per_node, args)
  File "/home/helenr6/Adv_mapper/train_split.py", line 357, in main_worker
    _array[args.index]=ood_np.cpu().data.numpy()
ValueError: could not broadcast input array from shape (95,22) into shape (22,)
=> using pre-trained model 'st_resnet'
s/ohp/session_1
torch.Size([640, 3, 224, 224])
(640, 22)
attach reg
0
TRAINING
/home/helenr6/Adv_mapper/train_split.py:125: UserWarning: You have chosen to seed training. This will turn on the CUDNN deterministic setting, which can slow down your training considerably! You may see unexpected behavior when restarting from checkpoints.
  warnings.warn('You have chosen to seed training. '
/localscratch/helenr6.6279052.0/env/lib/python3.7/site-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  cpuset_checked))
Epoch: [0][0/1]	Time  5.087 ( 5.087)	Data  1.665 ( 1.665)	Loss 1.7676e+00 (1.7676e+00)	Acc@1   0.02 (  0.02)	Acc@5   0.00 (  0.00)
[0.01729410826811887]
Test: [0/1]	Time  0.450 ( 0.450)	Loss 1.2847e+00 (1.2847e+00)	Acc@1   0.03 (  0.03)	Acc@5   0.00 (  0.00)
 * Acc@1 0.029 Acc@5 0.000
Test: [0/1]	Time  0.558 ( 0.558)	Loss 1.0209e+00 (1.0209e+00)	Acc@1  -0.01 ( -0.01)	Acc@5   0.00 (  0.00)
 * Acc@1 -0.013 Acc@5 0.000
1
TRAINING
Epoch: [1][0/1]	Time  0.966 ( 0.966)	Data  0.248 ( 0.248)	Loss 1.6660e+00 (1.6660e+00)	Acc@1   0.02 (  0.02)	Acc@5   0.00 (  0.00)
[0.0206301442662001]
Test: [0/1]	Time  0.241 ( 0.241)	Loss 1.2609e+00 (1.2609e+00)	Acc@1   0.04 (  0.04)	Acc@5   0.00 (  0.00)
 * Acc@1 0.037 Acc@5 0.000
Test: [0/1]	Time  0.285 ( 0.285)	Loss 9.4412e-01 (9.4412e-01)	Acc@1  -0.01 ( -0.01)	Acc@5   0.00 (  0.00)
 * Acc@1 -0.007 Acc@5 0.000
2
TRAINING
Epoch: [2][0/1]	Time  0.926 ( 0.926)	Data  0.251 ( 0.251)	Loss 1.5159e+00 (1.5159e+00)	Acc@1   0.03 (  0.03)	Acc@5   0.00 (  0.00)
[0.03045868622556441]
Test: [0/1]	Time  0.244 ( 0.244)	Loss 1.2340e+00 (1.2340e+00)	Acc@1   0.04 (  0.04)	Acc@5   0.00 (  0.00)
 * Acc@1 0.036 Acc@5 0.000
Test: [0/1]	Time  0.294 ( 0.294)	Loss 8.7984e-01 (8.7984e-01)	Acc@1   0.00 (  0.00)	Acc@5   0.00 (  0.00)
 * Acc@1 0.000 Acc@5 0.000
3
TRAINING
Epoch: [3][0/1]	Time  0.948 ( 0.948)	Data  0.242 ( 0.242)	Loss 1.3769e+00 (1.3769e+00)	Acc@1   0.04 (  0.04)	Acc@5   0.00 (  0.00)
[0.041900730657684085]
Test: [0/1]	Time  0.239 ( 0.239)	Loss 1.2099e+00 (1.2099e+00)	Acc@1   0.05 (  0.05)	Acc@5   0.00 (  0.00)
 * Acc@1 0.049 Acc@5 0.000
Test: [0/1]	Time  0.292 ( 0.292)	Loss 8.4837e-01 (8.4837e-01)	Acc@1   0.01 (  0.01)	Acc@5   0.00 (  0.00)
 * Acc@1 0.007 Acc@5 0.000
4
TRAINING
Epoch: [4][0/1]	Time  0.962 ( 0.962)	Data  0.253 ( 0.253)	Loss 1.2822e+00 (1.2822e+00)	Acc@1   0.05 (  0.05)	Acc@5   0.00 (  0.00)
[0.05318430990201892]
Test: [0/1]	Time  0.250 ( 0.250)	Loss 1.1907e+00 (1.1907e+00)	Acc@1   0.08 (  0.08)	Acc@5   0.00 (  0.00)
 * Acc@1 0.081 Acc@5 0.000
Test: [0/1]	Time  0.296 ( 0.296)	Loss 8.4534e-01 (8.4534e-01)	Acc@1   0.02 (  0.02)	Acc@5   0.00 (  0.00)
 * Acc@1 0.016 Acc@5 0.000
5
TRAINING
Epoch: [5][0/1]	Time  0.931 ( 0.931)	Data  0.243 ( 0.243)	Loss 1.2271e+00 (1.2271e+00)	Acc@1   0.07 (  0.07)	Acc@5   0.00 (  0.00)
[0.06580006706207814]
Test: [0/1]	Time  0.238 ( 0.238)	Loss 1.1756e+00 (1.1756e+00)	Acc@1   0.11 (  0.11)	Acc@5   0.00 (  0.00)
 * Acc@1 0.105 Acc@5 0.000
Test: [0/1]	Time  0.294 ( 0.294)	Loss 8.4830e-01 (8.4830e-01)	Acc@1   0.02 (  0.02)	Acc@5   0.00 (  0.00)
 * Acc@1 0.019 Acc@5 0.000
6
TRAINING
Epoch: [6][0/1]	Time  0.943 ( 0.943)	Data  0.253 ( 0.253)	Loss 1.1815e+00 (1.1815e+00)	Acc@1   0.09 (  0.09)	Acc@5   0.00 (  0.00)
[0.08648906638762394]
Test: [0/1]	Time  0.241 ( 0.241)	Loss 1.1626e+00 (1.1626e+00)	Acc@1   0.13 (  0.13)	Acc@5   0.00 (  0.00)
 * Acc@1 0.128 Acc@5 0.000
Test: [0/1]	Time  0.295 ( 0.295)	Loss 8.3307e-01 (8.3307e-01)	Acc@1   0.02 (  0.02)	Acc@5   0.00 (  0.00)
 * Acc@1 0.023 Acc@5 0.000
7
TRAINING
Epoch: [7][0/1]	Time  0.956 ( 0.956)	Data  0.256 ( 0.256)	Loss 1.1139e+00 (1.1139e+00)	Acc@1   0.10 (  0.10)	Acc@5   0.00 (  0.00)
[0.09945564924807695]
Test: [0/1]	Time  0.249 ( 0.249)	Loss 1.1501e+00 (1.1501e+00)	Acc@1   0.15 (  0.15)	Acc@5   0.00 (  0.00)
 * Acc@1 0.151 Acc@5 0.000
Test: [0/1]	Time  0.292 ( 0.292)	Loss 7.8869e-01 (7.8869e-01)	Acc@1   0.03 (  0.03)	Acc@5   0.00 (  0.00)
 * Acc@1 0.031 Acc@5 0.000
8
TRAINING
Epoch: [8][0/1]	Time  0.974 ( 0.974)	Data  0.262 ( 0.262)	Loss 1.0115e+00 (1.0115e+00)	Acc@1   0.11 (  0.11)	Acc@5   0.00 (  0.00)
[0.11322286629256507]
Test: [0/1]	Time  0.247 ( 0.247)	Loss 1.1386e+00 (1.1386e+00)	Acc@1   0.17 (  0.17)	Acc@5   0.00 (  0.00)
 * Acc@1 0.169 Acc@5 0.000
Test: [0/1]	Time  0.300 ( 0.300)	Loss 7.2275e-01 (7.2275e-01)	Acc@1   0.04 (  0.04)	Acc@5   0.00 (  0.00)
 * Acc@1 0.043 Acc@5 0.000
9
TRAINING
Epoch: [9][0/1]	Time  0.957 ( 0.957)	Data  0.245 ( 0.245)	Loss 8.8525e-01 (8.8525e-01)	Acc@1   0.13 (  0.13)	Acc@5   0.00 (  0.00)
[0.1279913685964889]
Test: [0/1]	Time  0.240 ( 0.240)	Loss 1.1293e+00 (1.1293e+00)	Acc@1   0.17 (  0.17)	Acc@5   0.00 (  0.00)
 * Acc@1 0.174 Acc@5 0.000
Test: [0/1]	Time  0.291 ( 0.291)	Loss 6.5454e-01 (6.5454e-01)	Acc@1   0.06 (  0.06)	Acc@5   0.00 (  0.00)
 * Acc@1 0.062 Acc@5 0.000
10
TRAINING
Epoch: [10][0/1]	Time  0.958 ( 0.958)	Data  0.247 ( 0.247)	Loss 7.5992e-01 (7.5992e-01)	Acc@1   0.15 (  0.15)	Acc@5   0.00 (  0.00)
[0.14996339671265663]
Test: [0/1]	Time  0.241 ( 0.241)	Loss 1.1230e+00 (1.1230e+00)	Acc@1   0.18 (  0.18)	Acc@5   0.00 (  0.00)
 * Acc@1 0.180 Acc@5 0.000
Test: [0/1]	Time  0.300 ( 0.300)	Loss 6.0254e-01 (6.0254e-01)	Acc@1   0.09 (  0.09)	Acc@5   0.00 (  0.00)
 * Acc@1 0.086 Acc@5 0.000
11
TRAINING
Epoch: [11][0/1]	Time  0.948 ( 0.948)	Data  0.252 ( 0.252)	Loss 6.5801e-01 (6.5801e-01)	Acc@1   0.18 (  0.18)	Acc@5   0.00 (  0.00)
[0.1776506836413507]
Test: [0/1]	Time  0.241 ( 0.241)	Loss 1.1191e+00 (1.1191e+00)	Acc@1   0.22 (  0.22)	Acc@5   0.00 (  0.00)
 * Acc@1 0.216 Acc@5 0.000
Test: [0/1]	Time  0.296 ( 0.296)	Loss 5.7381e-01 (5.7381e-01)	Acc@1   0.10 (  0.10)	Acc@5   0.00 (  0.00)
 * Acc@1 0.099 Acc@5 0.000
12
TRAINING
Epoch: [12][0/1]	Time  1.000 ( 1.000)	Data  0.290 ( 0.290)	Loss 5.8757e-01 (5.8757e-01)	Acc@1   0.21 (  0.21)	Acc@5   0.00 (  0.00)
[0.21164375126594173]
Test: [0/1]	Time  0.241 ( 0.241)	Loss 1.1153e+00 (1.1153e+00)	Acc@1   0.29 (  0.29)	Acc@5   0.00 (  0.00)
 * Acc@1 0.293 Acc@5 0.000
Test: [0/1]	Time  0.294 ( 0.294)	Loss 5.6159e-01 (5.6159e-01)	Acc@1   0.11 (  0.11)	Acc@5   0.00 (  0.00)
 * Acc@1 0.113 Acc@5 0.000
13
TRAINING
Epoch: [13][0/1]	Time  1.015 ( 1.015)	Data  0.305 ( 0.305)	Loss 5.4049e-01 (5.4049e-01)	Acc@1   0.24 (  0.24)	Acc@5   0.00 (  0.00)
[0.24393563144043895]
Test: [0/1]	Time  0.265 ( 0.265)	Loss 1.1089e+00 (1.1089e+00)	Acc@1   0.36 (  0.36)	Acc@5   0.00 (  0.00)
 * Acc@1 0.358 Acc@5 0.000
Test: [0/1]	Time  0.306 ( 0.306)	Loss 5.5109e-01 (5.5109e-01)	Acc@1   0.14 (  0.14)	Acc@5   0.00 (  0.00)
 * Acc@1 0.136 Acc@5 0.000
14
TRAINING
Epoch: [14][0/1]	Time  1.011 ( 1.011)	Data  0.297 ( 0.297)	Loss 5.0020e-01 (5.0020e-01)	Acc@1   0.28 (  0.28)	Acc@5   0.00 (  0.00)
[0.2785132788371907]
Test: [0/1]	Time  0.251 ( 0.251)	Loss 1.0978e+00 (1.0978e+00)	Acc@1   0.38 (  0.38)	Acc@5   0.00 (  0.00)
 * Acc@1 0.381 Acc@5 0.000
Test: [0/1]	Time  0.303 ( 0.303)	Loss 5.2908e-01 (5.2908e-01)	Acc@1   0.16 (  0.16)	Acc@5   0.00 (  0.00)
 * Acc@1 0.158 Acc@5 0.000
15
TRAINING
Epoch: [15][0/1]	Time  0.930 ( 0.930)	Data  0.243 ( 0.243)	Loss 4.5268e-01 (4.5268e-01)	Acc@1   0.32 (  0.32)	Acc@5   0.00 (  0.00)
[0.3220927897891929]
Test: [0/1]	Time  0.238 ( 0.238)	Loss 1.0818e+00 (1.0818e+00)	Acc@1   0.40 (  0.40)	Acc@5   0.00 (  0.00)
 * Acc@1 0.403 Acc@5 0.000
Test: [0/1]	Time  0.294 ( 0.294)	Loss 4.9127e-01 (4.9127e-01)	Acc@1   0.18 (  0.18)	Acc@5   0.00 (  0.00)
 * Acc@1 0.179 Acc@5 0.000
16
TRAINING
Epoch: [16][0/1]	Time  0.941 ( 0.941)	Data  0.248 ( 0.248)	Loss 3.9393e-01 (3.9393e-01)	Acc@1   0.37 (  0.37)	Acc@5   0.00 (  0.00)
[0.3650275659417438]
Test: [0/1]	Time  0.239 ( 0.239)	Loss 1.0624e+00 (1.0624e+00)	Acc@1   0.42 (  0.42)	Acc@5   0.00 (  0.00)
 * Acc@1 0.424 Acc@5 0.000
Test: [0/1]	Time  0.299 ( 0.299)	Loss 4.4329e-01 (4.4329e-01)	Acc@1   0.20 (  0.20)	Acc@5   0.00 (  0.00)
 * Acc@1 0.200 Acc@5 0.000
17
TRAINING
Epoch: [17][0/1]	Time  0.956 ( 0.956)	Data  0.268 ( 0.268)	Loss 3.3028e-01 (3.3028e-01)	Acc@1   0.41 (  0.41)	Acc@5   0.00 (  0.00)
[0.41428949722036834]
Test: [0/1]	Time  0.251 ( 0.251)	Loss 1.0421e+00 (1.0421e+00)	Acc@1   0.45 (  0.45)	Acc@5   0.00 (  0.00)
 * Acc@1 0.446 Acc@5 0.000
Test: [0/1]	Time  0.307 ( 0.307)	Loss 3.9597e-01 (3.9597e-01)	Acc@1   0.21 (  0.21)	Acc@5   0.00 (  0.00)
 * Acc@1 0.213 Acc@5 0.000
18
TRAINING
Epoch: [18][0/1]	Time  0.960 ( 0.960)	Data  0.248 ( 0.248)	Loss 2.7274e-01 (2.7274e-01)	Acc@1   0.46 (  0.46)	Acc@5   0.00 (  0.00)
[0.4647680543287428]
Test: [0/1]	Time  0.239 ( 0.239)	Loss 1.0235e+00 (1.0235e+00)	Acc@1   0.47 (  0.47)	Acc@5   0.00 (  0.00)
 * Acc@1 0.468 Acc@5 0.000
Test: [0/1]	Time  0.292 ( 0.292)	Loss 3.5853e-01 (3.5853e-01)	Acc@1   0.23 (  0.23)	Acc@5   0.00 (  0.00)
 * Acc@1 0.229 Acc@5 0.000
19
TRAINING
Epoch: [19][0/1]	Time  0.965 ( 0.965)	Data  0.268 ( 0.268)	Loss 2.2973e-01 (2.2973e-01)	Acc@1   0.51 (  0.51)	Acc@5   0.00 (  0.00)
[0.5093909443522449]
Test: [0/1]	Time  0.259 ( 0.259)	Loss 1.0077e+00 (1.0077e+00)	Acc@1   0.49 (  0.49)	Acc@5   0.00 (  0.00)
 * Acc@1 0.489 Acc@5 0.000
Test: [0/1]	Time  0.306 ( 0.306)	Loss 3.3390e-01 (3.3390e-01)	Acc@1   0.25 (  0.25)	Acc@5   0.00 (  0.00)
 * Acc@1 0.251 Acc@5 0.000
20
TRAINING
Epoch: [20][0/1]	Time  0.953 ( 0.953)	Data  0.264 ( 0.264)	Loss 2.0270e-01 (2.0270e-01)	Acc@1   0.55 (  0.55)	Acc@5   0.00 (  0.00)
[0.5527592667465298]
Test: [0/1]	Time  0.252 ( 0.252)	Loss 9.9505e-01 (9.9505e-01)	Acc@1   0.51 (  0.51)	Acc@5   0.00 (  0.00)
 * Acc@1 0.511 Acc@5 0.000
Test: [0/1]	Time  0.302 ( 0.302)	Loss 3.1842e-01 (3.1842e-01)	Acc@1   0.28 (  0.28)	Acc@5   0.00 (  0.00)
 * Acc@1 0.279 Acc@5 0.000
21
TRAINING
Epoch: [21][0/1]	Time  0.940 ( 0.940)	Data  0.246 ( 0.246)	Loss 1.8650e-01 (1.8650e-01)	Acc@1   0.59 (  0.59)	Acc@5   0.00 (  0.00)
[0.5907615136020563]
Test: [0/1]	Time  0.242 ( 0.242)	Loss 9.8492e-01 (9.8492e-01)	Acc@1   0.53 (  0.53)	Acc@5   0.00 (  0.00)
 * Acc@1 0.532 Acc@5 0.000
Test: [0/1]	Time  0.291 ( 0.291)	Loss 3.0543e-01 (3.0543e-01)	Acc@1   0.31 (  0.31)	Acc@5   0.00 (  0.00)
 * Acc@1 0.306 Acc@5 0.000
22
TRAINING
Epoch: [22][0/1]	Time  0.982 ( 0.982)	Data  0.285 ( 0.285)	Loss 1.7337e-01 (1.7337e-01)	Acc@1   0.63 (  0.63)	Acc@5   0.00 (  0.00)
[0.6305338803810814]
Test: [0/1]	Time  0.257 ( 0.257)	Loss 9.7666e-01 (9.7666e-01)	Acc@1   0.55 (  0.55)	Acc@5   0.00 (  0.00)
 * Acc@1 0.553 Acc@5 0.000
Test: [0/1]	Time  0.308 ( 0.308)	Loss 2.8981e-01 (2.8981e-01)	Acc@1   0.33 (  0.33)	Acc@5   0.00 (  0.00)
 * Acc@1 0.333 Acc@5 0.000
23
TRAINING
Epoch: [23][0/1]	Time  0.959 ( 0.959)	Data  0.262 ( 0.262)	Loss 1.5773e-01 (1.5773e-01)	Acc@1   0.67 (  0.67)	Acc@5   0.00 (  0.00)
[0.6718343980677822]
Test: [0/1]	Time  0.247 ( 0.247)	Loss 9.6996e-01 (9.6996e-01)	Acc@1   0.57 (  0.57)	Acc@5   0.00 (  0.00)
 * Acc@1 0.573 Acc@5 0.000
Test: [0/1]	Time  0.300 ( 0.300)	Loss 2.7066e-01 (2.7066e-01)	Acc@1   0.36 (  0.36)	Acc@5   0.00 (  0.00)
 * Acc@1 0.359 Acc@5 0.000
24
TRAINING
Epoch: [24][0/1]	Time  0.969 ( 0.969)	Data  0.258 ( 0.258)	Loss 1.3865e-01 (1.3865e-01)	Acc@1   0.71 (  0.71)	Acc@5   0.00 (  0.00)
[0.7116295558990937]
Test: [0/1]	Time  0.248 ( 0.248)	Loss 9.6481e-01 (9.6481e-01)	Acc@1   0.59 (  0.59)	Acc@5   0.00 (  0.00)
 * Acc@1 0.591 Acc@5 0.000
Test: [0/1]	Time  0.299 ( 0.299)	Loss 2.5094e-01 (2.5094e-01)	Acc@1   0.38 (  0.38)	Acc@5   0.00 (  0.00)
 * Acc@1 0.381 Acc@5 0.000
25
TRAINING
Epoch: [25][0/1]	Time  0.959 ( 0.959)	Data  0.265 ( 0.265)	Loss 1.1928e-01 (1.1928e-01)	Acc@1   0.75 (  0.75)	Acc@5   0.00 (  0.00)
[0.747556016801865]
Test: [0/1]	Time  0.247 ( 0.247)	Loss 9.6129e-01 (9.6129e-01)	Acc@1   0.61 (  0.61)	Acc@5   0.00 (  0.00)
 * Acc@1 0.606 Acc@5 0.000
Test: [0/1]	Time  0.297 ( 0.297)	Loss 2.3484e-01 (2.3484e-01)	Acc@1   0.40 (  0.40)	Acc@5   0.00 (  0.00)
 * Acc@1 0.405 Acc@5 0.000
26
TRAINING
Epoch: [26][0/1]	Time  0.968 ( 0.968)	Data  0.259 ( 0.259)	Loss 1.0399e-01 (1.0399e-01)	Acc@1   0.78 (  0.78)	Acc@5   0.00 (  0.00)
[0.7778264437170828]
Test: [0/1]	Time  0.264 ( 0.264)	Loss 9.5918e-01 (9.5918e-01)	Acc@1   0.62 (  0.62)	Acc@5   0.00 (  0.00)
 * Acc@1 0.619 Acc@5 0.000
Test: [0/1]	Time  0.306 ( 0.306)	Loss 2.2480e-01 (2.2480e-01)	Acc@1   0.43 (  0.43)	Acc@5   0.00 (  0.00)
 * Acc@1 0.431 Acc@5 0.000
27
TRAINING
Epoch: [27][0/1]	Time  0.963 ( 0.963)	Data  0.251 ( 0.251)	Loss 9.5347e-02 (9.5347e-02)	Acc@1   0.80 (  0.80)	Acc@5   0.00 (  0.00)
[0.8006172579900837]
Test: [0/1]	Time  0.242 ( 0.242)	Loss 9.5791e-01 (9.5791e-01)	Acc@1   0.63 (  0.63)	Acc@5   0.00 (  0.00)
 * Acc@1 0.629 Acc@5 0.000
Test: [0/1]	Time  0.296 ( 0.296)	Loss 2.2013e-01 (2.2013e-01)	Acc@1   0.45 (  0.45)	Acc@5   0.00 (  0.00)
 * Acc@1 0.453 Acc@5 0.000
28
TRAINING
Epoch: [28][0/1]	Time  0.965 ( 0.965)	Data  0.273 ( 0.273)	Loss 9.2789e-02 (9.2789e-02)	Acc@1   0.82 (  0.82)	Acc@5   0.00 (  0.00)
[0.823547499045926]
Test: [0/1]	Time  0.265 ( 0.265)	Loss 9.5671e-01 (9.5671e-01)	Acc@1   0.64 (  0.64)	Acc@5   0.00 (  0.00)
 * Acc@1 0.639 Acc@5 0.000
Test: [0/1]	Time  0.312 ( 0.312)	Loss 2.1767e-01 (2.1767e-01)	Acc@1   0.47 (  0.47)	Acc@5   0.00 (  0.00)
 * Acc@1 0.474 Acc@5 0.000
29
TRAINING
Epoch: [29][0/1]	Time  0.951 ( 0.951)	Data  0.247 ( 0.247)	Loss 9.3279e-02 (9.3279e-02)	Acc@1   0.84 (  0.84)	Acc@5   0.00 (  0.00)
[0.8419543049457452]
Test: [0/1]	Time  0.241 ( 0.241)	Loss 9.5487e-01 (9.5487e-01)	Acc@1   0.65 (  0.65)	Acc@5   0.00 (  0.00)
 * Acc@1 0.647 Acc@5 0.000
Test: [0/1]	Time  0.330 ( 0.330)	Loss 2.1389e-01 (2.1389e-01)	Acc@1   0.50 (  0.50)	Acc@5   0.00 (  0.00)
 * Acc@1 0.496 Acc@5 0.000
30
TRAINING
Epoch: [30][0/1]	Time  0.986 ( 0.986)	Data  0.245 ( 0.245)	Loss 9.3348e-02 (9.3348e-02)	Acc@1   0.86 (  0.86)	Acc@5   0.00 (  0.00)
[0.855885924105698]
Test: [0/1]	Time  0.244 ( 0.244)	Loss 9.5206e-01 (9.5206e-01)	Acc@1   0.65 (  0.65)	Acc@5   0.00 (  0.00)
 * Acc@1 0.655 Acc@5 0.000
Test: [0/1]	Time  0.290 ( 0.290)	Loss 2.0684e-01 (2.0684e-01)	Acc@1   0.52 (  0.52)	Acc@5   0.00 (  0.00)
 * Acc@1 0.516 Acc@5 0.000
31
TRAINING
Epoch: [31][0/1]	Time  0.967 ( 0.967)	Data  0.272 ( 0.272)	Loss 9.1000e-02 (9.1000e-02)	Acc@1   0.87 (  0.87)	Acc@5   0.00 (  0.00)
[0.8663391061057236]
Test: [0/1]	Time  0.260 ( 0.260)	Loss 9.4840e-01 (9.4840e-01)	Acc@1   0.66 (  0.66)	Acc@5   0.00 (  0.00)
 * Acc@1 0.662 Acc@5 0.000
Test: [0/1]	Time  0.308 ( 0.308)	Loss 1.9696e-01 (1.9696e-01)	Acc@1   0.54 (  0.54)	Acc@5   0.00 (  0.00)
 * Acc@1 0.536 Acc@5 0.000
32
TRAINING
Epoch: [32][0/1]	Time  0.973 ( 0.973)	Data  0.272 ( 0.272)	Loss 8.6465e-02 (8.6465e-02)	Acc@1   0.87 (  0.87)	Acc@5   0.00 (  0.00)
[0.8746412231481253]
Test: [0/1]	Time  0.255 ( 0.255)	Loss 9.4435e-01 (9.4435e-01)	Acc@1   0.67 (  0.67)	Acc@5   0.00 (  0.00)
 * Acc@1 0.669 Acc@5 0.000
Test: [0/1]	Time  0.304 ( 0.304)	Loss 1.8643e-01 (1.8643e-01)	Acc@1   0.55 (  0.55)	Acc@5   0.00 (  0.00)
 * Acc@1 0.554 Acc@5 0.000
33
TRAINING
Epoch: [33][0/1]	Time  0.942 ( 0.942)	Data  0.246 ( 0.246)	Loss 8.1560e-02 (8.1560e-02)	Acc@1   0.88 (  0.88)	Acc@5   0.00 (  0.00)
[0.8805025728714961]
Test: [0/1]	Time  0.241 ( 0.241)	Loss 9.4048e-01 (9.4048e-01)	Acc@1   0.67 (  0.67)	Acc@5   0.00 (  0.00)
 * Acc@1 0.675 Acc@5 0.000
Test: [0/1]	Time  0.295 ( 0.295)	Loss 1.7764e-01 (1.7764e-01)	Acc@1   0.57 (  0.57)	Acc@5   0.00 (  0.00)
 * Acc@1 0.574 Acc@5 0.000
34
TRAINING
Epoch: [34][0/1]	Time  0.951 ( 0.951)	Data  0.264 ( 0.264)	Loss 7.8290e-02 (7.8290e-02)	Acc@1   0.88 (  0.88)	Acc@5   0.00 (  0.00)
[0.883607310108227]
Test: [0/1]	Time  0.249 ( 0.249)	Loss 9.3723e-01 (9.3723e-01)	Acc@1   0.68 (  0.68)	Acc@5   0.00 (  0.00)
 * Acc@1 0.679 Acc@5 0.000
Test: [0/1]	Time  0.302 ( 0.302)	Loss 1.7190e-01 (1.7190e-01)	Acc@1   0.59 (  0.59)	Acc@5   0.00 (  0.00)
 * Acc@1 0.592 Acc@5 0.000
35
TRAINING
Epoch: [35][0/1]	Time  0.947 ( 0.947)	Data  0.246 ( 0.246)	Loss 7.7619e-02 (7.7619e-02)	Acc@1   0.88 (  0.88)	Acc@5   0.00 (  0.00)
[0.8840851973305948]
Test: [0/1]	Time  0.256 ( 0.256)	Loss 9.3485e-01 (9.3485e-01)	Acc@1   0.68 (  0.68)	Acc@5   0.00 (  0.00)
 * Acc@1 0.683 Acc@5 0.000
Test: [0/1]	Time  0.307 ( 0.307)	Loss 1.6895e-01 (1.6895e-01)	Acc@1   0.61 (  0.61)	Acc@5   0.00 (  0.00)
 * Acc@1 0.611 Acc@5 0.000
36
TRAINING
Epoch: [36][0/1]	Time  0.958 ( 0.958)	Data  0.247 ( 0.247)	Loss 7.9082e-02 (7.9082e-02)	Acc@1   0.88 (  0.88)	Acc@5   0.00 (  0.00)
[0.8814414341034305]
Test: [0/1]	Time  0.242 ( 0.242)	Loss 9.3337e-01 (9.3337e-01)	Acc@1   0.68 (  0.68)	Acc@5   0.00 (  0.00)
 * Acc@1 0.683 Acc@5 0.000
Test: [0/1]	Time  0.291 ( 0.291)	Loss 1.6749e-01 (1.6749e-01)	Acc@1   0.63 (  0.63)	Acc@5   0.00 (  0.00)
 * Acc@1 0.626 Acc@5 0.000
37
TRAINING
Epoch: [37][0/1]	Time  0.941 ( 0.941)	Data  0.251 ( 0.251)	Loss 8.1281e-02 (8.1281e-02)	Acc@1   0.88 (  0.88)	Acc@5   0.00 (  0.00)
[0.8798311893282751]
Test: [0/1]	Time  0.246 ( 0.246)	Loss 9.3272e-01 (9.3272e-01)	Acc@1   0.68 (  0.68)	Acc@5   0.00 (  0.00)
 * Acc@1 0.681 Acc@5 0.000
Test: [0/1]	Time  0.291 ( 0.291)	Loss 1.6613e-01 (1.6613e-01)	Acc@1   0.64 (  0.64)	Acc@5   0.00 (  0.00)
 * Acc@1 0.640 Acc@5 0.000
38
TRAINING
Epoch: [38][0/1]	Time  0.975 ( 0.975)	Data  0.284 ( 0.284)	Loss 8.2826e-02 (8.2826e-02)	Acc@1   0.88 (  0.88)	Acc@5   0.00 (  0.00)
[0.8800090481897971]
Test: [0/1]	Time  0.284 ( 0.284)	Loss 9.3281e-01 (9.3281e-01)	Acc@1   0.68 (  0.68)	Acc@5   0.00 (  0.00)
 * Acc@1 0.679 Acc@5 0.000
Test: [0/1]	Time  0.325 ( 0.325)	Loss 1.6417e-01 (1.6417e-01)	Acc@1   0.65 (  0.65)	Acc@5   0.00 (  0.00)
 * Acc@1 0.651 Acc@5 0.000
39
TRAINING
Epoch: [39][0/1]	Time  0.941 ( 0.941)	Data  0.247 ( 0.247)	Loss 8.3087e-02 (8.3087e-02)	Acc@1   0.88 (  0.88)	Acc@5   0.00 (  0.00)
[0.8789064231424178]
Test: [0/1]	Time  0.239 ( 0.239)	Loss 9.3354e-01 (9.3354e-01)	Acc@1   0.68 (  0.68)	Acc@5   0.00 (  0.00)
 * Acc@1 0.677 Acc@5 0.000
Test: [0/1]	Time  0.291 ( 0.291)	Loss 1.6186e-01 (1.6186e-01)	Acc@1   0.66 (  0.66)	Acc@5   0.00 (  0.00)
 * Acc@1 0.663 Acc@5 0.000
40
TRAINING
Epoch: [40][0/1]	Time  0.954 ( 0.954)	Data  0.245 ( 0.245)	Loss 8.2366e-02 (8.2366e-02)	Acc@1   0.88 (  0.88)	Acc@5   0.00 (  0.00)
[0.8781231437783301]
Test: [0/1]	Time  0.246 ( 0.246)	Loss 9.3481e-01 (9.3481e-01)	Acc@1   0.68 (  0.68)	Acc@5   0.00 (  0.00)
 * Acc@1 0.676 Acc@5 0.000
Test: [0/1]	Time  0.291 ( 0.291)	Loss 1.5992e-01 (1.5992e-01)	Acc@1   0.67 (  0.67)	Acc@5   0.00 (  0.00)
 * Acc@1 0.674 Acc@5 0.000
41
TRAINING
Epoch: [41][0/1]	Time  0.968 ( 0.968)	Data  0.269 ( 0.269)	Loss 8.1505e-02 (8.1505e-02)	Acc@1   0.88 (  0.88)	Acc@5   0.00 (  0.00)
[0.8770674047077525]
Test: [0/1]	Time  0.246 ( 0.246)	Loss 9.3646e-01 (9.3646e-01)	Acc@1   0.67 (  0.67)	Acc@5   0.00 (  0.00)
 * Acc@1 0.674 Acc@5 0.000
Test: [0/1]	Time  0.301 ( 0.301)	Loss 1.5901e-01 (1.5901e-01)	Acc@1   0.68 (  0.68)	Acc@5   0.00 (  0.00)
 * Acc@1 0.682 Acc@5 0.000
42
TRAINING
Epoch: [42][0/1]	Time  0.943 ( 0.943)	Data  0.250 ( 0.250)	Loss 8.1269e-02 (8.1269e-02)	Acc@1   0.88 (  0.88)	Acc@5   0.00 (  0.00)
[0.8764118368344458]
Test: [0/1]	Time  0.250 ( 0.250)	Loss 9.3821e-01 (9.3821e-01)	Acc@1   0.67 (  0.67)	Acc@5   0.00 (  0.00)
 * Acc@1 0.673 Acc@5 0.000
Test: [0/1]	Time  0.298 ( 0.298)	Loss 1.5923e-01 (1.5923e-01)	Acc@1   0.69 (  0.69)	Acc@5   0.00 (  0.00)
 * Acc@1 0.689 Acc@5 0.000
43
TRAINING
Epoch: [43][0/1]	Time  0.987 ( 0.987)	Data  0.290 ( 0.290)	Loss 8.1887e-02 (8.1887e-02)	Acc@1   0.88 (  0.88)	Acc@5   0.00 (  0.00)
[0.8769557555981684]
Test: [0/1]	Time  0.269 ( 0.269)	Loss 9.3977e-01 (9.3977e-01)	Acc@1   0.67 (  0.67)	Acc@5   0.00 (  0.00)
 * Acc@1 0.673 Acc@5 0.000
Test: [0/1]	Time  0.320 ( 0.320)	Loss 1.6008e-01 (1.6008e-01)	Acc@1   0.69 (  0.69)	Acc@5   0.00 (  0.00)
 * Acc@1 0.693 Acc@5 0.000
44
TRAINING
Epoch: [44][0/1]	Time  0.950 ( 0.950)	Data  0.246 ( 0.246)	Loss 8.3001e-02 (8.3001e-02)	Acc@1   0.88 (  0.88)	Acc@5   0.00 (  0.00)
[0.8782513622698741]
Test: [0/1]	Time  0.239 ( 0.239)	Loss 9.4090e-01 (9.4090e-01)	Acc@1   0.67 (  0.67)	Acc@5   0.00 (  0.00)
 * Acc@1 0.673 Acc@5 0.000
Test: [0/1]	Time  0.293 ( 0.293)	Loss 1.6080e-01 (1.6080e-01)	Acc@1   0.70 (  0.70)	Acc@5   0.00 (  0.00)
 * Acc@1 0.696 Acc@5 0.000
45
TRAINING
Epoch: [45][0/1]	Time  0.936 ( 0.936)	Data  0.248 ( 0.248)	Loss 8.3967e-02 (8.3967e-02)	Acc@1   0.88 (  0.88)	Acc@5   0.00 (  0.00)
[0.8804624280168671]
Test: [0/1]	Time  0.239 ( 0.239)	Loss 9.4145e-01 (9.4145e-01)	Acc@1   0.67 (  0.67)	Acc@5   0.00 (  0.00)
 * Acc@1 0.673 Acc@5 0.000
Test: [0/1]	Time  0.291 ( 0.291)	Loss 1.6080e-01 (1.6080e-01)	Acc@1   0.70 (  0.70)	Acc@5   0.00 (  0.00)
 * Acc@1 0.698 Acc@5 0.000
46
TRAINING
Epoch: [46][0/1]	Time  0.971 ( 0.971)	Data  0.248 ( 0.248)	Loss 8.4272e-02 (8.4272e-02)	Acc@1   0.88 (  0.88)	Acc@5   0.00 (  0.00)
[0.8836676850075108]
Test: [0/1]	Time  0.241 ( 0.241)	Loss 9.4142e-01 (9.4142e-01)	Acc@1   0.67 (  0.67)	Acc@5   0.00 (  0.00)
 * Acc@1 0.675 Acc@5 0.000
Test: [0/1]	Time  0.295 ( 0.295)	Loss 1.5996e-01 (1.5996e-01)	Acc@1   0.70 (  0.70)	Acc@5   0.00 (  0.00)
 * Acc@1 0.699 Acc@5 0.000
47
TRAINING
Epoch: [47][0/1]	Time  0.958 ( 0.958)	Data  0.250 ( 0.250)	Loss 8.3807e-02 (8.3807e-02)	Acc@1   0.89 (  0.89)	Acc@5   0.00 (  0.00)
[0.8870469847047779]
Test: [0/1]	Time  0.240 ( 0.240)	Loss 9.4097e-01 (9.4097e-01)	Acc@1   0.68 (  0.68)	Acc@5   0.00 (  0.00)
 * Acc@1 0.677 Acc@5 0.000
Test: [0/1]	Time  0.296 ( 0.296)	Loss 1.5861e-01 (1.5861e-01)	Acc@1   0.70 (  0.70)	Acc@5   0.00 (  0.00)
 * Acc@1 0.700 Acc@5 0.000
48
TRAINING
Epoch: [48][0/1]	Time  0.979 ( 0.979)	Data  0.282 ( 0.282)	Loss 8.2860e-02 (8.2860e-02)	Acc@1   0.89 (  0.89)	Acc@5   0.00 (  0.00)
[0.8904655866873532]
Test: [0/1]	Time  0.257 ( 0.257)	Loss 9.4028e-01 (9.4028e-01)	Acc@1   0.68 (  0.68)	Acc@5   0.00 (  0.00)
 * Acc@1 0.679 Acc@5 0.000
Test: [0/1]	Time  0.308 ( 0.308)	Loss 1.5727e-01 (1.5727e-01)	Acc@1   0.70 (  0.70)	Acc@5   0.00 (  0.00)
 * Acc@1 0.701 Acc@5 0.000
49
TRAINING
Epoch: [49][0/1]	Time  0.980 ( 0.980)	Data  0.286 ( 0.286)	Loss 8.1894e-02 (8.1894e-02)	Acc@1   0.89 (  0.89)	Acc@5   0.00 (  0.00)
[0.8938743792340447]
Test: [0/1]	Time  0.264 ( 0.264)	Loss 9.3956e-01 (9.3956e-01)	Acc@1   0.68 (  0.68)	Acc@5   0.00 (  0.00)
 * Acc@1 0.682 Acc@5 0.000
Test: [0/1]	Time  0.315 ( 0.315)	Loss 1.5633e-01 (1.5633e-01)	Acc@1   0.70 (  0.70)	Acc@5   0.00 (  0.00)
 * Acc@1 0.699 Acc@5 0.000
50
TRAINING
Epoch: [50][0/1]	Time  0.967 ( 0.967)	Data  0.282 ( 0.282)	Loss 8.1265e-02 (8.1265e-02)	Acc@1   0.90 (  0.90)	Acc@5   0.00 (  0.00)
[0.8970293482999881]
Test: [0/1]	Time  0.259 ( 0.259)	Loss 9.3900e-01 (9.3900e-01)	Acc@1   0.69 (  0.69)	Acc@5   0.00 (  0.00)
 * Acc@1 0.685 Acc@5 0.000
Test: [0/1]	Time  0.334 ( 0.334)	Loss 1.5594e-01 (1.5594e-01)	Acc@1   0.70 (  0.70)	Acc@5   0.00 (  0.00)
 * Acc@1 0.696 Acc@5 0.000
51
TRAINING
Epoch: [51][0/1]	Time  0.983 ( 0.983)	Data  0.274 ( 0.274)	Loss 8.1055e-02 (8.1055e-02)	Acc@1   0.90 (  0.90)	Acc@5   0.00 (  0.00)
[0.8997708101742147]
Test: [0/1]	Time  0.242 ( 0.242)	Loss 9.3869e-01 (9.3869e-01)	Acc@1   0.69 (  0.69)	Acc@5   0.00 (  0.00)
 * Acc@1 0.688 Acc@5 0.000
Test: [0/1]	Time  0.298 ( 0.298)	Loss 1.5594e-01 (1.5594e-01)	Acc@1   0.69 (  0.69)	Acc@5   0.00 (  0.00)
 * Acc@1 0.694 Acc@5 0.000
52
TRAINING
Epoch: [52][0/1]	Time  0.956 ( 0.956)	Data  0.283 ( 0.283)	Loss 8.1093e-02 (8.1093e-02)	Acc@1   0.90 (  0.90)	Acc@5   0.00 (  0.00)
[0.9029582221892867]
Test: [0/1]	Time  0.247 ( 0.247)	Loss 9.3870e-01 (9.3870e-01)	Acc@1   0.69 (  0.69)	Acc@5   0.00 (  0.00)
 * Acc@1 0.691 Acc@5 0.000
Test: [0/1]	Time  0.301 ( 0.301)	Loss 1.5606e-01 (1.5606e-01)	Acc@1   0.69 (  0.69)	Acc@5   0.00 (  0.00)
 * Acc@1 0.691 Acc@5 0.000
53
TRAINING
Epoch: [53][0/1]	Time  0.941 ( 0.941)	Data  0.266 ( 0.266)	Loss 8.1110e-02 (8.1110e-02)	Acc@1   0.91 (  0.91)	Acc@5   0.00 (  0.00)
[0.906519849104521]
Test: [0/1]	Time  0.246 ( 0.246)	Loss 9.3899e-01 (9.3899e-01)	Acc@1   0.69 (  0.69)	Acc@5   0.00 (  0.00)
 * Acc@1 0.694 Acc@5 0.000
slurmstepd: error: *** JOB 6279052 ON ng30602 CANCELLED AT 2022-05-27T05:59:21 DUE TO TIME LIMIT ***
